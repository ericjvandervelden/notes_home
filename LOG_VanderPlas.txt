/ See PRECIES ALS PIVOT TABLE (172) 
/ See GEVONDEN ZOALS PIVOT TABLES

/ See EINDE (178) 
/ See VERVOLG (178)
/ See READ_JSON HAS TO CREATE INDEX FOR THE DATAFRAME
/ See ZELF DICT
/ See FANCY INDEXING
/ See TIME SERIES
/ See PANDAS TIMESTAMP WITH TZ + DATETIMEINDEX MAKES UTC , RECOVER
/ See VERSCHIL DATETIMEINDEX PERIODINDEX TIMEDELTAINDEX

/ See VERVOLG (218) 
/ See INTERMEZZOS (218-260)
/ See VERVOLG (261)

/ 7	. 

/ lees	,
http://www.swig.org/tutorial.html

[eric@almond vanderplas]$ pip -V
pip 9.0.1 from /usr/lib/python2.7/site-packages (python 2.7)
[eric@almond vanderplas]$ pip3 -V
pip 9.0.1 from /usr/lib/python3.6/site-packages (python 3.6)

/ 7	. 

https://conda.io/docs/index.html
Docs
Next
Docs » User guide
* Installation
https://conda.io/docs/user-guide/install/index.html
Regular installation
Linux
https://conda.io/docs/user-guide/install/linux.html
Docs » User guide » Installation » Installing on Linux
Miniconda installer for Linux.
/ we download	,
~/Downloads/
-rw-rw-r--. 1 eric eric    58468498 Jun 28 23:20  Miniconda3-latest-Linux-x86_64.sh
/ ga terug	,
https://conda.io/docs/user-guide/install/linux.html

[eric@almond vanderplas]$ bash ~/Downloads/Miniconda3-latest-Linux-x86_64.sh 
Welcome to Miniconda3 4.5.4

In order to continue the installation process, please review the license
agreement.
Please, press ENTER to continue
>>> Enter
Please answer 'yes' or 'no':'
>>> yes

Miniconda3 will now be installed into this location:
/home/eric/miniconda3

  - Press ENTER to confirm the location
  - Press CTRL-C to abort the installation
  - Or specify a different location below

[/home/eric/miniconda3] >>> Enter    
PREFIX=/home/eric/miniconda3
installing: python-3.6.5-hc3d631a_2 ...
Python 3.6.5 :: Anaconda, Inc.
installing: ca-certificates-2018.03.07-0 ...
installing: conda-env-2.6.0-h36134e3_1 ...
installing: libgcc-ng-7.2.0-hdf63c60_3 ...
installing: libstdcxx-ng-7.2.0-hdf63c60_3 ...
installing: libffi-3.2.1-hd88cf55_4 ...
installing: ncurses-6.1-hf484d3e_0 ...
installing: openssl-1.0.2o-h20670df_0 ...
installing: tk-8.6.7-hc745277_3 ...
installing: xz-5.2.4-h14c3975_4 ...
installing: yaml-0.1.7-had09818_2 ...
installing: zlib-1.2.11-ha838bed_2 ...
installing: libedit-3.1.20170329-h6b74fdf_2 ...
installing: readline-7.0-ha6073c6_4 ...
installing: sqlite-3.23.1-he433501_0 ...
installing: asn1crypto-0.24.0-py36_0 ...
installing: certifi-2018.4.16-py36_0 ...
installing: chardet-3.0.4-py36h0f667ec_1 ...
installing: idna-2.6-py36h82fb2a8_1 ...
installing: pycosat-0.6.3-py36h0a5515d_0 ...
installing: pycparser-2.18-py36hf9f622e_1 ...
installing: pysocks-1.6.8-py36_0 ...
installing: ruamel_yaml-0.15.37-py36h14c3975_2 ...
installing: six-1.11.0-py36h372c433_1 ...
installing: cffi-1.11.5-py36h9745a5d_0 ...
installing: setuptools-39.2.0-py36_0 ...
installing: cryptography-2.2.2-py36h14c3975_0 ...
installing: wheel-0.31.1-py36_0 ...
installing: pip-10.0.1-py36_0 ...
installing: pyopenssl-18.0.0-py36_0 ...
installing: urllib3-1.22-py36hbe7ace6_0 ...
installing: requests-2.18.4-py36he2e5f8d_1 ...
installing: conda-4.5.4-py36_0 ...
installation finished.
Do you wish the installer to prepend the Miniconda3 install location
to PATH in your /home/eric/.bashrc ? [yes|no]
[no] >>> yes

Appending source /home/eric/miniconda3/bin/activate to /home/eric/.bashrc
A backup will be made to: /home/eric/.bashrc-miniconda3.bak


For this change to become active, you have to open a new terminal.

Thank you for installing Miniconda3!
[eric@almond vanderplas]$ cat ~/.bashrc
...
# added by Miniconda3 installer
export PATH="/home/eric/miniconda3/bin:$PATH"

[eric@almond vanderplas]$ ls ~/miniconda3/bin
2to3          idle3      lzma              python3            tabs      wish8.6
2to3-3.6      idle3.6    lzmadec           python3.6          tclsh     xz
activate      infocmp    lzmainfo          python3.6-config   tclsh8.6  xzcat
captoinfo     infotocap  lzmore            python3.6m         tic       xzcmp
chardetect    lzcat      ncursesw6-config  python3.6m-config  toe       xzdec
clear         lzcmp      openssl           python3-config     tput      xzdiff
conda         lzdiff     pip               pyvenv             tset      xzegrep
conda-env     lzegrep    pydoc             pyvenv-3.6         unlzma    xzfgrep
c_rehash      lzfgrep    pydoc3            reset              unxz      xzgrep
deactivate    lzgrep     pydoc3.6          sqlite3            wheel     xzless
easy_install  lzless     python            sqlite3_analyzer   wish      xzmore 

/ we doen nu even in een shell	,
[eric@almond vanderplas]$ PATH="/home/eric/miniconda3/bin:$PATH"

/ alles is nu python3.6	, 

[eric@almond vanderplas]$ python -V
Python 3.6.5 :: Anaconda, Inc.
[eric@almond vanderplas]$ pip -V
pip 10.0.1 from /home/eric/miniconda3/lib/python3.6/site-packages/pip (python 3.6)


[eric@almond vanderplas]$ ls -l ~/miniconda3/bin
total 5984
lrwxrwxrwx. 1 eric eric       8 Jun 30 14:59 2to3 -> 2to3-3.6
-rwxrwxr-x. 1 eric eric     109 Jun 30 14:59 2to3-3.6
-rw-rw-r--. 1 eric eric     121 Jun 30 14:59 activate
lrwxrwxrwx. 1 eric eric       3 Jun 30 14:59 captoinfo -> tic
-rwxrwxr-x. 1 eric eric     241 Jun 30 14:59 chardetect
-rwxrwxr-x. 2 eric eric   10056 May  9 14:10 clear
-rwxrwxr-x. 1 eric eric     228 Jun 30 14:59 conda
-rwxrwxr-x. 1 eric eric     237 Jun 30 14:59 conda-env
-rwxrwxr-x. 1 eric eric    5170 Jun 30 14:59 c_rehash
-rw-rw-r--. 1 eric eric     118 Jun 30 14:59 deactivate
-rwxrwxr-x. 1 eric eric     250 Jun 30 14:59 easy_install
lrwxrwxrwx. 1 eric eric       7 Jun 30 14:59 idle3 -> idle3.6
-rwxrwxr-x. 1 eric eric     107 Jun 30 14:59 idle3.6
-rwxrwxr-x. 2 eric eric   59280 May  9 14:10 infocmp
lrwxrwxrwx. 1 eric eric       3 Jun 30 14:59 infotocap -> tic
lrwxrwxrwx. 1 eric eric       2 Jun 30 14:59 lzcat -> xz
lrwxrwxrwx. 1 eric eric       6 Jun 30 14:59 lzcmp -> xzdiff
lrwxrwxrwx. 1 eric eric       6 Jun 30 14:59 lzdiff -> xzdiff
lrwxrwxrwx. 1 eric eric       6 Jun 30 14:59 lzegrep -> xzgrep
lrwxrwxrwx. 1 eric eric       6 Jun 30 14:59 lzfgrep -> xzgrep
lrwxrwxrwx. 1 eric eric       6 Jun 30 14:59 lzgrep -> xzgrep
lrwxrwxrwx. 1 eric eric       6 Jun 30 14:59 lzless -> xzless
lrwxrwxrwx. 1 eric eric       2 Jun 30 14:59 lzma -> xz
-rwxrwxr-x. 2 eric eric   20848 May 16 21:34 lzmadec
-rwxrwxr-x. 1 eric eric   16656 Jun 30 14:59 lzmainfo
lrwxrwxrwx. 1 eric eric       6 Jun 30 14:59 lzmore -> xzmore
-rwxrwxr-x. 1 eric eric    6219 Jun 30 14:59 ncursesw6-config
-rwxrwxr-x. 2 eric eric  667544 Mar 27 17:01 openssl
-rwxrwxr-x. 1 eric eric     232 Jun 30 14:59 pip
lrwxrwxrwx. 1 eric eric       8 Jun 30 14:59 pydoc -> pydoc3.6
lrwxrwxrwx. 1 eric eric       8 Jun 30 14:59 pydoc3 -> pydoc3.6
-rwxrwxr-x. 1 eric eric      92 Jun 30 14:59 pydoc3.6
lrwxrwxrwx. 1 eric eric       9 Jun 30 14:59 python -> python3.6
lrwxrwxrwx. 1 eric eric       9 Jun 30 14:59 python3 -> python3.6
-rwxrwxr-x. 1 eric eric 3752088 Jun 30 14:59 python3.6
lrwxrwxrwx. 1 eric eric      17 Jun 30 14:59 python3.6-config -> python3.6m-config
lrwxrwxrwx. 1 eric eric       9 Jun 30 14:59 python3.6m -> python3.6
-rwxrwxr-x. 1 eric eric    3426 Jun 30 14:59 python3.6m-config
lrwxrwxrwx. 1 eric eric      17 Jun 30 14:59 python3-config -> python3.6m-config
lrwxrwxrwx. 1 eric eric      10 Jun 30 14:59 pyvenv -> pyvenv-3.6
-rwxrwxr-x. 1 eric eric     449 Jun 30 14:59 pyvenv-3.6
lrwxrwxrwx. 1 eric eric       4 Jun 30 14:59 reset -> tset
-rwxrwxr-x. 2 eric eric 1131472 Apr 20 05:03 sqlite3
-rwxrwxr-x. 2 eric eric   29841 Nov  8  2017 sqlite3_analyzer
-rwxrwxr-x. 2 eric eric   14144 May  9 14:10 tabs
lrwxrwxrwx. 1 eric eric       8 Jun 30 14:59 tclsh -> tclsh8.6
-rwxrwxr-x. 2 eric eric   12000 Nov  8  2017 tclsh8.6
-rwxrwxr-x. 2 eric eric   83888 May  9 14:10 tic
-rwxrwxr-x. 2 eric eric   18240 May  9 14:10 toe
-rwxrwxr-x. 2 eric eric   18272 May  9 14:10 tput
-rwxrwxr-x. 2 eric eric   22344 May  9 14:10 tset
lrwxrwxrwx. 1 eric eric       2 Jun 30 14:59 unlzma -> xz
lrwxrwxrwx. 1 eric eric       2 Jun 30 14:59 unxz -> xz
-rwxrwxr-x. 1 eric eric     229 Jun 30 14:59 wheel
lrwxrwxrwx. 1 eric eric       7 Jun 30 14:59 wish -> wish8.6
-rwxrwxr-x. 2 eric eric   16248 Nov  8  2017 wish8.6
-rwxrwxr-x. 1 eric eric   99208 Jun 30 14:59 xz
lrwxrwxrwx. 1 eric eric       2 Jun 30 14:59 xzcat -> xz
lrwxrwxrwx. 1 eric eric       6 Jun 30 14:59 xzcmp -> xzdiff
-rwxrwxr-x. 2 eric eric   20848 May 16 21:34 xzdec
-rwxrwxr-x. 2 eric eric    6632 May 16 21:34 xzdiff
lrwxrwxrwx. 1 eric eric       6 Jun 30 14:59 xzegrep -> xzgrep
lrwxrwxrwx. 1 eric eric       6 Jun 30 14:59 xzfgrep -> xzgrep
-rwxrwxr-x. 2 eric eric    5628 May 16 21:34 xzgrep
-rwxrwxr-x. 2 eric eric    1802 May 16 21:34 xzless
-rwxrwxr-x. 2 eric eric    2161 May 16 21:34 xzmore

/ lees	,
/ we zien meteen alle versies	,
https://conda.io/docs/user-guide/install/test-installation.html

[eric@almond vanderplas]$ conda list .
# packages in environment at /home/eric/miniconda3:
#
# Name                    Version                   Build  Channel
asn1crypto                0.24.0                   py36_0  
ca-certificates           2018.03.07                    0  
certifi                   2018.4.16                py36_0  
cffi                      1.11.5           py36h9745a5d_0  
chardet                   3.0.4            py36h0f667ec_1  
conda                     4.5.4                    py36_0  
conda-env                 2.6.0                h36134e3_1  
cryptography              2.2.2            py36h14c3975_0  
idna                      2.6              py36h82fb2a8_1  
libedit                   3.1.20170329         h6b74fdf_2  
libffi                    3.2.1                hd88cf55_4  
libgcc-ng                 7.2.0                hdf63c60_3  
libstdcxx-ng              7.2.0                hdf63c60_3  
ncurses                   6.1                  hf484d3e_0  
openssl                   1.0.2o               h20670df_0  
pip                       10.0.1                   py36_0  
pycosat                   0.6.3            py36h0a5515d_0  
pycparser                 2.18             py36hf9f622e_1  
pyopenssl                 18.0.0                   py36_0  
pysocks                   1.6.8                    py36_0  
python                    3.6.5                hc3d631a_2  
readline                  7.0                  ha6073c6_4  
requests                  2.18.4           py36he2e5f8d_1  
ruamel_yaml               0.15.37          py36h14c3975_2  
setuptools                39.2.0                   py36_0  
six                       1.11.0           py36h372c433_1  
sqlite                    3.23.1               he433501_0  
tk                        8.6.7                hc745277_3  
urllib3                   1.22             py36hbe7ace6_0  
wheel                     0.31.1                   py36_0  
xz                        5.2.4                h14c3975_4  
yaml                      0.1.7                had09818_2  
zlib                      1.2.11               ha838bed_2  

/ 7	. 

/ terug naar PyData 2012 video van VanderPlas	,

/ we zien hieronder dat notebook ook wordt installed	, WH door jupyter	, 

[eric@almond vanderplas]$ conda install numpy scipy pandas matplotlib jupyter
Solving environment: done

## Package Plan ##

  environment location: /home/eric/miniconda3

  added / updated specs: 
    - jupyter
    - matplotlib
    - numpy
    - pandas
    - scipy


The following packages will be downloaded:

    package                    |            build
    ---------------------------|-----------------
    fontconfig-2.12.6          |       h49f89f6_0         283 KB
    backcall-0.1.0             |           py36_0          19 KB
    qt-5.9.5                   |       h7e424d6_0        84.9 MB
    prompt_toolkit-1.0.15      |   py36h17d85b1_0         339 KB
    ipython_genutils-0.2.0     |   py36hb52b0d5_0          39 KB
    mkl-2018.0.3               |                1       198.7 MB
    markupsafe-1.0             |   py36hd9260cd_1          24 KB
    bleach-2.1.3               |           py36_0          33 KB
    matplotlib-2.2.2           |   py36h0e671d2_1         6.6 MB
    cycler-0.10.0              |   py36h93f1223_0          13 KB
    ipykernel-4.8.2            |           py36_0         145 KB
    mkl_fft-1.0.1              |   py36h3010b51_0         140 KB
    wcwidth-0.1.7              |   py36hdf4376a_0          25 KB
    intel-openmp-2018.0.3      |                0         705 KB
    libxcb-1.13                |       h1bed415_1         502 KB
    pyzmq-17.0.0               |   py36h14c3975_0         454 KB
    freetype-2.8               |       hab7d2ae_1         804 KB
    tornado-5.0.2              |           py36_0         644 KB
    html5lib-1.0.1             |   py36h2f9c1c0_0         181 KB
    python-dateutil-2.7.3      |           py36_0         260 KB
    jinja2-2.10                |   py36ha16c418_0         184 KB
    libpng-1.6.34              |       hb9fc6fc_0         334 KB
    notebook-5.5.0             |           py36_0         7.0 MB
    qtconsole-4.3.1            |   py36h8f73b5b_0         150 KB
    jupyter-1.0.0              |           py36_4           5 KB
    kiwisolver-1.0.1           |   py36h764f252_0          84 KB
    nbconvert-5.3.1            |   py36hb41ffb7_0         398 KB
    ptyprocess-0.6.0           |           py36_0          23 KB
    nbformat-4.4.0             |   py36h31c9010_0         137 KB
    jsonschema-2.6.0           |   py36h006f8b5_0          62 KB
    gmp-6.1.2                  |       h6c8ec71_1         744 KB
    pickleshare-0.7.4          |   py36h63277f8_0          11 KB
    terminado-0.8.1            |           py36_1          21 KB
    icu-58.2                   |       h9c2bf20_1        22.5 MB
    jpeg-9b                    |       h024ee3a_2         248 KB
    webencodings-0.5.1         |   py36h800622e_1          19 KB
    pexpect-4.6.0              |           py36_0          77 KB
    mkl_random-1.0.1           |   py36h629b387_0         373 KB
    gst-plugins-base-1.14.0    |       hbbd80ab_1         6.3 MB
    dbus-1.13.2                |       h714fa37_1         554 KB
    pyparsing-2.2.0            |   py36hee85983_1          96 KB
    simplegeneric-0.8.1        |           py36_2           9 KB
    libxml2-2.9.8              |       h26e45fe_1         2.0 MB
    send2trash-1.5.0           |           py36_0          16 KB
    scipy-1.1.0                |   py36hfc37229_0        18.1 MB
    numpy-base-1.14.5          |   py36hdbf6ddf_1         4.1 MB
    pyqt-5.9.2                 |   py36h751905a_0         5.9 MB
    entrypoints-0.2.3          |   py36h1aec115_2           9 KB
    pcre-8.42                  |       h439df22_0         251 KB
    pandoc-2.2.1               |       h629c226_0        21.0 MB
    gstreamer-1.14.0           |       hb453b48_1         3.8 MB
    decorator-4.3.0            |           py36_0          15 KB
    libsodium-1.0.16           |       h1bed415_0         302 KB
    parso-0.2.1                |           py36_0         118 KB
    mistune-0.8.3              |   py36h14c3975_1         276 KB
    blas-1.0                   |              mkl           6 KB
    zeromq-4.2.5               |       h439df22_0         567 KB
    jupyter_console-5.2.0      |   py36he59e554_1          35 KB
    widgetsnbextension-3.2.1   |           py36_0         1.7 MB
    numpy-1.14.5               |   py36hcd700cb_1          94 KB
    testpath-0.3.1             |   py36h8cadb63_0          89 KB
    pandocfilters-1.4.2        |   py36ha6701b7_1          12 KB
    pytz-2018.4                |           py36_0         212 KB
    sip-4.19.8                 |   py36hf484d3e_0         290 KB
    ipython-6.4.0              |           py36_0         1.0 MB
    jupyter_client-5.2.3       |           py36_0         124 KB
    libgfortran-ng-7.2.0       |       hdf63c60_3         1.2 MB
    glib-2.56.1                |       h000015b_0         5.0 MB
    traitlets-4.3.2            |   py36h674d592_0         131 KB
    jupyter_core-4.4.0         |   py36h7c827e3_0          61 KB
    pandas-0.23.1              |   py36h637b7d7_0        11.9 MB
    ipywidgets-7.2.1           |           py36_0         144 KB
    jedi-0.12.0                |           py36_1         223 KB
    expat-2.2.5                |       he0dffb1_0         186 KB
    pygments-2.2.0             |   py36h0d3125c_0         1.3 MB
    ------------------------------------------------------------
                                           Total:       414.1 MB

The following NEW packages will be INSTALLED:

    backcall:           0.1.0-py36_0         
    blas:               1.0-mkl              
    bleach:             2.1.3-py36_0         
    cycler:             0.10.0-py36h93f1223_0
    dbus:               1.13.2-h714fa37_1    
    decorator:          4.3.0-py36_0         
    entrypoints:        0.2.3-py36h1aec115_2 
    expat:              2.2.5-he0dffb1_0     
    fontconfig:         2.12.6-h49f89f6_0    
    freetype:           2.8-hab7d2ae_1       
    glib:               2.56.1-h000015b_0    
    gmp:                6.1.2-h6c8ec71_1     
    gst-plugins-base:   1.14.0-hbbd80ab_1    
    gstreamer:          1.14.0-hb453b48_1    
    html5lib:           1.0.1-py36h2f9c1c0_0 
    icu:                58.2-h9c2bf20_1      
    intel-openmp:       2018.0.3-0           
    ipykernel:          4.8.2-py36_0         
    ipython:            6.4.0-py36_0         
    ipython_genutils:   0.2.0-py36hb52b0d5_0 
    ipywidgets:         7.2.1-py36_0         
    jedi:               0.12.0-py36_1        
    jinja2:             2.10-py36ha16c418_0  
    jpeg:               9b-h024ee3a_2        
    jsonschema:         2.6.0-py36h006f8b5_0 
    jupyter:            1.0.0-py36_4         
    jupyter_client:     5.2.3-py36_0         
    jupyter_console:    5.2.0-py36he59e554_1 
    jupyter_core:       4.4.0-py36h7c827e3_0 
    kiwisolver:         1.0.1-py36h764f252_0 
    libgfortran-ng:     7.2.0-hdf63c60_3     
    libpng:             1.6.34-hb9fc6fc_0    
    libsodium:          1.0.16-h1bed415_0    
    libxcb:             1.13-h1bed415_1      
    libxml2:            2.9.8-h26e45fe_1     
    markupsafe:         1.0-py36hd9260cd_1   
    matplotlib:         2.2.2-py36h0e671d2_1 
    mistune:            0.8.3-py36h14c3975_1 
    mkl:                2018.0.3-1           
    mkl_fft:            1.0.1-py36h3010b51_0 
    mkl_random:         1.0.1-py36h629b387_0 
    nbconvert:          5.3.1-py36hb41ffb7_0 
    nbformat:           4.4.0-py36h31c9010_0 
    notebook:           5.5.0-py36_0         
    numpy:              1.14.5-py36hcd700cb_1
    numpy-base:         1.14.5-py36hdbf6ddf_1
    pandas:             0.23.1-py36h637b7d7_0
    pandoc:             2.2.1-h629c226_0     
    pandocfilters:      1.4.2-py36ha6701b7_1 
    parso:              0.2.1-py36_0         
    pcre:               8.42-h439df22_0      
    pexpect:            4.6.0-py36_0         
    pickleshare:        0.7.4-py36h63277f8_0 
    prompt_toolkit:     1.0.15-py36h17d85b1_0
    ptyprocess:         0.6.0-py36_0         
    pygments:           2.2.0-py36h0d3125c_0 
    pyparsing:          2.2.0-py36hee85983_1 
    pyqt:               5.9.2-py36h751905a_0 
    python-dateutil:    2.7.3-py36_0         
    pytz:               2018.4-py36_0        
    pyzmq:              17.0.0-py36h14c3975_0
    qt:                 5.9.5-h7e424d6_0     
    qtconsole:          4.3.1-py36h8f73b5b_0 
    scipy:              1.1.0-py36hfc37229_0 
    send2trash:         1.5.0-py36_0         
    simplegeneric:      0.8.1-py36_2         
    sip:                4.19.8-py36hf484d3e_0
    terminado:          0.8.1-py36_1         
    testpath:           0.3.1-py36h8cadb63_0 
    tornado:            5.0.2-py36_0         
    traitlets:          4.3.2-py36h674d592_0 
    wcwidth:            0.1.7-py36hdf4376a_0 
    webencodings:       0.5.1-py36h800622e_1 
    widgetsnbextension: 3.2.1-py36_0         
    zeromq:             4.2.5-h439df22_0     

Proceed ([y]/n)? 

Downloading and Extracting Packages
fontconfig-2.12.6    |  283 KB | ####################################### | 100% 
backcall-0.1.0       |   19 KB | ####################################### | 100% 
qt-5.9.5             | 84.9 MB | ####################################### | 100% 
prompt_toolkit-1.0.1 |  339 KB | ####################################### | 100% 
ipython_genutils-0.2 |   39 KB | ####################################### | 100% 
mkl-2018.0.3         | 198.7 MB | ###################################### | 100% 
markupsafe-1.0       |   24 KB | ####################################### | 100% 
bleach-2.1.3         |   33 KB | ####################################### | 100% 
matplotlib-2.2.2     |  6.6 MB | ####################################### | 100% 
cycler-0.10.0        |   13 KB | ####################################### | 100% 
ipykernel-4.8.2      |  145 KB | ####################################### | 100% 
mkl_fft-1.0.1        |  140 KB | ####################################### | 100% 
wcwidth-0.1.7        |   25 KB | ####################################### | 100% 
intel-openmp-2018.0. |  705 KB | ####################################### | 100% 
libxcb-1.13          |  502 KB | ####################################### | 100% 
pyzmq-17.0.0         |  454 KB | ####################################### | 100% 
freetype-2.8         |  804 KB | ####################################### | 100% 
tornado-5.0.2        |  644 KB | ####################################### | 100% 
html5lib-1.0.1       |  181 KB | ####################################### | 100% 
python-dateutil-2.7. |  260 KB | ####################################### | 100% 
jinja2-2.10          |  184 KB | ####################################### | 100% 
libpng-1.6.34        |  334 KB | ####################################### | 100% 
notebook-5.5.0       |  7.0 MB | ####################################### | 100% 
qtconsole-4.3.1      |  150 KB | ####################################### | 100% 
jupyter-1.0.0        |    5 KB | ####################################### | 100% 
kiwisolver-1.0.1     |   84 KB | ####################################### | 100% 
nbconvert-5.3.1      |  398 KB | ####################################### | 100% 
ptyprocess-0.6.0     |   23 KB | ####################################### | 100% 
nbformat-4.4.0       |  137 KB | ####################################### | 100% 
jsonschema-2.6.0     |   62 KB | ####################################### | 100% 
gmp-6.1.2            |  744 KB | ####################################### | 100% 
pickleshare-0.7.4    |   11 KB | ####################################### | 100% 
terminado-0.8.1      |   21 KB | ####################################### | 100% 
icu-58.2             | 22.5 MB | ####################################### | 100% 
jpeg-9b              |  248 KB | ####################################### | 100% 
webencodings-0.5.1   |   19 KB | ####################################### | 100% 
pexpect-4.6.0        |   77 KB | ####################################### | 100% 
mkl_random-1.0.1     |  373 KB | ####################################### | 100% 
gst-plugins-base-1.1 |  6.3 MB | ####################################### | 100% 
dbus-1.13.2          |  554 KB | ####################################### | 100% 
pyparsing-2.2.0      |   96 KB | ####################################### | 100% 
simplegeneric-0.8.1  |    9 KB | ####################################### | 100% 
libxml2-2.9.8        |  2.0 MB | ####################################### | 100% 
send2trash-1.5.0     |   16 KB | ####################################### | 100% 
scipy-1.1.0          | 18.1 MB | ####################################### | 100% 
numpy-base-1.14.5    |  4.1 MB | ####################################### | 100% 
pyqt-5.9.2           |  5.9 MB | ####################################### | 100% 
entrypoints-0.2.3    |    9 KB | ####################################### | 100% 
pcre-8.42            |  251 KB | ####################################### | 100% 
pandoc-2.2.1         | 21.0 MB | ####################################### | 100% 
gstreamer-1.14.0     |  3.8 MB | ####################################### | 100% 
decorator-4.3.0      |   15 KB | ####################################### | 100% 
libsodium-1.0.16     |  302 KB | ####################################### | 100% 
parso-0.2.1          |  118 KB | ####################################### | 100% 
mistune-0.8.3        |  276 KB | ####################################### | 100% 
blas-1.0             |    6 KB | ####################################### | 100% 
zeromq-4.2.5         |  567 KB | ####################################### | 100% 
jupyter_console-5.2. |   35 KB | ####################################### | 100% 
widgetsnbextension-3 |  1.7 MB | ####################################### | 100% 
numpy-1.14.5         |   94 KB | ####################################### | 100% 
testpath-0.3.1       |   89 KB | ####################################### | 100% 
pandocfilters-1.4.2  |   12 KB | ####################################### | 100% 
pytz-2018.4          |  212 KB | ####################################### | 100% 
sip-4.19.8           |  290 KB | ####################################### | 100% 
ipython-6.4.0        |  1.0 MB | ####################################### | 100% 
jupyter_client-5.2.3 |  124 KB | ####################################### | 100% 
libgfortran-ng-7.2.0 |  1.2 MB | ####################################### | 100% 
glib-2.56.1          |  5.0 MB | ####################################### | 100% 
traitlets-4.3.2      |  131 KB | ####################################### | 100% 
jupyter_core-4.4.0   |   61 KB | ####################################### | 100% 
pandas-0.23.1        | 11.9 MB | ####################################### | 100% 
ipywidgets-7.2.1     |  144 KB | ####################################### | 100% 
jedi-0.12.0          |  223 KB | ####################################### | 100% 
expat-2.2.5          |  186 KB | ####################################### | 100% 
pygments-2.2.0       |  1.3 MB | ####################################### | 100% 
Preparing transaction: done
Verifying transaction: done
Executing transaction: done

[eric@almond vanderplas]$ ls ~/miniconda3/
bin/                         phrasebooks/
compiler_compat/             pkgs/
conda-meta/                  plugins/
doc/                         qml/
envs/                        resources/
etc/                         share/
include/                     ssl/
lib/                         translations/
libexec/                     var/
LICENSE.txt                  x86_64-conda_cos6-linux-gnu/
mkspecs/                     
[eric@almond vanderplas]$ ls ~/miniconda3/lib
cmake                                  libQt5InputSupport.prl
dbus-1.0                               libQt5Location.la
engines                                libQt5Location.prl
girepository-1.0                       libQt5Location.so
glib-2.0                               libQt5Location.so.5
gstreamer-1.0                          libQt5Location.so.5.9
icu                                    libQt5Location.so.5.9.5
itcl4.1.0                              libQt5Multimedia.la
libasan.so                             libQt5Multimedia.prl
libasan.so.4                           libQt5MultimediaQuick_p.la
libasan.so.4.0.0                       libQt5MultimediaQuick_p.prl
libatomic.so                           libQt5MultimediaQuick_p.so
libatomic.so.1                         libQt5MultimediaQuick_p.so.5
libatomic.so.1.2.0                     libQt5MultimediaQuick_p.so.5.9
libcrypto.a                            libQt5MultimediaQuick_p.so.5.9.5
libcrypto.so                           libQt5Multimedia.so
libcrypto.so.1.0.0                     libQt5Multimedia.so.5
libdbus-1.a                            libQt5Multimedia.so.5.9
libdbus-1.la                           libQt5Multimedia.so.5.9.5
libdbus-1.so                           libQt5MultimediaWidgets.la
libdbus-1.so.3                         libQt5MultimediaWidgets.prl
libdbus-1.so.3.22.0                    libQt5MultimediaWidgets.so
libedit.a                              libQt5MultimediaWidgets.so.5
libedit.la                             libQt5MultimediaWidgets.so.5.9
libedit.so                             libQt5MultimediaWidgets.so.5.9.5
libedit.so.0                           libQt5NetworkAuth.la
libedit.so.0.0.56                      libQt5NetworkAuth.prl
libexpat.a                             libQt5NetworkAuth.so
libexpat.la                            libQt5NetworkAuth.so.5
libexpat.so                            libQt5NetworkAuth.so.5.9
libexpat.so.1                          libQt5NetworkAuth.so.5.9.5
libexpat.so.1.6.7                      libQt5Network.la
libffi.a                               libQt5Network.prl
libffi.la                              libQt5Network.so
libffi.so                              libQt5Network.so.5
libffi.so.6                            libQt5Network.so.5.9
libffi.so.6.0.4                        libQt5Network.so.5.9.5
libfontconfig.a                        libQt5Nfc.la
libfontconfig.la                       libQt5Nfc.prl
libfontconfig.so                       libQt5Nfc.so
libfontconfig.so.1                     libQt5Nfc.so.5
libfontconfig.so.1.10.1                libQt5Nfc.so.5.9
libform.a                              libQt5Nfc.so.5.9.5
libform.so                             libQt5OpenGLExtensions.a
libformw.a                             libQt5OpenGLExtensions.la
libformw.so                            libQt5OpenGLExtensions.prl
libformw.so.6                          libQt5OpenGL.la
libformw.so.6.1                        libQt5OpenGL.prl
libfreetype.a                          libQt5OpenGL.so
libfreetype.la                         libQt5OpenGL.so.5
libfreetype.so                         libQt5OpenGL.so.5.9
libfreetype.so.6                       libQt5OpenGL.so.5.9.5
libfreetype.so.6.14.0                  libQt5PacketProtocol.a
libgcc_s.so                            libQt5PacketProtocol.la
libgcc_s.so.1                          libQt5PacketProtocol.prl
libgfortran.so                         libQt5PlatformCompositorSupport.a
libgfortran.so.4                       libQt5PlatformCompositorSupport.la
libgfortran.so.4.0.0                   libQt5PlatformCompositorSupport.prl
libgio-2.0.la                          libQt5Positioning.la
libgio-2.0.so                          libQt5Positioning.prl
libgio-2.0.so.0                        libQt5Positioning.so
libgio-2.0.so.0.5600.1                 libQt5Positioning.so.5
libglib-2.0.la                         libQt5Positioning.so.5.9
libglib-2.0.so                         libQt5Positioning.so.5.9.5
libglib-2.0.so.0                       libQt5PrintSupport.la
libglib-2.0.so.0.5600.1                libQt5PrintSupport.prl
libgmodule-2.0.la                      libQt5PrintSupport.so
libgmodule-2.0.so                      libQt5PrintSupport.so.5
libgmodule-2.0.so.0                    libQt5PrintSupport.so.5.9
libgmodule-2.0.so.0.5600.1             libQt5PrintSupport.so.5.9.5
libgmp.a                               libQt5Purchasing.la
libgmp.la                              libQt5Purchasing.prl
libgmp.so                              libQt5Purchasing.so
libgmp.so.10                           libQt5Purchasing.so.5
libgmp.so.10.3.2                       libQt5Purchasing.so.5.9
libgmpxx.a                             libQt5Purchasing.so.5.9.5
libgmpxx.la                            libQt5QmlDebug.a
libgmpxx.so                            libQt5QmlDebug.la
libgmpxx.so.4                          libQt5QmlDebug.prl
libgmpxx.so.4.5.2                      libQt5QmlDevTools.a
libgobject-2.0.la                      libQt5QmlDevTools.la
libgobject-2.0.so                      libQt5QmlDevTools.prl
libgobject-2.0.so.0                    libQt5Qml.la
libgobject-2.0.so.0.5600.1             libQt5Qml.prl
libgomp.so                             libQt5Qml.so
libgomp.so.1                           libQt5Qml.so.5
libgomp.so.1.0.0                       libQt5Qml.so.5.9
libgstallocators-1.0.la                libQt5Qml.so.5.9.5
libgstallocators-1.0.so                libQt5QuickControls2.la
libgstallocators-1.0.so.0              libQt5QuickControls2.prl
libgstallocators-1.0.so.0.1400.0       libQt5QuickControls2.so
libgstapp-1.0.la                       libQt5QuickControls2.so.5
libgstapp-1.0.so                       libQt5QuickControls2.so.5.9
libgstapp-1.0.so.0                     libQt5QuickControls2.so.5.9.5
libgstapp-1.0.so.0.1400.0              libQt5Quick.la
libgstaudio-1.0.la                     libQt5QuickParticles.la
libgstaudio-1.0.so                     libQt5QuickParticles.prl
libgstaudio-1.0.so.0                   libQt5QuickParticles.so
libgstaudio-1.0.so.0.1400.0            libQt5QuickParticles.so.5
libgstbase-1.0.la                      libQt5QuickParticles.so.5.9
libgstbase-1.0.so                      libQt5QuickParticles.so.5.9.5
libgstbase-1.0.so.0                    libQt5Quick.prl
libgstbase-1.0.so.0.1400.0             libQt5Quick.so
libgstcheck-1.0.la                     libQt5Quick.so.5
libgstcheck-1.0.so                     libQt5Quick.so.5.9
libgstcheck-1.0.so.0                   libQt5Quick.so.5.9.5
libgstcheck-1.0.so.0.1400.0            libQt5QuickTemplates2.la
libgstcontroller-1.0.la                libQt5QuickTemplates2.prl
libgstcontroller-1.0.so                libQt5QuickTemplates2.so
libgstcontroller-1.0.so.0              libQt5QuickTemplates2.so.5
libgstcontroller-1.0.so.0.1400.0       libQt5QuickTemplates2.so.5.9
libgstfft-1.0.la                       libQt5QuickTemplates2.so.5.9.5
libgstfft-1.0.so                       libQt5QuickTest.la
libgstfft-1.0.so.0                     libQt5QuickTest.prl
libgstfft-1.0.so.0.1400.0              libQt5QuickTest.so
libgstgl-1.0.la                        libQt5QuickTest.so.5
libgstgl-1.0.so                        libQt5QuickTest.so.5.9
libgstgl-1.0.so.0                      libQt5QuickTest.so.5.9.5
libgstgl-1.0.so.0.1400.0               libQt5QuickWidgets.la
libgstnet-1.0.la                       libQt5QuickWidgets.prl
libgstnet-1.0.so                       libQt5QuickWidgets.so
libgstnet-1.0.so.0                     libQt5QuickWidgets.so.5
libgstnet-1.0.so.0.1400.0              libQt5QuickWidgets.so.5.9
libgstpbutils-1.0.la                   libQt5QuickWidgets.so.5.9.5
libgstpbutils-1.0.so                   libQt5RemoteObjects.la
libgstpbutils-1.0.so.0                 libQt5RemoteObjects.prl
libgstpbutils-1.0.so.0.1400.0          libQt5RemoteObjects.so
libgstreamer-1.0.la                    libQt5RemoteObjects.so.5
libgstreamer-1.0.so                    libQt5RemoteObjects.so.5.9
libgstreamer-1.0.so.0                  libQt5RemoteObjects.so.5.9.5
libgstreamer-1.0.so.0.1400.0           libQt5Script.la
libgstriff-1.0.la                      libQt5Script.prl
libgstriff-1.0.so                      libQt5Script.so
libgstriff-1.0.so.0                    libQt5Script.so.5
libgstriff-1.0.so.0.1400.0             libQt5Script.so.5.9
libgstrtp-1.0.la                       libQt5Script.so.5.9.5
libgstrtp-1.0.so                       libQt5ScriptTools.la
libgstrtp-1.0.so.0                     libQt5ScriptTools.prl
libgstrtp-1.0.so.0.1400.0              libQt5ScriptTools.so
libgstrtsp-1.0.la                      libQt5ScriptTools.so.5
libgstrtsp-1.0.so                      libQt5ScriptTools.so.5.9
libgstrtsp-1.0.so.0                    libQt5ScriptTools.so.5.9.5
libgstrtsp-1.0.so.0.1400.0             libQt5Scxml.la
libgstsdp-1.0.la                       libQt5Scxml.prl
libgstsdp-1.0.so                       libQt5Scxml.so
libgstsdp-1.0.so.0                     libQt5Scxml.so.5
libgstsdp-1.0.so.0.1400.0              libQt5Scxml.so.5.9
libgsttag-1.0.la                       libQt5Scxml.so.5.9.5
libgsttag-1.0.so                       libQt5Sensors.la
libgsttag-1.0.so.0                     libQt5Sensors.prl
libgsttag-1.0.so.0.1400.0              libQt5Sensors.so
libgstvideo-1.0.la                     libQt5Sensors.so.5
libgstvideo-1.0.so                     libQt5Sensors.so.5.9
libgstvideo-1.0.so.0                   libQt5Sensors.so.5.9.5
libgstvideo-1.0.so.0.1400.0            libQt5SerialBus.la
libgthread-2.0.la                      libQt5SerialBus.prl
libgthread-2.0.so                      libQt5SerialBus.so
libgthread-2.0.so.0                    libQt5SerialBus.so.5
libgthread-2.0.so.0.5600.1             libQt5SerialBus.so.5.9
libhistory.a                           libQt5SerialBus.so.5.9.5
libhistory.so                          libQt5SerialPort.la
libhistory.so.7                        libQt5SerialPort.prl
libhistory.so.7.0                      libQt5SerialPort.so
libicudata.a                           libQt5SerialPort.so.5
libicudata.so                          libQt5SerialPort.so.5.9
libicudata.so.58                       libQt5SerialPort.so.5.9.5
libicudata.so.58.2                     libQt5ServiceSupport.a
libicui18n.a                           libQt5ServiceSupport.la
libicui18n.so                          libQt5ServiceSupport.prl
libicui18n.so.58                       libQt5Sql.la
libicui18n.so.58.2                     libQt5Sql.prl
libicuio.a                             libQt5Sql.so
libicuio.so                            libQt5Sql.so.5
libicuio.so.58                         libQt5Sql.so.5.9
libicuio.so.58.2                       libQt5Sql.so.5.9.5
libicutest.a                           libQt5Svg.la
libicutest.so                          libQt5Svg.prl
libicutest.so.58                       libQt5Svg.so
libicutest.so.58.2                     libQt5Svg.so.5
libicutu.a                             libQt5Svg.so.5.9
libicutu.so                            libQt5Svg.so.5.9.5
libicutu.so.58                         libQt5Test.la
libicutu.so.58.2                       libQt5Test.prl
libicuuc.a                             libQt5Test.so
libicuuc.so                            libQt5Test.so.5
libicuuc.so.58                         libQt5Test.so.5.9
libicuuc.so.58.2                       libQt5Test.so.5.9.5
libiomp5.so                            libQt5TextToSpeech.la
libiompstubs5.so                       libQt5TextToSpeech.prl
libitm.so                              libQt5TextToSpeech.so
libitm.so.1                            libQt5TextToSpeech.so.5
libitm.so.1.0.0                        libQt5TextToSpeech.so.5.9
libjpeg.a                              libQt5TextToSpeech.so.5.9.5
libjpeg.la                             libQt5ThemeSupport.a
libjpeg.so                             libQt5ThemeSupport.la
libjpeg.so.9                           libQt5ThemeSupport.prl
libjpeg.so.9.2.0                       libQt5UiTools.a
liblsan.so                             libQt5UiTools.la
liblsan.so.0                           libQt5UiTools.prl
liblsan.so.0.0.0                       libQt5WebChannel.la
liblzma.a                              libQt5WebChannel.prl
liblzma.la                             libQt5WebChannel.so
liblzma.so                             libQt5WebChannel.so.5
liblzma.so.5                           libQt5WebChannel.so.5.9
liblzma.so.5.2.4                       libQt5WebChannel.so.5.9.5
libmenu.a                              libQt5WebEngineCore.la
libmenu.so                             libQt5WebEngineCore.prl
libmenuw.a                             libQt5WebEngineCore.so
libmenuw.so                            libQt5WebEngineCore.so.5
libmenuw.so.6                          libQt5WebEngineCore.so.5.9
libmenuw.so.6.1                        libQt5WebEngineCore.so.5.9.5
libmkl_avx2.so                         libQt5WebEngine.la
libmkl_avx512_mic.so                   libQt5WebEngine.prl
libmkl_avx512.so                       libQt5WebEngine.so
libmkl_avx.so                          libQt5WebEngine.so.5
libmkl_blacs_intelmpi_ilp64.so         libQt5WebEngine.so.5.9
libmkl_blacs_intelmpi_lp64.so          libQt5WebEngine.so.5.9.5
libmkl_blacs_openmpi_ilp64.so          libQt5WebEngineWidgets.la
libmkl_blacs_openmpi_lp64.so           libQt5WebEngineWidgets.prl
libmkl_blacs_sgimpt_ilp64.so           libQt5WebEngineWidgets.so
libmkl_blacs_sgimpt_lp64.so            libQt5WebEngineWidgets.so.5
libmkl_cdft_core.so                    libQt5WebEngineWidgets.so.5.9
libmkl_core.so                         libQt5WebEngineWidgets.so.5.9.5
libmkl_def.so                          libQt5WebSockets.la
libmkl_gf_ilp64.so                     libQt5WebSockets.prl
libmkl_gf_lp64.so                      libQt5WebSockets.so
libmkl_gnu_thread.so                   libQt5WebSockets.so.5
libmkl_intel_ilp64.so                  libQt5WebSockets.so.5.9
libmkl_intel_lp64.so                   libQt5WebSockets.so.5.9.5
libmkl_intel_thread.so                 libQt5WebView.la
libmkl_mc3.so                          libQt5WebView.prl
libmkl_mc.so                           libQt5WebView.so
libmkl_pgi_thread.so                   libQt5WebView.so.5
libmkl_rt.so                           libQt5WebView.so.5.9
libmkl_scalapack_ilp64.so              libQt5WebView.so.5.9.5
libmkl_scalapack_lp64.so               libQt5Widgets.la
libmkl_sequential.so                   libQt5Widgets.prl
libmkl_tbb_thread.so                   libQt5Widgets.so
libmkl_vml_avx2.so                     libQt5Widgets.so.5
libmkl_vml_avx512_mic.so               libQt5Widgets.so.5.9
libmkl_vml_avx512.so                   libQt5Widgets.so.5.9.5
libmkl_vml_avx.so                      libQt5X11Extras.la
libmkl_vml_cmpt.so                     libQt5X11Extras.prl
libmkl_vml_def.so                      libQt5X11Extras.so
libmkl_vml_mc2.so                      libQt5X11Extras.so.5
libmkl_vml_mc3.so                      libQt5X11Extras.so.5.9
libmkl_vml_mc.so                       libQt5X11Extras.so.5.9.5
libncurses.a                           libQt5XcbQpa.la
libncurses++.a                         libQt5XcbQpa.prl
libncurses.so                          libQt5XcbQpa.so
libncurses++w.a                        libQt5XcbQpa.so.5
libncursesw.a                          libQt5XcbQpa.so.5.9
libncursesw.so                         libQt5XcbQpa.so.5.9.5
libncursesw.so.6                       libQt5Xml.la
libncursesw.so.6.1                     libQt5XmlPatterns.la
libpanel.a                             libQt5XmlPatterns.prl
libpanel.so                            libQt5XmlPatterns.so
libpanelw.a                            libQt5XmlPatterns.so.5
libpanelw.so                           libQt5XmlPatterns.so.5.9
libpanelw.so.6                         libQt5XmlPatterns.so.5.9.5
libpanelw.so.6.1                       libQt5Xml.prl
libpcre.a                              libQt5Xml.so
libpcrecpp.a                           libQt5Xml.so.5
libpcrecpp.la                          libQt5Xml.so.5.9
libpcrecpp.so                          libQt5Xml.so.5.9.5
libpcrecpp.so.0                        libquadmath.so
libpcrecpp.so.0.0.1                    libquadmath.so.0
libpcre.la                             libquadmath.so.0.0.0
libpcreposix.a                         libreadline.a
libpcreposix.la                        libreadline.so
libpcreposix.so                        libreadline.so.7
libpcreposix.so.0                      libreadline.so.7.0
libpcreposix.so.0.0.6                  libsodium.a
libpcre.so                             libsodium.la
libpcre.so.1                           libsodium.so
libpcre.so.1.2.10                      libsodium.so.23
libpng16.a                             libsodium.so.23.1.0
libpng16.la                            libsqlite3.a
libpng16.so                            libsqlite3.la
libpng16.so.16                         libsqlite3.so
libpng16.so.16.34.0                    libsqlite3.so.0
libpng.a                               libsqlite3.so.0.8.6
libpng.la                              libssl.a
libpng.so                              libssl.so
libpython3.6m.a                        libssl.so.1.0.0
libpython3.6m.so                       libstdc++.so
libpython3.6m.so.1                     libstdc++.so.6
libpython3.6m.so.1.0                   libstdc++.so.6.0.24
libqgsttools_p.prl                     libtcl8.6.so
libqgsttools_p.so                      libtcl.so
libqgsttools_p.so.1                    libtclstub8.6.a
libqgsttools_p.so.1.0                  libtinfo.a
libqgsttools_p.so.1.0.0                libtinfo.so
libQt53DAnimation.la                   libtinfow.a
libQt53DAnimation.prl                  libtinfow.so
libQt53DAnimation.so                   libtinfow.so.6
libQt53DAnimation.so.5                 libtinfow.so.6.1
libQt53DAnimation.so.5.9               libtk8.6.so
libQt53DAnimation.so.5.9.5             libtk.so
libQt53DCore.la                        libtkstub8.6.a
libQt53DCore.prl                       libtsan.so
libQt53DCore.so                        libtsan.so.0
libQt53DCore.so.5                      libtsan.so.0.0.0
libQt53DCore.so.5.9                    libubsan.so
libQt53DCore.so.5.9.5                  libubsan.so.0
libQt53DExtras.la                      libubsan.so.0.0.0
libQt53DExtras.prl                     libxcb.a
libQt53DExtras.so                      libxcb-composite.a
libQt53DExtras.so.5                    libxcb-composite.la
libQt53DExtras.so.5.9                  libxcb-composite.so
libQt53DExtras.so.5.9.5                libxcb-composite.so.0
libQt53DInput.la                       libxcb-composite.so.0.0.0
libQt53DInput.prl                      libxcb-damage.a
libQt53DInput.so                       libxcb-damage.la
libQt53DInput.so.5                     libxcb-damage.so
libQt53DInput.so.5.9                   libxcb-damage.so.0
libQt53DInput.so.5.9.5                 libxcb-damage.so.0.0.0
libQt53DLogic.la                       libxcb-dpms.a
libQt53DLogic.prl                      libxcb-dpms.la
libQt53DLogic.so                       libxcb-dpms.so
libQt53DLogic.so.5                     libxcb-dpms.so.0
libQt53DLogic.so.5.9                   libxcb-dpms.so.0.0.0
libQt53DLogic.so.5.9.5                 libxcb-dri2.a
libQt53DQuickAnimation.la              libxcb-dri2.la
libQt53DQuickAnimation.prl             libxcb-dri2.so
libQt53DQuickAnimation.so              libxcb-dri2.so.0
libQt53DQuickAnimation.so.5            libxcb-dri2.so.0.0.0
libQt53DQuickAnimation.so.5.9          libxcb-dri3.a
libQt53DQuickAnimation.so.5.9.5        libxcb-dri3.la
libQt53DQuickExtras.la                 libxcb-dri3.so
libQt53DQuickExtras.prl                libxcb-dri3.so.0
libQt53DQuickExtras.so                 libxcb-dri3.so.0.0.0
libQt53DQuickExtras.so.5               libxcb-glx.a
libQt53DQuickExtras.so.5.9             libxcb-glx.la
libQt53DQuickExtras.so.5.9.5           libxcb-glx.so
libQt53DQuickInput.la                  libxcb-glx.so.0
libQt53DQuickInput.prl                 libxcb-glx.so.0.0.0
libQt53DQuickInput.so                  libxcb.la
libQt53DQuickInput.so.5                libxcb-present.a
libQt53DQuickInput.so.5.9              libxcb-present.la
libQt53DQuickInput.so.5.9.5            libxcb-present.so
libQt53DQuick.la                       libxcb-present.so.0
libQt53DQuick.prl                      libxcb-present.so.0.0.0
libQt53DQuickRender.la                 libxcb-randr.a
libQt53DQuickRender.prl                libxcb-randr.la
libQt53DQuickRender.so                 libxcb-randr.so
libQt53DQuickRender.so.5               libxcb-randr.so.0
libQt53DQuickRender.so.5.9             libxcb-randr.so.0.1.0
libQt53DQuickRender.so.5.9.5           libxcb-record.a
libQt53DQuickScene2D.la                libxcb-record.la
libQt53DQuickScene2D.prl               libxcb-record.so
libQt53DQuickScene2D.so                libxcb-record.so.0
libQt53DQuickScene2D.so.5              libxcb-record.so.0.0.0
libQt53DQuickScene2D.so.5.9            libxcb-render.a
libQt53DQuickScene2D.so.5.9.5          libxcb-render.la
libQt53DQuick.so                       libxcb-render.so
libQt53DQuick.so.5                     libxcb-render.so.0
libQt53DQuick.so.5.9                   libxcb-render.so.0.0.0
libQt53DQuick.so.5.9.5                 libxcb-res.a
libQt53DRender.la                      libxcb-res.la
libQt53DRender.prl                     libxcb-res.so
libQt53DRender.so                      libxcb-res.so.0
libQt53DRender.so.5                    libxcb-res.so.0.0.0
libQt53DRender.so.5.9                  libxcb-screensaver.a
libQt53DRender.so.5.9.5                libxcb-screensaver.la
libQt5AccessibilitySupport.a           libxcb-screensaver.so
libQt5AccessibilitySupport.la          libxcb-screensaver.so.0
libQt5AccessibilitySupport.prl         libxcb-screensaver.so.0.0.0
libQt5Bluetooth.la                     libxcb-shape.a
libQt5Bluetooth.prl                    libxcb-shape.la
libQt5Bluetooth.so                     libxcb-shape.so
libQt5Bluetooth.so.5                   libxcb-shape.so.0
libQt5Bluetooth.so.5.9                 libxcb-shape.so.0.0.0
libQt5Bluetooth.so.5.9.5               libxcb-shm.a
libQt5Bootstrap.a                      libxcb-shm.la
libQt5Bootstrap.la                     libxcb-shm.so
libQt5Bootstrap.prl                    libxcb-shm.so.0
libQt5Charts.la                        libxcb-shm.so.0.0.0
libQt5Charts.prl                       libxcb.so
libQt5Charts.so                        libxcb.so.1
libQt5Charts.so.5                      libxcb.so.1.1.0
libQt5Charts.so.5.9                    libxcb-sync.a
libQt5Charts.so.5.9.5                  libxcb-sync.la
libQt5Concurrent.la                    libxcb-sync.so
libQt5Concurrent.prl                   libxcb-sync.so.1
libQt5Concurrent.so                    libxcb-sync.so.1.0.0
libQt5Concurrent.so.5                  libxcb-xf86dri.a
libQt5Concurrent.so.5.9                libxcb-xf86dri.la
libQt5Concurrent.so.5.9.5              libxcb-xf86dri.so
libQt5Core.la                          libxcb-xf86dri.so.0
libQt5Core.prl                         libxcb-xf86dri.so.0.0.0
libQt5Core.so                          libxcb-xfixes.a
libQt5Core.so.5                        libxcb-xfixes.la
libQt5Core.so.5.9                      libxcb-xfixes.so
libQt5Core.so.5.9.5                    libxcb-xfixes.so.0
libQt5DataVisualization.la             libxcb-xfixes.so.0.0.0
libQt5DataVisualization.prl            libxcb-xinerama.a
libQt5DataVisualization.so             libxcb-xinerama.la
libQt5DataVisualization.so.5           libxcb-xinerama.so
libQt5DataVisualization.so.5.9         libxcb-xinerama.so.0
libQt5DataVisualization.so.5.9.5       libxcb-xinerama.so.0.0.0
libQt5DBus.la                          libxcb-xinput.a
libQt5DBus.prl                         libxcb-xinput.la
libQt5DBus.so                          libxcb-xinput.so
libQt5DBus.so.5                        libxcb-xinput.so.0
libQt5DBus.so.5.9                      libxcb-xinput.so.0.1.0
libQt5DBus.so.5.9.5                    libxcb-xkb.a
libQt5DesignerComponents.la            libxcb-xkb.la
libQt5DesignerComponents.prl           libxcb-xkb.so
libQt5DesignerComponents.so            libxcb-xkb.so.1
libQt5DesignerComponents.so.5          libxcb-xkb.so.1.0.0
libQt5DesignerComponents.so.5.9        libxcb-xtest.a
libQt5DesignerComponents.so.5.9.5      libxcb-xtest.la
libQt5Designer.la                      libxcb-xtest.so
libQt5Designer.prl                     libxcb-xtest.so.0
libQt5Designer.so                      libxcb-xtest.so.0.0.0
libQt5Designer.so.5                    libxcb-xv.a
libQt5Designer.so.5.9                  libxcb-xv.la
libQt5Designer.so.5.9.5                libxcb-xvmc.a
libQt5DeviceDiscoverySupport.a         libxcb-xvmc.la
libQt5DeviceDiscoverySupport.la        libxcb-xvmc.so
libQt5DeviceDiscoverySupport.prl       libxcb-xvmc.so.0
libQt5EglFSDeviceIntegration.la        libxcb-xvmc.so.0.0.0
libQt5EglFSDeviceIntegration.prl       libxcb-xv.so
libQt5EglFSDeviceIntegration.so        libxcb-xv.so.0
libQt5EglFSDeviceIntegration.so.5      libxcb-xv.so.0.0.0
libQt5EglFSDeviceIntegration.so.5.9    libxml2.a
libQt5EglFSDeviceIntegration.so.5.9.5  libxml2.la
libQt5EglSupport.a                     libxml2.so
libQt5EglSupport.la                    libxml2.so.2
libQt5EglSupport.prl                   libxml2.so.2.9.8
libQt5EventDispatcherSupport.a         libyaml-0.so.2
libQt5EventDispatcherSupport.la        libyaml-0.so.2.0.5
libQt5EventDispatcherSupport.prl       libyaml.a
libQt5FbSupport.a                      libyaml.la
libQt5FbSupport.la                     libyaml.so
libQt5FbSupport.prl                    libz.a
libQt5FontDatabaseSupport.a            libzmq.a
libQt5FontDatabaseSupport.la           libzmq.la
libQt5FontDatabaseSupport.prl          libzmq.so
libQt5Gamepad.la                       libzmq.so.5
libQt5Gamepad.prl                      libzmq.so.5.1.5
libQt5Gamepad.so                       libz.so
libQt5Gamepad.so.5                     libz.so.1
libQt5Gamepad.so.5.9                   libz.so.1.2.11
libQt5Gamepad.so.5.9.5                 mkl_msg.cat
libQt5GlxSupport.a                     pkgconfig
libQt5GlxSupport.la                    python3.6
libQt5GlxSupport.prl                   sqlite3.20.0
libQt5Gui.la                           tcl8
libQt5Gui.prl                          tcl8.6
libQt5Gui.so                           tclConfig.sh
libQt5Gui.so.5                         tclooConfig.sh
libQt5Gui.so.5.9                       tdbc1.0.5
libQt5Gui.so.5.9.5                     tdbcmysql1.0.5
libQt5Help.la                          tdbcodbc1.0.5
libQt5Help.prl                         tdbcpostgres1.0.5
libQt5Help.so                          terminfo
libQt5Help.so.5                        thread2.8.1
libQt5Help.so.5.9                      tk8.6
libQt5Help.so.5.9.5                    tkConfig.sh
libQt5InputSupport.a                   xml2Conf.sh
libQt5InputSupport.la

/ In het VanderPlas boek (xv)	,

[eric@almond vanderplas]$ conda install scikit-learn
Solving environment: done

## Package Plan ##

  environment location: /home/eric/miniconda3

  added / updated specs: 
    - scikit-learn


The following packages will be downloaded:

    package                    |            build
    ---------------------------|-----------------
    scikit-learn-0.19.1        |   py36h7aa7ec6_0         5.2 MB

The following NEW packages will be INSTALLED:

    scikit-learn: 0.19.1-py36h7aa7ec6_0

Proceed ([y]/n)? y


Downloading and Extracting Packages
scikit-learn-0.19.1  |  5.2 MB | ####################################### | 100% 
Preparing transaction: done
Verifying transaction: done
Executing transaction: done

[eric@almond vanderplas]$  conda env list
# conda environments:
#
base                  *  /home/eric/miniconda3

/ met $ conda create -n <name> python=<version> numpy=<version> scipy
/ create je een andere env	, 
/ see install tensorflow	,
https://www.tensorflow.org/install/install_linux#InstallingVirtualenv


[eric@almond vanderplas]$ conda install numpy
Solving environment: done

# All requested packages already installed.

[eric@almond vanderplas]$ conda install seaborn
Solving environment: done

## Package Plan ##

  environment location: /home/eric/miniconda3

  added / updated specs: 
    - seaborn


The following packages will be downloaded:

    package                    |            build
    ---------------------------|-----------------
    patsy-0.5.0                |           py36_0         322 KB
    seaborn-0.8.1              |   py36hfad7ec4_0         335 KB
    statsmodels-0.9.0          |   py36h3010b51_0         8.9 MB
    ------------------------------------------------------------
                                           Total:         9.5 MB

The following NEW packages will be INSTALLED:

    patsy:       0.5.0-py36_0        
    seaborn:     0.8.1-py36hfad7ec4_0
    statsmodels: 0.9.0-py36h3010b51_0

Proceed ([y]/n)? y


Downloading and Extracting Packages
patsy-0.5.0          |  322 KB | ####################################### | 100% 
seaborn-0.8.1        |  335 KB | ####################################### | 100% 
statsmodels-0.9.0    |  8.9 MB | ####################################### | 100% 
Preparing transaction: done
Verifying transaction: done
Executing transaction: done

[eric@almond vanderplas]$ conda install notebook
Solving environment: done

# All requested packages already installed.

/ Deze gaan we NIET doen	,
[eric@almond vanderplas]$ conda install ipython-notebook
Solving environment: done

## Package Plan ##

  environment location: /home/eric/miniconda3

  added / updated specs: 
    - ipython-notebook


The following packages will be downloaded:

    package                    |            build
    ---------------------------|-----------------
    python-dateutil-2.7.3      |           py35_0         261 KB
    pandocfilters-1.4.2        |   py35h1565a15_1          12 KB
    cycler-0.10.0              |   py35hc4d5149_0          13 KB
    pickleshare-0.7.4          |   py35hd57304d_0          11 KB
    conda-4.5.4                |           py35_0         1.0 MB
    nbconvert-5.3.1            |   py35hc5194e3_0         397 KB
    mkl_fft-1.0.1              |   py35h3010b51_0         139 KB
    pip-10.0.1                 |           py35_0         1.8 MB
    numpy-1.14.5               |   py35hcd700cb_0          94 KB
    setuptools-39.2.0          |           py35_0         565 KB
    terminado-0.8.1            |           py35_1          21 KB
    jupyter-1.0.0              |           py35_4           5 KB
    chardet-3.0.4              |   py35hb6e9ddf_1         190 KB
    ipywidgets-7.2.1           |           py35_0         144 KB
    jinja2-2.10                |   py35h480ab6d_0         182 KB
    pandas-0.23.1              |   py35h637b7d7_0        11.8 MB
    entrypoints-0.2.3          |   py35h48174a2_2           9 KB
    notebook-5.5.0             |           py35_0         7.0 MB
    prompt_toolkit-1.0.15      |   py35hc09de7a_0         343 KB
    pycosat-0.6.3              |   py35h6b6bb97_0         104 KB
    decorator-4.3.0            |           py35_0          15 KB
    widgetsnbextension-3.2.1   |           py35_0         1.7 MB
    matplotlib-2.2.2           |   py35h0e671d2_1         6.7 MB
    markupsafe-1.0             |   py35h4f4fcf6_1          25 KB
    scipy-1.1.0                |   py35hfc37229_0        18.1 MB
    numpy-base-1.14.5          |   py35hdbf6ddf_0         4.1 MB
    jedi-0.12.0                |           py35_1         225 KB
    jupyter_core-4.4.0         |   py35ha89e94b_0          61 KB
    ruamel_yaml-0.15.40        |   py35h14c3975_2         242 KB
    simplegeneric-0.8.1        |           py35_2           9 KB
    seaborn-0.8.1              |   py35h04cba02_0         339 KB
    sip-4.19.8                 |   py35hf484d3e_0         291 KB
    html5lib-1.0.1             |   py35h2f9c1c0_0         189 KB
    testpath-0.3.1             |   py35had42eaf_0          89 KB
    statsmodels-0.9.0          |   py35h3010b51_0         8.8 MB
    ipython_genutils-0.2.0     |   py35hc9e07d0_0          39 KB
    six-1.11.0                 |   py35h423b573_1          21 KB
    mkl_random-1.0.1           |   py35h629b387_0         364 KB
    cffi-1.11.5                |   py35h9745a5d_0         213 KB
    certifi-2018.4.16          |           py35_0         143 KB
    patsy-0.5.0                |           py35_0         322 KB
    jupyter_client-5.2.3       |           py35_0         125 KB
    cryptography-2.2.2         |   py35h14c3975_0         599 KB
    idna-2.7                   |           py35_0         133 KB
    asn1crypto-0.24.0          |           py35_0         156 KB
    pysocks-1.6.8              |           py35_0          22 KB
    pexpect-4.6.0              |           py35_0          77 KB
    pycparser-2.18             |   py35h61b3040_1         170 KB
    pyqt-5.9.2                 |   py35h751905a_0         5.9 MB
    ipython-6.4.0              |           py35_0         1.0 MB
    jupyter_console-5.2.0      |   py35h4044a63_1          35 KB
    qtconsole-4.3.1            |   py35h4626a06_0         151 KB
    scikit-learn-0.19.1        |   py35hbf1f462_0         5.2 MB
    ipython-notebook-4.0.4     |           py35_0           5 KB
    traitlets-4.3.2            |   py35ha522a97_0         131 KB
    python-3.5.5               |       hc3d631a_4        28.3 MB
    wheel-0.31.1               |           py35_0          63 KB
    ptyprocess-0.6.0           |           py35_0          23 KB
    parso-0.2.1                |           py35_0         119 KB
    pyopenssl-18.0.0           |           py35_0          82 KB
    bleach-2.1.3               |           py35_0          33 KB
    pygments-2.2.0             |   py35h0f41973_0         1.3 MB
    ipykernel-4.8.2            |           py35_0         146 KB
    pyzmq-17.0.0               |   py35h14c3975_0         457 KB
    requests-2.19.1            |           py35_0          97 KB
    backcall-0.1.0             |           py35_0          19 KB
    webencodings-0.5.1         |   py35hb6cf162_1          19 KB
    wcwidth-0.1.7              |   py35hcd08066_0          25 KB
    jsonschema-2.6.0           |   py35h4395190_0          63 KB
    mistune-0.8.3              |   py35h14c3975_1         268 KB
    send2trash-1.5.0           |           py35_0          16 KB
    pyparsing-2.2.0            |   py35h041ed72_1          96 KB
    tornado-5.0.2              |           py35_0         644 KB
    kiwisolver-1.0.1           |   py35hcb1117a_0          84 KB
    urllib3-1.23               |           py35_0         153 KB
    pytz-2018.4                |           py35_0         212 KB
    nbformat-4.4.0             |   py35h12e6e07_0         138 KB
    ------------------------------------------------------------
                                           Total:       111.9 MB

The following NEW packages will be INSTALLED:

    ipython-notebook:   4.0.4-py35_0          

The following packages will be UPDATED:

    asn1crypto:         0.24.0-py36_0          --> 0.24.0-py35_0         
    backcall:           0.1.0-py36_0           --> 0.1.0-py35_0          
    bleach:             2.1.3-py36_0           --> 2.1.3-py35_0          
    certifi:            2018.4.16-py36_0       --> 2018.4.16-py35_0      
    cffi:               1.11.5-py36h9745a5d_0  --> 1.11.5-py35h9745a5d_0 
    chardet:            3.0.4-py36h0f667ec_1   --> 3.0.4-py35hb6e9ddf_1  
    conda:              4.5.4-py36_0           --> 4.5.4-py35_0          
    cryptography:       2.2.2-py36h14c3975_0   --> 2.2.2-py35h14c3975_0  
    cycler:             0.10.0-py36h93f1223_0  --> 0.10.0-py35hc4d5149_0 
    decorator:          4.3.0-py36_0           --> 4.3.0-py35_0          
    entrypoints:        0.2.3-py36h1aec115_2   --> 0.2.3-py35h48174a2_2  
    html5lib:           1.0.1-py36h2f9c1c0_0   --> 1.0.1-py35h2f9c1c0_0  
    idna:               2.6-py36h82fb2a8_1     --> 2.7-py35_0            
    ipykernel:          4.8.2-py36_0           --> 4.8.2-py35_0          
    ipython:            6.4.0-py36_0           --> 6.4.0-py35_0          
    ipython_genutils:   0.2.0-py36hb52b0d5_0   --> 0.2.0-py35hc9e07d0_0  
    ipywidgets:         7.2.1-py36_0           --> 7.2.1-py35_0          
    jedi:               0.12.0-py36_1          --> 0.12.0-py35_1         
    jinja2:             2.10-py36ha16c418_0    --> 2.10-py35h480ab6d_0   
    jsonschema:         2.6.0-py36h006f8b5_0   --> 2.6.0-py35h4395190_0  
    jupyter:            1.0.0-py36_4           --> 1.0.0-py35_4          
    jupyter_client:     5.2.3-py36_0           --> 5.2.3-py35_0          
    jupyter_console:    5.2.0-py36he59e554_1   --> 5.2.0-py35h4044a63_1  
    jupyter_core:       4.4.0-py36h7c827e3_0   --> 4.4.0-py35ha89e94b_0  
    kiwisolver:         1.0.1-py36h764f252_0   --> 1.0.1-py35hcb1117a_0  
    markupsafe:         1.0-py36hd9260cd_1     --> 1.0-py35h4f4fcf6_1    
    matplotlib:         2.2.2-py36h0e671d2_1   --> 2.2.2-py35h0e671d2_1  
    mistune:            0.8.3-py36h14c3975_1   --> 0.8.3-py35h14c3975_1  
    mkl_fft:            1.0.1-py36h3010b51_0   --> 1.0.1-py35h3010b51_0  
    mkl_random:         1.0.1-py36h629b387_0   --> 1.0.1-py35h629b387_0  
    nbconvert:          5.3.1-py36hb41ffb7_0   --> 5.3.1-py35hc5194e3_0  
    nbformat:           4.4.0-py36h31c9010_0   --> 4.4.0-py35h12e6e07_0  
    notebook:           5.5.0-py36_0           --> 5.5.0-py35_0          
    pandas:             0.23.1-py36h637b7d7_0  --> 0.23.1-py35h637b7d7_0 
    pandocfilters:      1.4.2-py36ha6701b7_1   --> 1.4.2-py35h1565a15_1  
    parso:              0.2.1-py36_0           --> 0.2.1-py35_0          
    patsy:              0.5.0-py36_0           --> 0.5.0-py35_0          
    pexpect:            4.6.0-py36_0           --> 4.6.0-py35_0          
    pickleshare:        0.7.4-py36h63277f8_0   --> 0.7.4-py35hd57304d_0  
    pip:                10.0.1-py36_0          --> 10.0.1-py35_0         
    prompt_toolkit:     1.0.15-py36h17d85b1_0  --> 1.0.15-py35hc09de7a_0 
    ptyprocess:         0.6.0-py36_0           --> 0.6.0-py35_0          
    pycosat:            0.6.3-py36h0a5515d_0   --> 0.6.3-py35h6b6bb97_0  
    pycparser:          2.18-py36hf9f622e_1    --> 2.18-py35h61b3040_1   
    pygments:           2.2.0-py36h0d3125c_0   --> 2.2.0-py35h0f41973_0  
    pyopenssl:          18.0.0-py36_0          --> 18.0.0-py35_0         
    pyparsing:          2.2.0-py36hee85983_1   --> 2.2.0-py35h041ed72_1  
    pyqt:               5.9.2-py36h751905a_0   --> 5.9.2-py35h751905a_0  
    pysocks:            1.6.8-py36_0           --> 1.6.8-py35_0          
    python-dateutil:    2.7.3-py36_0           --> 2.7.3-py35_0          
    pytz:               2018.4-py36_0          --> 2018.4-py35_0         
    pyzmq:              17.0.0-py36h14c3975_0  --> 17.0.0-py35h14c3975_0 
    qtconsole:          4.3.1-py36h8f73b5b_0   --> 4.3.1-py35h4626a06_0  
    requests:           2.18.4-py36he2e5f8d_1  --> 2.19.1-py35_0         
    ruamel_yaml:        0.15.37-py36h14c3975_2 --> 0.15.40-py35h14c3975_2
    scikit-learn:       0.19.1-py36h7aa7ec6_0  --> 0.19.1-py35hbf1f462_0 
    scipy:              1.1.0-py36hfc37229_0   --> 1.1.0-py35hfc37229_0  
    seaborn:            0.8.1-py36hfad7ec4_0   --> 0.8.1-py35h04cba02_0  
    send2trash:         1.5.0-py36_0           --> 1.5.0-py35_0          
    setuptools:         39.2.0-py36_0          --> 39.2.0-py35_0         
    simplegeneric:      0.8.1-py36_2           --> 0.8.1-py35_2          
    sip:                4.19.8-py36hf484d3e_0  --> 4.19.8-py35hf484d3e_0 
    six:                1.11.0-py36h372c433_1  --> 1.11.0-py35h423b573_1 
    statsmodels:        0.9.0-py36h3010b51_0   --> 0.9.0-py35h3010b51_0  
    terminado:          0.8.1-py36_1           --> 0.8.1-py35_1          
    testpath:           0.3.1-py36h8cadb63_0   --> 0.3.1-py35had42eaf_0  
    tornado:            5.0.2-py36_0           --> 5.0.2-py35_0          
    traitlets:          4.3.2-py36h674d592_0   --> 4.3.2-py35ha522a97_0  
    urllib3:            1.22-py36hbe7ace6_0    --> 1.23-py35_0           
    wcwidth:            0.1.7-py36hdf4376a_0   --> 0.1.7-py35hcd08066_0  
    webencodings:       0.5.1-py36h800622e_1   --> 0.5.1-py35hb6cf162_1  
    wheel:              0.31.1-py36_0          --> 0.31.1-py35_0         
    widgetsnbextension: 3.2.1-py36_0           --> 3.2.1-py35_0          

The following packages will be DOWNGRADED:

    numpy:              1.14.5-py36hcd700cb_1  --> 1.14.5-py35hcd700cb_0 
    numpy-base:         1.14.5-py36hdbf6ddf_1  --> 1.14.5-py35hdbf6ddf_0 
    python:             3.6.5-hc3d631a_2       --> 3.5.5-hc3d631a_4      

Proceed ([y]/n)? n

/ lees	,
https://ipython.org/notebook.html

/ WH is ipython-notebook nu jupyter notebook 	, en die hebben we al	,

/ boek (2)

[eric@almond vanderplas]$ ipython
Python 3.6.5 |Anaconda, Inc.| (default, Apr 29 2018, 16:14:56) 
Type 'copyright', 'credits' or 'license' for more information
IPython 6.4.0 -- An enhanced Interactive Python. Type '?' for help.

In [1]: 

/ in een andere shell	,

[eric@almond vanderplas]$ jupyter notebook
[I 16:02:48.584 NotebookApp] Writing notebook server cookie secret to /run/user/1000/jupyter/notebook_cookie_secret
[I 16:02:48.780 NotebookApp] Serving notebooks from local directory: /home/eric/Devel/python/vanderplas
[I 16:02:48.780 NotebookApp] 0 active kernels
[I 16:02:48.780 NotebookApp] The Jupyter Notebook is running at:
[I 16:02:48.780 NotebookApp] http://localhost:8888/?token=94030f83ca8af38df70bb461d2c34e712c9b4cbeda580ca7
[I 16:02:48.780 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[C 16:02:48.784 NotebookApp] 
    
    Copy/paste this URL into your browser when you connect for the first time,
    to login with a token:
        http://localhost:8888/?token=94030f83ca8af38df70bb461d2c34e712c9b4cbeda580ca7&token=94030f83ca8af38df70bb461d2c34e712c9b4cbeda580ca7
Created new window in existing browser session.
[I 16:02:49.483 NotebookApp] Accepting one-time-token-authenticated connection from 127.0.0.1

/ we zien in chrome	,
http://localhost:8888/tree



/ lees	,
http://ipython.readthedocs.io/en/stable/interactive/tutorial.html

/ 13	. 

In [15]: def fct2(a):
    ...:     return 7
    ...: 
    ...: 

In [16]: fct2(7)
Out[16]: 7

/ we moeten 2 extra newlines geven na de return	, 
/ dit is WH omdat je zo meerdere fcts kunt def	:

In [69]: def f1(a,b):
    ...:     return a/b
    ...: 
    ...: def f2(x):
    ...:     a=x
    ...:     b=x-1
    ...:     return f1(a,b)
    ...: 
    ...: 

In [70]: 
/ tussen f1 en f2 moet een newline	,
/ 13	. 

/ met dir() zien we de vars die we hebben def	,

/ opruimen	,

In [23]:  del fct

In [24]: del fct2

In [25]: del l

/ 13	. 

/ dir met arg geeft fct op L	,

In [34]: L=[1,2,3]

In [35]: dir(L)
Out[35]: 
['__add__',
 '__class__',
 '__contains__',
 '__delattr__',
 '__delitem__',
 '__dir__',
 '__doc__',
 '__eq__',
 '__format__',
 '__ge__',
 '__getattribute__',
 '__getitem__',
 '__gt__',
 '__hash__',
 '__iadd__',
 '__imul__',
 '__init__',
 '__init_subclass__',
 '__iter__',
 '__le__',
 '__len__',
 '__lt__',
 '__mul__',
 '__ne__',
 '__new__',
 '__reduce__',
 '__reduce_ex__',
 '__repr__',
 '__reversed__',
 '__rmul__',
 '__setattr__',
 '__setitem__',
 '__sizeof__',
 '__str__',
 '__subclasshook__',
 'append',
 'clear',
 'copy',
 'count',
 'extend',
 'index',
 'insert',
 'pop',
 'remove',
 'reverse',
 'sort']

/ maar je kunt ook TAB	,

In [36]: L.
            L.append  L.count   L.insert  L.reverse 
            L.clear   L.extend  L.pop     L.sort    
            L.copy    L.index   L.remove            

/ als je de fcts wilt zien die met _ beginnen, moet je de _ geven	, en dan TAB	,
In [37]: L.__
              L.__add__           L.__delitem__       L.__format__         
              L.__class__         L.__dir__           L.__ge__             
              L.__contains__      L.__doc__           L.__getattribute__  >
              L.__delattr__       L.__eq__            L.__getitem__        

In [38]: from itertools import TAB 
                  accumulate                    compress                       
                  chain                         count                          
                  combinations                  cycle                         >
                  combinations_with_replacement dropwhile                      

In [39]: import            
                 IPython                                           
                 OpenSSL                                           
                 PyQt5                                           > 
                 abc                                               
/ met pijltjes zie je de anderen	,

/ 13	.

In [39]: *Warning?
BytesWarning
DeprecationWarning
FutureWarning
ImportWarning
PendingDeprecationWarning
ResourceWarning
RuntimeWarning
SyntaxWarning
UnicodeWarning
UserWarning
Warning

/ 13	. 


In [40]: !ls
PythonDataScienceHandbook
/ Met ! een bash command	,

In [46]: !pwd
/home/eric/Devel/python/vanderplas

In [47]: %cd ..
/home/eric/Devel/python

In [48]: !pwd
/home/eric/Devel/python

In [49]: %cd vanderplas/
/home/eric/Devel/python/vanderplas

In [50]: %automagic

Automagic is OFF, % prefix IS needed for line magics.

In [51]: %automagic

Automagic is ON, % prefix IS NOT needed for line magics.

In [52]: cd ..
/home/eric/Devel/python

In [53]: cd vanderplas/
/home/eric/Devel/python/vanderplas

/ 13	 .

In [69]: def f1(a,b):
    ...:     return a/b
    ...: 
    ...: def f2(x):
    ...:     a=x
    ...:     b=x-1
    ...:     return f1(a,b)
    ...: 
    ...: 

In [70]: def f3(a):
    ...:     return a
    ...: 
    ...: 

In [71]: del f3

In [72]: f2(1)
---------------------------------------------------------------------------
ZeroDivisionError                         Traceback (most recent call last)
<ipython-input-72-133f42941cdb> in <module>()
----> 1 f2(1)

<ipython-input-69-c701046c5cec> in f2(x)
      5     a=x
      6     b=x-1
----> 7     return f1(a,b)

<ipython-input-69-c701046c5cec> in f1(a, b)
      1 def f1(a,b):
----> 2     return a/b
      3 
      4 def f2(x):
      5     a=x

ZeroDivisionError: division by zero

/ dit is xmode Context

/ 13	. 

In [76]: %xmode Plain
/ of	,
In [76]: xmode Plain
Exception reporting mode: Plain

In [77]: f2(1)
Traceback (most recent call last):
  File "<ipython-input-77-133f42941cdb>", line 1, in <module>
    f2(1)
  File "<ipython-input-69-c701046c5cec>", line 7, in f2
    return f1(a,b)
  File "<ipython-input-69-c701046c5cec>", line 2, in f1
    return a/b
ZeroDivisionError: division by zero

/ 13	. 

In [80]:  xmode Verbose
Exception reporting mode: Verbose

In [81]: f2(1)
---------------------------------------------------------------------------
ZeroDivisionError                         Traceback (most recent call last)
<ipython-input-81-133f42941cdb> in <module>()
----> 1 f2(1)
        global f2 = <function f2 at 0x7f1850068840>

<ipython-input-69-c701046c5cec> in f2(x=1)
      5     a=x
      6     b=x-1
----> 7     return f1(a,b)
        global f1 = <function f1 at 0x7f18501700d0>
        a = 1
        b = 0

<ipython-input-69-c701046c5cec> in f1(a=1, b=0)
      1 def f1(a,b):
----> 2     return a/b
        a = 1
        b = 0
      3 
      4 def f2(x):
      5     a=x

ZeroDivisionError: division by zero

/ 13	. 

In [98]: %time f1(7,13)
CPU times: user 11 µs, sys: 0 ns, total: 11 µs
Wall time: 16.5 µs
Out[98]: 0.5384615384615384

/ 13	.

In [100]: %time sum(range(100))
CPU times: user 13 µs, sys: 2 µs, total: 15 µs
Wall time: 20.5 µs
Out[100]: 4950

In [101]: %timeit sum(range(100))
1.11 µs ± 6.18 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)

/ %timeit doet sum(range(100)) een aantal keer, en middelt	,

/ 13	. 

In [6]: %time sum(range(10000000))
CPU times: user 179 ms, sys: 974 µs, total: 180 ms
Wall time: 180 ms
Out[6]: 49999995000000
/ 10 000 000

In [5]: %time sum(range(100000000))
CPU times: user 1.78 s, sys: 1.86 ms, total: 1.78 s
Wall time: 1.79 s
Out[5]: 4999999950000000
/ 100 000 000

/ we gaan verder met 10 milj	,

In [9]: %timeit sum(range(10000000))
191 ms ± 14 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)

In [10]: %prun sum(range(10000000))
/ of	,
In [10]: prun sum(range(10000000))
         4 function calls in 0.181 seconds

   Ordered by: internal time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.181    0.181    0.181    0.181 {built-in method builtins.sum}
        1    0.000    0.000    0.181    0.181 <string>:1(<module>)
        1    0.000    0.000    0.181    0.181 {built-in method builtins.exec}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}

In [13]: %lprun sum(range(10000000))
UsageError: Line magic function `%lprun` not found.
 
In [11]: %memit sum(range(10000000))
UsageError: Line magic function `%memit` not found.

In [12]: %mprun sum(range(10000000))
UsageError: Line magic function `%mprun` not found.

/ 13	. 

In [41]: [i**2 for i in range(0,5)]
Out[41]: [0, 1, 4, 9, 16]

In [42]: l=[random.random()for i in range(0,1000)]

/ doe	,

In [43]: %timeit l.sort()
12.3 µs ± 33.7 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)

/ of	,

In [52]: %time l.sort()
CPU times: user 47 µs, sys: 1e+03 ns, total: 48 µs
Wall time: 53.6 µs

In [53]: %time l.sort()
CPU times: user 38 µs, sys: 0 ns, total: 38 µs
Wall time: 43.2 µs

/ met %timeit sneller als met %time	,

/ 13	. 

n [58]: def sum_of_lists(N):
    ...:     total=0
    ...:     for i in range(5):
    ...:         l=[j^(j>>i)for j in range(N)]
    ...:         total+=sum(l)
    ...:     return total
    ...: 
    ...: 

In [61]: %prun sum_of_lists(10000000)
         14 function calls in 5.972 seconds

   Ordered by: internal time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        5    5.192    1.038    5.192    1.038 <ipython-input-58-c461eb9ea5c9>:4(<listcomp>)
        5    0.363    0.073    0.363    0.073 {built-in method builtins.sum}
        1    0.321    0.321    5.875    5.875 <ipython-input-58-c461eb9ea5c9>:1(sum_of_lists)
        1    0.097    0.097    5.972    5.972 <string>:1(<module>)
        1    0.000    0.000    5.972    5.972 {built-in method builtins.exec}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}

/ we zien ze geordend naar tottime	,

/ :4 is WH regel 4, dat is de list comprehension	, die wordt 5 keer called	, en de total time is 5.192. 
/ Ook 5 keer wordt sum called	, (er staat niet :5 voor regel 5 TODO)	, total is 5.192+0.363=5.555	, 
/ dan 1 keer regel 1, dus 5.555+0.321 = 5.876	, klopt aardig	, ...
/ het totaal duurt dus 5.972	,

/ 7	. 

/ we moeten uit ipython gaan	,

[eric@almond vanderplas]$ pip install line_profiler
Collecting line_profiler
  Downloading https://files.pythonhosted.org/packages/14/fc/ecf4e238bb601ff829068e5a72cd1bd67b0ee0ae379db172eb6a0779c6b6/line_profiler-2.1.2.tar.gz (83kB)
    100% |████████████████████████████████| 92kB 1.0MB/s 
Requirement already satisfied: IPython>=0.13 in /home/eric/miniconda3/lib/python3.6/site-packages (from line_profiler) (6.4.0)
Requirement already satisfied: setuptools>=18.5 in /home/eric/miniconda3/lib/python3.6/site-packages (from IPython>=0.13->line_profiler) (39.2.0)
Requirement already satisfied: jedi>=0.10 in /home/eric/miniconda3/lib/python3.6/site-packages (from IPython>=0.13->line_profiler) (0.12.0)
Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.15 in /home/eric/miniconda3/lib/python3.6/site-packages (from IPython>=0.13->line_profiler) (1.0.15)
Requirement already satisfied: pygments in /home/eric/miniconda3/lib/python3.6/site-packages (from IPython>=0.13->line_profiler) (2.2.0)
Requirement already satisfied: traitlets>=4.2 in /home/eric/miniconda3/lib/python3.6/site-packages (from IPython>=0.13->line_profiler) (4.3.2)
Requirement already satisfied: backcall in /home/eric/miniconda3/lib/python3.6/site-packages (from IPython>=0.13->line_profiler) (0.1.0)
Requirement already satisfied: pickleshare in /home/eric/miniconda3/lib/python3.6/site-packages (from IPython>=0.13->line_profiler) (0.7.4)
Requirement already satisfied: pexpect; sys_platform != "win32" in /home/eric/miniconda3/lib/python3.6/site-packages (from IPython>=0.13->line_profiler) (4.6.0)
Requirement already satisfied: simplegeneric>0.8 in /home/eric/miniconda3/lib/python3.6/site-packages (from IPython>=0.13->line_profiler) (0.8.1)
Requirement already satisfied: decorator in /home/eric/miniconda3/lib/python3.6/site-packages (from IPython>=0.13->line_profiler) (4.3.0)
Requirement already satisfied: parso>=0.2.0 in /home/eric/miniconda3/lib/python3.6/site-packages (from jedi>=0.10->IPython>=0.13->line_profiler) (0.2.1)
Requirement already satisfied: six>=1.9.0 in /home/eric/miniconda3/lib/python3.6/site-packages (from prompt-toolkit<2.0.0,>=1.0.15->IPython>=0.13->line_profiler) (1.11.0)
Requirement already satisfied: wcwidth in /home/eric/miniconda3/lib/python3.6/site-packages (from prompt-toolkit<2.0.0,>=1.0.15->IPython>=0.13->line_profiler) (0.1.7)
Requirement already satisfied: ipython_genutils in /home/eric/miniconda3/lib/python3.6/site-packages (from traitlets>=4.2->IPython>=0.13->line_profiler) (0.2.0)
Requirement already satisfied: ptyprocess>=0.5 in /home/eric/miniconda3/lib/python3.6/site-packages (from pexpect; sys_platform != "win32"->IPython>=0.13->line_profiler) (0.6.0)
Building wheels for collected packages: line-profiler
  Running setup.py bdist_wheel for line-profiler ... done
  Stored in directory: /home/eric/.cache/pip/wheels/05/7d/9b/aafbe8d78dc2b2c644d2efd2f060ab3258143860142575193a
Successfully built line-profiler
mkl-random 1.0.1 requires cython, which is not installed.
mkl-fft 1.0.0 requires cython, which is not installed.
Installing collected packages: line-profiler
Successfully installed line-profiler-2.1.2

/ mkl-random 1.0.1 requires cython, which is not installed.
/ mkl-fft 1.0.0 requires cython, which is not installed.
/ mkl-random, mkl-fft zijn wel installed, maar we moete cython nog install	,
/ TODO

eric@almond vanderplas]$ conda list
# packages in environment at /home/eric/miniconda3:
#
# Name                    Version                   Build  Channel
asn1crypto                0.24.0                   py36_0  
...
blas                      1.0                         mkl  
...
libxml2                   2.9.8                h26e45fe_1  
line-profiler             2.1.2                     <pip>

[eric@almond vanderplas]$ pip list
Package            Version  
------------------ ---------
asn1crypto         0.24.0   
/ geen blas	,
line-profiler      2.1.2    
MarkupSafe         1.0      
matplotlib         2.2.2    
mistune            0.8.3    
mkl-fft            1.0.0    
mkl-random         1.0.1    
...

/ we zien packages bij conda en pip	, 
/ wat is conda install en pip install	?

/ 7	. 

/ (47) reshape

/ Intermezzo

/ google	,
np.random.seed
/ lees	,
https://stackoverflow.com/questions/21494489/what-does-numpy-random-seed0-do

np.random.seed(0) makes the random numbers predictable

>>> numpy.random.seed(0) ; numpy.random.rand(4)
array([ 0.55,  0.72,  0.6 ,  0.54])
>>> numpy.random.seed(0) ; numpy.random.rand(4)
array([ 0.55,  0.72,  0.6 ,  0.54])
With the seed reset (every time), the same set of numbers will appear every time.

If the random seed is not reset, different numbers appear with every invocation:

>>> numpy.random.rand(4)
array([ 0.42,  0.65,  0.44,  0.89])
>>> numpy.random.rand(4)
array([ 0.96,  0.38,  0.79,  0.53])
(pseudo-)random numbers work by starting with a number (the seed), multiplying it by a large number, then taking modulo of that product. The resulting number is then used as the seed to generate the next "random" number. When you set the seed (every time), it does the same thing every time, giving you the same numbers.

If you want seemingly random numbers, do not set the seed. If you have code that uses random numbers that you want to debug, however, it can be very helpful to set the seed before each run so that the code does the same thing every time you run it.

To get the most random numbers for each run, call numpy.random.seed(). This will cause numpy to set the seed to a random number obtained from /dev/urandom or its Windows analog or, if neither of those is available, it will use the clock.

/ 13	. 

/ lees	,
https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.random.randint.html

/ als we alleen low geven, dan [0,low)
/ als we low en high geven, dan [low,high) 

In [30]: np.random.randint(low=2)
Out[30]: 0

In [31]: np.random.randint(low=2)
Out[31]: 1

In [27]: np.random.randint(low=2,high=5)
Out[27]: 3

In [28]: np.random.randint(low=2,high=5)
Out[28]: 4


In [20]: np.random.randint(2,size=(4,3))
/=
In [20]: np.random.randint(low=2,size=(4,3))
Out[20]: 
array([[0, 1, 0],
       [1, 1, 1],
       [1, 1, 1],
       [1, 0, 0]])

In [21]: np.random.randint(2,high=5,size=(4,3))
/=
In [21]: np.random.randint(low=2,high=5,size=(4,3))
Out[21]: 
array([[2, 2, 3],
       [4, 2, 4],
       [4, 4, 3],
       [4, 2, 3]])

/ Einde Intermezzo

/ (39)

/ 13	. 

In [34]: type([1,2,3])
Out[34]: list

In [36]: type(np.array([1,2,3]))
Out[36]: numpy.ndarray

/ 13	. 

In [38]: [range(i,i+3)for i in [2,4,6]]
Out[38]: [range(2, 5), range(4, 7), range(6, 9)]

In [40]: np.array([range(i,i+3)for i in [2,4,6]])
Out[40]: 
array([[2, 3, 4],
       [4, 5, 6],
       [6, 7, 8]])

/ 13	. 

In [41]: np.random.randint(0,10,(3,3))
Out[41]: 
array([[9, 8, 7],
       [1, 6, 8],
       [5, 9, 9]])

In [42]: np.random.randint(0,10,(3,3))
Out[42]: 
array([[9, 3, 0],
       [0, 2, 8],
       [8, 2, 9]])

/ Intermezzo

/ np.random.rand(3,3) = np.random.random((3,3))
/ np.random.random werkt net als randint	, met size=(3,3)	,

In [61]: np.random.seed(0)

In [62]: np.random.rand(3,3)
Out[62]: 
array([[0.5488135 , 0.71518937, 0.60276338],
       [0.54488318, 0.4236548 , 0.64589411],
       [0.43758721, 0.891773  , 0.96366276]])

In [63]: np.random.seed(0)

In [64]: np.random.random((3,3))
Out[64]: 
array([[0.5488135 , 0.71518937, 0.60276338],
       [0.54488318, 0.4236548 , 0.64589411],
       [0.43758721, 0.891773  , 0.96366276]])

/ 1313	. 

In [75]: np.random.randint(256,512,(3,3),np.int8)
ValueError: high is out of bounds for int8

In [77]: np.random.seed(0)

In [78]: np.random.randint(256,512,(3,3),np.int64)
Out[78]: 
array([[428, 303, 373],
       [448, 323, 507],
       [451, 359, 265]])

In [79]: np.random.seed(0)

In [80]: np.random.randint(256,512,(3,3),np.int64)
Out[80]: 
array([[428, 303, 373],
       [448, 323, 507],
       [451, 359, 265]])

/ ndarray staat voor n dimensional array	,

/ Einde Intermezzo

/ Intermezzo

In [96]: np.array(list(range(0,9)),size=(3,3))
/ kan NIET	,

In [109]: np.array([range(i,i+3)for i in range(0,9,3)])
Out[109]: 
array([[0, 1, 2],
       [3, 4, 5],
       [6, 7, 8]])


/ 13	. 

In [139]: np.reshape(np.arange(9),newshape=(3,3),order='F')
Out[139]: 
array([[0, 3, 6],
       [1, 4, 7],
       [2, 5, 8]])

In [140]: np.reshape(np.arange(9),newshape=(3,3),order='C')
Out[140]: 
array([[0, 1, 2],
       [3, 4, 5],
       [6, 7, 8]])


/ Einde Intermezzo

/ 13	 

/ numpy slice is ref	, python slice is copy	,

In [148]: m=np.reshape(np.arange(16),newshape=(4,4),order='F')

In [149]: m
Out[149]: 
array([[ 0,  4,  8, 12],
       [ 1,  5,  9, 13],
       [ 2,  6, 10, 14],
       [ 3,  7, 11, 15]])

In [150]: m[:,::2]
Out[150]: 
array([[ 0,  8],
       [ 1,  9],
       [ 2, 10],
       [ 3, 11]])

In [151]: m[:,::2][0,1]=18	/ we veranderen de slice	,

In [152]: m											/ we zien de verandering in m op [0,2]	,
Out[152]: 
array([[ 0,  4, 18, 12],
       [ 1,  5,  9, 13],
       [ 2,  6, 10, 14],
       [ 3,  7, 11, 15]])

/ 1313	. 

/ er is ook de copy fct	,

/ we veranderen alleen in de cpy	,	

In [153]: c=m[:,::2].copy()

In [154]: c
Out[154]: 
array([[ 0, 18],
       [ 1,  9],
       [ 2, 10],
       [ 3, 11]])

In [155]: c[0,1]=28

In [156]: c
Out[156]: 
array([[ 0, 28],
       [ 1,  9],
       [ 2, 10],
       [ 3, 11]])

In [157]: m
Out[157]: 
array([[ 0,  4, 18, 12],
       [ 1,  5,  9, 13],
       [ 2,  6, 10, 14],
       [ 3,  7, 11, 15]])


/ 13	. 

In [158]: x=np.array([1,2,3])

In [163]: x.reshape(3,1)
Out[163]: 
array([[1],
       [2],
       [3]])

In [164]: x
Out[164]: array([1, 2, 3])

/ je moet de reshape dus wel save	,

/ Intermezzo

In [185]: m=np.arange(16)

In [186]: m.shape
Out[186]: (16,)

In [187]: n=m.reshape(1,16)

In [188]: n.shape
Out[188]: (1, 16)

In [189]: n2=m.reshape(16,1)

In [190]: n2.shape
Out[190]: (16, 1)




/ Einde Intermezzo


/ Intermezzo

In [230]: af=np.array([[1,2],[3,4]],order="F")

In [231]: af.flatten(order="K")
Out[231]: array([1, 3, 2, 4])

In [232]: ac=np.array([[1,2],[3,4]],order="C")

In [233]: ac.flatten(order="K")
Out[233]: array([1, 2, 3, 4])

In [234]: af
Out[234]: 
array([[1, 2],
       [3, 4]])

In [235]: ac
Out[235]: 
array([[1, 2],
       [3, 4]])


/ 13 .

In [237]: at=ac.transpose()

In [238]: at
Out[238]: 
array([[1, 3],
       [2, 4]])

In [239]: at.flatten(order="K")
Out[239]: array([1, 2, 3, 4])

/ 13. 

In [255]: bf=np.reshape(np.arange(1,5),newshape=(2,2),order='F')

In [256]: bc=np.reshape(np.arange(1,5),newshape=(2,2),order='C')

In [257]: bf.flatten("K")
Out[257]: array([1, 2, 3, 4])

In [258]: bc.flatten("K")
Out[258]: array([1, 2, 3, 4])

n [259]: bf
Out[259]: 
array([[1, 3],
       [2, 4]])

In [260]: bc
Out[260]: 
array([[1, 2],
       [3, 4]])

/ 13	. 

In [268]: af
Out[268]: 
array([[1, 2],
       [3, 4]])

In [269]: np.reshape(af,newshape=(2,2),order="C")
Out[269]: 
array([[1, 2],
       [3, 4]])

In [270]: np.reshape(af,newshape=(2,2),order="F")
Out[270]: 
array([[1, 2],
       [3, 4]])

In [271]: af.flatten("C")
Out[271]: array([1, 2, 3, 4])

In [272]: af.flatten("F")
Out[272]: array([1, 3, 2, 4])

In [273]: af.flatten("K")
Out[273]: array([1, 3, 2, 4])

/ 13	. 

In [278]: np.reshape(af,newshape=(1,4),order="C")
Out[278]: array([[1, 2, 3, 4]])

In [279]: ac
Out[279]: 
array([[1, 2],
       [3, 4]])

In [280]: np.reshape(ac,newshape=(1,4),order="C")
Out[280]: array([[1, 2, 3, 4]])

In [281]: af
Out[281]: 
array([[1, 2],
       [3, 4]])



/ Einde Intermezzo

/ lees	,
https://cloud.google.com/appengine/docs/standard/python/tools/setting-up-eclipse

/ Intermezzo

/ we download	,
https://github.com/numpy/numpy/tree/v1.14.5

[eric@almond numpy]$ pwd
/home/eric/Devel/python/numpy
[eric@almond numpy]$  git checkout v1.14.5
/ we moeten nog een branch maken	, 
/ TODO

[eric@almond numpy]$ less ./numpy/core/tests/test_multiarray.py
...

/ lees ook	,
./numpy/core/src/multiarray/arrayobject.c
./numpy/core/src/multiarray/multiarraymodule.c

In [312]:  dt=np.dtype("i4,(2,3)f8,f4")
In [315]: a=np.zeros((2,2),dtype=dt)

In [316]: a
Out[316]: 
array([[(0, [[0., 0., 0.], [0., 0., 0.]], 0.),
        (0, [[0., 0., 0.], [0., 0., 0.]], 0.)],
       [(0, [[0., 0., 0.], [0., 0., 0.]], 0.),
        (0, [[0., 0., 0.], [0., 0., 0.]], 0.)]],
      dtype=[('f0', '<i4'), ('f1', '<f8', (2, 3)), ('f2', '<f4')])

/ lees	,
https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.dtypes.html

/ i = signed int	, u= unsigned int	,
/ i4 = WH int32	,

/ we proberen	,
class TestStructured(object):
    def test_subarray_field_access(self):
        a = np.zeros((3, 5), dtype=[('a', ('i4', (2, 2)))])
        a['a'] = np.arange(60).reshape(3, 5, 2, 2)

/ we doen	,
In [330]: dt=np.dtype([('name',('i4',(2,2)))])

/ dit kan	,
In [335]: arr=np.zeros((1,2),dtype=dt)
In [336]: arr
Out[336]: 
array([[([[0, 0], [0, 0]],), ([[0, 0], [0, 0]],)]],
      dtype=[('name', '<i4', (2, 2))])

/ en dit kan	,
In [337]: arr['name']=np.arange(1,9).reshape(1,2,2,2)
In [338]: arr
Out[338]: 
array([[([[1, 2], [3, 4]],), ([[5, 6], [7, 8]],)]],
      dtype=[('name', '<i4', (2, 2))])

/ de 1ste keer zonder 'name', 	de 2de keer met	,
/ TODO




/ Einde Intermezzo

/ Intermezzo

/ mckinney boek(456)

In [344]: arr_c=np.ones((10,10),order="C")

In [345]: arr_f=np.ones((10,10),order="F")

In [346]: arr_c.flags
Out[346]: 
  C_CONTIGUOUS : True
  F_CONTIGUOUS : False
  OWNDATA : True
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False

In [347]: arr_f.flags
Out[347]: 
  C_CONTIGUOUS : False
  F_CONTIGUOUS : True
  OWNDATA : True
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False

In [348]: arr_f.copy("C").flags
Out[348]: 
  C_CONTIGUOUS : True
  F_CONTIGUOUS : False
  OWNDATA : True
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False

In [350]: arr_c[:5]
/=
In [351]: arr_c[:5,:]
Out[351]: 
array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])

In [352]: arr_c[:5,:].flags
Out[352]: 
  C_CONTIGUOUS : True
  F_CONTIGUOUS : False
  OWNDATA : False
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False

In [353]: arr_c[:,:5]
Out[353]: 
array([[1., 1., 1., 1., 1.],
       [1., 1., 1., 1., 1.],
       [1., 1., 1., 1., 1.],
       [1., 1., 1., 1., 1.],
       [1., 1., 1., 1., 1.],
       [1., 1., 1., 1., 1.],
       [1., 1., 1., 1., 1.],
       [1., 1., 1., 1., 1.],
       [1., 1., 1., 1., 1.],
       [1., 1., 1., 1., 1.]])

In [354]: arr_c[:,:5].flags
Out[354]: 
  C_CONTIGUOUS : False
  F_CONTIGUOUS : False
  OWNDATA : False
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False

/ Einde Intermezzo

/ Intermezzo

/ kijk naar verschil:

In [355]: a=np.arange(9).reshape((3,3))
In [356]: a
Out[356]: 
array([[0, 1, 2],
       [3, 4, 5],
       [6, 7, 8]])

In [357]: a.flags
Out[357]: 
  C_CONTIGUOUS : True
  F_CONTIGUOUS : False
  OWNDATA : False
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False

In [358]: ar=np.reshape(a,newshape=(3,3),order="F")			# doet NIETS	,
In [366]: ar.flags
Out[366]: 
  C_CONTIGUOUS : True
  F_CONTIGUOUS : False
  OWNDATA : False
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False
In [367]: ar
Out[367]: 
array([[0, 1, 2],
       [3, 4, 5],
       [6, 7, 8]])


/ 13	. 

In [362]: ar=np.reshape(np.arange(9),newshape=(3,3),order="F")
In [369]: ar.flags
Out[369]: 
  C_CONTIGUOUS : False
  F_CONTIGUOUS : True
  OWNDATA : False
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False

In [370]: ar
Out[370]: 
array([[0, 3, 6],
       [1, 4, 7],
       [2, 5, 8]])


/ maar 	deze wel	,


/ 13	. 

In [388]: b=np.array(np.arange(12))
/=WH 
In [388]: b=np.arange(12)

In [389]: b
Out[389]: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])

In [400]: b .flags
Out[400]: 
  C_CONTIGUOUS : True
  F_CONTIGUOUS : True
  OWNDATA : True
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False


In [390]: br=np.reshape(b,newshape=(3,4),order="F")

In [391]: br
Out[391]: 
array([[ 0,  3,  6,  9],
       [ 1,  4,  7, 10],
       [ 2,  5,  8, 11]])

In [392]: br.flags
Out[392]: 
  C_CONTIGUOUS : False
  F_CONTIGUOUS : True
  OWNDATA : False
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False

n [404]: br2=np.reshape(br,newshape=(4,3))

In [405]: br2
Out[405]: 
array([[ 0,  3,  6],
       [ 9,  1,  4],
       [ 7, 10,  2],
       [ 5,  8, 11]])

In [406]: br2.flags
Out[406]: 
  C_CONTIGUOUS : True 	/ !
  F_CONTIGUOUS : False
  OWNDATA : False
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False


In [409]: br3=np.reshape(br,newshape=(4,3),order="F")

In [410]: br3
Out[410]: 
array([[ 0,  4,  8],
       [ 1,  5,  9],
       [ 2,  6, 10],
       [ 3,  7, 11]])

In [411]: br3.flags
Out[411]: 
  C_CONTIGUOUS : False
  F_CONTIGUOUS : True 			/ !
  OWNDATA : False
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False




////////////////////////////////////////////

/ 13	. 

/ lees	,
https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.ravel.html#numpy.ravel
order : {‘C’,’F’, ‘A’, ‘K’}, optional
The elements of a are read using this index order. ‘C’ means to index the elements in row-major, C-style order, with the last axis index changing fastest, back to the first axis index changing slowest. ‘F’ means to index the elements in column-major, Fortran-style order, with the first index changing fastest, and the last index changing slowest. 



In [536]: a=np.arange(12)

In [537]: ar=np.reshape(a,newshape=(4,3),order="C")

In [538]: ar.flatten("K")
Out[538]: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])

In [539]: ar2=np.reshape(a,newshape=(4,3),order="F")

In [540]: ar2.flatten("K")
Out[540]: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])

In [541]: ar
Out[541]: 
array([[ 0,  1,  2],
       [ 3,  4,  5],
       [ 6,  7,  8],
       [ 9, 10, 11]])

In [542]: ar2
Out[542]: 
array([[ 0,  4,  8],
       [ 1,  5,  9],
       [ 2,  6, 10],
       [ 3,  7, 11]])



/ 13	. 

https://docs.scipy.org/doc/numpy-1.14.0/reference/arrays.html
/ we zien: array methods
->
https://docs.scipy.org/doc/numpy-1.14.0/reference/arrays.ndarray.html#array-methods



/ 13	. 

In [372]: a=np.arange(12)

In [373]: a
Out[373]: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])

In [374]: type(a)
Out[374]: numpy.ndarray

In [375]: a.flags
Out[375]: 
  C_CONTIGUOUS : True
  F_CONTIGUOUS : True
  OWNDATA : True
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False

In [376]: ar=np.reshape(a,newshape=(3,4),order="F")

In [378]: ar
Out[378]: 
array([[ 0,  3,  6,  9],
       [ 1,  4,  7, 10],
       [ 2,  5,  8, 11]])

In [381]: ar.flags
Out[381]: 
  C_CONTIGUOUS : False
  F_CONTIGUOUS : True
  OWNDATA : False
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False

In [470]: ar.flatten("K")
Out[470]: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])

/ de mem is op de fortran manier	,


In [379]: ar2=np.reshape(ar,newshape=(3,4),order="C")		

In [472]: ar2
Out[472]: 
array([[ 0,  3,  6,  9],
       [ 1,  4,  7, 10],
       [ 2,  5,  8, 11]])


In [380]: ar2.flags
Out[380]: 
  C_CONTIGUOUS : False
  F_CONTIGUOUS : True
  OWNDATA : False
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False

In [484]: ar2.flatten("K")
Out[484]: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])

In [477]: ar2=np.reshape(ar,newshape=(4,3),order="C")

In [478]: ar2
Out[478]: 
array([[ 0,  3,  6],
       [ 9,  1,  4],
       [ 7, 10,  2],
       [ 5,  8, 11]])

In [479]: ar2.flags
Out[479]: 
  C_CONTIGUOUS : True
  F_CONTIGUOUS : False
  OWNDATA : False
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False

In [480]: ar2.flatten("K")
Out[480]: array([ 0,  3,  6,  9,  1,  4,  7, 10,  2,  5,  8, 11])

/ 13	. 

In [488]:  a=np.arange(12)
In [489]: a
Out[489]: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])
In [491]: a.flags
Out[491]: 
  C_CONTIGUOUS : True
  F_CONTIGUOUS : True
  OWNDATA : True
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False
In [493]: a.flatten("K")
Out[493]: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])

In [494]: ar=np.reshape(a,newshape=(3,4),order="C")

In [495]: ar
Out[495]: 
array([[ 0,  1,  2,  3],
       [ 4,  5,  6,  7],
       [ 8,  9, 10, 11]])

In [496]: ar.flags
Out[496]: 
  C_CONTIGUOUS : True
  F_CONTIGUOUS : False
  OWNDATA : False
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False

In [497]: ar.flatten("K")
Out[497]: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])

/ de memory is op de C manier	,

In [498]: ar2=np.reshape(ar,newshape=(3,4),order="F")

In [499]: ar2
Out[499]: 
array([[ 0,  1,  2,  3],
       [ 4,  5,  6,  7],
       [ 8,  9, 10, 11]])

In [500]: ar2.flags
Out[500]: 
  C_CONTIGUOUS : True
  F_CONTIGUOUS : False
  OWNDATA : False
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False

In [501]: ar2.flatten("K")
Out[501]: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])

/ bij ar2 gebeurt hetzelfde als bij ar3 hieronder	, maar omdat de size=(3,4) blijft hoeft hij niets te doen	,
/ de 1ste kolom blijft 0,4,8	, en de mem blijft op de C manier	,

In [502]: ar3=np.reshape(ar,newshape=(4,3),order="F")

In [503]: ar3
Out[503]: 
array([[ 0,  5, 10],
       [ 4,  9,  3],
       [ 8,  2,  7],
       [ 1,  6, 11]])

In [504]: ar3.flags
Out[504]: 
  C_CONTIGUOUS : False
  F_CONTIGUOUS : True
  OWNDATA : False
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False

In [505]: ar3.flatten("K")
Out[505]: array([ 0,  4,  8,  1,  5,  9,  2,  6, 10,  3,  7, 11])

/ de 1ste kolom wordt 0,4,8,1 en zo gaat hij het ook in mem store	, op de fortran manier	,


/ 13	. 

In [526]: b
Out[526]: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])

In [390]: br=np.reshape(b,newshape=(3,4),order="F")

In [391]: br
Out[391]:
array([[ 0,  3,  6,  9],
       [ 1,  4,  7, 10],
       [ 2,  5,  8, 11]])

In [392]: br.flags
Out[392]:
  C_CONTIGUOUS : False
  F_CONTIGUOUS : True
  OWNDATA : False
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False

In [455]: br.flatten("K")
Out[455]: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])

In [445]: br2=np.reshape(br,newshape=(4,3),order="C")

In [446]: br2
Out[446]: 
array([[ 0,  3,  6],
       [ 9,  1,  4],
       [ 7, 10,  2],
       [ 5,  8, 11]])

In [450]: br2.flags
Out[450]: 
  C_CONTIGUOUS : True
  F_CONTIGUOUS : False
  OWNDATA : False
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False


In [447]: br2.flatten("K")
Out[447]: array([ 0,  3,  6,  9,  1,  4,  7, 10,  2,  5,  8, 11])

/ nieuwe size & nieuwe order -> nieuwe mem 	,


In [458]: e=np.reshape(br,newshape=(4,3),order="F")	 / verander alleen size, laat order f	,

In [459]: e
Out[459]: 
array([[ 0,  4,  8],
       [ 1,  5,  9],
       [ 2,  6, 10],
       [ 3,  7, 11]])

In [460]: e.flags
Out[460]: 
  C_CONTIGUOUS : False
  F_CONTIGUOUS : True
  OWNDATA : False
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False

In [461]: e.flatten("K")
Out[461]: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])
/ de mem blijft onveranderd	,

/ 13	. 

In [536]: a=np.arange(12)

In [537]: ar=np.reshape(a,newshape=(4,3),order="C")

In [541]: ar
Out[541]: 
array([[ 0,  1,  2],
       [ 3,  4,  5],
       [ 6,  7,  8],
       [ 9, 10, 11]])

In [548]: ar.flags
Out[548]: 
  C_CONTIGUOUS : True
  F_CONTIGUOUS : False
  OWNDATA : False
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False

In [543]: ar.ravel()
/=
In [543]: ar.ravel("C")																						/ default	,
Out[543]: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])
In [551]: ar.ravel("F")
Out[551]: array([ 0,  3,  6,  9,  1,  4,  7, 10,  2,  5,  8, 11])

In [538]: ar.flatten("K")
Out[538]: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])

In [539]: ar2=np.reshape(a,newshape=(4,3),order="F")

In [542]: ar2
Out[542]: 
array([[ 0,  4,  8],
       [ 1,  5,  9],
       [ 2,  6, 10],
       [ 3,  7, 11]])

In [549]: ar2.flags
Out[549]: 
  C_CONTIGUOUS : False
  F_CONTIGUOUS : True
  OWNDATA : False
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False


In [540]: ar2.flatten("K")
Out[540]: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])

In [550]: ar2.ravel()
/=
In [550]: ar2.ravel("C")
Out[550]: array([ 0,  4,  8,  1,  5,  9,  2,  6, 10,  3,  7, 11])

In [544]: ar3=np.reshape(ar,newshape=(3,4),order="F")

n [552]: ar3
Out[552]: 
array([[ 0,  9,  7,  5],
       [ 3,  1, 10,  8],
       [ 6,  4,  2, 11]])


In [545]: ar3.flatten("K")
Out[545]: array([ 0,  3,  6,  9,  1,  4,  7, 10,  2,  5,  8, 11])

In [547]: ar3.ravel()
/=
In [547]: ar3.ravel("C")
Out[547]: array([ 0,  9,  7,  5,  3,  1, 10,  8,  6,  4,  2, 11])

/ 13	. 

/ WH hetzelfde:
In [584]: a=np.array(range(12))
/=
In [587]: a=np.arange(12)

/ 13	 .

/ lees	,
https://docs.scipy.org/doc/numpy-1.14.0/reference/index.html
->
https://docs.scipy.org/doc/numpy-1.14.0/reference/arrays.html
->
https://docs.scipy.org/doc/numpy-1.14.0/reference/arrays.ndarray.html#constructing-arrays

In [612]: a=np.array(range(12))

In [613]: ar=a.reshape((4,3),order="F")

In [614]: ar
Out[614]: 
array([[ 0,  4,  8],
       [ 1,  5,  9],
       [ 2,  6, 10],
       [ 3,  7, 11]])

In [615]: ar.flatten("K")
Out[615]: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])

In [616]: ar.flags
Out[616]: 
  C_CONTIGUOUS : False
  F_CONTIGUOUS : True
  OWNDATA : False
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False

/ 13	. 

In [617]: a=np.array(range(12),order="F")

In [618]: a
Out[618]: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])

In [619]: a.shape=(4,3)

In [620]: a
Out[620]: 
array([[ 0,  1,  2],
       [ 3,  4,  5],
       [ 6,  7,  8],
       [ 9, 10, 11]])

In [625]: a.flags
Out[625]: 
  C_CONTIGUOUS : True	  	/ !  Onthoud: TODO 
  F_CONTIGUOUS : False
  OWNDATA : True
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False

In [621]: b=a.T

In [622]: b
Out[622]: 
array([[ 0,  3,  6,  9],
       [ 1,  4,  7, 10],
       [ 2,  5,  8, 11]])

In [623]: b.shape
Out[623]: (3, 4)

In [624]: b.flags
Out[624]: 
  C_CONTIGUOUS : False
  F_CONTIGUOUS : True			/ ! 
  OWNDATA : False
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False

/ 13	. 

//////////////////////////////////////////////////////////////////

/ order="F" heeft alleen zin als a shape heeft met NIET een van de dimensies 1	,


In [94]: a=np.arange(9)
In [96]: a.reshape((3,3),order="F")
Out[96]: 
array([[0, 3, 6],
       [1, 4, 7],
       [2, 5, 8]])

In [82]: a=np.array(np.arange(9),order="F")
/ zinloos	,
/ als a.shape=(1,9) of (9,1) , dan werkt order="F" niet	, see (*) onder	,

In [87]: a=np.array([[1,2],[3,4]],order="F")
/ zin, array is fortran contiguous	,maar bedenk dat de 1ste kolom
(1
(3
/ is	,
In [91]: a.flatten("K")
Out[91]: array([1, 3, 2, 4])

/ (*)

In [94]: a=np.arange(9)
In [101]: a.reshape((9,1),order="F")
Out[101]: 
array([[0],
       [1],
       [2],
       [3],
       [4],
       [5],
       [6],
       [7],
       [8]])

In [102]: a.flags
Out[102]: 
  C_CONTIGUOUS : True
  F_CONTIGUOUS : True
  OWNDATA : True
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False

/ Einde (*)

/ wat ook kan is	,

In [106]:  a=np.array([[1,2],[3,4]],order="F")

In [107]: a.flags
Out[107]: 
  C_CONTIGUOUS : False
  F_CONTIGUOUS : True
	...

/ maar let op dat de 1ste kolom is	,
(1
(3


///////////////////////////////////////////////////////////////////


/ 13	. 

/ lees voorbeelden in	reshape, 
https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.reshape.html#numpy.reshape

/ 13	. 

/ hier staat dat je het array
(1 2
(3 4)
/ als fortran moet zien, dus de 1ste kolom is 
(1
(3
/ en niet 
(1
(2
/ dus in het mem staat 1 3 2 4 omdat we het in deze volgorde hebben ingevoerd	, en de order = f	,en dus 1 de 1ste kolom
(1
(3
/ als we dit array T, dan blijft het mem onveranded 1 3 2 4	, maar wordt de order= c, dus zien we in de 1ste kolom	,
(1 
(2 

In [629]: a=np.array([[1,2],[3,4]],order="F")
In [631]: a.flags
Out[631]: 
  C_CONTIGUOUS : False
  F_CONTIGUOUS : True
  OWNDATA : True
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False

In [633]: a.flatten("K")
Out[633]: array([1, 3, 2, 4])

In [634]: a
Out[634]: 
array([[1, 2],
       [3, 4]])

/ en	,

In [665]: b=a.T

In [666]: b
Out[666]: 
array([[1, 3],
       [2, 4]])

In [667]: b .flags
Out[667]: 
  C_CONTIGUOUS : True
  F_CONTIGUOUS : False
  OWNDATA : False
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False

In [668]: b.flatten("K")
Out[668]: array([1, 3, 2, 4])

/ 1313	. 

In [653]: a=np.array([[1,2],[3,4]],order="C")

In [654]: a.flags
Out[654]: 
  C_CONTIGUOUS : True
  F_CONTIGUOUS : False
  OWNDATA : True
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False

In [655]: a
Out[655]: 
array([[1, 2],
       [3, 4]])

In [656]: a.flatten("K")
Out[656]: array([1, 2, 3, 4])

/ en	,

In [657]: b=a.T

In [658]: b.flatten("K")
Out[658]: array([1, 2, 3, 4])

In [659]: b.flags
Out[659]: 
  C_CONTIGUOUS : False
  F_CONTIGUOUS : True
  OWNDATA : False
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False

In [660]: b
Out[660]: 
array([[1, 3],
       [2, 4]])

/ 1313	. 

/ CREATE ARRAY WITH SHAPE
/ ORDER=FORTRAN


/ hier wordt WH de order gewoon niet used, is niet toepasbaar op object (= 1ste arg)	,
In [636]: a=np.array([1,2,3,4],order="F") 	/ order="F" is useless	, not used,	

/ Zo moet het:

In [194]:  a=np.arange(9)        
In [193]: a.reshape((3,3),order="F")
Out[193]: 
array([[0, 3, 6],
       [1, 4, 7],
       [2, 5, 8]])
In [202]: r.flags
Out[202]: 
  C_CONTIGUOUS : False
  F_CONTIGUOUS : True
	...
In [203]: r.flatten("K")
Out[203]: array([0, 1, 2, 3, 4, 5, 6, 7, 8])

In [212]: r=np.ones((3,3),order='F')  
/ OK	,
In [213]: r=np.empty((3,3),order='F')  
/ OK	,
In [213]: r=np.zeros((3,3),order='F')  
/ OK	,


/ lees	,
https://stackoverflow.com/questions/4535374/initialize-a-numpy-array


/ 13	. 

/ Hier zien we heel goed het verschil	,

In [213]: a=np.arange(9).reshape(3,3)

In [214]: a
Out[214]: 
array([[0, 1, 2],
       [3, 4, 5],
       [6, 7, 8]])

In [215]: a=np.arange(9).reshape((3,3),order='f')

In [216]: a
Out[216]: 
array([[0, 3, 6],
       [1, 4, 7],
       [2, 5, 8]])

/ 13	 .

/ als je een matrix wilt met gegeven kolommen, kun je die het beste als rijen geven, en dan .T doen:
In [332]: a=np.array([[1,2],[3,4]],order='c').T
n [334]: a.flags
Out[334]: 
  C_CONTIGUOUS : False
  F_CONTIGUOUS : True
  OWNDATA : False
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False

In [335]: a
Out[335]: 
array([[1, 3],
       [2, 4]])

In [336]: a.flatten('k')
Out[336]: array([1, 2, 3, 4])

/ 1313	. 

/ maar het kan ook zo:

In [337]: a=np.arange(1,5).reshape((2,2),order='f')

In [338]: a
Out[338]: 
array([[1, 3],
       [2, 4]])

In [339]: a.flatten('k')
Out[339]: array([1, 2, 3, 4])

In [340]: a.flags
Out[340]: 
  C_CONTIGUOUS : False
  F_CONTIGUOUS : True
  OWNDATA : False
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False

/ 13	 .

/ lees over indexes	,
https://stackoverflow.com/questions/22053050/difference-between-numpy-array-shape-r-1-and-r

/ ook: (3,) betekent (3)	, dus een vector van 3 lang	,


/ Einde CREATE ARRAY WITH SHAPE
/ Einde ORDER=FORTRAN

/////////////////////////////////


/ Einde Intermezzo

/ Intermezzo

/ 13	. 

/ lees	,
https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.reshape.html#numpy.reshape

numpy.reshape(a, newshape, order='C')[source]
/ order='C' betekent: default is 'C'	,

/ er zijn positional arguments, en keyword arguments	,
/ bij keyword arguments maakt de volgorde niet uit	,
/ regel: na een keyword arg mogen alleen keyword args	,


/ 3 positional arguments	,
In [226]: b=np.arange(9)
In [234]: np.reshape(b,(3,3),'F')
Out[234]: 
array([[0, 3, 6],
       [1, 4, 7],
       [2, 5, 8]])
/ OK	,

/ 1 positional arg, 2 keyword args	,
In [241]: np.reshape(a=b,newshape=(3,3),order='F')
/ of	,
In [252]: np.reshape(a=b,order='F',newshape=(3,3))
/ OK	, 


In [241]: np.reshape(b,newshape=(3,3),order='F')
/ OK	, 
In [242]: np.reshape(b,(3,3),order='F')
/ OK	,
In [243]: np.reshape(b,newshape=(3,3),'F')
/ ERR
SyntaxError: positional argument follows keyword argument

/ 13	. 

/ er is ook de functie numpy.ndarray.reshape(shape,order='C')

/ let op verschil numpy.reshape(a,newshape,order='C') en numpy.ndarray.reshape(shape,order='C')


In [246]: b.reshape((3,3),order='F')
/ of	,
In [246]: b.reshape(3,3,order='F')
/ OK	,
In [247]: b.reshape((3,3),'F')
/ ERR	,
TypeError: 'tuple' object cannot be interpreted as an integer
In [274]: b.reshape(shape=(3,3),order='F')
TypeError: function takes at most 1 argument (2 given)
In [275]: b.reshape(3,3,'F')
TypeError: 'str' object cannot be interpreted as an integer

/ deze fct kan een aantal ints als arg hebben	, 
/ dus als je geen keyword args hebt, verwacht hij ints	, en daarom b.reshape((3,3),'F') is ERR	, omdat (3,3) geen int is, en omdat 'F' geen int is	,
/ b.reshape(shape=(3,3),order='F') 
/ TODO (waarom ERR) 

/ Einde Intermezzo

/ 13	. 

In [226]: b=np.arange(9)
In [234]: np.reshape(b,(3,3),'F')
Out[234]: 
array([[0, 3, 6],
       [1, 4, 7],
       [2, 5, 8]])
/ we hoeven geen order= of newshape= 

/ lees	,
https://stackoverflow.com/questions/4535374/initialize-a-numpy-array

/ (28)

/ ^ is xor	,

/ 3>>1=1 (rond naar beneden af)	,
/ 1>>1=0
/ 2>>1=1
/ en 	,
/ 3^1=2
/ 2^1=3

In [698]: [j^(j>>0)for j in range(4)]
Out[698]: [0, 0, 0, 0]

In [699]: [j^(j>>1)for j in range(4)]
Out[699]: [0, 1, 3, 2]

In [700]: [j^(j>>2)for j in range(4)]
Out[700]: [0, 1, 2, 3]

In [701]: %load_ext line_profiler
In [704]: %lprun -f sum_of_lists sum_of_lists(500000)
Timer unit: 1e-06 s

Total time: 0.610975 s
File: <ipython-input-681-fde2563d2945>
Function: sum_of_lists at line 1

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
     1                                           def sum_of_lists(N):
     2         1          5.0      5.0      0.0      t=0
     3         6         26.0      4.3      0.0      for i in range(5):
     4         5     592177.0 118435.4     96.9          L=[j^(j>>i) for j in range(N)]
     5         5      18766.0   3753.2      3.1          t+=sum(L)
     6         1          1.0      1.0      0.0      return t

/  (47)

In [4]: a=np.array([1,2,3,4])

In [5]: a.flags
Out[5]: 
  C_CONTIGUOUS : True
  F_CONTIGUOUS : True
  OWNDATA : True
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False

In [10]: r=a.reshape(4,1)

In [11]: r
Out[11]: 
array([[1],
       [2],
       [3],
       [4]])

In [15]: r.flags
Out[15]: 
  C_CONTIGUOUS : True
  F_CONTIGUOUS : True
  OWNDATA : False
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False

In [16]: s=a[:,np.newaxis]

In [17]: s
Out[17]: 
array([[1],
       [2],
       [3],
       [4]])

In [18]: s.flags
Out[18]: 
  C_CONTIGUOUS : True
  F_CONTIGUOUS : True
  OWNDATA : False
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False

/ lees over jupyter notebook password,
http://jupyter-notebook.readthedocs.io/en/stable/public_server.html

/ 13	 

/ lees over %load, %writefile	,
https://stackoverflow.com/questions/21034373/how-to-load-edit-run-save-text-files-py-into-an-ipython-notebook-cell

[eric@almond vanderplas]$ cat compute_reciprocals.py 

#import numpy as np

def compute_reciprocals(values):
    output=np.empty(len(values))
    for i in range(len(values)):
        output[i]=1.0/values[i]
    return output

/ we kunnen met/zonder: import numpy	,
/ als we zonder, dan moeten we in ipython dat alsnog doen, voordat we hem use	, voor de fct def hoeft het niet	,

/ stel we comment out	, 

[eric@almond vanderplas]$ ipython

In [1]: %load compute_reciprocals.py

In [2]: # %load compute_reciprocals.py
   ...: #import numpy as np
   ...: 
   ...: def compute_reciprocals(values):
   ...:     output=np.empty(len(values))
   ...:     for i in range(len(values)):
   ...:         output[i]=1.0/values[i]
   ...:     return output
   ...: 
   ...: 

In [3]: import numpy as np 	# voordat we np.random.seed use hieronder, moeten we dit doen	,

In [4]: np.random.seed(0)

In [6]: v=np.random.randint(1,10,size=5)

In [7]: compute_reciprocals(v)
Out[7]: array([0.16666667, 1.        , 0.25      , 0.25      , 0.125     ])

/ als we wel in compute_reciprocals: import numpy , hoeven we dat niet meer in ipython te doen na de %load	,

/ 1313	. 

/ we kunnen ook alles in 1 keer import	,

$ vi 51.py

import numpy as np

def compute_reciprocals(values):
    output=np.empty(len(values))
    for i in range(len(values)):
        output[i]=1.0/values[i]
    return output

np.random.seed(0)
values=np.random.randint(1,10,size=5)
compute_reciprocals(values)

/ als je deze %load 51.py	, dan zie je meteen	,
Out[7]: array([0.16666667, 1.        , 0.25      , 0.25      , 0.125     ])

/ 13	. 

In [7]: %load compute_reciprocals.py

In [8]: # %load compute_reciprocals.py
   ...: import numpy as np
   ...: 
   ...: def compute_reciprocals(values):
   ...:     output=np.empty(len(values))
   ...:     for i in range(len(values)):
   ...:         output[i]=1.0/values[i]
   ...:     return output
   ...: 
   ...: 

In [9]: values=np.random.randint(1,100,size=1000000)

In [10]: %timeit compute_reciprocals(values)
3.79 s ± 14.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)

/ 1313	. 

/ maar als we 1.0 vervangen door 1	, dus 1/values[i]	, dan 

In [31]: %timeit compute_reciprocals(values)
367 ms ± 8.78 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)

/ TODO

/ 1313	. 

/ dit kan ook:
/ dit zijn juist de ufuncs:

In [38]: values=np.random.randint(1,100,size=100)

In [39]: 1/values
Out[39]: 
array([0.07142857, 0.03030303, 0.01492537, 0.04347826, 0.02702703,
...

/ 1313	. 

In [57]: del compute_reciprocals
In [57]: dir()                  
/ check	,

/ we hebben een groot array values, hoe de 1ste item te zien?
In [62]: values[:10]
Out[62]: array([45, 48, 65, 68, 68, 10, 84, 22, 37, 88])
In [64]: values.size
Out[64]: 1000000

/ 1313	. 


values=np.random.randint(1,100,1000000)

/ we hebben 2 scripts , een met 1/values[i] en een met 1.0/values[i]

[eric@almond vanderplas]$ cat compute_reciprocals_1.py 
import numpy as np
def compute_reciprocals_1(values):
    output=np.empty(len(values))
    for i in range(len(values)):
        output[i]=1/values[i]
    return output

[eric@almond vanderplas]$ cat compute_reciprocals_1_0.py 
import numpy as np
def compute_reciprocals_1_0(values):
    output=np.empty(len(values))
    for i in range(len(values)):
        output[i]=1.0/values[i]
    return output

In [57]: %load compute_reciprocals_1.py
...
In [58]: %load compute_reciprocals_1_0.py
...

In [65]: %timeit 1/values
3.11 ms ± 7.49 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)

In [66]: %timeit 1.0/values
3.11 ms ± 14.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)

In [67]: %timeit compute_reciprocals_1(values)
364 ms ± 8.78 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)

In [68]: %timeit compute_reciprocals_1_0(values)
3.74 s ± 9.57 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)

/ we zien dat ufunct 1.0/values even snel is als 1/values
/ we zien dat ufunc 1.0/values 1000 keer sneller is als for loops 1.0/values[i] 
/ we zien dat ufunc 1/values 100 keer sneller is als for loops 1/values[i] 
/ we zien dat for loop 1/values[i] 10 keer sneller is als loops 1.0/values[i]
/ WH omdat values int64's zijn	, 

/ 1313	 .

/ we nemen array van float64	, ipv int64	,

/ dan nagenoeg gelijk	,

/ oef	,
In [131]: 1+np.random.sample(5,)
Out[131]: array([1.01998767, 1.44171092, 1.97958673, 1.35944446, 1.48089353])

In [136]: a=1+np.random.sample(10000,)

In [137]: %timeit compute_reciprocals_1(a)
3.99 ms ± 18.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)

In [138]: %timeit compute_reciprocals_1_0(a)
2.36 ms ± 27.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)




/ Intermezzo


/ opties %timeit

In [73]: %timeit -r 10 1.0/values
3.12 ms ± 17.7 µs per loop (mean ± std. dev. of 10 runs, 100 loops each)

In [74]: %timeit -n 10 1.0/values
3.15 ms ± 103 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)

/ Einde Intermezzo

/ 1313	 .

n [75]: np.arange(5)/np.arange(1,6)
Out[75]: array([0.        , 0.5       , 0.66666667, 0.75      , 0.8       ])

In [76]: %timeit np.arange(5)/np.arange(1,6)
3.34 µs ± 9.25 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)





/ 1313	. 

/ in een for loop duurt 1.0/values[i] lang omdat hij de juiste / moet vinden: hij moet eerst de types van 1.0 en values[i] bepalen	,


/ 1313	. 

/ lees over ...	,
https://stackoverflow.com/questions/752602/slicing-in-python-expressions-documentation/753260#753260
/ lees over quad	, lambda	,
https://stackoverflow.com/questions/51643687/how-to-use-exp-in-integration-function

/ (52)

In [279]: a=np.arange(9).reshape((3,3),order='f')

In [280]: a
Out[280]: 
array([[0, 3, 6],
       [1, 4, 7],
       [2, 5, 8]])

In [283]: a**2
Out[283]: 
array([[ 0,  9, 36],
       [ 1, 16, 49],
       [ 4, 25, 64]])

/ (53) 

n [281]: a=np.arange(9).reshape((3,3),order='f')

In [282]: a
Out[282]: 
array([[0, 3, 6],
       [1, 4, 7],
       [2, 5, 8]])

In [291]: a//3
Out[291]: 
array([[0, 1, 2],
       [0, 1, 2],
       [0, 1, 2]])

In [292]: a%3
Out[292]: 
array([[0, 0, 0],
       [1, 1, 1],
       [2, 2, 2]])

In [293]:  a+2
/=
In [294]: np.add(a,2)
Out[294]: 
array([[ 2,  5,  8],
       [ 3,  6,  9],
       [ 4,  7, 10]])

/ (54)

In [297]:  b=a-5

In [298]: b
Out[298]: 
array([[-5, -2,  1],
       [-4, -1,  2],
       [-3,  0,  3]])

In [299]: np.abs(b)
Out[299]: 
array([[5, 2, 1],
       [4, 1, 2],
       [3, 0, 3]])

/ er is GEEN |b|	,

/ Intermezzo

In [306]: np.linspace(0,10,10+1)
Out[306]: array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])

In [307]: np.linspace(1,10,10)
Out[307]: array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])

/ Einde Intermezzo

/ bovenkant cirkel	,
In [312]: theta=np.linspace(0,np.pi,6+1)

In [313]: np.sin(theta)
Out[313]: 
array([0.00000000e+00, 5.00000000e-01, 8.66025404e-01, 1.00000000e+00,
       8.66025404e-01, 5.00000000e-01, 1.22464680e-16])

In [315]: np.sqrt(3)/2
Out[315]: 0.8660254037844386

In [319]: np.exp?
/ voorbeeld matplotlib	,
/ TODO

/ je kunt geven	,
np.info(np.sin)
/ of	,
np.sin?

/ 1313	. 

/ np.power	,

In [354]: np.power(2,np.arange(9).reshape(3,3,order='f'))
Out[354]: 
array([[  1,   8,  64],
       [  2,  16, 128],
       [  4,  32, 256]])
/ je kunt ook ** use	,

/ 2 of [2] als 1ste arg	, het 2de array kan alle shapes hebben	,  
/ als 1ste array length>1	, dan moet shape 2de array passen	, 

In [406]: r=np.arange(2,5)
In [407]: c=r.reshape(3,1)						# c=r.T werkt NIET	,
In [408]: er=np.arange(9).reshape(3,3)
In [409]: ec=er.T

In [414]: r
Out[414]: array([2, 3, 4])
In [415]: er
Out[415]: 
array([[0, 1, 2],
       [3, 4, 5],
       [6, 7, 8]])
In [437]: r**er
Out[437]: 
array([[    1,     3,    16],
       [    8,    81,  1024],
       [   64,  2187, 65536]])

In [428]: c
Out[428]: 
array([[2],
       [3],
       [4]])
In [429]: er
Out[429]: 
array([[0, 1, 2],
       [3, 4, 5],
       [6, 7, 8]])
In [438]: c**er
Out[438]: 
array([[    1,     2,     4],
       [   27,    81,   243],
       [ 4096, 16384, 65536]])

In [431]: r
Out[431]: array([2, 3, 4])
In [432]: ec
Out[432]: 
array([[0, 3, 6],
       [1, 4, 7],
       [2, 5, 8]])
In [439]: r**ec
Out[439]: 
array([[    1,    27,  4096],
       [    2,    81, 16384],
       [    4,   243, 65536]])

In [434]: c
Out[434]: 
array([[2],
       [3],
       [4]])
In [435]: ec
Out[435]: 
array([[0, 3, 6],
       [1, 4, 7],
       [2, 5, 8]])
In [440]: c**ec
Out[440]: 
array([[    1,     8,    64],
       [    3,    81,  2187],
       [   16,  1024, 65536]])

/ 13	. 

/ lees over *args, **kwargs	,
https://www.saltycrane.com/blog/2008/01/how-to-use-args-and-kwargs-in-python/

/ (57). 

In [458]: x=np.arange(5)

In [459]: y=np.empty(10)

In [460]: np.power(2,x,out=y[::2])
Out[460]: array([ 1.,  2.,  4.,  8., 16.])

In [461]: y
Out[461]: array([ 1.,  0.,  2.,  0.,  4.,  0.,  8.,  0., 16.,  0.])

/ 1313	. 

In [456]: y[::2]=2**x

In [457]: y
Out[457]: array([ 1.,  0.,  2.,  0.,  4.,  0.,  8.,  0., 16.,  0.])

/ dit kan ook, maar dan is er een temp array	, lijkt op zoals in C++	,

/ (58)

/ tensors	,

In [485]: r=np.arange(1,4)

In [486]: r
Out[486]: array([1, 2, 3])

In [487]: r2=np.arange(5,8)

In [488]: r2
Out[488]: array([5, 6, 7])

In [489]: c=r.reshape(3,1)

In [490]: c2=r2.reshape(3,1)

In [511]: tcc2=np.multiply.outer(c,c2)

In [514]: tcc2
Out[514]: 
array([[[[ 5],
         [ 6],
         [ 7]]],


       [[[10],
         [12],
         [14]]],


       [[[15],
         [18],
         [21]]]])


In [512]: tcc2.flags
Out[512]: 
  C_CONTIGUOUS : True
  F_CONTIGUOUS : False
  OWNDATA : True
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False

In [513]: tcc2.shape
Out[513]: (3, 1, 3, 1)

/ de getallen zijn OK, als je tensor product berekent:

1   5 	5  10  15
2 . 6 = 6  12	 18
3   7   7  14  21

In [515]: trr2=np.multiply.outer(r,r2)

In [516]: trr2
Out[516]: 
array([[ 5,  6,  7],
       [10, 12, 14],
       [15, 18, 21]])

In [517]: trr2.shape
Out[517]: (3, 3)

/ dit is hetzelfde tensor product als boven	, maar T	, en makkelijke shape	,

/ (59)

In [532]: np.random.random is np.random.random_sample
Out[532]: True

In [543]: l=np.random.random_sample(10000)
In [539]: %timeit np.sum(l)
9.77 µs ± 46.4 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)
In [540]: %timeit sum(l)
816 µs ± 3.89 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)
In [546]: %timeit l.sum()
7.45 µs ± 25.6 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)

/ (60)

/ in sum(axis=0): axis is de collapsing axis: dus je berekent de som van de column 	,

In [549]: er
Out[549]: 
array([[0, 1, 2],
       [3, 4, 5],
       [6, 7, 8]])

In [550]: er.sum(axis=0)
Out[550]: array([ 9, 12, 15])

/ (61)

[eric@almond vanderplas]$ find -name president* | xargs -I % cp % .

/ we moeten ! use	,
In [555]: !head -4 president_heights.csv
order,name,height(cm)
1,George Washington,189
2,John Adams,170
3,Thomas Jefferson,189

/ ook in '...' kunnen we TAB	,
In [557]: data = pd.read_csv('president_heights.csv')

In [559]:  data[:5]
Out[559]: 
   order               name  height(cm)
0      1  George Washington         189
1      2         John Adams         170
2      3   Thomas Jefferson         189
3      4      James Madison         163
4      5       James Monroe         183

/ ook in '...' kunnen we TAB	,
In [562]:  data['height(cm)'][:5]
Out[562]: 
0    189
1    170
2    189
3    163
4    183
Name: height(cm), dtype: int64

In [9]: type(data)
Out[9]: pandas.core.frame.DataFrame

In [566]: s=data['height(cm)']

In [567]: type(s)
Out[567]: pandas.core.series.Series

In [569]: s[:5]
Out[569]: 
0    189
1    170
2    189
3    163
4    183
Name: height(cm), dtype: int64

n [572]: a=np.array(s)

In [573]: a[:5]
Out[573]: array([189, 170, 189, 163, 183])

In [575]: a.mean()
Out[575]: 179.73809523809524

In [576]: a.std()
Out[576]: 6.931843442745892

In [577]: a.min()
Out[577]: 163

In [578]: a.max()
Out[578]: 193

n [580]: np.percentile(a,25)
Out[580]: 174.25
/ dus 25% zit onder 174.25

In [581]: np.median(a)
Out[581]: 182.0

In [582]: np.percentile(a,75)
Out[582]: 183.0
/ dus 75% zit onder 174.25

/ Intermezzo

/ %matplotlib geeft ERR in ipython	, 

[eric@almond vanderplas]$ conda install pgi
Solving environment: failed

PackagesNotFoundError: The following packages are not available from current channels:

  - pgi

Current channels:

  - https://repo.anaconda.com/pkgs/main/linux-64
  - https://repo.anaconda.com/pkgs/main/noarch
  - https://repo.anaconda.com/pkgs/free/linux-64
  - https://repo.anaconda.com/pkgs/free/noarch
  - https://repo.anaconda.com/pkgs/r/linux-64
  - https://repo.anaconda.com/pkgs/r/noarch
  - https://repo.anaconda.com/pkgs/pro/linux-64
  - https://repo.anaconda.com/pkgs/pro/noarch

To search for alternate channels that may provide the conda package you're
looking for, navigate to

    https://anaconda.org

and use the search bar at the top of the page.

/ hetzelfde voor: pygobject	,

/ maar met pip lukt het wel	,
/ TODO
[eric@almond vanderplas]$ pip install pgi
Collecting pgi
  Downloading https://files.pythonhosted.org/packages/ed/92/60411ba83f86fa128932466e7ffc86d806d075da64c04d6d45c99a08f4dc/pgi-0.0.11.2.tar.gz (239kB)
    100% |████████████████████████████████| 245kB 1.1MB/s 
Building wheels for collected packages: pgi
  Running setup.py bdist_wheel for pgi ... done
  Stored in directory: /home/eric/.cache/pip/wheels/6e/e9/c9/eaace58bfb7b8b763fe48e1a77477718857259009c3c8e6101
Successfully built pgi
mkl-random 1.0.1 requires cython, which is not installed.
mkl-fft 1.0.0 requires cython, which is not installed.
Installing collected packages: pgi
Successfully installed pgi-0.0.11.2
You are using pip version 10.0.1, however version 18.0 is available.
You should consider upgrading via the 'pip install --upgrade pip' command.

[eric@almond vanderplas]$ conda install cairo
Solving environment: done

## Package Plan ##

  environment location: /home/eric/miniconda3

  added / updated specs: 
    - cairo


The following packages will be downloaded:

    package                    |            build
    ---------------------------|-----------------
    cairo-1.14.12              |       h8948797_3         1.3 MB
    matplotlib-2.2.2           |   py36hb69df0a_2         6.6 MB
    libuuid-1.0.3              |       h1bed415_2          16 KB
    conda-4.5.9                |           py36_0         1.0 MB
    openssl-1.0.2o             |       h14c3975_1         3.4 MB
    qt-5.9.6                   |       h52aff34_0        86.7 MB
    freetype-2.9.1             |       h8a8886c_0         821 KB
    fontconfig-2.13.0          |       h9420a91_0         291 KB
    pixman-0.34.0              |       hceecf20_3         598 KB
    ------------------------------------------------------------
                                           Total:       100.8 MB

The following NEW packages will be INSTALLED:

    cairo:      1.14.12-h8948797_3  
    libuuid:    1.0.3-h1bed415_2    
    pixman:     0.34.0-hceecf20_3   

The following packages will be UPDATED:

    conda:      4.5.4-py36_0         --> 4.5.9-py36_0        
    fontconfig: 2.12.6-h49f89f6_0    --> 2.13.0-h9420a91_0   
    freetype:   2.8-hab7d2ae_1       --> 2.9.1-h8a8886c_0    
    matplotlib: 2.2.2-py36h0e671d2_1 --> 2.2.2-py36hb69df0a_2
    openssl:    1.0.2o-h20670df_0    --> 1.0.2o-h14c3975_1   
    qt:         5.9.5-h7e424d6_0     --> 5.9.6-h52aff34_0    

/ we zien	,
[eric@almond vanderplas]$ ls ~eric/miniconda3/pkgs/ | grep openssl
openssl-1.0.2o-h14c3975_1
...
[eric@almond vanderplas]$ ls ~eric/miniconda3/lib/python3.6/site-packages/  | grep pgi
pgi
...

/ lees	,
https://pypi.org/project/pgi/
https://pygobject.readthedocs.io/en/latest/

/ lees	,
https://conda.io/docs/user-guide/tasks/manage-pkgs.html
/ use de pip uit de conda env	,
/ we kunnen de conda installed en de pip installed pkgs zien met $ conda list	,
$ conda list
cairo                     1.14.12              h8948797_3  
pgi                       0.0.11.2                  <pip>

/ ga naar anaconda, en zoek	,
https://anaconda.org/search?q=pygobject
/ pgi is er niet, maar pygobject wel	,
/ welke pygobject moet je nemen?
/ TODO

/ na deze installs	, als we ipython opnieuw start	,

In [1]: %matplotlib
Using matplotlib backend: Qt5Agg

/ maak nog eens een nieuwe env, en kijk wat nodig was hiervoor	,
/ TODO

/ Einde Intermezzo

/ (62)

In [1]: %matplotlib
Using matplotlib backend: Qt5Agg

In [3]: import matplotlib.pyplot as plt

In [4]: import seaborn

In [5]: seaborn.set()

In [7]: import pandas as pd

In [8]: data=pd.read_csv('president_heights.csv')

In [9]: type(data)
Out[9]: pandas.core.frame.DataFrame

In [10]: s=data['height(cm)']
    ...: 

In [11]: s[:5]
Out[11]: 
0    189
1    170
2    189
3    163
4    183
Name: height(cm), dtype: int64

In [12]: import numpy as np

In [13]: a=np.array(s)

In [14]: plt.hist(a)
Out[14]: 
(array([ 1.,  2.,  3.,  5.,  3.,  6., 12.,  3.,  5.,  2.]),
 array([163., 166., 169., 172., 175., 178., 181., 184., 187., 190., 193.]),
 <a list of 10 Patch objects>)
/ we zien de grafiek al	,

In [15]: plt.title('Height distribution of US Presidents')
Out[15]: Text(0.5,1,'Height distribution of US Presidents')
/ komt in de grafiek erbij	,

In [16]: plt.xlabel('height(cm)')
Out[16]: Text(0.5,23.5222,'height(cm)')
/ komt erbij,

In [17]: plt.ylabel('number')
Out[17]: Text(47.0972,0.5,'number')
/ komt erbij	,

/ klik de grafiek weg	, en ga verder in ipython	,

/ 13	. 

/ in de notebook werkt het ook OK	, doe daar	,
> %matplotlib inline

/ (64)

/ lees	,
https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.indexing.html

Each newaxis object in the selection tuple serves to expand the dimensions of the resulting selection by one unit-length dimension. The added dimension is the position of the newaxis object in the selection tuple.

In [18]: a=np.arange(3)
In [24]: a.shape
Out[24]: (3,)
/ 1 dimensie	,

In [19]: b=np.arange(3,6)[:,np.newaxis]
In [22]: b.shape
Out[22]: (3, 1)

In [25]:   c=np.arange(3)[:,np.newaxis,np.newaxis]
In [27]: c.shape
Out[27]: (3, 1, 1)

In [35]: d=np.arange(9,12)[np.newaxis,:]
In [37]: d.shape
Out[37]: (1, 3)


In [31]: a
Out[31]: array([0, 1, 2])

In [32]: b
Out[32]: 
array([[3],
       [4],
       [5]])

In [44]: a*b
/ of	,
In [44]: b*a
Out[44]: 
array([[ 0,  3,  6],
       [ 0,  4,  8],
       [ 0,  5, 10]])


In [26]: c
Out[26]: 
array([[[6]],

       [[7]],

       [[8]]])

In [48]: a*c
/ of	,
In [48]: c*a

Out[48]: 
array([[[ 0,  6, 12]],

       [[ 0,  7, 14]],

       [[ 0,  8, 16]]])


In [36]: d
Out[36]: array([[9, 10, 11]])

In [52]: a*d
Out[52]: array([[ 0, 10, 22]])

In [52]: a*d
/ of	,
In [52]: d*a
Out[52]: array([[ 0, 10, 22]])




In [29]: a.flags
In [29]: b.flags
In [29]: c.flags
In [29]: d.flags
Out[29]: 
  C_CONTIGUOUS : True
  F_CONTIGUOUS : True
  OWNDATA : False
  WRITEABLE : True
  ALIGNED : True
  WRITEBACKIFCOPY : False
  UPDATEIFCOPY : False

/ Intermezzo

/ we maken een 3 dim array:

In [71]: j=np.array([[[1,2],[3,4]],[[5,6],[7,8]]])

In [72]: j
Out[72]: 
array([[[1, 2],
        [3, 4]],

       [[5, 6],
        [7, 8]]])

In [74]: j.shape
Out[74]: (2, 2, 2)

In [75]:  j.flags
Out[75]: 
  C_CONTIGUOUS : True
  F_CONTIGUOUS : False

In [76]: k=j.T

In [77]: k.flags
Out[77]: 
  C_CONTIGUOUS : False
  F_CONTIGUOUS : True

In [78]: k
Out[78]: 
array([[[1, 5],
        [3, 7]],

       [[2, 6],
        [4, 8]]])

In [79]: j.flatten('k')
Out[79]: array([1, 2, 3, 4, 5, 6, 7, 8])

In [80]: k.flatten('k')
Out[80]: array([1, 2, 3, 4, 5, 6, 7, 8])

/ wat gebeurt er bij .T? De hoofdvlak (3 dim hoofddiagonaal) is 
1 6
3 8
/ daar spiegel je in	, dus worden verwisseld:
2 en 5
4 	 7

/ Einde Intermezzo

/ Intermezzo

/ we maken een 4 dim array:

In [71]: l=np.array([[[[1,2],[3,4]],[[5,6],[7,8]]],[[[11,12],[13,14]],[[15,16],[17,18]]]])

In [82]: l
Out[82]: 
array([[[[ 1,  2],
         [ 3,  4]],

        [[ 5,  6],
         [ 7,  8]]],


       [[[11, 12],
         [13, 14]],

        [[15, 16],
         [17, 18]]]])

In [83]: l.shape
Out[83]: (2, 2, 2, 2)

/ Einde Intermezzo

/ (69)

In [123]: x=np.linspace(0,2,13)*np.pi

In [124]: x
Out[124]: 
array([0.        , 0.52359878, 1.04719755, 1.57079633, 2.0943951 ,
       2.61799388, 3.14159265, 3.66519143, 4.1887902 , 4.71238898,
       5.23598776, 5.75958653, 6.28318531])

In [125]: y=x[:,np.newaxis]

In [126]: y
Out[126]: 
array([[0.        ],
       [0.52359878],
       [1.04719755],
       [1.57079633],
       [2.0943951 ],
       [2.61799388],
       [3.14159265],
       [3.66519143],
       [4.1887902 ],
       [4.71238898],
       [5.23598776],
       [5.75958653],
       [6.28318531]])

In [127]: z=np.sin(x)+np.cos(y)

In [128]: z
Out[128]: 
array([[ 1.00000000e+00,  1.50000000e+00,  1.86602540e+00,
         2.00000000e+00,  1.86602540e+00,  1.50000000e+00,
         1.00000000e+00,  5.00000000e-01,  1.33974596e-01,
         0.00000000e+00,  1.33974596e-01,  5.00000000e-01,
         1.00000000e+00],
       [ 8.66025404e-01,  1.36602540e+00,  1.73205081e+00,
         1.86602540e+00,  1.73205081e+00,  1.36602540e+00,
         8.66025404e-01,  3.66025404e-01,  3.33066907e-16,
        -1.33974596e-01, -3.33066907e-16,  3.66025404e-01,
         8.66025404e-01],
       [ 5.00000000e-01,  1.00000000e+00,  1.36602540e+00,
         1.50000000e+00,  1.36602540e+00,  1.00000000e+00,
         5.00000000e-01,  7.21644966e-16, -3.66025404e-01,
        -5.00000000e-01, -3.66025404e-01, -3.33066907e-16,
         5.00000000e-01],
       [ 6.12323400e-17,  5.00000000e-01,  8.66025404e-01,
         1.00000000e+00,  8.66025404e-01,  5.00000000e-01,
         1.83697020e-16, -5.00000000e-01, -8.66025404e-01,
        -1.00000000e+00, -8.66025404e-01, -5.00000000e-01,
        -1.83697020e-16],
       [-5.00000000e-01,  1.66533454e-16,  3.66025404e-01,
         5.00000000e-01,  3.66025404e-01,  5.55111512e-16,
        -5.00000000e-01, -1.00000000e+00, -1.36602540e+00,
        -1.50000000e+00, -1.36602540e+00, -1.00000000e+00,
        -5.00000000e-01],
       [-8.66025404e-01, -3.66025404e-01,  1.11022302e-16,
         1.33974596e-01,  2.22044605e-16, -3.66025404e-01,
        -8.66025404e-01, -1.36602540e+00, -1.73205081e+00,
        -1.86602540e+00, -1.73205081e+00, -1.36602540e+00,
        -8.66025404e-01],
       [-1.00000000e+00, -5.00000000e-01, -1.33974596e-01,
         0.00000000e+00, -1.33974596e-01, -5.00000000e-01,
        -1.00000000e+00, -1.50000000e+00, -1.86602540e+00,
        -2.00000000e+00, -1.86602540e+00, -1.50000000e+00,
        -1.00000000e+00],
       [-8.66025404e-01, -3.66025404e-01, -4.44089210e-16,
         1.33974596e-01, -3.33066907e-16, -3.66025404e-01,
        -8.66025404e-01, -1.36602540e+00, -1.73205081e+00,
        -1.86602540e+00, -1.73205081e+00, -1.36602540e+00,
        -8.66025404e-01],
       [-5.00000000e-01, -4.99600361e-16,  3.66025404e-01,
         5.00000000e-01,  3.66025404e-01, -1.11022302e-16,
        -5.00000000e-01, -1.00000000e+00, -1.36602540e+00,
        -1.50000000e+00, -1.36602540e+00, -1.00000000e+00,
        -5.00000000e-01],
       [-1.83697020e-16,  5.00000000e-01,  8.66025404e-01,
         1.00000000e+00,  8.66025404e-01,  5.00000000e-01,
        -6.12323400e-17, -5.00000000e-01, -8.66025404e-01,
        -1.00000000e+00, -8.66025404e-01, -5.00000000e-01,
        -4.28626380e-16],
       [ 5.00000000e-01,  1.00000000e+00,  1.36602540e+00,
         1.50000000e+00,  1.36602540e+00,  1.00000000e+00,
         5.00000000e-01, -5.55111512e-17, -3.66025404e-01,
        -5.00000000e-01, -3.66025404e-01, -1.11022302e-15,
         5.00000000e-01],
       [ 8.66025404e-01,  1.36602540e+00,  1.73205081e+00,
         1.86602540e+00,  1.73205081e+00,  1.36602540e+00,
         8.66025404e-01,  3.66025404e-01,  0.00000000e+00,
        -1.33974596e-01, -6.66133815e-16,  3.66025404e-01,
         8.66025404e-01],
       [ 1.00000000e+00,  1.50000000e+00,  1.86602540e+00,
         2.00000000e+00,  1.86602540e+00,  1.50000000e+00,
         1.00000000e+00,  5.00000000e-01,  1.33974596e-01,
         0.00000000e+00,  1.33974596e-01,  5.00000000e-01,
         1.00000000e+00]])

In [149]: x+y
Out[149]: 
array([[ 0.        ,  0.52359878,  1.04719755,  1.57079633,  2.0943951 ,
         2.61799388,  3.14159265,  3.66519143,  4.1887902 ,  4.71238898,
         5.23598776,  5.75958653,  6.28318531],
       [ 0.52359878,  1.04719755,  1.57079633,  2.0943951 ,  2.61799388,
         3.14159265,  3.66519143,  4.1887902 ,  4.71238898,  5.23598776,
         5.75958653,  6.28318531,  6.80678408],
       [ 1.04719755,  1.57079633,  2.0943951 ,  2.61799388,  3.14159265,
         3.66519143,  4.1887902 ,  4.71238898,  5.23598776,  5.75958653,
         6.28318531,  6.80678408,  7.33038286],
       [ 1.57079633,  2.0943951 ,  2.61799388,  3.14159265,  3.66519143,
         4.1887902 ,  4.71238898,  5.23598776,  5.75958653,  6.28318531,
         6.80678408,  7.33038286,  7.85398163],
       [ 2.0943951 ,  2.61799388,  3.14159265,  3.66519143,  4.1887902 ,
         4.71238898,  5.23598776,  5.75958653,  6.28318531,  6.80678408,
         7.33038286,  7.85398163,  8.37758041],
       [ 2.61799388,  3.14159265,  3.66519143,  4.1887902 ,  4.71238898,
         5.23598776,  5.75958653,  6.28318531,  6.80678408,  7.33038286,
         7.85398163,  8.37758041,  8.90117919],
       [ 3.14159265,  3.66519143,  4.1887902 ,  4.71238898,  5.23598776,
         5.75958653,  6.28318531,  6.80678408,  7.33038286,  7.85398163,
         8.37758041,  8.90117919,  9.42477796],
       [ 3.66519143,  4.1887902 ,  4.71238898,  5.23598776,  5.75958653,
         6.28318531,  6.80678408,  7.33038286,  7.85398163,  8.37758041,
         8.90117919,  9.42477796,  9.94837674],
       [ 4.1887902 ,  4.71238898,  5.23598776,  5.75958653,  6.28318531,
         6.80678408,  7.33038286,  7.85398163,  8.37758041,  8.90117919,
         9.42477796,  9.94837674, 10.47197551],
       [ 4.71238898,  5.23598776,  5.75958653,  6.28318531,  6.80678408,
         7.33038286,  7.85398163,  8.37758041,  8.90117919,  9.42477796,
         9.94837674, 10.47197551, 10.99557429],
       [ 5.23598776,  5.75958653,  6.28318531,  6.80678408,  7.33038286,
         7.85398163,  8.37758041,  8.90117919,  9.42477796,  9.94837674,
        10.47197551, 10.99557429, 11.51917306],
       [ 5.75958653,  6.28318531,  6.80678408,  7.33038286,  7.85398163,
         8.37758041,  8.90117919,  9.42477796,  9.94837674, 10.47197551,
        10.99557429, 11.51917306, 12.04277184],
       [ 6.28318531,  6.80678408,  7.33038286,  7.85398163,  8.37758041,
         8.90117919,  9.42477796,  9.94837674, 10.47197551, 10.99557429,
        11.51917306, 12.04277184, 12.56637061]])

In [157]: z
Out[157]: 
array([[ 1.00000000e+00,  1.50000000e+00,  1.86602540e+00,
         2.00000000e+00,  1.86602540e+00,  1.50000000e+00,
         1.00000000e+00,  5.00000000e-01,  1.33974596e-01,
         0.00000000e+00,  1.33974596e-01,  5.00000000e-01,
         1.00000000e+00],
       [ 8.66025404e-01,  1.36602540e+00,  1.73205081e+00,
         1.86602540e+00,  1.73205081e+00,  1.36602540e+00,
         8.66025404e-01,  3.66025404e-01,  3.33066907e-16,
        -1.33974596e-01, -3.33066907e-16,  3.66025404e-01,
         8.66025404e-01],
       [ 5.00000000e-01,  1.00000000e+00,  1.36602540e+00,
         1.50000000e+00,  1.36602540e+00,  1.00000000e+00,
         5.00000000e-01,  7.21644966e-16, -3.66025404e-01,
        -5.00000000e-01, -3.66025404e-01, -3.33066907e-16,
         5.00000000e-01],
       [ 6.12323400e-17,  5.00000000e-01,  8.66025404e-01,
         1.00000000e+00,  8.66025404e-01,  5.00000000e-01,
         1.83697020e-16, -5.00000000e-01, -8.66025404e-01,
        -1.00000000e+00, -8.66025404e-01, -5.00000000e-01,
        -1.83697020e-16],
       [-5.00000000e-01,  1.66533454e-16,  3.66025404e-01,
         5.00000000e-01,  3.66025404e-01,  5.55111512e-16,
        -5.00000000e-01, -1.00000000e+00, -1.36602540e+00,
        -1.50000000e+00, -1.36602540e+00, -1.00000000e+00,
        -5.00000000e-01],
       [-8.66025404e-01, -3.66025404e-01,  1.11022302e-16,
         1.33974596e-01,  2.22044605e-16, -3.66025404e-01,
        -8.66025404e-01, -1.36602540e+00, -1.73205081e+00,
        -1.86602540e+00, -1.73205081e+00, -1.36602540e+00,
        -8.66025404e-01],
       [-1.00000000e+00, -5.00000000e-01, -1.33974596e-01,
         0.00000000e+00, -1.33974596e-01, -5.00000000e-01,
        -1.00000000e+00, -1.50000000e+00, -1.86602540e+00,
        -2.00000000e+00, -1.86602540e+00, -1.50000000e+00,
        -1.00000000e+00],
       [-8.66025404e-01, -3.66025404e-01, -4.44089210e-16,
         1.33974596e-01, -3.33066907e-16, -3.66025404e-01,
        -8.66025404e-01, -1.36602540e+00, -1.73205081e+00,
        -1.86602540e+00, -1.73205081e+00, -1.36602540e+00,
        -8.66025404e-01],
       [-5.00000000e-01, -4.99600361e-16,  3.66025404e-01,
         5.00000000e-01,  3.66025404e-01, -1.11022302e-16,
        -5.00000000e-01, -1.00000000e+00, -1.36602540e+00,
        -1.50000000e+00, -1.36602540e+00, -1.00000000e+00,
        -5.00000000e-01],
       [-1.83697020e-16,  5.00000000e-01,  8.66025404e-01,
         1.00000000e+00,  8.66025404e-01,  5.00000000e-01,
        -6.12323400e-17, -5.00000000e-01, -8.66025404e-01,
        -1.00000000e+00, -8.66025404e-01, -5.00000000e-01,
        -4.28626380e-16],
       [ 5.00000000e-01,  1.00000000e+00,  1.36602540e+00,
         1.50000000e+00,  1.36602540e+00,  1.00000000e+00,
         5.00000000e-01, -5.55111512e-17, -3.66025404e-01,
        -5.00000000e-01, -3.66025404e-01, -1.11022302e-15,
         5.00000000e-01],
       [ 8.66025404e-01,  1.36602540e+00,  1.73205081e+00,
         1.86602540e+00,  1.73205081e+00,  1.36602540e+00,
         8.66025404e-01,  3.66025404e-01,  0.00000000e+00,
        -1.33974596e-01, -6.66133815e-16,  3.66025404e-01,
         8.66025404e-01],
       [ 1.00000000e+00,  1.50000000e+00,  1.86602540e+00,
         2.00000000e+00,  1.86602540e+00,  1.50000000e+00,
         1.00000000e+00,  5.00000000e-01,  1.33974596e-01,
         0.00000000e+00,  1.33974596e-01,  5.00000000e-01,
         1.00000000e+00]])

In [137]:  %matplotlib
Using matplotlib backend: Qt5Agg
In [138]: import matplotlib.pyplot as plt
In [143]: plt.imshow(z)
Out[143]: <matplotlib.image.AxesImage at 0x7f8c30719f98>
/ we zien de graph	,
In [161]: plt.colorbar()
Out[161]: <matplotlib.colorbar.Colorbar at 0x7f8c2ef79160>
/ je ziet wat de kleuren betekenen	,


/ we hebben de args origin, extent, cmap niet used	,

/ Intermezzo

/ we oef met eenvoudigere fcts	, 

In [153]: z2=np.sin(x)+0*np.cos(y)
In [154]: plt.imshow(z2,origin='lower',extent=[0,2*np.pi,0,2*np.pi])
Out[154]: <matplotlib.image.AxesImage at 0x7f8c2f4c7940>

In [155]: z2=0*np.sin(x)+np.cos(y)
In [154]: plt.imshow(z2,origin='lower',extent=[0,2*np.pi,0,2*np.pi])

/ we zien dat rood = 0	, wit >0 en zwart <0	,
/ doe	,
In [161]: plt.colorbar()

/ origin='upper' toch (links, altijd) onder	,
/ TODO

/ cmap is colormap	,

/ lees	,
https://matplotlib.org/api/_as_gen/matplotlib.pyplot.imshow.html
/ als je click op de voorbeelden	, krijg je een voorbeeld programma	,

/ Einde Intermezzo

/ (70)

[eric@almond vanderplas]$ find PythonDataScienceHandbook/ -name "Seattle*" | xargs -I % cp % .
In [168]: rainfall=pd.read_csv('Seattle2014.csv')

In [167]:  rainfall[:7]
Out[167]: 
             STATION  ...   WT03
0  GHCND:USW00024233  ...  -9999
1  GHCND:USW00024233  ...  -9999
2  GHCND:USW00024233  ...  -9999
3  GHCND:USW00024233  ...  -9999
4  GHCND:USW00024233  ...  -9999
5  GHCND:USW00024233  ...  -9999
6  GHCND:USW00024233  ...  -9999

[7 rows x 17 columns]

/ we zien maar een paar columns print	,
/ TODO

In [171]: type(rainfall.PRCP)
Out[171]: pandas.core.series.Series

In [172]: rainfall.PRCP[:7]
Out[172]: 
0      0
1     41
2     15
3      0
4      0
5      3
6    122
Name: PRCP, dtype: int64

In [175]: rainfall.PRCP is rainfall['PRCP']
Out[175]: True

In [177]: type(rainfall['PRCP'].values)
Out[177]: numpy.ndarray

In [179]: rainfall['PRCP'].values[:7]
Out[179]: array([  0,  41,  15,   0,   0,   3, 122])

In [180]: rainfall=rainfall['PRCP'].values
/=
In [180]: rainfall=rainfall.PRCP.values

In [189]: inches[:7]
Out[189]: 
array([0.        , 0.16141732, 0.05905512, 0.        , 0.        ,
       0.01181102, 0.48031496])

In [190]: inches.shape
Out[190]: (365,)

/ deze 4 lines hoeft niet, is al eerder	,
In [192]: %matplotlib	/ als we deze toch doen, verdwijnt grafiek	, er wordt nieuwe ... gemaakt	,
Using matplotlib backend: Qt5Agg

In [193]: import matplotlib.pyplot as plt

In [194]: import seaborn

In [195]: seaborn.set()

In [200]: plt.hist(inches,40)
Out[200]: 
(array([245.,  14.,  13.,  17.,   8.,   6.,   5.,   6.,   4.,   3.,   7.,
          6.,   3.,   3.,   3.,   4.,   4.,   2.,   4.,   0.,   0.,   1.,
          1.,   1.,   0.,   0.,   0.,   2.,   1.,   1.,   0.,   0.,   0.,
          0.,   0.,   0.,   0.,   0.,   0.,   1.]),
 array([0.        , 0.04596457, 0.09192913, 0.1378937 , 0.18385827,
        0.22982283, 0.2757874 , 0.32175197, 0.36771654, 0.4136811 ,
        0.45964567, 0.50561024, 0.5515748 , 0.59753937, 0.64350394,
        0.6894685 , 0.73543307, 0.78139764, 0.8273622 , 0.87332677,
        0.91929134, 0.96525591, 1.01122047, 1.05718504, 1.10314961,
        1.14911417, 1.19507874, 1.24104331, 1.28700787, 1.33297244,
        1.37893701, 1.42490157, 1.47086614, 1.51683071, 1.56279528,
        1.60875984, 1.65472441, 1.70068898, 1.74665354, 1.79261811,
        1.83858268]),
 <a list of 40 Patch objects>)

/ wat is 40, en de 40 getallen die worden returned?
/ TODO

/ (73)

In [207]: x=rng.randint(10,size=(3,4))
In [210]: x
Out[210]: 
array([[5, 0, 3, 3],
       [7, 9, 3, 5],
       [2, 4, 7, 6]])
In [211]: x<6
/=
In [212]: np.less(x,6)
Out[211]: 
array([[ True,  True,  True,  True],
       [False, False,  True,  True],
       [ True,  True, False, False]])


In [213]: np.count_nonzero(x<6)
Out[213]: 8

In [220]: False is 0
Out[220]: False
/ maar False wordt opgevat/converted to 0 en True als 1	,
In [222]: False.real
Out[222]: 0
In [223]: True.real
Out[223]: 1
/ Geef False.TAB	, je ziet alle properties,	

In [216]: (x<6)[0,1]
Out[216]: True
In [214]: type(x<6)
Out[214]: numpy.ndarray
In [217]: type((x<6)[0,1])
Out[217]: numpy.bool_

In [218]: np.sum(x<6)
Out[218]: 8

In [226]: np.sum(x<6,axis=0)
Out[226]: array([2, 2, 2, 2])

In [227]: np.sum(x<6,axis=1)
Out[227]: array([4, 2, 2])

/ axis=0 is de 1ste as, de verticale, naar beneden as, dus de actie is over de rijen	, dus np.sum(x<6,axis=0) sommeert de rijen voor iedere kolom,
/ axis=1 is de 2de as, de horizontale, naar rechts as, dus de actie is over de kolommen, dus np.sum(x<6,axis=1) sommeert de kolommen voor iedere rij	, 

/ axis geeft waarover de actie (sum in dit geval) aan	,

/ axis=0 is de 1ste as, dus np.sum(...,axis=0) sommeert over de rijen	,  dus berekent de np.sum voor iedere kolom	,
/ axis=1 is de 2de as, dus np.sum(...,axis=1) sommeert over de kolommen,  dus berekent de np.sum voor iedere rij,

In [228]: np.all(x<8,axis=1)
Out[228]: array([ True, False,  True])
/ actie 'np.all' over de kolommen	, dus voor iedere rij	,

/ (74)

In [234]: np.sum(inches>=0)
Out[234]: 365


/ we moeten extra (...)	,
In [231]: np.sum((inches>0.5)&(inches<1))
/=
In [236]: np.sum(np.bitwise_and(inches>0.5,inches<1))
/=
In [236]: np.sum(np.bitwise_and(inches>.5,inches<1))
Out[231]: 29

/ dagen zonder regen	,
In [238]: np.sum(inches==0)
Out[238]: 215

/ (76)

In [239]: x
Out[239]: 
array([[5, 0, 3, 3],
       [7, 9, 3, 5],
       [2, 4, 7, 6]])

In [240]: x<5
Out[240]: 
array([[False,  True,  True,  True],
       [False, False,  True, False],
       [ True,  True, False, False]])
In [241]: x[x<5]
Out[241]: array([0, 3, 3, 3, 2, 4])

In [245]: rainy=inches>0
In [256]: rainy
Out[256]: 
array([False,  True,  True, False, False,  True,  True,  True,  True,
        True,  True,  True, False, False, False, False, False, False,
       False, False, False,  True, False, False, False, False, False,
        True,  True, False,  True,  True, False, False, False, False,
       False, False,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True, False, False, False,  True,  True,  True,  True,
        True,  True, False,  True,  True,  True, False, False,  True,
        True,  True,  True,  True, False,  True, False, False, False,
       False, False,  True,  True,  True,  True,  True, False, False,
       False, False,  True, False,  True, False, False,  True, False,
       False, False, False, False, False,  True,  True,  True, False,
        True, False,  True,  True,  True,  True, False,  True,  True,
       False, False, False, False, False,  True,  True,  True, False,
       False,  True,  True,  True, False, False, False, False, False,
       False, False, False, False, False, False, False,  True, False,
        True, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
        True,  True, False,  True,  True,  True, False,  True,  True,
       False, False, False, False, False, False,  True,  True, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False,  True,  True, False, False, False,
       False, False, False, False, False, False,  True, False, False,
       False, False, False, False, False, False,  True,  True,  True,
       False,  True, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False,  True,  True,
       False,  True, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False,  True,  True,
       False, False, False,  True,  True,  True,  True,  True, False,
       False,  True, False, False, False, False, False, False, False,
       False, False, False,  True,  True, False,  True,  True,  True,
       False,  True,  True, False,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True, False,  True,
        True,  True,  True,  True, False, False,  True, False, False,
       False, False, False, False, False, False, False, False,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
       False, False, False, False,  True,  True,  True, False,  True,
        True,  True,  True, False, False, False, False, False,  True,
        True,  True,  True, False, False,  True,  True, False, False,
        True,  True, False, False, False])


In [249]: days=np.arange(365)
In [248]: days
Out[248]: 
array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,
        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,
        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,
        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,
        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,
        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,
        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,
        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,
       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,
       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,
       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,
       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,
       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,
       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,
       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,
       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,
       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,
       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,
       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,
       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,
       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,
       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,
       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,
       325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,
       338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,
       351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,
       364])
In [251]: f=days-172<90

In [252]: f
Out[252]: 
array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False])
In [256]: s=days-172>0
In [254]: s
Out[254]: 
array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True])
In [255]: summer=s&f
In [255]: summer
Out[255]: 
array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False])

In [257]: inches
Out[257]: 
array([0.        , 0.16141732, 0.05905512, 0.        , 0.        ,
       0.01181102, 0.48031496, 0.38188976, 0.22834646, 0.16929134,
       0.83858268, 0.05905512, 0.        , 0.        , 0.        ,
       0.        , 0.        , 0.        , 0.        , 0.        ,
       0.        , 0.01968504, 0.        , 0.        , 0.        ,
       0.        , 0.        , 0.3503937 , 0.8503937 , 0.        ,
       0.09055118, 0.07874016, 0.        , 0.        , 0.        ,
       0.        , 0.        , 0.        , 0.2007874 , 0.01968504,
       0.72047244, 0.66929134, 0.18110236, 0.07086614, 0.37007874,
       0.46062992, 1.03937008, 0.57086614, 0.5984252 , 0.03937008,
       0.11811024, 0.11023622, 0.0984252 , 0.24015748, 0.51181102,
       0.01181102, 0.        , 0.        , 0.        , 0.01968504,
       0.7519685 , 0.42125984, 0.6496063 , 1.83858268, 0.11811024,
       0.        , 1.27165354, 0.16929134, 0.74015748, 0.        ,
       0.        , 0.01968504, 0.27165354, 0.31889764, 1.09055118,
       0.01181102, 0.        , 0.01968504, 0.        , 0.        ,
       0.        , 0.        , 0.        , 0.16141732, 0.14173228,
       0.01181102, 0.87007874, 0.5511811 , 0.        , 0.        ,
       0.        , 0.        , 0.0984252 , 0.        , 0.18110236,
       0.        , 0.        , 0.18110236, 0.        , 0.        ,
       0.        , 0.        , 0.        , 0.        , 0.01968504,
       0.42913386, 0.72834646, 0.        , 0.53937008, 0.        ,
       0.2007874 , 0.55905512, 0.3503937 , 0.48818898, 0.        ,
       0.12992126, 0.27165354, 0.        , 0.        , 0.        ,
       0.        , 0.        , 1.31102362, 0.62992126, 0.2007874 ,
       0.        , 0.        , 0.53937008, 0.07874016, 0.01968504,
       0.        , 0.        , 0.        , 0.        , 0.        ,
       0.        , 0.        , 0.        , 0.        , 0.        ,
       0.        , 0.        , 0.1496063 , 0.        , 0.22047244,
       0.        , 0.        , 0.        , 0.        , 0.        ,
       0.        , 0.        , 0.        , 0.        , 0.        ,
       0.        , 0.        , 0.        , 0.        , 0.        ,
       0.        , 0.        , 0.07086614, 0.2519685 , 0.        ,
       0.01968504, 0.14173228, 0.0511811 , 0.        , 0.03149606,
       0.01181102, 0.        , 0.        , 0.        , 0.        ,
       0.        , 0.        , 0.07086614, 0.09055118, 0.        ,
       0.        , 0.        , 0.        , 0.        , 0.        ,
       0.        , 0.        , 0.        , 0.        , 0.        ,
       0.        , 0.        , 0.        , 0.        , 0.        ,
       0.        , 0.        , 0.        , 0.        , 0.        ,
       0.        , 0.        , 0.01181102, 0.75984252, 0.        ,
       0.        , 0.        , 0.        , 0.        , 0.        ,
       0.        , 0.        , 0.        , 0.01968504, 0.        ,
       0.        , 0.        , 0.        , 0.        , 0.        ,
       0.        , 0.        , 0.01968504, 0.5       , 0.8503937 ,
       0.        , 0.03937008, 0.        , 0.        , 0.        ,
       0.        , 0.        , 0.        , 0.        , 0.        ,
       0.        , 0.        , 0.        , 0.        , 0.        ,
       0.        , 0.33070866, 0.0511811 , 0.        , 0.11811024,
       0.        , 0.        , 0.        , 0.        , 0.        ,
       0.        , 0.        , 0.        , 0.        , 0.        ,
       0.        , 0.        , 0.        , 0.        , 0.01968504,
       0.01181102, 0.        , 0.        , 0.        , 0.01181102,
       0.72047244, 0.7992126 , 0.16929134, 0.3503937 , 0.        ,
       0.        , 0.03149606, 0.        , 0.        , 0.        ,
       0.        , 0.        , 0.        , 0.        , 0.        ,
       0.        , 0.        , 0.01181102, 0.29133858, 0.        ,
       0.2992126 , 0.27952756, 0.33858268, 0.        , 0.12992126,
       0.59055118, 0.        , 0.46062992, 0.03937008, 1.25984252,
       0.37007874, 0.16141732, 0.24015748, 0.05905512, 0.03149606,
       0.5       , 0.01968504, 1.        , 0.66929134, 0.        ,
       0.07086614, 0.42913386, 0.16141732, 0.18897638, 0.16141732,
       0.        , 0.        , 0.2007874 , 0.        , 0.        ,
       0.        , 0.        , 0.        , 0.        , 0.        ,
       0.        , 0.        , 0.        , 0.14173228, 0.5984252 ,
       0.01968504, 0.46850394, 0.0511811 , 0.72047244, 0.01181102,
       0.12992126, 1.3503937 , 0.14173228, 0.        , 0.        ,
       0.        , 0.        , 0.03149606, 0.11811024, 0.29133858,
       0.        , 0.35826772, 0.38976378, 0.51181102, 0.27165354,
       0.        , 0.        , 0.        , 0.        , 0.        ,
       0.11023622, 0.51181102, 0.11811024, 0.77165354, 0.        ,
       0.        , 0.81102362, 0.20866142, 0.        , 0.        ,
       0.12992126, 0.16141732, 0.        , 0.        , 0.        ])

In [258]: inches[rainy]		/ rainy is mask
Out[258]: 
array([0.16141732, 0.05905512, 0.01181102, 0.48031496, 0.38188976,
       0.22834646, 0.16929134, 0.83858268, 0.05905512, 0.01968504,
       0.3503937 , 0.8503937 , 0.09055118, 0.07874016, 0.2007874 ,
       0.01968504, 0.72047244, 0.66929134, 0.18110236, 0.07086614,
       0.37007874, 0.46062992, 1.03937008, 0.57086614, 0.5984252 ,
       0.03937008, 0.11811024, 0.11023622, 0.0984252 , 0.24015748,
       0.51181102, 0.01181102, 0.01968504, 0.7519685 , 0.42125984,
       0.6496063 , 1.83858268, 0.11811024, 1.27165354, 0.16929134,
       0.74015748, 0.01968504, 0.27165354, 0.31889764, 1.09055118,
       0.01181102, 0.01968504, 0.16141732, 0.14173228, 0.01181102,
       0.87007874, 0.5511811 , 0.0984252 , 0.18110236, 0.18110236,
       0.01968504, 0.42913386, 0.72834646, 0.53937008, 0.2007874 ,
       0.55905512, 0.3503937 , 0.48818898, 0.12992126, 0.27165354,
       1.31102362, 0.62992126, 0.2007874 , 0.53937008, 0.07874016,
       0.01968504, 0.1496063 , 0.22047244, 0.07086614, 0.2519685 ,
       0.01968504, 0.14173228, 0.0511811 , 0.03149606, 0.01181102,
       0.07086614, 0.09055118, 0.01181102, 0.75984252, 0.01968504,
       0.01968504, 0.5       , 0.8503937 , 0.03937008, 0.33070866,
       0.0511811 , 0.11811024, 0.01968504, 0.01181102, 0.01181102,
       0.72047244, 0.7992126 , 0.16929134, 0.3503937 , 0.03149606,
       0.01181102, 0.29133858, 0.2992126 , 0.27952756, 0.33858268,
       0.12992126, 0.59055118, 0.46062992, 0.03937008, 1.25984252,
       0.37007874, 0.16141732, 0.24015748, 0.05905512, 0.03149606,
       0.5       , 0.01968504, 1.        , 0.66929134, 0.07086614,
       0.42913386, 0.16141732, 0.18897638, 0.16141732, 0.2007874 ,
       0.14173228, 0.5984252 , 0.01968504, 0.46850394, 0.0511811 ,
       0.72047244, 0.01181102, 0.12992126, 1.3503937 , 0.14173228,
       0.03149606, 0.11811024, 0.29133858, 0.35826772, 0.38976378,
       0.51181102, 0.27165354, 0.11023622, 0.51181102, 0.11811024,
       0.77165354, 0.81102362, 0.20866142, 0.12992126, 0.16141732])

In [259]: np.median(inches[rainy])
Out[259]: 0.19488188976377951

/ aantallen	,
In [280]: np.sum(rainy==True)
Out[280]: 150
In [281]: np.sum(summer==True)
Out[281]: 89

/ we willen de mediaan met de hand uitrekenen: let erop dat je eerst sorteert	,

In [296]: a=np.sort(inches[rainy])

In [297]: (a[74]+a[75])/2
Out[297]: 0.19488188976377951
/ klopt	,

/ 13	 .

/ SAMENVATTING 

In [302]: rainy.size
Out[302]: 365

In [303]: summer.size
Out[303]: 365

In [304]: inches.size
Out[304]: 365

In [305]: inches[rainy].size
Out[305]: 150

In [306]: inches[summer].size
Out[306]: 89


In [298]: inches[summer]
Out[298]: 
array([0.        , 0.        , 0.        , 0.        , 0.07086614,
       0.09055118, 0.        , 0.        , 0.        , 0.        ,
       0.        , 0.        , 0.        , 0.        , 0.        ,
       0.        , 0.        , 0.        , 0.        , 0.        ,
       0.        , 0.        , 0.        , 0.        , 0.        ,
       0.        , 0.        , 0.        , 0.        , 0.01181102,
       0.75984252, 0.        , 0.        , 0.        , 0.        ,
       0.        , 0.        , 0.        , 0.        , 0.        ,
       0.01968504, 0.        , 0.        , 0.        , 0.        ,
       0.        , 0.        , 0.        , 0.        , 0.01968504,
       0.5       , 0.8503937 , 0.        , 0.03937008, 0.        ,
       0.        , 0.        , 0.        , 0.        , 0.        ,
       0.        , 0.        , 0.        , 0.        , 0.        ,
       0.        , 0.        , 0.        , 0.33070866, 0.0511811 ,
       0.        , 0.11811024, 0.        , 0.        , 0.        ,
       0.        , 0.        , 0.        , 0.        , 0.        ,
       0.        , 0.        , 0.        , 0.        , 0.        ,
       0.        , 0.01968504, 0.01181102, 0.        ])

In [299]: inches[rainy]
Out[299]: 
array([0.16141732, 0.05905512, 0.01181102, 0.48031496, 0.38188976,
       0.22834646, 0.16929134, 0.83858268, 0.05905512, 0.01968504,
       0.3503937 , 0.8503937 , 0.09055118, 0.07874016, 0.2007874 ,
       0.01968504, 0.72047244, 0.66929134, 0.18110236, 0.07086614,
       0.37007874, 0.46062992, 1.03937008, 0.57086614, 0.5984252 ,
       0.03937008, 0.11811024, 0.11023622, 0.0984252 , 0.24015748,
       0.51181102, 0.01181102, 0.01968504, 0.7519685 , 0.42125984,
       0.6496063 , 1.83858268, 0.11811024, 1.27165354, 0.16929134,
       0.74015748, 0.01968504, 0.27165354, 0.31889764, 1.09055118,
       0.01181102, 0.01968504, 0.16141732, 0.14173228, 0.01181102,
       0.87007874, 0.5511811 , 0.0984252 , 0.18110236, 0.18110236,
       0.01968504, 0.42913386, 0.72834646, 0.53937008, 0.2007874 ,
       0.55905512, 0.3503937 , 0.48818898, 0.12992126, 0.27165354,
       1.31102362, 0.62992126, 0.2007874 , 0.53937008, 0.07874016,
       0.01968504, 0.1496063 , 0.22047244, 0.07086614, 0.2519685 ,
       0.01968504, 0.14173228, 0.0511811 , 0.03149606, 0.01181102,
       0.07086614, 0.09055118, 0.01181102, 0.75984252, 0.01968504,
       0.01968504, 0.5       , 0.8503937 , 0.03937008, 0.33070866,
       0.0511811 , 0.11811024, 0.01968504, 0.01181102, 0.01181102,
       0.72047244, 0.7992126 , 0.16929134, 0.3503937 , 0.03149606,
       0.01181102, 0.29133858, 0.2992126 , 0.27952756, 0.33858268,
       0.12992126, 0.59055118, 0.46062992, 0.03937008, 1.25984252,
       0.37007874, 0.16141732, 0.24015748, 0.05905512, 0.03149606,
       0.5       , 0.01968504, 1.        , 0.66929134, 0.07086614,
       0.42913386, 0.16141732, 0.18897638, 0.16141732, 0.2007874 ,
       0.14173228, 0.5984252 , 0.01968504, 0.46850394, 0.0511811 ,
       0.72047244, 0.01181102, 0.12992126, 1.3503937 , 0.14173228,
       0.03149606, 0.11811024, 0.29133858, 0.35826772, 0.38976378,
       0.51181102, 0.27165354, 0.11023622, 0.51181102, 0.11811024,
       0.77165354, 0.81102362, 0.20866142, 0.12992126, 0.16141732])


In [300]: rainy
Out[300]: 
array([False,  True,  True, False, False,  True,  True,  True,  True,
        True,  True,  True, False, False, False, False, False, False,
       False, False, False,  True, False, False, False, False, False,
        True,  True, False,  True,  True, False, False, False, False,
       False, False,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True, False, False, False,  True,  True,  True,  True,
        True,  True, False,  True,  True,  True, False, False,  True,
        True,  True,  True,  True, False,  True, False, False, False,
       False, False,  True,  True,  True,  True,  True, False, False,
       False, False,  True, False,  True, False, False,  True, False,
       False, False, False, False, False,  True,  True,  True, False,
        True, False,  True,  True,  True,  True, False,  True,  True,
       False, False, False, False, False,  True,  True,  True, False,
       False,  True,  True,  True, False, False, False, False, False,
       False, False, False, False, False, False, False,  True, False,
        True, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
        True,  True, False,  True,  True,  True, False,  True,  True,
       False, False, False, False, False, False,  True,  True, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False,  True,  True, False, False, False,
       False, False, False, False, False, False,  True, False, False,
       False, False, False, False, False, False,  True,  True,  True,
       False,  True, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False,  True,  True,
       False,  True, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False,  True,  True,
       False, False, False,  True,  True,  True,  True,  True, False,
       False,  True, False, False, False, False, False, False, False,
       False, False, False,  True,  True, False,  True,  True,  True,
       False,  True,  True, False,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True, False,  True,
        True,  True,  True,  True, False, False,  True, False, False,
       False, False, False, False, False, False, False, False,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
       False, False, False, False,  True,  True,  True, False,  True,
        True,  True,  True, False, False, False, False, False,  True,
        True,  True,  True, False, False,  True,  True, False, False,
        True,  True, False, False, False])

In [301]: summer
Out[301]: 
array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False])


/ Einde SAMENVATTING 

In [310]: rainy & ~summer
Out[310]: 
array([False,  True,  True, False, False,  True,  True,  True,  True,
        True,  True,  True, False, False, False, False, False, False,
       False, False, False,  True, False, False, False, False, False,
        True,  True, False,  True,  True, False, False, False, False,
       False, False,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True, False, False, False,  True,  True,  True,  True,
        True,  True, False,  True,  True,  True, False, False,  True,
        True,  True,  True,  True, False,  True, False, False, False,
       False, False,  True,  True,  True,  True,  True, False, False,
       False, False,  True, False,  True, False, False,  True, False,
       False, False, False, False, False,  True,  True,  True, False,
        True, False,  True,  True,  True,  True, False,  True,  True,
       False, False, False, False, False,  True,  True,  True, False,
       False,  True,  True,  True, False, False, False, False, False,
       False, False, False, False, False, False, False,  True, False,
        True, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
        True,  True, False,  True,  True,  True, False,  True,  True,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,  True,  True, False,
       False,  True, False, False, False, False, False, False, False,
       False, False, False,  True,  True, False,  True,  True,  True,
       False,  True,  True, False,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True, False,  True,
        True,  True,  True,  True, False, False,  True, False, False,
       False, False, False, False, False, False, False, False,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
       False, False, False, False,  True,  True,  True, False,  True,
        True,  True,  True, False, False, False, False, False,  True,
        True,  True,  True, False, False,  True,  True, False, False,
        True,  True, False, False, False])

In [315]: inches[rainy&~summer]
Out[315]: 
array([0.16141732, 0.05905512, 0.01181102, 0.48031496, 0.38188976,
       0.22834646, 0.16929134, 0.83858268, 0.05905512, 0.01968504,
       0.3503937 , 0.8503937 , 0.09055118, 0.07874016, 0.2007874 ,
       0.01968504, 0.72047244, 0.66929134, 0.18110236, 0.07086614,
       0.37007874, 0.46062992, 1.03937008, 0.57086614, 0.5984252 ,
       0.03937008, 0.11811024, 0.11023622, 0.0984252 , 0.24015748,
       0.51181102, 0.01181102, 0.01968504, 0.7519685 , 0.42125984,
       0.6496063 , 1.83858268, 0.11811024, 1.27165354, 0.16929134,
       0.74015748, 0.01968504, 0.27165354, 0.31889764, 1.09055118,
       0.01181102, 0.01968504, 0.16141732, 0.14173228, 0.01181102,
       0.87007874, 0.5511811 , 0.0984252 , 0.18110236, 0.18110236,
       0.01968504, 0.42913386, 0.72834646, 0.53937008, 0.2007874 ,
       0.55905512, 0.3503937 , 0.48818898, 0.12992126, 0.27165354,
       1.31102362, 0.62992126, 0.2007874 , 0.53937008, 0.07874016,
       0.01968504, 0.1496063 , 0.22047244, 0.07086614, 0.2519685 ,
       0.01968504, 0.14173228, 0.0511811 , 0.03149606, 0.01181102,
       0.01181102, 0.72047244, 0.7992126 , 0.16929134, 0.3503937 ,
       0.03149606, 0.01181102, 0.29133858, 0.2992126 , 0.27952756,
       0.33858268, 0.12992126, 0.59055118, 0.46062992, 0.03937008,
       1.25984252, 0.37007874, 0.16141732, 0.24015748, 0.05905512,
       0.03149606, 0.5       , 0.01968504, 1.        , 0.66929134,
       0.07086614, 0.42913386, 0.16141732, 0.18897638, 0.16141732,
       0.2007874 , 0.14173228, 0.5984252 , 0.01968504, 0.46850394,
       0.0511811 , 0.72047244, 0.01181102, 0.12992126, 1.3503937 ,
       0.14173228, 0.03149606, 0.11811024, 0.29133858, 0.35826772,
       0.38976378, 0.51181102, 0.27165354, 0.11023622, 0.51181102,
       0.11811024, 0.77165354, 0.81102362, 0.20866142, 0.12992126,
       0.16141732])

In [314]: inches[rainy&~summer].size
Out[314]: 136

In [313]: np.median(inches[rainy&~summer])
Out[313]: 0.20078740157480315

/ (77)

/ Intermezzo

/ and	, 

/ als linker arg zoiets als False, 	dan is and het 1st arg	, anders het 2de	,

In [330]: 0 and 3
Out[330]: 0
In [335]: False and 3
Out[335]: False
In [336]: () and 3
Out[336]: ()
In [340]: '' and 3
Out[340]: ''

In [341]: 23423 and 3
Out[341]: 3
In [342]: True and 3
Out[342]: 3
In [345]: (34) and 3
Out[345]: 3
In [346]: 'f' and 3
Out[346]: 3

/ Einde Intermezzo

In [326]: 42&21
Out[326]: 0

In [327]: 42 and 21
Out[327]: 21


In [323]: bool (42 & 21)
Out[323]: False

In [324]: bool (42 and 21)
Out[324]: True

/ 1313	 

In [349]: a=np.array([1,0],dtype=bool)

In [350]: a
Out[350]: array([ True, False])

In [351]: b=np.array([1,1],dtype=bool)

In [352]: b
Out[352]: array([ True,  True])

In [353]: a|b
Out[353]: array([ True,  True])

In [354]: a&b
Out[354]: array([ True, False])

In [355]: a^b
Out[355]: array([False,  True])

In [356]: a or b
---------------------------------------------------------------------------
ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()

/ 1313	. 

In [357]: x=np.arange(10)
In [360]: (4<x)&(x<8)
Out[360]: 
array([False, False, False, False, False,  True,  True,  True, False,
       False])
/ we moeten (...), anders doet hij eerst x&x en dan dezelfde fout als hierboven	,
---------------------------------------------------------------------------
ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()

/ 1313	. 

In [362]: x>5
Out[362]: 
array([False, False, False, False, False, False,  True,  True,  True,
        True])
In [361]: x[x>5]
Out[361]: array([6, 7, 8, 9])

/ (79)

/ fancy indexes	,

In [363]: r=np.random.RandomState(42)
In [365]: x=r.randint(100,size=10)
In [366]: x
Out[366]: array([51, 92, 14, 71, 60, 20, 82, 86, 74, 74])
In [368]: x[[3,7,4]]
Out[368]: array([71, 86, 60])
/ let op	: NIET x([3,7,4])	, is fct call	,

/ 1313	. 

/ de index array bepaalt de shape van het array	, en de indexing van het index array bepaalt de indexing van het array:  

In [377]: x[np.array([[3,7],[4,5]])]
Out[377]: 
array([[71, 86],
       [60, 20]])

In [378]: x[np.array([[3,7],[4,5]]).T]
Out[378]: 
array([[71, 60],
       [86, 20]])

/ Intermezzo

In [373]: a=np.array([[3,7],[4,5]])

In [374]: a
Out[374]: 
array([[3, 7],
       [4, 5]])

In [375]: b=np.array([[3,7],[4,5]],order='f')

In [376]: b
Out[376]: 
array([[3, 7],
       [4, 5]])

/ b is een fortran array	, maar de 1ste kolom is
(3
(4 

In [382]: a.flatten('k')
Out[382]: array([3, 7, 4, 5])

In [381]: b.flatten('k')
Out[381]: array([3, 4, 7, 5])


/ Einde Intermezzo

/ 1313	. 

/ we hadden tot nu toe een vector array (10,)	, 
/ nu een matrix array	, we moeten dan 2 index arrays hebben	,

In [393]: x.shape
Out[393]: (10,)

In [384]: X
Out[384]: 
array([[ 0,  1,  2,  3],
       [ 4,  5,  6,  7],
       [ 8,  9, 10, 11]])

In [394]: X.shape
Out[394]: (3, 4)


In [386]: r=np.array([0,1,2])
In [387]: c=np.array([2,1,3])

In [389]: X[r,c]
Out[389]: array([ 2,  5, 11])

In [396]: X[r,c].shape
Out[396]: (3,)

/ Intermezzo

/ vectoren en matrices met 1 rij of 1 colom zijn nog steeds en c en fortran contiguous	,
/ de .T doet niets op vectors	,

In [411]: r
Out[411]: array([0, 1, 2])
In [413]: r.shape
Out[413]: (3,)
In [414]: r.flags
Out[414]: 
  C_CONTIGUOUS : True
  F_CONTIGUOUS : True
In [415]: r.T
Out[415]: array([0, 1, 2])

In [417]: r[:,np.newaxis]
Out[417]: 
array([[0],
       [1],
       [2]])

In [418]: r[:,np.newaxis].shape
Out[418]: (3, 1)
In [419]: r[:,np.newaxis].flags
Out[419]: 
  C_CONTIGUOUS : True
  F_CONTIGUOUS : True

In [417]: r[:,np.newaxis]
Out[417]: 
array([[0],
       [1],
       [2]])
In [418]: r[:,np.newaxis].shape
Out[418]: (3, 1)
In [419]: r[:,np.newaxis].flags
Out[419]: 
  C_CONTIGUOUS : True
  F_CONTIGUOUS : True

In [420]: r[:,np.newaxis].T
Out[420]: array([[0, 1, 2]])
In [422]: r[:,np.newaxis].T.shape
Out[422]: (1, 3)
In [421]: r[:,np.newaxis].T.flags
Out[421]: 
  C_CONTIGUOUS : True
  F_CONTIGUOUS : True

/ Einde Intermezzo

/ 1313	. 

In [427]: r[:,np.newaxis]
Out[427]: 
array([[0],
       [1],
       [2]])
In [428]: c
Out[428]: array([2, 1, 3])
In [425]: X
Out[425]: 
array([[ 0,  1,  2,  3],
       [ 4,  5,  6,  7],
       [ 8,  9, 10, 11]])
In [424]: X[r[:,np.newaxis],c]
Out[424]: 
array([[ 2,  1,  3],
       [ 6,  5,  7],
       [10,  9, 11]])

In [429]: r[:,np.newaxis]*c
Out[429]: 
array([[0, 0, 0],
       [2, 1, 3],
       [4, 2, 6]])

/ (80)

In [431]: r[:,np.newaxis]
Out[431]: 
array([[0],
       [1],
       [2]])
In [432]: bc=np.array([True,False,True,False])
In [434]: X
Out[434]: 
array([[ 0,  1,  2,  3],
       [ 4,  5,  6,  7],
       [ 8,  9, 10, 11]])
In [433]: X[r[:,np.newaxis],bc]
Out[433]: 
array([[ 0,  2],
       [ 4,  6],
       [ 8, 10]])

/ (81)

[eric@almond vanderplas]$ find PythonDataScienceHandbook/ -type f| xargs grep  'rand.multivariate_normal' 
PythonDataScienceHandbook/notebooks/02.07-Fancy-Indexing.ipynb:    "X = rand.multivariate_normal(mean, cov, 100)\n",

/ Intermezzo

/ als je xargs -I % use, dan moet -je grep -H doen	, anders zien we geen filename	, 
eric@almond vanderplas]$ find PythonDataScienceHandbook/ -type f| xargs -I % grep -H 'rand.multivariate_normal' % 
PythonDataScienceHandbook/notebooks/02.07-Fancy-Indexing.ipynb:    "X = rand.multivariate_normal(mean, cov, 100)\n",
/ dit is een eig van grep	, 
eric@almond vanderplas]$ grep multivariate PythonDataScienceHandbook/notebooks/02.07-Fancy-Indexing.ipynb 
    "X = rand.multivariate_normal(mean, cov, 100)\n",

[eric@almond vanderplas]$ find PythonDataScienceHandbook/ -type f| xargs echo grep  'rand.multivariate_normal' 
grep rand.multivariate_normal PythonDataScienceHandbook/.gitignore PythonDataScienceHandbook/LICENSE-CODE PythonDataScienceHandbook/LICENSE-TEXT PythonDataScienceHandbook/website/.gitignore PythonDataScienceHandbook/website/Makefile PythonDataScienceHandbook/website/pelicanconf.py PythonDataScienceHa...

/ je kunt ook 	,
[eric@almond vanderplas]$ grep -r 'rand.multivariate' PythonDataScienceHandbook
PythonDataScienceHandbook/notebooks/02.07-Fancy-Indexing.ipynb:    "X = rand.multivariate_normal(mean, cov, 100)\n",

/ Einde Intermezzo

In [435]: mean =np.array([0,0])
In [438]: cov = np.array([[1,2],[2,5]])
In [439]: X=np.random.multivariate_normal(mean,cov,100)

In [440]: X
Out[440]: 
array([[-5.40191366e-01, -8.87538971e-01],
       [-3.89654813e-01, -1.37636532e-01],
       [ 7.61432561e-01, -6.40251291e-01],
       [-1.03831705e+00, -1.86302057e+00],
...
In [441]: X.shape
Out[441]: (100, 2)

In [450]: X[:,0]
Out[450]: 
array([-1.04404639, -0.02265366, -0.14017158,  0.04027339,  1.12509504,
        1.1287036 , -1.30052737, -0.2975982 ,  0.46488593, -1.12224037,
...
In [451]: X[:,1]
Out[451]: 
array([-2.05408595, -0.85512458,  0.96347698,  0.50459911,  3.67306331,
        1.87039537, -3.65485601, -1.19557167,  1.34599462, -3.0480775 ,
...

In [443]: %matplotlib

In [444]: plt.scatter(X[:,0],X[:,1])
Out[444]: <matplotlib.collections.PathCollection at 0x7f8c318a7be0>

In [445]: X=np.random.multivariate_normal(mean,cov,100)
In [446]: plt.scatter(X[:,0],X[:,1])
Out[446]: <matplotlib.collections.PathCollection at 0x7f8c2f2a74a8>

In [447]: X=np.random.multivariate_normal(mean,cov,100)
In [448]: plt.scatter(X[:,0],X[:,1])
Out[448]: <matplotlib.collections.PathCollection at 0x7f8c31892668>

/ Telkens komt er in dezelfde assenstelsel 100 punten erbij, met een andere kleur, dus we zien nu 3 kleuren	,

/ Intermezzo

/ er zijn,
np.random.multinomial									/ binomial, trinomial bestaat niet, >2 is multinomial	,
np.random.multivariate_normal	,

np.random.multivariate_normal?

>>> mean = (1, 2)
>>> cov = [[1, 0], [0, 1]]
>>> x = np.random.multivariate_normal(mean, cov, (3, 3))
>>> x.shape
(3, 3, 2)

The following is probably true, given that 0.6 is roughly twice the
standard deviation:

>>> list((x[0,0,:] - mean) < 0.6)
[True, True]

/ Einde Intermezzo

/ 1313	. 

/ als we	,  
In [469]: np.random.seed(0)
In [470]: n=np.random.multivariate_normal(mean,cov,12)
...
In [469]: np.random.seed(0)
In [470]: n=np.random.multivariate_normal(mean,cov,12)
...
/ dan zien we 2 keer dezelfde	, 

/ 1313	. 

/ voorbeeld uit 
np.random.multivariate_normal?

In [483]: mean
Out[483]: (0, 0)

In [484]: cov
Out[484]: [[1, 0], [0, 1]]

In [477]: np.random.seed(0)

In [478]: n=np.random.multivariate_normal(mean,cov,9)

In [479]: n
Out[479]:
				n[:,0] = kolom 0 
array([[ 1.76405235,  0.40015721],	/ n[0,:] = rij 0
       [ 0.97873798,  2.2408932 ],
       [ 1.86755799, -0.97727788],
       [ 0.95008842, -0.15135721],
       [-0.10321885,  0.4105985 ],
       [ 0.14404357,  1.45427351],
       [ 0.76103773,  0.12167502],
       [ 0.44386323,  0.33367433],
       [ 1.49407907, -0.20515826]])	/ n[8,:]

In [495]:  n.shape
Out[495]: (9, 2)

In [515]: n[0]==n[0,:]
Out[515]: array([ True,  True])
In [513]: n[0]==[n[0,0],n[0,1]]
Out[513]: array([ True,  True])


In [480]: np.random.seed(0)

In [481]: m=np.random.multivariate_normal(mean,cov,(3,3))

In [482]: m
Out[482]: 
array([[[ 1.76405235,  0.40015721],	/ m[0,0,:]
        [ 0.97873798,  2.2408932 ],	/ m[0,1,:]
        [ 1.86755799, -0.97727788]],/ m[0,2,:]

       [[ 0.95008842, -0.15135721],/ m[1,0,:]
        [-0.10321885,  0.4105985 ],/ m[1,1,:]
        [ 0.14404357,  1.45427351]],/ m[1,2,:]

       [[ 0.76103773,  0.12167502],/ m[2,0,:]
        [ 0.44386323,  0.33367433],/ m[2,1,:]
        [ 1.49407907, -0.20515826]]])/ m[2,2,:]

In [496]:  m.shape
Out[496]: (3, 3, 2)

>>> list((x[0,0,:] - mean) < 0.6)
[True, True]
/TODO

/ bij ons	,
In [523]: list(m[0,0,:])
Out[523]: [1.764052345967664, 0.4001572083672233]
In [525]: list(m[0,0,:]<0.6)
Out[525]: [False, True]

/ Wat is verschil, reden tussen
n=np.random.multivariate_normal(mean,cov,9)
/ en	,
m=np.random.multivariate_normal(mean,cov,(3,3))

/ (81)

/ Intermezzo

/ np.random.choice om een aantal indices te vinden	, 

In [547]: np.random.choice(16,8,replace=False)
Out[547]: array([ 5,  4,  2, 10, 14,  6,  9, 13])

In [548]: np.random.choice(32,8,replace=False)
Out[548]: array([16, 13, 22, 24, 28, 26, 12, 20])

/ lees	,
np.random.choice?

>>> np.random.choice(5, 3)
array([0, 3, 4])
>>> #This is equivalent to np.random.randint(0,5,3)

>>> np.random.choice(5, 3, replace=False)
array([3,1,0])
>>> #This is equivalent to np.random.permutation(np.arange(5))[:3]

/ lees,
https://stackoverflow.com/questions/40689152/what-does-replacement-mean-in-numpy-random-choice
/ als je replace=True, dan kan een getal meerdere keren voorkomen in de sample	, 
In [561]: np.random.seed(0)
In [562]: i=np.random.choice(5,3,replace=True)
In [563]: i
Out[563]: array([4, 0, 3])
In [564]: i=np.random.choice(5,3,replace=True)
In [565]: i
Out[565]: array([3, 3, 1])


/ Einde Intermezzo

In [550]: np.random.seed(0)                                       
In [550]: X=np.random.multivariate_normal([0,0],[[1,2],[2,5]],100)
In [553]: X.shape
Out[553]: (100, 2)

In [634]: X[:10]
Out[634]: 
array([[-1.78290539, -3.87118733],
       [-1.76178869, -1.82780883],
       [-1.35141055, -4.32039163],
       [-0.81984535, -2.14310962],
       [-0.06176746,  0.29530878],
       [-0.68960528, -0.09076013],
       [-0.74967019, -1.67816385],
       [-0.53776779, -0.93711981],
       [-1.30183841, -3.36497764],
       [ 0.03761145, -0.8336645 ]])


In [550]: np.random.seed(0)                                       
In [550]: indices=np.random.choice(X.shape[0],20,replace=False)
In [632]: indices
Out[632]: 
array([26, 86,  2, 55, 75, 93, 16, 73, 54, 95, 53, 92, 78, 13,  7, 30, 22,
       24, 33,  8])
/ 20 verschillende indices uit 0, ..., 99	,


In [577]: selection = X[indices] 	 /fancy indexing	,
In [642]: selection
Out[642]: 
array([[ 0.92373079,  0.95217633],
       [-0.54247156, -2.01430721],
       [-1.35141055, -4.32039163],
       [-2.07212778, -4.02186332],
       [-0.59262085,  0.4237955 ],
       [ 1.00035445,  2.47153236],
       [ 1.57822507,  1.66617373],
       [ 0.41587414,  2.21305872],
       [-2.34313526, -4.05433127],
       [ 1.09224809,  2.92597394],
       [ 0.66817268,  0.8040723 ],
       [ 0.03544238, -1.64848923],
       [-0.62760397, -2.68407946],
       [ 0.0293568 , -0.13173275],
       [-0.53776779, -0.93711981],
       [ 0.75886748,  1.44289063],
       [ 0.638501  ,  1.06730956],
       [ 1.57245937,  3.56598432],
       [ 1.32900778,  3.70942052],
       [-1.30183841, -3.36497764]])


/ we hebben de oude grafiek (met 3 samples) nog staan	, doe daarom eerst %matplotlib	,

In [580]: %matplotlib
Using matplotlib backend: Qt5Agg
In [581]: plt.scatter(X[:,0],X[:,1],alpha=.3)
Out[581]: <matplotlib.collections.PathCollection at 0x7f8c2ddc9cc0>
In [645]: plt.scatter(selection[:,0],selection[:,1],s=200,facecolors='none',edge
     ...: colors='r')
Out[645]: <matplotlib.collections.PathCollection at 0x7f8c2d686278>

/ vergeet edgecolors niet	, anders zien we de 20 selection points niet	,
/ met autocompletion geeft hij wel edgepoints, maar niet facecolors	,
/ TODO


/ Intermezzo

/ lees over de s param in matplotlib.scatter	,
https://stackoverflow.com/questions/14827650/pyplot-scatter-plot-marker-size

/ lees over facecolors in matplotlib.scatter	,
https://stackoverflow.com/questions/45247486/how-to-do-a-scatter-plot-with-different-edgecolor-in-matplotlib?answertab=active#tab-top
->
https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.scatter.html
-> voorbeeld onderaan, click	,
https://matplotlib.org/gallery/shapes_and_collections/scatter.html#sphx-glr-gallery-shapes-and-collections-scatter-py

/ 13	. 

/ voorbeeld uit	,
https://matplotlib.org/gallery/shapes_and_collections/scatter.html#sphx-glr-gallery-shapes-and-collections-scatter-py

In [591]: N=50

In [592]: x=np.random.rand(N)

In [593]: x
Out[593]: 
array([0.0871293 , 0.0202184 , 0.83261985, 0.77815675, 0.87001215,
       0.97861834, 0.79915856, 0.46147936, 0.78052918, 0.11827443,
       0.63992102, 0.14335329, 0.94466892, 0.52184832, 0.41466194,
       0.26455561, 0.77423369, 0.45615033, 0.56843395, 0.0187898 ,
       0.6176355 , 0.61209572, 0.616934  , 0.94374808, 0.6818203 ,
       0.3595079 , 0.43703195, 0.6976312 , 0.06022547, 0.66676672,
       0.67063787, 0.21038256, 0.1289263 , 0.31542835, 0.36371077,
       0.57019677, 0.43860151, 0.98837384, 0.10204481, 0.20887676,
       0.16130952, 0.65310833, 0.2532916 , 0.46631077, 0.24442559,
       0.15896958, 0.11037514, 0.65632959, 0.13818295, 0.19658236])

In [594]: y=np.random.rand(N)

In [595]: colors=np.random.rand(N)

In [596]: area=(30*np.random.rand(N))**2

In [597]: plt.scatter(x,y,s=area,c=colors,alpha=.5)
Out[597]: <matplotlib.collections.PathCollection at 0x7f8c2db9b320>

In [598]: x
Out[598]: 
array([0.0871293 , 0.0202184 , 0.83261985, 0.77815675, 0.87001215,
       0.97861834, 0.79915856, 0.46147936, 0.78052918, 0.11827443,
       0.63992102, 0.14335329, 0.94466892, 0.52184832, 0.41466194,
       0.26455561, 0.77423369, 0.45615033, 0.56843395, 0.0187898 ,
       0.6176355 , 0.61209572, 0.616934  , 0.94374808, 0.6818203 ,
       0.3595079 , 0.43703195, 0.6976312 , 0.06022547, 0.66676672,
       0.67063787, 0.21038256, 0.1289263 , 0.31542835, 0.36371077,
       0.57019677, 0.43860151, 0.98837384, 0.10204481, 0.20887676,
       0.16130952, 0.65310833, 0.2532916 , 0.46631077, 0.24442559,
       0.15896958, 0.11037514, 0.65632959, 0.13818295, 0.19658236])

In [599]: y
Out[599]: 
array([0.36872517, 0.82099323, 0.09710128, 0.83794491, 0.09609841,
       0.97645947, 0.4686512 , 0.97676109, 0.60484552, 0.73926358,
       0.03918779, 0.28280696, 0.12019656, 0.2961402 , 0.11872772,
       0.31798318, 0.41426299, 0.0641475 , 0.69247212, 0.56660145,
       0.26538949, 0.52324805, 0.09394051, 0.5759465 , 0.9292962 ,
       0.31856895, 0.66741038, 0.13179786, 0.7163272 , 0.28940609,
       0.18319136, 0.58651293, 0.02010755, 0.82894003, 0.00469548,
       0.67781654, 0.27000797, 0.73519402, 0.96218855, 0.24875314,
       0.57615733, 0.59204193, 0.57225191, 0.22308163, 0.95274901,
       0.44712538, 0.84640867, 0.69947928, 0.29743695, 0.81379782])

In [600]: colors
Out[600]: 
array([0.39650574, 0.8811032 , 0.58127287, 0.88173536, 0.69253159,
       0.72525428, 0.50132438, 0.95608363, 0.6439902 , 0.42385505,
       0.60639321, 0.0191932 , 0.30157482, 0.66017354, 0.29007761,
       0.61801543, 0.4287687 , 0.13547406, 0.29828233, 0.56996491,
       0.59087276, 0.57432525, 0.65320082, 0.65210327, 0.43141844,
       0.8965466 , 0.36756187, 0.43586493, 0.89192336, 0.80619399,
       0.70388858, 0.10022689, 0.91948261, 0.7142413 , 0.99884701,
       0.1494483 , 0.86812606, 0.16249293, 0.61555956, 0.12381998,
       0.84800823, 0.80731896, 0.56910074, 0.4071833 , 0.069167  ,
       0.69742877, 0.45354268, 0.7220556 , 0.86638233, 0.97552151])

In [601]: area
Out[601]: 
array([6.59159425e+02, 1.23497791e-01, 1.16625786e+02, 4.79597599e+02,
       2.65110715e+01, 2.44331231e+02, 2.65735528e+00, 3.59987490e+01,
       3.08751183e-01, 5.66960440e+02, 4.51280393e+01, 1.07341005e+02,
       7.75201399e+02, 4.46579685e+02, 9.12345690e-01, 2.44117487e+01,
       3.47611863e+02, 2.99873559e+02, 5.09336950e+01, 7.85480215e+02,
       3.39258776e+02, 2.58212250e+02, 3.13194402e+02, 4.79770360e+02,
       8.75787122e+01, 1.42722013e+02, 3.96309591e+01, 3.12010519e+01,
       8.02655290e+02, 4.92241841e+02, 2.16494859e+02, 4.65456717e+01,
       5.82274978e+01, 3.03064510e+00, 1.69846024e+02, 8.74950048e+01,
       4.36404829e+02, 1.28426807e+02, 2.90317329e+01, 5.48135672e-01,
       4.07026164e+00, 4.15417087e+02, 1.85256744e+02, 2.59125525e+02,
       7.23617467e+02, 8.82694108e+02, 4.23398717e+01, 3.95705433e+02,
       6.24048067e+01, 3.83817401e-01])

/ 13	 .

/ voorbeeld uit	,
https://stackoverflow.com/questions/45247486/how-to-do-a-scatter-plot-with-different-edgecolor-in-matplotlib?answertab=active#tab-top

In [602]: %matplotlib
Using matplotlib backend: Qt5Agg

In [603]: x=range(0,12,2)

In [604]: x
Out[604]: range(0, 12, 2)

In [605]: x=np.arange(12,2)

In [606]: x
Out[606]: array([], dtype=int64)

In [607]: np.arange?

In [608]: x=np.arange(0,12,2)

In [609]: x
Out[609]: array([ 0,  2,  4,  6,  8, 10])

In [610]: y=np.zeros(x.size)

In [611]: y
Out[611]: array([0., 0., 0., 0., 0., 0.])

In [612]: s=[20*4**n for n in np.arange(x.size)]

In [613]: s
Out[613]: [20, 80, 320, 1280, 5120, 20480]

In [614]: plt.scatter(x,y=s=s)
  File "<ipython-input-614-51e7e6fb0183>", line 1
    plt.scatter(x,y=s=s)
                     ^
SyntaxError: invalid syntax


In [615]: plt.scatter(x,y,s=s)
Out[615]: <matplotlib.collections.PathCollection at 0x7f8c2da28400>

/ 13	. 

/ lees	,
https://stackoverflow.com/questions/4143502/how-to-do-a-scatter-plot-with-empty-circles-in-python

x = np.random.randn(60) 
y = np.random.randn(60)
plt.scatter(x, y, s=80, facecolors='none', edgecolors='r')
plt.show()
/ zonder edgecolors zien we de punten niet	, omdat we facecolors='none' hebben	,
/ we kunnen ook	,
In [660]: plt.scatter(x,y,s=80,edgecolors='r',facecolors='b',alpha=.3)
Out[660]: <matplotlib.collections.PathCollection at 0x7f8c2d318320>



/ Einde Intermezzo

/ (84)

In [661]: np.random.seed(0)

In [662]: x=np.random.randn(100)

In [663]: x
Out[663]: 
array([ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,  1.86755799,
       -0.97727788,  0.95008842, -0.15135721, -0.10321885,  0.4105985 ,
        0.14404357,  1.45427351,  0.76103773,  0.12167502,  0.44386323,
        0.33367433,  1.49407907, -0.20515826,  0.3130677 , -0.85409574,
       -2.55298982,  0.6536186 ,  0.8644362 , -0.74216502,  2.26975462,
       -1.45436567,  0.04575852, -0.18718385,  1.53277921,  1.46935877,
        0.15494743,  0.37816252, -0.88778575, -1.98079647, -0.34791215,
        0.15634897,  1.23029068,  1.20237985, -0.38732682, -0.30230275,
       -1.04855297, -1.42001794, -1.70627019,  1.9507754 , -0.50965218,
       -0.4380743 , -1.25279536,  0.77749036, -1.61389785, -0.21274028,
       -0.89546656,  0.3869025 , -0.51080514, -1.18063218, -0.02818223,
        0.42833187,  0.06651722,  0.3024719 , -0.63432209, -0.36274117,
       -0.67246045, -0.35955316, -0.81314628, -1.7262826 ,  0.17742614,
       -0.40178094, -1.63019835,  0.46278226, -0.90729836,  0.0519454 ,
        0.72909056,  0.12898291,  1.13940068, -1.23482582,  0.40234164,
       -0.68481009, -0.87079715, -0.57884966, -0.31155253,  0.05616534,
       -1.16514984,  0.90082649,  0.46566244, -1.53624369,  1.48825219,
        1.89588918,  1.17877957, -0.17992484, -1.07075262,  1.05445173,
       -0.40317695,  1.22244507,  0.20827498,  0.97663904,  0.3563664 ,
        0.70657317,  0.01050002,  1.78587049,  0.12691209,  0.40198936])

In [664]: np.max(x)
Out[664]: 2.2697546239876076

In [665]: bins=np.linspace(-5,5,20)

/ Intermezzo

/ 20 punten van -5 t/m 5	,
In []: bins
Out[]: 
array([-5.        , -4.47368421, -3.94736842, -3.42105263, -2.89473684,		
       -2.36842105, -1.84210526, -1.31578947, -0.78947368, -0.26315789,
        0.26315789,  0.78947368,  1.31578947,  1.84210526,  2.36842105,
        2.89473684,  3.42105263,  3.94736842,  4.47368421,  5.        ])
/ we zien niet de echte grens	,

/ Dit zijn de echte grenzen	,
In [89]: bins[0]
Out[89]: -5.0
In [90]: bins[1]
Out[90]: -4.473684210526316
In [91]: bins[2]
Out[91]: -3.947368421052632

0			1												2																				/ index
(,-5](-5,-4.473684210526316](-4.473684210526316,-3.947368421052632] 	/ interval	,

In [88]: np.searchsorted(bins,-4.473684210526317)
Out[88]: 1
In [86]: np.searchsorted(bins,-4.473684210526316)
Out[86]: 1
In [87]: np.searchsorted(bins,-4.473684210526315)
Out[87]: 2

/ Einde Intermezzo

np.zeros_like?
Parameters
----------
a : array_like
    The shape and data-type of `a` define these same attributes of
    the returned array.

/ geef een array zoals bins, maar dan met 0's er in	,	van hetzelfde type	, hier numpy.floats64	,


In [667]: counts=np.zeros_like(bins)
In [669]: counts
Out[669]: 
array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0.])

In [673]: i=np.searchsorted(bins,x)

In [674]: i
Out[674]: 
array([13, 11, 12, 14, 14,  8, 12, 10, 10, 11, 10, 13, 11, 10, 11, 11, 13,
       10, 11,  8,  5, 11, 12,  9, 14,  7, 10, 10, 13, 13, 10, 11,  8,  6,
        9, 10, 12, 12,  9,  9,  8,  7,  7, 14,  9,  9,  8, 11,  7, 10,  8,
       11,  9,  8, 10, 11, 10, 11,  9,  9,  9,  9,  8,  7, 10,  9,  7, 11,
        8, 10, 11, 10, 12,  8, 11,  9,  8,  9,  9, 10,  8, 12, 11,  7, 13,
       14, 12, 10,  8, 12,  9, 12, 10, 12, 11, 11, 10, 13, 10, 11])

/ Intermezzo

In [12]: binsf=np.linspace(0,5,6)

In [13]: binsf
Out[13]: array([0., 1., 2., 3., 4., 5.])

/ het interval wordt verdeeld in (,0](0,1](1,2]...(4,5],(5,)
/ index:													0   1    2         5   6

In [48]: np.searchsorted(binsf,10)
Out[48]: 6
In [47]: np.searchsorted(binsf,5)
Out[47]: 5
...
In [42]: np.searchsorted(binsf,1.00001)
Out[42]: 2
In [43]: np.searchsorted(binsf,1.000)
Out[43]: 1
In [44]: np.searchsorted(binsf,.0001)
Out[44]: 1
In [45]: np.searchsorted(binsf,.0)
Out[45]: 0
In [46]: np.searchsorted(binsf,-10)
Out[46]: 0
/ Denk dus: getal zit in interval tot aan ...	, ... is de index	,


In [14]: x=np.array([.5,.3,6.5,3.3,2.1,2])
In [15]: np.searchsorted(bins,x)
Out[15]: array([1, 1, 6, 4, 3, 2])

/ Einde Intermezzo

/ Intermezzo

/ we hebben i	, hoe vaak komt elk getal voor?

/ lees	,
https://stackoverflow.com/questions/6252280/find-the-most-frequent-number-in-a-numpy-vector

/ Ook met : from collections import Counter
/ TODO

In [101]: x=np.random.randint(10,20,10)

In [102]: x
Out[102]: array([18, 16, 16, 19, 11, 16, 18, 18, 13, 12])
In [107]: np.max(x)
Out[107]: 19 


In [103]: np.bincount(x)
Out[103]: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 3, 0, 3, 1])
In [104]: np.bincount(x).size
Out[104]: 20

/ np.bincount kijkt naar max, en dat wordt grootste index in count array	, dus count array is max+1 lang	, 

/ Einde Intermezzo

/ we hadden	,

In [697]: x
Out[697]: 
array([ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,  1.86755799,
       -0.97727788,  0.95008842, -0.15135721, -0.10321885,  0.4105985 ,
        0.14404357,  1.45427351,  0.76103773,  0.12167502,  0.44386323,
        0.33367433,  1.49407907, -0.20515826,  0.3130677 , -0.85409574,
       -2.55298982,  0.6536186 ,  0.8644362 , -0.74216502,  2.26975462,
       -1.45436567,  0.04575852, -0.18718385,  1.53277921,  1.46935877,
        0.15494743,  0.37816252, -0.88778575, -1.98079647, -0.34791215,
        0.15634897,  1.23029068,  1.20237985, -0.38732682, -0.30230275,
       -1.04855297, -1.42001794, -1.70627019,  1.9507754 , -0.50965218,
       -0.4380743 , -1.25279536,  0.77749036, -1.61389785, -0.21274028,
       -0.89546656,  0.3869025 , -0.51080514, -1.18063218, -0.02818223,
        0.42833187,  0.06651722,  0.3024719 , -0.63432209, -0.36274117,
       -0.67246045, -0.35955316, -0.81314628, -1.7262826 ,  0.17742614,
       -0.40178094, -1.63019835,  0.46278226, -0.90729836,  0.0519454 ,
        0.72909056,  0.12898291,  1.13940068, -1.23482582,  0.40234164,
       -0.68481009, -0.87079715, -0.57884966, -0.31155253,  0.05616534,
       -1.16514984,  0.90082649,  0.46566244, -1.53624369,  1.48825219,
        1.89588918,  1.17877957, -0.17992484, -1.07075262,  1.05445173,
       -0.40317695,  1.22244507,  0.20827498,  0.97663904,  0.3563664 ,
        0.70657317,  0.01050002,  1.78587049,  0.12691209,  0.40198936])

In [698]: bins
Out[698]: 
array([-5.        , -4.47368421, -3.94736842, -3.42105263, -2.89473684,
       -2.36842105, -1.84210526, -1.31578947, -0.78947368, -0.26315789,
        0.26315789,  0.78947368,  1.31578947,  1.84210526,  2.36842105,
        2.89473684,  3.42105263,  3.94736842,  4.47368421,  5.        ])

In [696]: i
Out[696]: 
array([13, 11, 12, 14, 14,  8, 12, 10, 10, 11, 10, 13, 11, 10, 11, 11, 13,
       10, 11,  8,  5, 11, 12,  9, 14,  7, 10, 10, 13, 13, 10, 11,  8,  6,
        9, 10, 12, 12,  9,  9,  8,  7,  7, 14,  9,  9,  8, 11,  7, 10,  8,
       11,  9,  8, 10, 11, 10, 11,  9,  9,  9,  9,  8,  7, 10,  9,  7, 11,
        8, 10, 11, 10, 12,  8, 11,  9,  8,  9,  9, 10,  8, 12, 11,  7, 13,
       14, 12, 10,  8, 12,  9, 12, 10, 12, 11, 11, 10, 13, 10, 11])

/ welke komt het meest voor? En hoe vaak?

/ we doen	,
In [700]: cnt=np.bincount(i)
In [701]: cnt
Out[701]: array([ 0,  0,  0,  0,  0,  1,  1,  7, 13, 16, 20, 19, 11,  7,  5])
In [702]: np.max(i)
Out[702]: 14
In [703]: cnt.size
Out[703]: 15

/ deze komt het meest voor	,
In [717]: np.argmax(cnt)
Out[717]: 10
/ en zo vaak:
In [719]: cnt[np.argmax(cnt)]
Out[719]: 20

/ Vind index die het minst voorkomt	,
/ TODO

/ np.nonzero(arr) = indexes waar arr!=0


/ Intermezzo

/ voorbeelden bij	,
np.argmax?

>>> a = np.arange(6).reshape(2,3)
>>> a
array([[0, 1, 2],
       [3, 4, 5]])
>>> np.argmax(a)
5
>>> np.argmax(a, axis=0)
array([1, 1, 1])
>>> np.argmax(a, axis=1)
array([2, 2])

Indexes of the maximal elements of a N-dimensional array:

>>> ind = np.unravel_index(np.argmax(a, axis=None), a.shape)
>>> ind
(1, 2)
>>> a[ind]
5
/ TODO


/ Einde Intermezzo

/ we hebben	, 

n [729]: counts
Out[729]: 
array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0.])

In [730]: i
Out[730]: 
array([13, 11, 12, 14, 14,  8, 12, 10, 10, 11, 10, 13, 11, 10, 11, 11, 13,
       10, 11,  8,  5, 11, 12,  9, 14,  7, 10, 10, 13, 13, 10, 11,  8,  6,
        9, 10, 12, 12,  9,  9,  8,  7,  7, 14,  9,  9,  8, 11,  7, 10,  8,
       11,  9,  8, 10, 11, 10, 11,  9,  9,  9,  9,  8,  7, 10,  9,  7, 11,
        8, 10, 11, 10, 12,  8, 11,  9,  8,  9,  9, 10,  8, 12, 11,  7, 13,
       14, 12, 10,  8, 12,  9, 12, 10, 12, 11, 11, 10, 13, 10, 11])

In [732]: counts
Out[732]: 
array([ 0.,  0.,  0.,  0.,  0.,  1.,  1.,  7., 13., 16., 20., 19., 11.,
        7.,  5.,  0.,  0.,  0.,  0.,  0.])

/ vergl	,
In [700]: cnt=np.bincount(i)
n [733]:  cnt
Out[733]: array([ 0,  0,  0,  0,  0,  1,  1,  7, 13, 16, 20, 19, 11,  7,  5])

/ counts is beter	, want cnt stopt bij grootste index van bins, waar bins!=0	, en dat is niet goed	,

/ dan	,

In [737]: bins
Out[737]: 
array([-5.        , -4.47368421, -3.94736842, -3.42105263, -2.89473684,
       -2.36842105, -1.84210526, -1.31578947, -0.78947368, -0.26315789,
        0.26315789,  0.78947368,  1.31578947,  1.84210526,  2.36842105,
        2.89473684,  3.42105263,  3.94736842,  4.47368421,  5.        ])
In [738]: counts
Out[738]: 
array([ 0.,  0.,  0.,  0.,  0.,  1.,  1.,  7., 13., 16., 20., 19., 11.,
        7.,  5.,  0.,  0.,  0.,  0.,  0.])
In [735]: %matplotlib
Using matplotlib backend: Qt5Agg

In [736]: plt.plot(bins,counts,linestyle='steps')
Out[736]: [<matplotlib.lines.Line2D at 0x7f8c2d0a3320>]
/ OK	,

/ 13	.

/ Maar zonder np.searchsorted, en een counts np.array  en np.add.at	, kunnen we met x en bins in 1 keer	,
In [779]: plt.hist(x,bins,histtype='step'
     ...: )
Out[779]: 
(array([ 0.,  0.,  0.,  0.,  1.,  1.,  7., 13., 16., 20., 19., 11.,  7.,
         5.,  0.,  0.,  0.,  0.,  0.]),
 array([-5.        , -4.47368421, -3.94736842, -3.42105263, -2.89473684,
        -2.36842105, -1.84210526, -1.31578947, -0.78947368, -0.26315789,
         0.26315789,  0.78947368,  1.31578947,  1.84210526,  2.36842105,
         2.89473684,  3.42105263,  3.94736842,  4.47368421,  5.        ]),
 <a list of 1 Patch objects>)
/ OK	, we zien ook het hist	,

/ 13	.

/ voor .histogram hoeven we niet eerst counts te create,	voor np.searchsorted & np.add.at wel	,

In [780]: del counts
In [781]: del edges
In [782]: counts,edges=np.histogram(x,bins)
In [783]: counts
Out[783]: 
array([ 0,  0,  0,  0,  1,  1,  7, 13, 16, 20, 19, 11,  7,  5,  0,  0,  0,
        0,  0])
In [784]: edges is bins
Out[784]: True

In [775]: counts=np.zeros_like(bins)
In [776]: np.add.at(counts,np.searchsorted(bins,x),1)

In [777]: counts
Out[777]: 
array([ 0.,  0.,  0.,  0.,  0.,  1.,  1.,  7., 13., 16., 20., 19., 11.,
        7.,  5.,  0.,  0.,  0.,  0.,  0.])

/ we zien dat counts van type numpy.int64 is bij .histogram	, 
/ maar omdat we np.zeros_like(bins) hebben gedaan , is hij bij np.searchsorted van type numpy.float64	, maar dat hoeft niet: we kunnen 
In [791]: counts=np.zeros(20,dtype=np.int64)
In [776]: np.add.at(counts,np.searchsorted(bins,x),1)

/ 13	. 

In [795]: del counts

In [796]: del edges

In [797]: %timeit counts,edges=np.histogram(x,bins)
87.7 µs ± 152 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)

In [798]: counts=np.zeros(20,dtype=np.int64)

In [799]: %timeit np.add.at(counts,np.searchsorted(bins,x),1)
16 µs ± 69.3 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)

/ om meerdere lines te meten, use %%timeit

In [800]: %%timeit
     ...: counts=np.zeros(20,dtype=np.int64)
     ...: np.add.at(counts,np.searchsorted(bins,x),1)
     ...: 
18.3 µs ± 47.1 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)

/ maar als we x een groot array laten zijn	,

In [803]: x=np.random.randn(1000000)

In [807]: del edges
NameError: name 'edges' is not defined
In [808]: del counts
In [809]: %timeit counts,edges=np.histogram(x,bins)
69.6 ms ± 41.1 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)

In [811]: counts=np.zeros(20,dtype=np.int64)
In [812]: %%timeit
     ...: counts=np.zeros(20,dtype=np.int64)
     ...: np.add.at(counts,np.searchsorted(bins,x),1)
     ...: 
91.3 ms ± 362 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)

/ nu is .histogram de snelste	,


/ 13	 

/ google	,
numpy how to check number in interval
/ lees	,
https://stackoverflow.com/questions/618093/how-to-find-whether-a-number-belongs-to-a-particular-range-in-python
/ in ipython:
'yes' if 0 < x < 0.5 else 'no'
/ in script WH:
print 'yes' if 0 < x < 0.5 else 'no'

/ (86)

/ sort	,

/ oef	,
In [817]: x=np.random.randint(0,100,16)
In [818]: x
Out[818]: array([47, 64, 67, 67,  9, 83, 21, 36, 87, 70, 88, 88, 12, 58, 65, 39])
In [819]: x[10:]
Out[819]: array([88, 88, 12, 58, 65, 39])
In [822]: np.argmin(x[10:])
Out[822]: 2

/ oef	,
x=[9,5,2,4]
/ na i=2 is 
x=[2,4,5,9]
/ dan bij i=3 is np.argmin(x[3:])=0	, dus wisselt het alg 3 met zichzelf	,

/ omdat np.argmin(x[i:]) index i op 0 set	, moet je i+ doen om de index in x te krijgen van het min	,

/ (87)

/ er zijn ndarray.sort en numpy.sort	 , en ndarray.sort = numpy.ndarray.sort	,
/ we kunnen 
np.sort(x)	/= numpy.sort
x.sort()		/= numpy.ndarray.sort	,

/ lees	,
https://developers.google.com/edu/python/sorting
/ in python heb je sorted en .sort	,
/ sorted(alist) werkt op de list alist	, en alist.sort() sorts alist	,

/ Intermezzo

/ lees	,
https://stackoverflow.com/questions/22994423/difference-between-np-random-seed-and-np-random-randomstate 

np.random.seed(1234)
np.random.uniform(0, 10, 5)
#array([ 1.9151945 ,  6.22108771,  4.37727739,  7.85358584,  7.79975808])
np.random.rand(2,3)
#array([[ 0.27259261,  0.27646426,  0.80187218],
#       [ 0.95813935,  0.87593263,  0.35781727]])

r = np.random.RandomState(1234)
r.uniform(0, 10, 5)
#array([ 1.9151945 ,  6.22108771,  4.37727739,  7.85358584,  7.79975808])
r.rand(2,3)
#array([[ 0.27259261,  0.27646426,  0.80187218],
#       [ 0.95813935,  0.87593263,  0.35781727]])

/ als je een initiele seed geeft,  zie je die met .get_state():

In [861]: r=np.random.RandomState(7)

In [862]: r.get_state()
Out[862]: 
('MT19937', array([         7, 4097098180, 3572822661, 1142383841, 2757143652,
        4148075075, 1140792134,  204456458, 3824478202, 1670563398,
...

/ als je dan een actie doet	, verandert de state	,

In [866]: r.rand()
Out[866]: 0.07630828937395717
In [867]: r.get_state()
Out[867]: 
('MT19937', array([2022286329, 1444425037, 2858264774, 1581888170,  958328592,
         424657840, 3083047336, 4028460642, 3212988162, 2823205209,
...
In [868]: r.rand()
Out[868]: 0.7799187922401146

/ als we opnieuw	,
In [869]: r=np.random.RandomState(2022286329)
In [870]: r.rand()
Out[870]: 0.5412265689852084
/ Dus het gaat toch anders	,
/ TODO

/ 13	. 

In [872]: r.rand(2)
Out[872]: array([0.65564312, 0.6144584 ])

In [873]: r.rand(2,2)
Out[873]: 
array([[0.49288474, 0.88290346],
       [0.61165609, 0.15416921]])

In [874]: r.rand(0)
Out[874]: array([], dtype=float64)
In [875]: r.rand(0,0)
Out[875]: array([], shape=(0, 0), dtype=float64)


/ Einde Intermezzo

/ (88)

/ in np.partition(x,3) staan de kleinste 3 getallen uit x vooraan, dus voor index 3	,

/ (89)

/ 2 dim array	,

In [938]: x=np.arange(1,5)
In [939]: x
Out[939]: array([1, 2, 3, 4])
In [940]: x.reshape(2,2)
Out[940]: 
array([[1, 2],
       [3, 4]])

In [941]: y=np.array([1,2])

In [942]: y2=y[:,np.newaxis]
In [943]: y2
Out[943]: 
array([[1],
       [2]])

In [944]: y1=y[np.newaxis,:]
In [945]: y1
Out[945]: array([[1, 2]])




/ 3 dim array	,

In [931]: x=np.arange(1,9).reshape(2,2,2)
Out[931]: 
array([[[1, 2],
        [3, 4]],

       [[5, 6],
        [7, 8]]])

/ denk  1234 op de grond en 5678 boven,
/ de 1-richting is omhoog, de 2-richting naar voren, en de 3-richting naar rechts, 
/ de kolom richting in een vlak is altijd in  positieve richting	,
	5		6
 /   /
7   8
	1   2
 /   /
3		4

In [990]: x[0,:,:]	/ omhoog	, grondvlak	,
Out[990]: 
array([[1, 2],
       [3, 4]])

In [991]: x[:,0,:]	/ naar voren, achtervlak	,
Out[991]: 
array([[1, 2],
       [5, 6]])

In [992]: x[:,:,0]	 / naar rechts, linker zijvlak	,
Out[992]: 
array([[1, 3],
       [5, 7]])
/ omdat net als in het grondvlak de kolomrichting naar positieve richting is, is dat in het linker zijvlak ook	,dus
1 3 
5 7

In [976]: x[0]
Out[976]: 
array([[1, 2],
       [3, 4]])
In [986]: x.T[0]
Out[986]: 
array([[1, 5],
       [3, 7]])

In [977]: x[0][0]
Out[977]: array([1, 2])
In [987]: x.T[0][0]
Out[987]: array([1, 5])
In [980]: x[0].T[0]
Out[980]: array([1, 3])


In [959]: y
Out[959]: 
array([[1, 2],
       [3, 4]])

/ 13	. 

/ we willen 
array([[[1, 3],
        [2, 4]],

       [[5, 7],
        [6, 8]]])

/ we dachten zo:

In [1007]: x
Out[1007]: 
array([[[1, 2],
        [3, 4]],

       [[5, 6],
        [7, 8]]])

In [1008]: [x[0],x[1]]
Out[1008]: 
[array([[1, 2],
        [3, 4]]), array([[5, 6],
        [7, 8]])]

/ 1313	. 

In [931]: x=np.arange(1,9).reshape(2,2,2)

/ terwijl z[0].T fortran is	, blijft z[0] c na z[0]=z[0].T	, 

In [1036]: z=x.copy()
In [1040]: z[0]=z[0].T
In [1043]: z[0].flags
Out[1043]: 
  C_CONTIGUOUS : True
  F_CONTIGUOUS : False

/ 1313	. 

In [931]: x=np.arange(1,9).reshape(2,2,2)
In [1052]: [x[0].T,x[1].T]
Out[1052]: 
[array([[1, 3],
        [2, 4]]), array([[5, 7],
        [6, 8]])]

/ 1313	. 

In [931]: x=np.arange(1,9).reshape(2,2,2)

In [1049]: z=np.array([x[0].T,x[1].T])

In [1050]: z
Out[1050]: 
array([[[1, 3],
        [2, 4]],

       [[5, 7],
        [6, 8]]])

In [1051]: z.flags
Out[1051]: 
  C_CONTIGUOUS : True
  F_CONTIGUOUS : False

/ doe daarom	,

In [1054]: z=np.array([x[0].T,x[1].T],order='f')

In [1055]: z
Out[1055]: 
array([[[1, 3],
        [2, 4]],

       [[5, 7],
        [6, 8]]])

In [1057]: z.flags
Out[1057]: 
  C_CONTIGUOUS : False
  F_CONTIGUOUS : True

In [1058]: z[0].flags
Out[1058]: 
  C_CONTIGUOUS : False
  F_CONTIGUOUS : False

/ terwijl	,
In [1062]: x[0].T.flags
Out[1062]: 
  C_CONTIGUOUS : False
  F_CONTIGUOUS : True


In [1059]: z[0]
Out[1059]: 
array([[1, 3],
       [2, 4]])

In [1060]: z[0][0]
Out[1060]: array([1, 3])
/ NIET de bedoeling	,

/ 1313	. 

In [1074]: z=np.array([1,3,2,4,5,7,6,8],order='f')

In [1075]: z=z.reshape(2,2,2)

In [1076]: z
Out[1076]: 
array([[[1, 3],
        [2, 4]],

       [[5, 7],
        [6, 8]]])

In [1077]: z[0]
Out[1077]: 
array([[1, 3],
       [2, 4]])

In [1078]: z[0][0]
Out[1078]: array([1, 3])

/ denk fout: order doet niet bij 1-dim 

In [1079]: z.flags
Out[1079]: 
  C_CONTIGUOUS : True
  F_CONTIGUOUS : False

/ 1313	. 

In [1082]:  z=np.arange(1,9).reshape(2,2,2).T

In [1083]: z
Out[1083]: 
array([[[1, 5],
        [3, 7]],

       [[2, 6],
        [4, 8]]])

In [1084]: z.flags
Out[1084]: 
  C_CONTIGUOUS : False
  F_CONTIGUOUS : True

In [1086]: z[0].flags
Out[1086]: 
  C_CONTIGUOUS : False
  F_CONTIGUOUS : False

In [1088]: z[0][0]
Out[1088]: array([1, 5])
/ Nog fout	, 
/ TODO

/ 1313	. 

In [1108]: z0=np.arange(1,5).reshape(2,2).T
In [1111]: z1=np.arange(5,9).reshape(2,2).T
In [1112]: z=np.array([z0,z1],order='f')
In [1113]: z.flags
Out[1113]: 
  C_CONTIGUOUS : False
  F_CONTIGUOUS : True
In [1114]: z[0].flags
Out[1114]: 
  C_CONTIGUOUS : False
  F_CONTIGUOUS : False
/ de fortran order van z[0] is teniet gedaan	,
/ TODO


/ 13	. 

In [1127]: y=np.arange(1,5).reshape(2,2)

In [1124]: y
Out[1124]: 
array([[1, 2],
       [3, 4]])


In [960]: y1=y[np.newaxis,:,:]	/ [[1,2],[3,4]] in grondvlak 
In [961]: y2=y[:,np.newaxis,:]/ [[1,2],[3,4]] in achtervlak 
In [962]: y3=y[:,:,np.newaxis]/ [[1,2],[3,4]] in linkervlak	, 

In [1134]: y1
Out[1134]: 
array([[[1, 2],			/ [[1,2],[3,4]] in grondvlak
        [3, 4]]])

In [1138]: y1[1]=np.arange(5,9).reshape(2,2)
IndexError: index 1 is out of bounds for axis 0 with size 1

/ lees	,
https://stackoverflow.com/questions/4226386/resizing-and-stretching-a-numpy-array

/ 131313	,

In [1205]: w1=np.repeat(y1,2,axis=0)

In [1206]: w1
Out[1206]: 
array([[[1, 2],
        [3, 4]],

       [[1, 2],
        [3, 4]]])
/ we zien [[1,2],[3,4]] ook in bovenvlak	,

In [1207]: w1[1,:,:]
Out[1207]: 
array([[1, 2],
       [3, 4]])


/ 131313	 , 


In [1201]: y2
Out[1201]: 
array([[[1, 2]],		/ [[1,2],[3,4]] in achtervlak	,

       [[3, 4]]])


In [1194]: z2=y2.copy()

In [1196]: w2=np.repeat(z2,2,axis=1)
Out[1196]: w2 
Out[1196]: 
array([[[1, 2],	
        [1, 2]],	

       [[3, 4],
        [3, 4]]]
/ het wordt genoteerd: [[1,2],[1,2]] in grondvlak, en [[3,4],[3,4]] in het bovenvlak
/ maar waar het om gaat, en waar het gelijk aan is is [[1,2],[3,4]] in het achtervlak en in het voorvlak	,

In [1198]: w2[:,0,:]	 / achtervlak
Out[1198]: 
array([[1, 2],
       [3, 4]])

In [1199]: w2[:,1,:]	/ voorvlak	,
Out[1199]: 
array([[1, 2],
       [3, 4]])

/ 131313	, 

/ [[1,2],[3,4]] in het linkervlak	,
/ dat noteren ze altijd als onder/bovenvlak: [[1],[2]] in het ondervlak	, [[3],[4]] boven	,
In [1211]: y3
Out[1211]: 
array([[[1],
        [2]],

       [[3],
        [4]]])


In [1209]: w3=np.repeat(y3,2,axis=2)

/ [[1,1],[2,2]] in het ondervlak, en [[3,3],[4,4]] boven
/=
/ [[1,2],[3,4]] links en nu ook rechts	,
In [1210]: w3
Out[1210]: 
array([[[1, 1],
        [2, 2]],

       [[3, 3],
        [4, 4]]])

/ 1313	. 

/ RICHTINGEN

/ onthoud	, 

  	|1
		|
		/-----3
	 /2

/ 1313	. 

/ we oef (89)

In [1230]: k=np.array([[1,2],[3,4]])

In [1231]: k.shape
Out[1231]: (2, 2)

/ set set in achtervlak:
1 2
3 4
In [1233]: k[:,np.newaxis,:]
Out[1233]: 
array([[[1, 2]],

       [[3, 4]]])

/ set in grondvlak:
1 2
3 4
In [1234]: k[np.newaxis,:,:]
Out[1234]: 
array([[[1, 2],
        [3, 4]]])



/ we gaan broadcast	,						/ !
/ set in achter en voorvlak	, resp in onder en bovenvlak en trek af	,
In [1232]: k[:,np.newaxis,:]-k[np.newaxis,:,:]
Out[1232]: 
array([[[ 0,  0],
        [-2, -2]],

       [[ 2,  2],
        [ 0,  0]]])

/ het ziet er zo uit:
	3 4	achte							1 2 boven 			2 2
	1 2 				- 	 		 3 4				= 	 0 0

3 4	voor								1 2 onder 		  0 0	
1 2			 				 		 	 3 4					  -2-2

/ 1313	. 

/ we nemen 4 punten	,

In [1241]: l=np.array([[1,2],[3,4],[2,1],[4,3]])

In [1242]: np.sum((l[:,np.newaxis,:]-l[np.newaxis,:,:])**2,axis=-1)
Out[1242]: 
array([[ 0,  8,  2, 10],
       [ 8,  0, 10,  2],
       [ 2, 10,  0,  8],
       [10,  2,  8,  0]])

/ klopt, de onderlinge afstand tussen
pnt 1 en pnt 2 is 8: |(1,2)-(3,4)|**2
pnt 1 en pnt 3 is 2: |(1,2)-(2,1)|**2 
...

/ we hebben array	,
1 2
3 4
2 1
4 3
/ en deze zetten we in achtervlak en in het grondvlak,  dus 
/ in het achtervlak
4 3
2 1
3 4
1 2 	- beneden in het achtervlak	,
/ en in het grond vlak	,
1 2 - achteraan in het grondvlak
3 4 
2 1
4 3

/ en we broadcast ze beide:
/ de 1ste in nog eens 3 voorvlakken	, de 2de in nog eens 3 bovenvlakken	,
/ ieder is een gelijke balk, shape=(4,4,2)
/  we krijgen 2 balken	, we zien links en rechts op de hoofddiagonaal/vlak van de balken de punten 1 2, 3 4 , 2 1 en 4 3	. Buiten het hoofdvlak zien we de onderlingen punten 2 keer	, bijv 1 2 en 4 3 , en ook 4 3 en 2 1 aan de andere kant van het hoofdvlak	,
/ we hebben gedaan: 
In [1247]: n=l[:,np.newaxis,:]-l[np.newaxis,:,:]
In [1247]: n
Out[1247]: 
array([[[ 0,  0],	 / grond
        [-2, -2],
        [-1,  1],
        [-3, -1]],

       [[ 2,  2],	/ vlak erboven
        [ 0,  0],
        [ 1,  3],
        [-1,  1]],

       [[ 1, -1],		/ vlak erboven
        [-1, -3],
        [ 0,  0],
        [-2, -2]],

       [[ 3,  1],	/ vlak erboven
        [ 1, -1],
        [ 2,  2],
        [ 0,  0]]])

In [1262]: n.shape
Out[1262]: (4,4,2)

In [1248]: r=np.sum((l[:,np.newaxis,:]-l[np.newaxis,:,:])**2,axis=-1)
Out[1248]: r 
array([[ 0,  8,  2, 10],
       [ 8,  0, 10,  2],
       [ 2, 10,  0,  8],
       [10,  2,  8,  0]])
/ axis -1, want dan tel je de 2 coord bij elkaar op	, dat moet met lengte**2	,

In [1263]: r.shape
Out[1263]: (4,4)

In [1270]: r.diagonal()
Out[1270]: array([0, 0, 0, 0])

In [1271]: np.argsort(r,axis=1)
Out[1271]: 
array([[0, 2, 1, 3],
       [1, 3, 0, 2],
       [2, 0, 3, 1],
       [3, 1, 2, 0]])

/ hij sorteert over de kolommen(axis=1) iedere rij	, 
/ dus bijv de 2de rij: 8,0,10,2 is gesorteerd (geef de indexes): 1,3,0,2

/ de 1ste index op elke rij is die van het diagonaal elem, want die heeft onderlinge afstand met zichzelf van 0	, 
/ Dus we zien op de 1ste rij dat van index 0 , dat is 1,2,  het dichtst bij is index 2, en dat is: 2,1, en daarna index 1, dat is 3,4 en daarna index 3, dat is 4,3	, 
/ Dus we zien op de 2de rij dat van index 1 , dat is 3,4 , het dichtst bij is index 3, en dat is: 4,3, daarna index 0, dat is 1,2 en daarna index 2 , dat is 2,1	, 
...

/ 1313	. 

/ als we niet precies willen weten welk punt het dichts bij ligt, en die daarna, en die daarna, kunnen we ook zeggen: geef de bijv 2 dichtsbijzijnde punten:

/ ipv X	,
In [1312]: l
Out[1312]: 
array([[1, 2],
       [3, 4],
       [2, 1],
       [4, 3]])

In [1273]: r
Out[1273]: 
array([[ 0,  8,  2, 10],
       [ 8,  0, 10,  2],
       [ 2, 10,  0,  8],
       [10,  2,  8,  0]])


/ ik vind dit duidelijk	;
In [1271]: np.argsort(r,axis=1)
Out[1271]: 
array([[0, 2, 1, 3],
       [1, 3, 0, 2],	  bij pnt 1 ligt 3 het dichtst bij, daarna 0	,
       [2, 0, 3, 1],
       [3, 1, 2, 0]])

/ het boek doet:
In [1310]: p=np.argpartition(r,3,axis=1)
In [1311]: p
Out[1311]: 
array([[2, 0, 1, 3],		/ waarom is niet 0,2,1 bijv? TODO	, het is rond pnt 0
       [1, 3, 0, 2],	 / 1,3,0 liggen het dichtst bij elkaar	, het is rond pnt 1	,
       [2, 0, 3, 1],
       [3, 1, 2, 0]])

/ i=0	, j=2,0,1	/ trek lijn van 0 naar 2, (0 naar 0) en 0 naar 1 
/ i=1	, j=1,3,0 /trek lijn van (1 naar 1), 1 naar 3 en 1 naar 0	,
/ i=2	, j=2,0,3
/ i=3	, j=3,1,2

/ we zien	,

				x1
			 /	\
			/		x3
	    x0 /
			\ /
			x2
/ 13	. 

/ terug naar (89)

In [1212]: X
Out[1212]: 
array([[0.5488135 , 0.71518937],
       [0.60276338, 0.54488318],
       [0.4236548 , 0.64589411],
       [0.43758721, 0.891773  ],
       [0.96366276, 0.38344152],
       [0.79172504, 0.52889492],
       [0.56804456, 0.92559664],
       [0.07103606, 0.0871293 ],
       [0.0202184 , 0.83261985],
       [0.77815675, 0.87001215]])

/ de 1ste kolom	, (boven de grafiek)	,
In [1214]: X[:,0]
Out[1214]: 
array([0.5488135 , 0.60276338, 0.4236548 , 0.43758721, 0.96366276,
       0.79172504, 0.56804456, 0.07103606, 0.0202184 , 0.77815675])

/ we berekenen onderin	,
/ we zien dat de rijen niet op 1 regel kunnen, maar op 2	,
In [1264]: n=X[:,np.newaxis,:]-X[np.newaxis,:,:]
In [1262]: n.shape
Out[1262]: (10, 10, 2)
In [1250]: r=np.sum((X[:,np.newaxis,:]-X[np.newaxis,:,:])**2,axis=-1)
Out[1250]: 
array([[0.        , 0.03191478, 0.02046653, 0.04355307, 0.28215654, 	/ rij 1
        0.09371163, 0.04464105, 0.62273073, 0.2932027 , 0.07656842],
       [0.03191478, 0.        , 0.04228309, 0.14761571, 0.15631178,		/ rij 2
        0.03596213, 0.14614813, 0.49227256, 0.42215104, 0.13647168],
       [0.02046653, 0.04228309, 0.        , 0.06065054, 0.36048996,
        0.14916451, 0.09908191, 0.43655809, 0.19762743, 0.17590053],
       [0.04355307, 0.14761571, 0.06065054, 0.        , 0.53515638,
        0.2570941 , 0.01816316, 0.78181123, 0.17769582, 0.11646115],
       [0.28215654, 0.15631178, 0.36048996, 0.53515638, 0.        ,
        0.05071927, 0.45044593, 0.88458336, 1.09184844, 0.27116346],
       [0.09371163, 0.03596213, 0.14916451, 0.2570941 , 0.05071927,
        0.        , 0.20740521, 0.71454947, 0.68747133, 0.11654506],
       [0.04464105, 0.14614813, 0.09908191, 0.01816316, 0.45044593,
        0.20740521, 0.        , 0.95004493, 0.30875819, 0.04723677],
       [0.62273073, 0.49227256, 0.43655809, 0.78181123, 0.88458336,
        0.71454947, 0.95004493, 0.        , 0.55833859, 1.11292523],
       [0.2932027 , 0.42215104, 0.19762743, 0.17769582, 1.09184844,
        0.68747133, 0.30875819, 0.55833859, 0.        , 0.57586873],
       [0.07656842, 0.13647168, 0.17590053, 0.11646115, 0.27116346,
        0.11654506, 0.04723677, 1.11292523, 0.57586873, 0.        ]])

In [1265]: r.shape
Out[1265]: (10, 10)
...

/ (93)

In [1313]: t={'names':('name','age','weight'),'formats':('U10','i4','f8')}

In [1314]: d=np.zeros(4,dtype=t)

In [1315]: d
Out[1315]: 
array([('', 0, 0.), ('', 0, 0.), ('', 0, 0.), ('', 0, 0.)],
      dtype=[('name', '<U10'), ('age', '<i4'), ('weight', '<f8')])

/ we kunnen net zo goed	,

In [1322]: t2=[('name','U10'),('age','i4'),('weight','f8')]

In [1323]: d2=np.zeros(4,dtype=t2)

In [1329]: d2
Out[1329]: 
array([('', 0, 0.), ('', 0, 0.), ('', 0, 0.), ('', 0, 0.)],
      dtype=[('name', '<U10'), ('age', '<i4'), ('weight', '<f8')])

In [1328]: d == d2
Out[1328]: array([ True,  True,  True,  True])

In [1384]: d.ndim
Out[1384]: 1
In [1390]: d[0]
Out[1390]: ('Alice', 25, 55.)
In [1391]: d[0].ndim
Out[1391]: 0
In [1392]: d[0]['name']
Out[1392]: 'Alice'
In [1393]: d[0][0]			/ !
Out[1393]: 'Alice'
In [1394]: d[0][:]
IndexError: too many indices for array
/ Dit komt omdat d[0].ndim==0	,

In [1444]: d[0]
Out[1444]: ('Alice', 25, 55.)
/ en 	,
In [1445]: d['name']
Out[1445]: array(['Alice', 'Bob', 'Cathy', 'Doug'], dtype='<U10')

In [1396]: type(d)
Out[1396]: numpy.ndarray
In [1395]: type(d[0])
Out[1395]: numpy.void

In [1397]: d[:]
Out[1397]: 
array([('Alice', 25, 55. ), ('Bob', 45, 85.5), ('Cathy', 37, 68. ),
       ('Doug', 19, 61.5)],
      dtype=[('name', '<U10'), ('age', '<i4'), ('weight', '<f8')])

/ dus d is een numpy.ndarray, maar d[0] niet	,
/ d[0]['name'] is OK	, maar d[0][0] kan ook, 

/ Intermezzo

In [1322]: t2=[('name','U10'),('age','i4'),('weight','f8')]
In [1372]: t2[0][0]
Out[1372]: 'name'
In [1373]: t2[0][1]
Out[1373]: 'U10'
In [1374]: t2.ndim
AttributeError: 'list' object has no attribute 'ndim'


/ we gebruiken hier t2 op een hele andere manier dan als dtype attr van een np.zeros	, 
In [1375]: a2=np.array(t2)		 
In [1402]: a2.shape
Out[1402]: (3, 2)
In [1376]: a2[0]
Out[1376]: array(['name', 'U10'], dtype='<U6')
In [1377]: a2[0][0]
Out[1377]: 'name'


/ als we	,
In [1403]: t3=[['name','U10'],['age','i4'],['weight','f8']]
In [1408]: a3=np.array(t3)
/ dan zijn t2 != t3	, maar a2 == a3	,

In [1378]: a2[0][1]
Out[1378]: 'U10'
In [1379]: a2.ndim
Out[1379]: 2
In [1380]: a2[0].ndim
Out[1380]: 1
In [1381]: a2[1].ndim
Out[1381]: 1
In [1382]: a2[0][:]
Out[1382]: array(['name', 'U10'], dtype='<U6')

/ waar komt '<U6' vandaan?

/ 1313	. 

In [1422]: a=np.array([['name','U10'],['weight','f4']])
In [1423]: a
Out[1423]: 
array([['name', 'U10'],
       ['weight', 'f4']], dtype='<U6')

/ pakt max size , van 'weight'	, 

/ 1313	. 

/ let op verschil	,

/ np.array heeft nl een 2de arg dtype	,

In [1426]: a4=np.array('name','U10')
In [1427]: a4
Out[1427]: array('name', dtype='<U10')

In [1425]: a=np.array(['name','U10'])
In [1428]: a
Out[1428]: array(['name', 'U10'], dtype='<U4')

/ 1313	. 

/ ipv dtype attr van np.zeros, kan ook van np.array	,

In [1431]: a5=np.array([],dtype=t2)
In [1432]: a5
Out[1432]: array([], dtype=[('name', '<U10'), ('age', '<i4'), ('weight', '<f8')])

In [1433]: a5=np.array((),dtype=t2)
ValueError: could not assign tuple of length 0 to structure with 3 fields.

In [1436]: a5=np.array([()],dtype=t2)
ValueError: could not assign tuple of length 0 to structure with 3 fields.

In [1437]: a5=np.array(['foo'],dtype=t2)
ValueError: invalid literal for int() with base 10: 'foo'

In [1439]: a5=np.array([('foo',7,12.)],dtype=t2)
In [1440]: a5
Out[1440]: 
array([('foo', 7, 12.)],
      dtype=[('name', '<U10'), ('age', '<i4'), ('weight', '<f8')])
In [1441]: a5[0]
Out[1441]: ('foo', 7, 12.)
In [1442]: a5[0]['name']
Out[1442]: 'foo'

/ 13 .

In [1443]: d
Out[1443]: 
array([('Alice', 25, 55. ), ('Bob', 45, 85.5), ('Cathy', 37, 68. ),
       ('Doug', 19, 61.5)],
      dtype=[('name', '<U10'), ('age', '<i4'), ('weight', '<f8')])

In [1444]: d[0]
Out[1444]: ('Alice', 25, 55.)

In [1445]: d['name']
Out[1445]: array(['Alice', 'Bob', 'Cathy', 'Doug'], dtype='<U10')

/ hoe zit dit?

In [1446]: d[:]['name']
Out[1446]: array(['Alice', 'Bob', 'Cathy', 'Doug'], dtype='<U10')

In [1447]: d['name'][:]
Out[1447]: array(['Alice', 'Bob', 'Cathy', 'Doug'], dtype='<U10')

In [1448]: d[0][:]
IndexError: too many indices for array

In [1449]: d[:][0]
Out[1449]: ('Alice', 25, 55.)

In [1450]: d[0]
Out[1450]: ('Alice', 25, 55.)

/ TODO

/ Einde Intermezzo

In [1452]: d
Out[1452]: 
array([('Alice', 25, 55. ), ('Bob', 45, 85.5), ('Cathy', 37, 68. ),
       ('Doug', 19, 61.5)],
      dtype=[('name', '<U10'), ('age', '<i4'), ('weight', '<f8')])

In [1451]: d['age']<30
Out[1451]: array([ True, False, False,  True])

In [1453]: d[d['age']<30]
Out[1453]: 
array([('Alice', 25, 55. ), ('Doug', 19, 61.5)],
      dtype=[('name', '<U10'), ('age', '<i4'), ('weight', '<f8')])

In [1454]: d[d['age']<30]['name']
Out[1454]: array(['Alice', 'Doug'], dtype='<U10')

/ (94)

/ we hadden al 	,

In [1457]: t
Out[1457]: {'names': ('name', 'age', 'weight'), 'formats': ('U10', 'i4', 'f8')}
In [1455]: t2
Out[1455]: [('name', 'U10'), ('age', 'i4'), ('weight', 'f8')]
In [1456]: t3
Out[1456]: [['name', 'U10'], ['age', 'i4'], ['weight', 'f8']]

/ we kunnen ook zonder names	, die worden gen	,

In [1466]: np.dtype('U10,i4,f8')
Out[1466]: dtype([('f0', '<U10'), ('f1', '<i4'), ('f2', '<f8')])

In [1468]: a4=np.zeros(4,dtype=np.dtype('U10,i4,f8'))

In [1469]: a4
Out[1469]: 
array([('', 0, 0.), ('', 0, 0.), ('', 0, 0.), ('', 0, 0.)],
      dtype=[('f0', '<U10'), ('f1', '<i4'), ('f2', '<f8')])

In [1472]: a4[0]=('foo',9,7.)
In [1473]: a4
Out[1473]: 
array([('foo', 9, 7.), ('', 0, 0.), ('', 0, 0.), ('', 0, 0.)],
      dtype=[('f0', '<U10'), ('f1', '<i4'), ('f2', '<f8')])


/ Intermezzo

/ 13	. 

In [1466]: np.dtype('U10,i4,f8')
Out[1466]: dtype([('f0', '<U10'), ('f1', '<i4'), ('f2', '<f8')])

/ NIET	,
In [1465]: np.dtype('U10','i4','f8')
Out[1465]: dtype('<U10')

/ 13	 .

In [1480]: np.dtype((np.unicode,10))
Out[1480]: dtype('<U10')

/ NIET,
In [1481]: np.dtype(np.unicode,10)
Out[1481]: dtype('<U')

/ 13	. 

In [1495]: np.dtype([('f0',np.float128)])
Out[1495]: dtype([('f0', '<f16')])

In [1496]: np.dtype([(np.float128)])
TypeError: data type not understood

/ 13	. 

In [1499]: np.dtype('f16')
Out[1499]: dtype('float128')

/ we vergeten de []	,
In [1500]: np.dtype(('n1','f16'))
TypeError: data type "n1" not understood

In [1502]: np.dtype([('n1','f16')])
Out[1502]: dtype([('n1', '<f16')])
/=
In [1504]: np.dtype([('n1',np.float128)])
Out[1504]: dtype([('n1', '<f16')])

/ 13	. 

/ met meerdere types verschijnen er names	,

In [1505]: np.dtype('f16')
Out[1505]: dtype('float128')

In [1506]: np.dtype('f16,f4')
Out[1506]: dtype([('f0', '<f16'), ('f1', '<f4')])

/ 13	 

/ wat is eq aan 	, met np.float...s	?
In [1506]: np.dtype('f16,f4')
/=
Out[1506]: dtype([('f0', '<f16'), ('f1', '<f4')])

/ WH alleen	, we moeten de names geven	, anders: TypeError: data type not understood
In [1513]: np.dtype([('f0',np.float128),('f1',np.float64)])
Out[1513]: dtype([('f0', '<f16'), ('f1', '<f8')])

In [1514]: np.dtype([('f0',(np.unicode_,10)),('f1',np.float64)])			/ !
Out[1514]: dtype([('f0', '<U10'), ('f1', '<f8')])
/ OK,	

/ (95)

In [1515]: t=np.dtype([('id','i8'),('mat','f8',(3,3))])
In [1516]: X=np.zeros(1,dtype=t)

In [1517]: X
Out[1517]: 
array([(0, [[0., 0., 0.], [0., 0., 0.], [0., 0., 0.]])],
      dtype=[('id', '<i8'), ('mat', '<f8', (3, 3))])

In [1518]: X[0]																							 / 0==id	,
Out[1518]: (0, [[0., 0., 0.], [0., 0., 0.], [0., 0., 0.]])
In [1526]: X['mat']
Out[1526]: 
array([[[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]]])

/ we zien dus	, 
[ [[0., 0., 0.], [0., 0., 0.], [0., 0., 0.]]]
/ een array van 3 rijen	, [[0., 0., 0.], [0., 0., 0.], [0., 0., 0.]], in het grondvlak	, vandaar dat er nog een [...]; er kunnen meerdere lagen zijn	, maar nu dus maar 1	,

In [1528]: X['mat'][0]
Out[1528]: 
array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.]])
/ (alleen) het 3-dim array op de grond	,



/ 7	. 

/ PANDAS

/ (98)

In [1530]: import pandas

In [1531]: pandas.__version__
Out[1531]: '0.23.1'

In [1534]: pdict={'Cal':234234,'Tex':808098}
In [1535]: p=pd.Series(pdict)
In [1537]: p
Out[1537]: 
Cal    234234
Tex    808098
dtype: int64

In [1538]: adict={'Cal':3,'Tex':7}
In [1539]: a=pd.Series(adict)
In [1540]: a
Out[1540]: 
Cal    3
Tex    7
dtype: int64

/ let op {...}	, 
In [1542]: t=pd.DataFrame({'p':p,'a':a})
In [1543]: t
Out[1543]: 
          p  a
Cal  234234  3
Tex  808098  7

In [1550]: t.columns
Out[1550]: Index(['p', 'a'], dtype='object')
In [1544]: t.index
Out[1544]: Index(['Cal', 'Tex'], dtype='object')

In [1559]: t['p']
Out[1559]: 
Cal    234234
Tex    808098
Name: p, dtype: int64
In [1560]: type(t['p'])
Out[1560]: pandas.core.series.Series

In [1562]: t['p']['Cal']	/ t['p'] is een Series,	en dat is een soort dictionary, en daarop kun je wel een key van nemen, hier 'Cal'	,
Out[1562]: 234234

/ t is ook wel een soort Series	, maar de keys zijn de columns, niet de indexes	,
In [1564]: t['Cal']	
KeyError: 'Cal'
In [1564]: t[0]
KeyError: 0
In [1573]: t[:,'p']
TypeError: unhashable type: 'slice'

/ in een numpy.array kun je in beide posities een index geven	, bij pandas.DataFrame maar in 1	, de columns	, als we deze geven, is dat aut. de 1ste	, dus t['p']	, we hoeven en kunnen niet zoiets als t[:,'p']	, 

In [1565]: a=np.array([1,2,3,4]).reshape(2,2)
In [1566]: a
Out[1566]: 
array([[1, 2],
       [3, 4]])
In [1567]: a[0]
/=
In [1568]: a[0,:]
Out[1567]: array([1, 2])
In [1569]: a[:,0]
Out[1569]: array([1, 3])

/ (104)

In [1573]: pd.DataFrame([{'a':1,'b':2},{'b':3,'c':4}])
Out[1573]: 
     a  b    c
0  1.0  2  NaN
1  NaN  3  4.0

/ Als er NaN in een kolom staat, zijn die andere getallen in de kolom floats,
/ TODO

/ (105)

In [1576]: t=np.dtype('i8,f8')
In [1577]: a=np.zeros(4,dtype=t)
In [1578]: a
Out[1578]: 
array([(0, 0.), (0, 0.), (0, 0.), (0, 0.)],
      dtype=[('f0', '<i8'), ('f1', '<f8')])
/ a refs niet naar t	, heeft 'm copy	, dus we kunnen t voor iets anders use	,
In [1580]: t=pd.DataFrame(a)
In [1581]: t
Out[1581]: 
   f0   f1
0   0  0.0
1   0  0.0
2   0  0.0
3   0  0.0

/ (107)

In [1583]: a=np.arange(16).reshape(4,4)
In [1586]: a
Out[1586]: 
array([[ 0,  1,  2,  3],
       [ 4,  5,  6,  7],
       [ 8,  9, 10, 11],
       [12, 13, 14, 15]])
In [1591]: a[2,[1,3]]
Out[1591]: array([ 9, 11])

/ 13	. 

/ een pd.Series is als een dict en als een arr	,

In [1594]: s=pd.Series([.25,.5,.75,1],index=['a','b','c','d'])

In [1599]: s['a']
Out[1599]: 0.25
In [1602]: 'a' in s
Out[1602]: True
In [1603]: s.keys()
Out[1603]: Index(['a', 'b', 'c', 'd'], dtype='object')


In [1601]: s[0]
Out[1601]: 0.25
In [1600]: s[:]
Out[1600]: 
a    0.25
b    0.50
c    0.75
d    1.00
dtype: float64
In [1596]: s['a':'c']
Out[1596]: 
a    0.25
b    0.50
c    0.75
dtype: float64
In [1597]: s[0:2]
Out[1597]: 
0    0.25
1    0.50
dtype: float64

/ We zien verschil bij expliciete en impliciete index	, bij 'a':'c' zien we ook de entry bij 'c'	, bij 0:2 zien we niet de entry bij 2	,

/ 13	. 

/ maar als we een expliciete index hebben met integers, en je doet 1:3, dan zijn dat de impliciete indexes	, 
/ en bij impliciete indices wordt de bovengrens zelf niet meegenomen bij een slice	, 

In [1613]: s2=pd.Series([.25,.5,.75,1],index=[1,2,3,4])
In [1614]: s2
Out[1614]: 
1    0.25
2    0.50
3    0.75
4    1.00
dtype: float64
/ deze heeft impliciete indices 0,1,2,3	,

/ pak impliciete 1,2 van de indices 0,1,2,3	, 
In [1613]: s2[1:3]
Out[1613]: 
2    0.50
3    0.75
dtype: float64

In [1616]: s2.loc[1:3]	 / expliciete 1,2,3 van 1,2,3,4
Out[1616]:
1    0.25
2    0.50
3    0.75
dtype: float64

In [1617]: s2.iloc[1:3]	 / impliciete 1,2 van 0,1,2,3
Out[1617]: 
2    0.50
3    0.75
dtype: float64

/ (112)

In [1619]: pdict={'Cal':234234,'Tex':808098}
In [1620]: p=pd.Series(pdict)
In [1621]: adict={'Cal':3,'Tex':7}
In [1622]: a=pd.Series(adict)
In [1623]: t=pd.DataFrame({'p':p,'a':a})

In [1626]: t
Out[1626]: 
          p  a
Cal  234234  3
Tex  808098  7


/ 13	. 

/ als t een pd.DataFrame, dan is t.values een np.ndarray	,

In [1624]: t.values
Out[1624]: 
array([[234234,      3],
       [808098,      7]])

In [1625]: type(t.values)
Out[1625]: numpy.ndarray

In [1637]: t.values[:,0]
Out[1637]: array([234234, 808098])
In [1638]: t.values[0]
/=
In [1638]: t.values[0,:]
Out[1638]: array([234234,      3])

/ 13	 .

/ we kunnen een pd.DataFrame .T	, dat is dan ook een pd.DataFrame	,

In [1640]: t
Out[1640]: 
          p  a
Cal  234234  3
Tex  808098  7

In [1641]: t.T
Out[1641]: 
      Cal     Tex
p  234234  808098
a       3       7

In [1642]: t['p']
Out[1642]: 
Cal    234234
Tex    808098
Name: p, dtype: int64

In [1643]: t.T['Cal']
Out[1643]: 
p    234234
a         3
Name: Cal, dtype: int64

In [1648]: t['Cal']
KeyError: unknown key
In [1648]: t.T['p']
KeyError: unknown key

/ 13	 .

/ voor alle selecties geldt dat het zelf ook pd.DataFrames zijn	,

In [1679]: type(t[:'a'])
Out[1679]: pandas.core.frame.DataFrame

In [1680]: type(t.loc[:'Cal',:'a'])
Out[1680]: pandas.core.frame.DataFrame

In [1681]: type(t.iloc[:,:1])
Out[1681]: pandas.core.frame.DataFrame

/ Daarom zien we in het antwoord altijd ook de expliciete indexes	,


/ 13	. 

/ we kunnen met .iloc de impliciete indexes van np.ndarray use	, 

In [1653]: t
Out[1653]: 
          p  a
Cal  234234  3
Tex  808098  7
In [1654]: t.iloc[:,:1]
Out[1654]: 
          p
Cal  234234
Tex  808098
In [1656]: t.iloc[:1,:]
Out[1656]: 
          p  a
Cal  234234  3

/ als we 	, dan zien we niet de expliciete indexes	,
In [1657]: t.values[:1,:]
Out[1657]: array([[234234,      3]])

/ 1313	. 

/ bij expliciet indexes is het altijd t/m	,

/ in de columns maakt met/zonder .loc niet uit	, maar in de rows wel	, zonder .loc gaat het niet in de rows	,

/ dus zonder .loc kan je t alleen index op columns	,

In [1660]: t[:'a']
/=
In [1660]: t.loc[:'a']
Out[1660]: 
          p  a
Cal  234234  3
Tex  808098  7

In [1665]: t.loc[:'Tex',:'a']
Out[1665]: 
          p  a
Cal  234234  3
Tex  808098  7
In [1666]: t.loc[:,:'a']
Out[1666]: 
          p  a
Cal  234234  3
Tex  808098  7
In [1669]: t[:'Tex',:'a']
TypeError: unhashable type: 'slice'

/ .iloc werkt met implicit indexes	, dus exclusief het eind	,
/ maar we zien wel de expliciete indexes	, want de selectie is ook de pd.DataFrame	,

In [1670]: t.iloc[:1,:1]
Out[1670]: 
          p
Cal  234234
In [1671]: t.iloc[:,:1]
Out[1671]: 
          p
Cal  234234
Tex  808098


/ werkt wel, maar is deprecated	,
In [1669]: t.ix[:1,:'a']
/home/eric/miniconda3/bin/ipython:1: DeprecationWarning: 
.ix is deprecated. Please use
.loc for label based indexing or
.iloc for positional indexing

See the documentation here:
http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated
  #!/home/eric/miniconda3/bin/python
Out[1669]: 
          p  a
Cal  234234  3

/ 13	. 

In [1675]: t[t.a>3]
Out[1675]: 
          p  a
Tex  808098  7

In [1676]: type(t[t.a>3])
/=
In [1676]: type.loc(t[t.a>3])
Out[1676]: pandas.core.frame.DataFrame

/ t[t.a>3] is zelf ook een (kleinere) pd.DataFrame

In [1687]: t[:]
/=
In [1687]: t.loc[:]
/=
In [1687]: t.loc[:,:]	
Out[1687]: 
          p  a
Cal  234234  3
Tex  808098  7

/ 1313	.

/ als je maar 1 param geeft, is dat een column	,

In [1713]: t['a']
Out[1713]: 
Cal    3
Tex    7
Name: a, dtype: int64

In [1784]: t[:]			/ ook 	,
Out[1784]: 
          p  a
Cal  234234  3
Tex  808098  7


In [1714]: t[:'a']	/ hij ziet :, hij ziet 'a' als overbodig	,
Out[1714]: 
          p  a
Cal  234234  3
Tex  808098  7

In [1715]: t[:'p']/ net zo	,
Out[1715]: 
          p  a
Cal  234234  3
Tex  808098  7


/ SAMENVATTING SERIES DATAFRAMES 

/ 13	. 

In [1693]: t.loc[['p']]
KeyError: "None of [['p']] are in the [index]"

In [1696]: t.loc['p']
KeyError: 'the label [p] is not in the [index]'

In [1712]: t['p']
Out[1712]: 
Cal    234234
Tex    808098
Name: p, dtype: int64

n [1713]: t['a']
Out[1713]: 
Cal    3
Tex    7
Name: a, dtype: int64

In [1714]: t[:'a']
Out[1714]: 
          p  a
Cal  234234  3
Tex  808098  7

In [1715]: t[:'p']
Out[1715]: 
          p  a
Cal  234234  3
Tex  808098  7

/ 13	. 

In [1727]: p=pd.Series([.25,.5,.75,1],index=['a','b','c','d'])
In [1727]: p
Out[1727]: 
a    0.25
b    0.50
c    0.75
d    1.00
dtype: float64

In [1738]: type(p.iloc[1:3])
Out[1738]: pandas.core.series.Series

In [1728]: p['b']
Out[1728]: 0.5

In [1729]: p[:'b']
Out[1729]: 
a    0.25
b    0.50
dtype: float64

In [1730]: p['a':'c']
Out[1730]: 
a    0.25
b    0.50
c    0.75
dtype: float64

In [1731]: p['b':]
Out[1731]: 
b    0.50
c    0.75
d    1.00
dtype: float64

In [1733]: p.loc['a':'c']
Out[1733]: 
a    0.25
b    0.50
c    0.75
dtype: float64

In [1734]: p.iloc[1:3]
Out[1734]: 
b    0.50
c    0.75
dtype: float64

In [1735]: p['e']=1.25
In [1737]: p['b':]
Out[1737]: 
b    0.50
c    0.75
d    1.00
e    1.25
dtype: float64

/ 13	. 

In [1739]: p=pd.Series({'Cal':234234,'Flor':36353,'Tex':808098})
In [1740]: a=pd.Series({'Cal':7,'Flor':13,'Tex':6})
In [1741]: b=pd.Series({'Cal':'foo','Flor':'bar','Tex':'baz'})
In [1742]: t2=pd.DataFrame({'p':p,'a':a,'b':b})
In [1743]: t2
Out[1743]: 
           p   a    b
Cal   234234   7  foo
Flor   36353  13  bar
Tex   808098   6  baz

/ Bij pd.DataFrame 

/ als je maar 1 param use	, kun je alleen columns geven	, 1 column of een array van columns, maar array achtige dingen zoals 'p':'a' kan niet	,
/ zonder .loc of .iloc zie je een pd.DataFrame als een dict van pd.Series (columns) ,

/ als je 2 params use	, kan dat alleen met .loc of .iloce, en geef	,eerst de index, dan de column	,

/ 1313	. 

/ 1 param, column(s)

In [1744]: t2['p']
Out[1744]: 
Cal     234234
Flor     36353
Tex     808098
Name: p, dtype: int64

In [1764]: t2[['p','a']]
Out[1764]: 
           p   a
Cal   234234   7
Flor   36353  13
Tex   808098   6

In [1745]: t2['p':'a']
Out[1745]: 
Empty DataFrame
Columns: [p, a, b]
Index: []

In [1758]: t2['Cal','p']
KeyError: ('Cal', 'p')

/ 1313	.

/ 2 params, indexes and columns	,

In [1758]: t2.loc['Cal','p']
Out[1758]: 234234


In [1747]: t2.loc['p':'a','Cal']
/ de volgorde is verkeerd	,

In [1748]: t2.loc['Cal']
/=
In [1766]: t2.loc['Cal',:]
Out[1748]: 
p    234234
a         7
b       foo
Name: Cal, dtype: object

In [1768]: t2.loc[:,'p']
Out[1768]: 
Cal     234234
Flor     36353
Tex     808098
Name: p, dtype: int64


In [1750]: t2.loc['Cal','p']
Out[1750]: 234234

In [1751]: t2.loc['Cal','p':'a']
Out[1751]: 
p    234234
a         7
Name: Cal, dtype: object

In [1752]: t2.loc['Cal':'Flor','p':'a']
Out[1752]: 
           p   a
Cal   234234   7
Flor   36353  13

In [1753]: t2.iloc[:2,:2]
Out[1753]: 
           p   a
Cal   234234   7
Flor   36353  13

In [1754]: t2.iloc[:,:2]
Out[1754]: 
           p   a
Cal   234234   7
Flor   36353  13
Tex   808098   6

In [1755]: t2.loc['Cal':,'p':'a']
Out[1755]: 
           p   a
Cal   234234   7
Flor   36353  13
Tex   808098   6

In [1756]: t2.loc[:,'p':'a']
Out[1756]: 
           p   a
Cal   234234   7
Flor   36353  13
Tex   808098   6

/ Einde SAMENVATTING SERIES DATAFRAMES 

/ (113)

/ zelf pd.Series maken, voor welke row en welke columns moet select	,

In [1874]: t2
Out[1874]: 
           p   a    b
Cal   234234   7  foo
Flor   36353  13  bar
Tex   808098   6  baz

///////////////////////////////////////////////////////////////////////////
/ we kunnen zelf ook 2 pd.Series maken:
In [1843]: alt=pd.Series([False,True,False],index=['Cal','Flor','Tex'])
In [1849]: altc=pd.Series(['a','b'])
/ en doen	,
t2[alt,altc]
/ alt is als where: selects welke rows	, 
/ altc is als select: selects welke columns	,

/ t2.loc[:,'a']> 7 vergl met where a>7	, in sql is a ook een column	,
/ : vergl met select *
//////////////////////////////////////////////////////////////////

In [1791]: t2.loc[t2['a']>7]
/=
In [1790]: t2.loc[t2.loc[:,'a']>7]
/=
In [1812]: t2.loc[t2.loc[:,'a']>7,:]
Out[1791]: 
          p   a    b
Flor  36353  13  bar

In [1809]: t2.loc[:,['a','b']]
Out[1809]: 
       a    b
Cal    7  foo
Flor  13  bar
Tex    6  baz

In [1810]: t2.loc['Cal',['a','b']]
Out[1810]: 
a      7
b    foo
Name: Cal, dtype: object

/ 1313	 .

In [1846]: t2
Out[1846]: 
           p   a    b
Cal   234234   7  foo
Flor   36353  13  bar
Tex   808098   6  baz

In [1848]: t2[t2['a']>7]
Out[1848]: 
          p   a    b
Flor  36353  13  bar

//////////////////////////////
/ we zien dat een pd.DataFrame niet symm is	, 
/ je kunt t2['a']>7	, maar t2['Cal']>7 of zoiets is er niet: de columns hebben niet allen dezelfde type	,


/ Hoe werkt	,
t2[t2['a']>7]
/=
t2[t2.loc[:,'a']>7]
/=
t2.loc[t2.loc[:,'a']>7]
/=
t2.loc[t2.loc[:,'a']>7,:]	

t2.loc[t2.loc[:,'a']>7,:]	
/ .loc moet vooraan	, anders,	
t2[t2.loc[:,'a']>7,:]	
TypeError: 'Series' objects are mutable, thus they cannot be hashed


In [1814]: t2['a']>7
Out[1814]: 
Cal     False
Flor     True
Tex     False
Name: a, dtype: bool
In [1815]: type(t2['a']>7)
Out[1815]: pandas.core.series.Series

In [1829]: t2.loc[t2.loc[:,'a']>7,'a']
Out[1829]: 
Flor    13
Name: a, dtype: int64
/ .loc moet vooraan	, anders,	
t2[t2.loc[:,'a']>7,'a']	
TypeError: 'Series' objects are mutable, thus they cannot be hashed

In [1835]: t2.loc[t2.loc[:,'a']>7,'a':'b']
/=
In [1836]: t2.loc[t2.loc[:,'a']>7,['a','b']]
Out[1836]: 
       a    b
Flor  13  bar

/ 131313	 .

/ we kunnen zelf ook 2 pd.Series maken:
In [1843]: alt=pd.Series([False,True,False],index=['Cal','Flor','Tex'])
In [1849]: altc=pd.Series(['a','b'])
/ en doen	,
t2[alt,altc]


In [1839]: type(t2['a']>7)
Out[1839]: pandas.core.series.Series

In [1840]: (t2['a']>7).index
Out[1840]: Index(['Cal', 'Flor', 'Tex'], dtype='object')
In [1842]: (t2['a']>7).values
Out[1842]: array([False,  True, False])

/ we kunnen zelf een pd.Series maken	, 

In [1843]: alt=pd.Series([False,True,False],index=['Cal','Flor','Tex'])

In [1844]: alt
Out[1844]: 
Cal     False
Flor     True
Tex     False
dtype: bool

In [1845]: t2[alt]
Out[1845]: 
          p   a    b
Flor  36353  13  bar

In [1849]: altc=pd.Series(['a','b'])

In [1860]: altc
Out[1860]: 
0    a
1    b
dtype: object

In [1850]: altc.index
Out[1850]: RangeIndex(start=0, stop=2, step=1)

In [1855]: t2.loc[alt,altc]
Out[1855]: 
       a    b
Flor  13  bar

/ we mogen in de columns ook expliciete indexes geven	,
In [1856]: altc2=pd.Series(['a','b'],index=['foo','bar'])

In [1857]: t2.loc[alt,altc2]
Out[1857]: 
       a    b
Flor  13  bar

/ Einde (113)

/ (117)

/ we kunnen ook zo een pd.DataFrame maken	,

In [1878]: x=pd.DataFrame(columns=['a','b','c'],index=['k','l'],data=np.random.randint(1,20,size=(2,3)))
In [1879]: x.index
Out[1879]: Index(['k', 'l'], dtype='object')
In [1880]: x.columns
Out[1880]: Index(['a', 'b', 'c'], dtype='object')

/ 13	 .

In [1882]: A=pd.DataFrame(rng.randint(0,20,(2,2)),columns=list('AB'))

In [1883]: A
Out[1883]: 
    A   B
0  15   4
1   3  19

In [1885]: A.stack()
Out[1885]: 
0  A    15
   B     4
1  A     3
   B    19
dtype: int64
In [1894]: type(A.stack())
Out[1894]: pandas.core.series.Series

In [1890]: A.mean()
Out[1890]: 
A     9.0
B    11.5
dtype: float64
In [1893]: type(A.mean())
Out[1893]: pandas.core.series.Series

In [1896]: A.mean().mean()
Out[1896]: 10.25
In [1897]: type(A.mean().mean())
Out[1897]: numpy.float64

In [1891]: A.stack().mean()
Out[1891]: 10.25
In [1895]: type(A.stack().mean())
Out[1895]: numpy.float64

In [1899]: A.mean(axis=1)
Out[1899]: 
0     9.5
1    11.0
dtype: float64

/ Series heeft ook een mean() ,maar deze heeft geen axis attr	,
/ Dus A.stack().mean(axis=...)) is er niet	,

/ (119)

In [1905]: A
Out[1905]: 
    A   B
0  15   4
1   3  19

In [1906]: A.iloc[0,:]
Out[1906]: 
A    15
B     4
Name: 0, dtype: int64
/ Waarom schrijven ze als kolom?
/ TODO

In [1907]: A-A.iloc[0,:]
Out[1907]: 
    A   B
0   0   0
1 -12  15

/ 13	. 

In [1931]: rng=np.random.RandomState(7)
In [1932]: A=pd.DataFrame(rng.randint(10,size=(4,4)),columns=list('QRST'))
In [1933]: A
Out[1933]: 
   Q  R  S  T
0  4  9  6  3
1  3  7  7  9
2  7  8  9  8
3  7  6  4  0

In [1947]: A.iloc[:1,:]
Out[1947]: 
   Q  R  S  T
0  4  9  6  3

In [1948]: A.iloc[:,:1]
Out[1948]: 
   Q
0  4
1  3
2  7
3  7

In [1961]: A.iloc[0,:] == A.iloc[:1,:]
Out[1961]: 
      Q     R     S     T
0  True  True  True  True


In [1957]: A.subtract(A.iloc[0,:],axis=1)
Out[1957]: 
   Q  R  S  T
0  0  0  0  0
1 -1 -2  1  6
2  3 -1  3  5
3  3 -3 -2 -3

In [1960]: A.subtract(A.iloc[:,0],axis=0)
Out[1960]: 
   Q  R  S  T
0  0  5  2 -1
1  0  4  4  6
2  0  1  2  1
3  0 -1 -3 -7

In [1958]: A.subtract(A.iloc[:1,:],axis=1)
Out[1958]: 
     Q    R    S    T
0  0.0  0.0  0.0  0.0
1  NaN  NaN  NaN  NaN
2  NaN  NaN  NaN  NaN
3  NaN  NaN  NaN  NaN

/ 13	. 

In [1961]: A.iloc[0,:] == A.iloc[:1,:]
Out[1961]: 
      Q     R     S     T
0  True  True  True  True

In [1967]: type(A.iloc[0,:])
Out[1967]: pandas.core.series.Series

In [1968]: type(A.iloc[:1,:])
Out[1968]: pandas.core.frame.DataFrame

/ Series noteren ze dus altijd verticaal	,
In [1970]: A.iloc[0,:]
Out[1970]: 
Q    4
R    9
S    6
T    3
Name: 0, dtype: int64

In [1971]: A.iloc[:1,:]
Out[1971]: 
   Q  R  S  T
0  4  9  6  3

/ Series noteren ze dus altijd verticaal	,
In [1972]: A.iloc[:,0]
Out[1972]: 
0    4
1    3
2    7
3    7
Name: Q, dtype: int64

In [1973]: A.iloc[:,:1]
Out[1973]: 
   Q
0  4
1  3
2  7
3  7

/ 1313	 .

/////////////////////////////////////////////////////////
/ A.iloc[:1,:] is een df	, A.iloc[0,:] is een ser	, 
/ een ser wordt broadcast	, een df niet	,

In [1977]: A.iloc[:1,:]
Out[1977]: 
   Q  R  S  T
0  4  9  6  3
/ dit is een df, en die blijft zo	,

In [1978]: A
Out[1978]: 
   Q  R  S  T
0  4  9  6  3
1  3  7  7  9
2  7  8  9  8
3  7  6  4  0

In [1986]: A.subtract(A.iloc[:1,:])
Out[1986]: 
     Q    R    S    T
0  0.0  0.0  0.0  0.0
1  NaN  NaN  NaN  NaN
2  NaN  NaN  NaN  NaN
3  NaN  NaN  NaN  NaN


In [1984]: A.subtract(A.iloc[:1,:],fill_value=3.5)
Out[1984]: 
     Q    R    S    T
0  0.0  0.0  0.0  0.0
1 -0.5  3.5  3.5  5.5
2  3.5  4.5  5.5  4.5
3  3.5  2.5  0.5 -3.5
/ - 3.5 in rij 1,2,3	,

In [1987]: A.loc[0,:]
Out[1987]: 
Q    4
R    9
S    6
T    3
Name: 0, dtype: int64
/ ser, is verticaal genoteerd	, deze wordt broadcast:

In [1989]: A.subtract(A.iloc[0,:])
Out[1989]: 
   Q  R  S  T
0  0  0  0  0
1 -1 -2  1  6
2  3 -1  3  5
3  3 -3 -2 -3

/ 1313	. 

///////////////////////////////////////////////////////
/ .substract een ser of een df: axis is as van de index, dus als je rows subtract, is de as van de indexes dus columns	, 

In [1999]: A.subtract(A.iloc[0,:],axis='columns')
/=
In [2001]: A.subtract(A.iloc[0,:],axis=1)
Out[1999]: 
   Q  R  S  T
0  0  0  0  0
1 -1 -2  1  6
2  3 -1  3  5
3  3 -3 -2 -3

In [2000]: A.subtract(A.iloc[:,0],axis='rows')
/=
In [2001]: A.subtract(A.iloc[:,0],axis=0)
Out[2000]: 
   Q  R  S  T
0  0  5  2 -1
1  0  4  4  6
2  0  1  2  1
3  0 -1 -3 -7

/ 131313	, 

/////////////////////////////////////////////////////////
/ verschil df-df of df-ser, -ser: broadcast	, -df niet, want het is al een df	, 

In [2007]: A.subtract(A.iloc[0,:],axis='columns')
Out[2007]: 
   Q  R  S  T
0  0  0  0  0
1 -1 -2  1  6
2  3 -1  3  5
3  3 -3 -2 -3

In [2009]: A.subtract(A.iloc[:1,:],fill_value=3.5,axis='columns')
Out[2009]: 
     Q    R    S    T
0  0.0  0.0  0.0  0.0
1 -0.5  3.5  3.5  5.5
2  3.5  4.5  5.5  4.5
3  3.5  2.5  0.5 -3.5

/ 1313	. 

/ herinner	,
In [1271]: np.argsort(r,axis=1)
Out[1271]: 
array([[0, 2, 1, 3],
       [1, 3, 0, 2],	  bij pnt 1 ligt 3 het dichtst bij, daarna 0	,
       [2, 0, 3, 1],
       [3, 1, 2, 0]])
/ axis is de as waarin je sort	, dus columns hier	, 

In [2009]: A.subtract(A.iloc[:1,:],fill_value=3.5,axis='columns')
Out[2009]: 
     Q    R    S    T
0  0.0  0.0  0.0  0.0
1 -0.5  3.5  3.5  5.5
2  3.5  4.5  5.5  4.5
3  3.5  2.5  0.5 -3.5

/ (123)

/ Intermezzo

/ casts	,

In [2096]: float(1)
Out[2096]: 1.0

In [2098]: np.float64(1)
Out[2098]: 1.0

In [2099]: np.float64(np.NaN)
Out[2099]: nan
In [2107]: float(np.NaN)
Out[2107]: nan
In [2100]: type(np.NaN)
Out[2100]: float
/ TODO verschil np.float64 en float	,
In [2105]: np.float64(np.NaN) is np.NaN
Out[2105]: False
In [2106]: float(np.NaN) is np.NaN
Out[2106]: True

In [2101]: np.float64(None)
Out[2101]: nan

In [2103]: str(np.NaN)
Out[2103]: 'nan'

In [2104]: str(None)
Out[2104]: 'None'

In [2108]: int(3.3)
Out[2108]: 3
In [2109]: int(None)
TypeError: int() argument must be a string, a bytes-like object or a number, not 'NoneType'
In [2110]: int(np.NaN)
ValueError: cannot convert float NaN to integer

In [2032]: class person:pass
In [2112]: person(None)
TypeError: object() takes no parameters
In [2113]: person(np.NaN)
TypeError: object() takes no parameters

/ Einde Intermezzo

/ 13	. 

/ np.array en pd.Series	,

/ Intermezzo

In [15]: s=pd.Series(['foo','bar'])
In [16]: s
Out[16]: 
0    foo
1    bar
dtype: object
/ Waarom NIET dtype: str
/ TODO

/ s.str zijn coll string fcts,	
In [23]: s.str.cat()
Out[23]: 'foobar'

/ Einde Intermezzo

In [2050]: a=np.array([1,None])
In [2051]: a
Out[2051]: array([1, None], dtype=object)
In [2067]: a.dtype
Out[2067]: dtype('O')

In [2053]: type(a[0])
Out[2053]: int
In [2054]: type(a[1])
Out[2054]: NoneType

In [2128]: np.sum(a)
TypeError: unsupported operand type(s) for +: 'int' and 'NoneType'


In [2128]: s=pd.Series([1,None])
In [2130]: s
Out[2130]: 
0    1.0
1    NaN
dtype: float64

In [2129]: np.sum(s)
Out[2129]: 1.0



/ 13	. 

In [2055]: a=np.array([1,'foo'])
In [2056]: a
Out[2056]: array(['1', 'foo'], dtype='<U21')

In [2131]: s=pd.Series([1,'foo'])
In [2132]: s
Out[2132]: 
0      1
1    foo
dtype: object

In [2133]: type(s[0])
Out[2133]: int
In [2134]: type(s[1])
Out[2134]: str

/ welke operaties?
/ TODO


/ 13	. 

In [2057]: a=np.array([1,.1])
In [2058]: a
Out[2058]: array([1. , 0.1])
In [2065]: a.dtype
Out[2065]: dtype('float64')

In [2138]: s=pd.Series([1,.1])
In [2139]: s
Out[2139]: 
0    1.0
1    0.1
dtype: float64


/ 13	. 

In [2059]: a=np.array([1,np.NaN])
In [2060]: a
Out[2060]: array([ 1., nan])

In [2094]: np.sum(a)
Out[2094]: nan

In [2122]: s=pd.Series([1,np.NaN])
In [2123]: s
Out[2123]: 
0    1.0
1    NaN
dtype: float64

In [2124]: np.sum(s)
Out[2124]: 1.0


/ 13	. 

In [2061]: a=np.array([None,np.NaN])
In [2062]: a
Out[2062]: array([None, nan], dtype=object)
In [2071]: a.dtype
Out[2071]: dtype('O')

In [2074]: type(a[0])
Out[2074]: NoneType
In [2072]: type(a[1])
Out[2072]: float

In [2092]: np.sum(a)
TypeError: unsupported operand type(s) for +: 'NoneType' and 'float'

In [2117]: s=pd.Series([None,np.NaN])
In [2118]: s
Out[2118]: 
0   NaN
1   NaN
dtype: float64

In [2119]: np.sum(s)
Out[2119]: 0.0

/ 13	. 


In [2075]: a=np.array([np.NaN,'foo'])
In [2076]: a
Out[2076]: array(['nan', 'foo'], dtype='<U32')

/ concatenate items in np.array	,
/ TODO

In [6]: s=pd.Series([np.NaN,'foo'])
In [7]: s
Out[7]: 
0    NaN
1    foo
dtype: object

In [26]: s.str.cat()
Out[26]: 'foo'


/ 13	. 

In [2077]: a=np.array([None,'foo'])
In [2078]: a
Out[2078]: array([None, 'foo'], dtype=object)

In [9]: s=pd.Series([None,'foo'])
In [10]: s
Out[10]: 
0    None
1     foo
dtype: object

In [45]: s.str.cat()
Out[45]: 'foo'

/ (124)

/ tabel bovenaan	, 

/ als in een ser bool of object, dan bestaan None en np.NaN naast elkaar (in Pandas zijn str object)
/ als in een ser int of float, wordt een None een np.NaN	, 

/ dat is wel logisch: een int of float ser zijn getallen dus None -> np.NaN (en ints worden floats), WH zijn dan operaties zoals np.sum effectief	, 

/ maar hebben we een ser met een 1 en een 'foo', dan is dit een object ser	, en kunnen None en np.nan naast elkaar bestaan; het is geen typisch int of float ser, dus zijn de operaties zoals np.sum niet effectief	, zie beneden	,

/ kunnen met een mask de floats eruit halen?
/ TODO

In [46]: s=pd.Series([True,False])

In [47]: s
Out[47]: 
0     True
1    False
dtype: bool

In [48]: s=pd.Series([True,False,None])

In [49]: s
Out[49]: 
0     True
1    False
2     None
dtype: object

In [50]: s=pd.Series([True,False,np.NaN])

In [51]: s
Out[51]: 
0     True
1    False
2      NaN
dtype: object

In [52]: s=pd.Series([True,False,np.NaN,None])

In [53]: s
Out[53]: 
0     True
1    False
2      NaN
3     None
dtype: object

/ 13	. 

In [54]: s=pd.Series(['foo'])

In [55]: s
Out[55]: 
0    foo
dtype: object

In [56]: s=pd.Series(['foo',None,np.nan])

In [57]: s
Out[57]: 
0     foo
1    None
2     NaN
dtype: object

In [58]: s=pd.Series([1,None,np.nan])

In [59]: s
Out[59]: 
0    1.0
1    NaN
2    NaN
dtype: float64

In [60]: s=pd.Series([1.,None,np.nan])

In [61]: s
Out[61]: 
0    1.0
1    NaN
2    NaN
dtype: float64

/ 13	. 

In [67]: s=pd.Series([1,2,'foo',None,np.nan])
In [67]: s
Out[67]: 
0       1
1       2
2     foo
3    None
4     NaN
dtype: object

In [72]: s=s.drop(2)
Out[72]: 
0       1
1       2
3    None
4     NaN
dtype: object

In [77]: np.sum(s)
Out[77]: 3

/ 13	. 

//////////////////////////////////////////////////////////////////////////////////////
/ een ser met floats heeft optimized operations , en een ser met objects niet	,

In [80]: %timeit np.sum(np.arange(1e6,dtype=np.int))
1.78 ms ± 6.95 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)

In [81]: %timeit np.sum(np.arange(1e6,dtype=np.object))
60.3 ms ± 167 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)

/ let op extra (...)	,
In [91]: np.concatenate((np.arange(10),np.arange(10)))
Out[91]: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9])

In [93]: s=pd.Series(np.concatenate((np.arange(1e1),[4])))
In [94]: s
Out[94]: 
0     0.0
1     1.0
2     2.0
3     3.0
4     4.0
5     5.0
6     6.0
7     7.0
8     8.0
9     9.0
10    4.0
dtype: float64

In [95]: s=pd.Series(np.concatenate((np.arange(1e1),[None])))
In [96]: s
Out[96]: 
0        0
1        1
2        2
3        3
4        4
5        5
6        6
7        7
8        8
9        9
10    None
dtype: object

In [98]: s=pd.Series(np.concatenate((np.arange(1e1),[np.nan])))

In [99]: s
Out[99]: 
0     0.0
1     1.0
2     2.0
3     3.0
4     4.0
5     5.0
6     6.0
7     7.0
8     8.0
9     9.0
10    NaN
dtype: float64

/ we maken een ser met floats	, en een ser met floats, en NaN, die ook een float is, dus hoeft eig niet	, en een ser met floats en een None, dat dus een ser van objects wordt, 
/ bij de ser van objects gaat np.sum veel langzamer	, 

In [105]: s=pd.Series(np.arange(1e6))

In [106]: s.dtype
Out[106]: dtype('float64')

In [107]: %timeit np.sum(s)
4.61 ms ± 13.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)

In [108]: s=pd.Series(np.concatenate((np.arange(1e6),[np.nan])))

In [109]: s.dtype
Out[109]: dtype('float64')

In [110]: %timeit np.sum(s)
4.55 ms ± 15.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)

In [111]: s=pd.Series(np.concatenate((np.arange(1e6),[None])))

In [112]: s.dtype
Out[112]: dtype('O')

In [113]: %timeit np.sum(s)
60.9 ms ± 167 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)

/ (125)

/ 13	 .

/ dropna in ser	,

In [115]: s=pd.Series([1,2,None,np.nan])

In [116]: s
Out[116]: 
0    1.0
1    2.0
2    NaN
3    NaN
dtype: float64
In [117]: s.dropna()
Out[117]: 
0    1.0
1    2.0
dtype: float64
In [118]: s
Out[118]: 
0    1.0
1    2.0
2    NaN
3    NaN
dtype: float64

/ 13	. 

/ dropna in df	,

/ 1313	. 

/ drop row or column als er een np.nan in staat	,

In [121]: df=pd.DataFrame([[1,np.nan,2],[2,3,5],[np.nan,4,6]])

In [122]: df
Out[122]: 
     0    1  2
0  1.0  NaN  2
1  2.0  3.0  5
2  NaN  4.0  6

In [123]: df.dropna()
/=
In [124]: df.dropna(axis=0)
Out[123]: 
     0    1  2
1  2.0  3.0  5
/ de actie is in de columns, dus had axis=1 verwacht	,
/ TODO

In [125]: df.dropna(axis=1)
Out[125]: 
   2
0  2
1  5
2  6
/ de actie is in de rows	, dus had axis=0 verwacht	,
/ TODO

/ 1313	.

/ herinner: 1 param is altijd 'n column 	,
In [126]: df[3]=np.nan

In [127]: df
Out[127]: 
     0    1  2   3
0  1.0  NaN  2 NaN
1  2.0  3.0  5 NaN
2  NaN  4.0  6 NaN

In [128]: df.dropna(axis=1,how='all')
Out[128]: 
     0    1  2
0  1.0  NaN  2
1  2.0  3.0  5
2  NaN  4.0  6
/ had axis=0 verwacht, want dat is de richting van de actie	,

In [130]: df.dropna(axis=1,how='any')
Out[130]: 
   2
0  2
1  5
2  6

/ thresh is : retain that many not null values	,
In [135]: df.dropna(axis=0,thresh=3)
Out[135]: 
     0    1  2   3
1  2.0  3.0  5 NaN

/ 13	. 

/ .dropna() drops ook None	,

In [141]: df=pd.DataFrame([[1,np.nan,'foo'],[2,3,5],[2,4,None]])

/ set None in een column (=dtype) waar ook een object of boolean in staat	, anders wordt hij een np.nan	,
In [144]: df.dtypes
Out[144]: 
0      int64
1    float64
2     object
dtype: object

In [142]: df
Out[142]: 
   0    1     2
0  1  NaN   foo
1  2  3.0     5
2  2  4.0  None

In [143]: df.dropna()
Out[143]: 
   0    1  2
1  2  3.0  5

/ 1313	. 

In [145]: df.isnull()
Out[145]: 
       0      1      2
0  False   True  False
1  False  False  False
2  False  False   True

/ 1313	. 

In [149]: df
Out[149]: 
   0    1     2
0  1  NaN   foo
1  2  3.0     5
2  2  4.0  None

In [150]: df.fillna(method='ffill',axis=0)
Out[150]: 
   0    1    2
0  1  NaN  foo
1  2  3.0    5
2  2  4.0    5
/ de actie is in de rijen, dus axis=0 klopt	,

In [151]: df.fillna(method='ffill',axis=1)
Out[151]: 
   0  1    2
0  1  1  foo
1  2  3    5
2  2  4    4
/ de actie is in de columns, dus axis=1 klopt	,

/ we zien omdat de np.nan is weg, dat de floats ints zijn geworden	, maar
In [162]: df.fillna(method='ffill',axis=1).loc[:,1].dtype
Out[162]: dtype('O')
/ TODO

/ (128)

In [167]: i=[('Cal',2000),('Cal',2010),('NY',2000),('NY',2010),('Tex',2000),('Te
     ...: x',2010)]
In [168]: i
Out[168]: 
[('Cal', 2000),
 ('Cal', 2010),
 ('NY', 2000),
 ('NY', 2010),
 ('Tex', 2000),
 ('Tex', 2010)]

In [171]: p=[3387,3725,1897,1937,2085,2514]

In [172]: pop=pd.Series(p,index=i)
In [173]: pop
Out[173]: 
(Cal, 2000)    3387
(Cal, 2010)    3725
(NY, 2000)     1897
(NY, 2010)     1937
(Tex, 2010)    2085
(Tex, 2010)    2514
dtype: int64

In [176]: type(pop)
Out[176]: pandas.core.series.Series

In [192]: pop.index
Out[192]: 
Index([('Cal', 2000), ('Cal', 2010),  ('NY', 2000),  ('NY', 2010),
       ('Tex', 2000), ('Tex', 2010)],
      dtype='object')

In [193]: pop[('Cal',2010)]
Out[193]: 3725


In [195]: pop[[i for i in pop.index if i[1]==2010]]
Out[195]: 
(Cal, 2010)    3725
(NY, 2010)     1937
(Tex, 2010)    2514
dtype: int64

In [196]: idx=pd.MultiIndex.from_tuples(i)
In [197]: idx
Out[197]: 
MultiIndex(levels=[['Cal', 'NY', 'Tex'], [2000, 2010]],
           labels=[[0, 0, 1, 1, 2, 2], [0, 1, 0, 1, 0, 1]])


/ Ik had per ongeluk ('Tex',2010) 2 keer in i gegeven, en niet ('Tex',2000)	, dan krijg je allerlei errors
/ dit kon NIET: In [193]: pop[('Cal',2010)]
/ we kregen toen ook	,
In [169]: idx=pd.MultiIndex.from_tuples(i)
In [170]: idx
Out[170]: 
MultiIndex(levels=[['Cal', 'NY', 'Tex'], [2000, 2010]],
           labels=[[0, 0, 1, 1, 2, 2], [0, 1, 0, 1, 1, 1]])
/ je ziet de fout in labels: [0, 1, 0, 1, 1, 1]

In [200]: pop2=pop.reindex(idx)
In [201]: pop2
Out[201]: 
Cal  2000    3387
     2010    3725
NY   2000    1897
     2010    1937
Tex  2000    2085
     2010    2514
dtype: int64

In [215]: type(pop)
Out[215]: pandas.core.series.Series
In [212]: type(pop2)
Out[212]: pandas.core.series.Series

/ vergl	,
In [217]: pop[[i for i in pop.index if i[1]==2010]]
Out[217]: 
(Cal, 2010)    3725
(NY, 2010)     1937
(Tex, 2010)    2514
dtype: int64
/ vs	,
In [218]: pop2[:,2010]
Out[218]: 
Cal    3725
NY     1937
Tex    2514
dtype: int64

/ (130)

In [223]: pop2_df=pop2.unstack()
In [225]: type(pop2_df)
Out[225]: pandas.core.frame.DataFrame
In [224]: pop2_df
Out[224]: 
     2000  2010
Cal  3387  3725
NY   1897  1937
Tex  2085  2514

In [227]: pop2_df.loc[:,2010]
Out[227]: 
Cal    3725
NY     1937
Tex    2514
Name: 2010, dtype: int64

/ weer terug naar pd.Series:

In [229]: pop2_cp=pop2_df.stack()

In [230]: type(pop2_cp)
Out[230]: pandas.core.series.Series

In [231]: pop2_cp
Out[231]: 
Cal  2000    3387
     2010    3725
NY   2000    1897
     2010    1937
Tex  2000    2085
     2010    2514
dtype: int64

In [233]: pop2_cp == pop
Out[233]: 
Cal  2000    True
     2010    True
NY   2000    True
     2010    True
Tex  2000    True
     2010    True
dtype: bool

/ (131)

/ we maken een df als een dict van 2 sers , dat zijn de 2 cols	,

In [240]: pop2_df2=pd.DataFrame({'total':pop2,'<18':[9267,9284,4687,4318,5906,68
     ...: 79]})
In [241]: pop2_df2
Out[241]: 
          total   <18
Cal 2000   3387  9267
    2010   3725  9284
NY  2000   1897  4687
    2010   1937  4318
Tex 2000   2085  5906
    2010   2514  6879
/ dit is df met 2 sers	,

/ dit was df eq. aan ser	, 
In [242]: pop2_df
Out[242]: 
     2000  2010
Cal  3387  3725
NY   1897  1937
Tex  2085  2514

In [245]: pop2_df2['<18']/pop2_df2['total']
Out[245]: 
Cal  2000    2.736050
     2010    2.492349
NY   2000    2.470743
     2010    2.229220
Tex  2000    2.832614
     2010    2.736277
dtype: float64
/ geen realistische cijfers...

/ (131)

/ how to create multiindexed ser or df	,

/ 1313	. 

/ we geven nu niet een dict van 2 sers	, maar meteen numpy.ndarray	,

In [246]: np.random.seed(7)

In [247]: df=pd.DataFrame(np.random.rand(4,2))
In [248]: df
Out[248]: 
          0         1
0  0.076308  0.779919
1  0.438409  0.723465
2  0.977990  0.538496
3  0.501120  0.072051

In [249]: df=pd.DataFrame(np.random.rand(4,2),index=[['a','a','b','b'],[1,2,1,2]
     ...: ])

In [250]: df
Out[250]: 
            0         1
a 1  0.268439  0.499883
  2  0.679230  0.803739
b 1  0.380941  0.065936
  2  0.288146  0.909594

/ dus de row indexes worden van 0,1,2,3 naar ('a',1),('a',2),('b',1),('b',2)

In [251]: df=pd.DataFrame(np.random.rand(4,2),index=[['a','a','b','b'],[1,2,1,2]
     ...: ],columns=['data1','data2'])

In [252]: df
Out[252]: 
        data1     data2
a 1  0.213385  0.452124
  2  0.931206  0.024899
b 1  0.600549  0.950130
  2  0.230303  0.548490

/ deze multiindex is gemaakt voor ons	,
In [254]: df.index
Out[254]: 
MultiIndex(levels=[['a', 'b'], [1, 2]],
           labels=[[0, 0, 1, 1], [0, 1, 0, 1]])

/ (132)

/ zelf multiindexes maken	,

/ deze is het mooist	,
In [255]: i=pd.MultiIndex.from_product([['a','b'],[1,2]])
Out[255]: i 
Out[255]: 
MultiIndex(levels=[['a', 'b'], [1, 2]],
           labels=[[0, 0, 1, 1], [0, 1, 0, 1]])

/ (133)

/ naam de levels of de index	,

In [259]: i.names=['c','n']
In [260]: i
Out[260]: 
MultiIndex(levels=[['a', 'b'], [1, 2]],
           labels=[[0, 0, 1, 1], [0, 1, 0, 1]],
           names=['c', 'n'])

In [266]: pd.DataFrame(np.random.rand(4,3),index=i)
Out[266]: 
            0         1         2
c n                              
a 1  0.092262  0.709394  0.524346
  2  0.696160  0.955468  0.682914
b 1  0.053129  0.308853  0.592595
  2  0.235120  0.964971  0.945048


In [264]: pd.DataFrame(np.random.rand(4,3),index=i,columns=['p','q','r'])
Out[264]: 
                 p         q         r
c		 n
a    1    0.459093  0.719324  0.412992
     2    0.906423  0.180452  0.741119
b    1    0.422374  0.426454  0.634380
     2    0.522906  0.414886  0.001427

/ (133)

/ multiindex on columns	,

In [273]: i=pd.MultiIndex.from_product([[2013,2014],[1,2]],names=['year','visit'
     ...: ])
In [274]: i
Out[274]: 
MultiIndex(levels=[[2013, 2014], [1, 2]],
           labels=[[0, 0, 1, 1], [0, 1, 0, 1]],
           names=['year', 'visit'])

In [276]: c
Out[276]: 
MultiIndex(levels=[['Bob', 'Guido', 'Sue'], ['HR', 'Temp']],
           labels=[[0, 0, 1, 1, 2, 2], [0, 1, 0, 1, 0, 1]],
           names=['subject', 'type'])

In [277]: np.random.seed(7)
In [278]: data=np.round(np.random.randn(4,6),1)
In [279]: data
Out[279]: 
array([[ 1.7, -0.5,  0. ,  0.4, -0.8,  0. ],
       [-0. , -1.8,  1. ,  0.6, -0.6, -0.2],
       [ 0.5, -0.3, -0.2, -1.5,  0.6,  0.1],
       [ 0.3, -1.5,  1.7,  0.2, -0.4,  2. ]])

In [282]: data[:,::2]*=10
In [283]: data
Out[283]: 
array([[17. , -0.5,  0. ,  0.4, -8. ,  0. ],
       [-0. , -1.8, 10. ,  0.6, -6. , -0.2],
       [ 5. , -0.3, -2. , -1.5,  6. ,  0.1],
       [ 3. , -1.5, 17. ,  0.2, -4. ,  2. ]])

In [284]: data+=37

In [285]: data
Out[285]: 
array([[54. , 36.5, 37. , 37.4, 29. , 37. ],
       [37. , 35.2, 47. , 37.6, 31. , 36.8],
       [42. , 36.7, 35. , 35.5, 43. , 37.1],
       [40. , 35.5, 54. , 37.2, 33. , 39. ]])

In [286]: health_data=pd.DataFrame(data,index=i,columns=c)

In [287]: health_data
Out[287]: 
subject      Bob       Guido         Sue      
type          HR  Temp    HR  Temp    HR  Temp
year visit                                    
2013 1      54.0  36.5  37.0  37.4  29.0  37.0
     2      37.0  35.2  47.0  37.6  31.0  36.8
2014 1      42.0  36.7  35.0  35.5  43.0  37.1
     2      40.0  35.5  54.0  37.2  33.0  39.0

/ HR = heart rate	,


/ in feite 4 dim matrix	,

In [288]: health_data['Guido']
Out[288]: 
type          HR  Temp
year visit            
2013 1      37.0  37.4
     2      47.0  37.6
2014 1      35.0  35.5
     2      54.0  37.2

In [295]: health_data.loc[:,:'Guido']
Out[295]: 
subject      Bob       Guido      
type          HR  Temp    HR  Temp
year visit                        
2013 1      54.0  36.5  37.0  37.4
     2      37.0  35.2  47.0  37.6
2014 1      42.0  36.7  35.0  35.5
     2      40.0  35.5  54.0  37.2

/ meer	, 
/ TODO

/ (134)

In [300]: pop2
Out[300]: 
Cal  2000    3387
     2010    3725
NY   2000    1897
     2010    1937
Tex  2000    2085
     2010    2514
dtype: int64

In [301]: pop2['Cal',2000]
Out[301]: 3387

In [303]: pop2['Cal']
Out[303]: 
2000    3387
2010    3725
dtype: int64

In [302]: pop2[:,2000]
Out[302]: 
Cal    3387
NY     1897
Tex    2085
dtype: int64

/ (136)

In [308]: health_data
Out[308]: 
subject      Bob       Guido         Sue      
type          HR  Temp    HR  Temp    HR  Temp
year visit                                    
2013 1      54.0  36.5  37.0  37.4  29.0  37.0
     2      37.0  35.2  47.0  37.6  31.0  36.8
2014 1      42.0  36.7  35.0  35.5  43.0  37.1
     2      40.0  35.5  54.0  37.2  33.0  39.0
In [309]: type(health_data)
Out[309]: pandas.core.frame.DataFrame

In [311]: health_data['Guido']
Out[311]: 
type          HR  Temp
year visit            
2013 1      37.0  37.4
     2      47.0  37.6
2014 1      35.0  35.5
     2      54.0  37.2
In [312]: type(health_data['Guido'])
Out[312]: pandas.core.frame.DataFrame

In [316]: health_data['Guido']['HR']
Out[316]: 
year  visit
2013  1        37.0
      2        47.0
2014  1        35.0
      2        54.0
Name: HR, dtype: float64

/ let op extra [...]	in fancy indexing	,
In [317]: health_data['Guido'][['HR','Temp']]
Out[317]: 
type          HR  Temp
year visit            
2013 1      37.0  37.4
     2      47.0  37.6
2014 1      35.0  35.5
     2      54.0  37.2
In [318]: type(health_data['Guido'][['HR','Temp']])
Out[318]: pandas.core.frame.DataFrame

/ we kunnen	,
In [320]: health_data['Guido'][['HR','Temp']]['HR']
Out[320]: 
year  visit
2013  1        37.0
      2        47.0
2014  1        35.0
      2        54.0
Name: HR, dtype: float64
/ maar =	,
In [321]: health_data['Guido']['HR']
Out[321]: 
year  visit
2013  1        37.0
      2        47.0
2014  1        35.0
      2        54.0
Name: HR, dtype: float64

/ 13	.

In [326]: health_data['Guido']
Out[326]: 
type          HR  Temp
year visit            
2013 1      37.0  37.4
     2      47.0  37.6
2014 1      35.0  35.5
     2      54.0  37.2

/ geen (...) na loc	,
In [325]: health_data['Guido'].loc[:,'HR']
Out[325]: 
year  visit
2013  1        37.0
      2        47.0
2014  1        35.0
      2        54.0
Name: HR, dtype: float64

In [330]: health_data['Guido'].loc[2013,:]
/=
In [332]: health_data.loc[2013,'Guido']
Out[330]: 
type     HR  Temp
visit            
1      37.0  37.4
2      47.0  37.6

In [334]: health_data.loc[2013,('Guido','HR')]
Out[334]: 
visit
1    37.0
2    47.0
Name: (Guido, HR), dtype: float64

/ Intermezzo

In [337]: health_data['Guido','HR']	 / dit werkt WH omdat = (...)
/=
In [338]: health_data[('Guido','HR')]
Out[338]: 
year  visit
2013  1        37.0
      2        47.0
2014  1        35.0
      2        54.0
Name: (Guido, HR), dtype: float64


/ Einde Intermezzo

In [347]: health_data
Out[347]: 
subject      Bob       Guido         Sue      
type          HR  Temp    HR  Temp    HR  Temp
year visit                                    
2013 1      54.0  36.5  37.0  37.4  29.0  37.0
     2      37.0  35.2  47.0  37.6  31.0  36.8
2014 1      42.0  36.7  35.0  35.5  43.0  37.1
     2      40.0  35.5  54.0  37.2  33.0  39.0

In [346]: health_data.iloc[:1,:1]
Out[346]: 
subject      Bob
type          HR
year visit      
2013 1      54.0

/ Intermezzo

/ :1,:1 is 0,0	, maar het type is anders,

In [348]: health_data.iloc[0,0]
Out[348]: 54.0

In [349]: type(health_data.iloc[0,0])
Out[349]: numpy.float64

In [350]: type(health_data.iloc[:1,:1])
Out[350]: pandas.core.frame.DataFrame

/ Einde Intermezzo

/ (137)

/ binnen (...) kun je geen : use	,

In [356]: health_data.loc[:,'Bob']
Out[356]: 
type          HR  Temp
year visit            
2013 1      54.0  36.5
     2      37.0  35.2
2014 1      42.0  36.7
     2      40.0  35.5

/ binnen (...) kun je geen : use	,
In [365]: health_data.loc[(2013,1),('Bob','HR')]
Out[365]: 54.0

In [369]: health_data.loc[(2013,:),('Bob','HR')]
/ ERR
In [370]: health_data.loc[(:,1),('Bob','HR')]
/ ERR

In [371]: health_data.loc[:,('Bob','HR')]
Out[371]: 
year  visit
2013  1        54.0
      2        37.0
2014  1        42.0
      2        40.0
Name: (Bob, HR), dtype: float64
/ OK	,

In [373]: health_data.loc[(2013,1),:]
Out[373]: 
subject  type
Bob      HR      54.0
         Temp    36.5
Guido    HR      37.0
         Temp    37.4
Sue      HR      29.0
         Temp    37.0
Name: (2013, 1), dtype: float64
/ OK	,

/ use daarom 
In [374]: idx=pd.IndexSlice
In [375]: health_data.loc[idx[:,1],('Bob','HR')]
Out[375]: 
year  visit
2013  1        54.0
2014  1        42.0
Name: (Bob, HR), dtype: float64

/ (137)

/ rearrange

/ let op : op (138) staan ser	, dus vandaar dat data['a':'b'] okay	,

/ de indexes van de ser pop2 hebben nog geen namen	,

In [405]: type(pop2)
Out[405]: pandas.core.series.Series

In [379]: pop2
Out[379]: 
Cal  2000    3387
     2010    3725
NY   2000    1897
     2010    1937
Tex  2000    2085
     2010    2514
dtype: int64
In [381]: pop2.index.names
Out[381]: FrozenList([None, None])

In [383]: pop2.index.names=['state','year']
In [384]: pop2
Out[384]: 
state  year
Cal    2000    3387
       2010    3725
NY     2000    1897
       2010    1937
Tex    2000    2085
       2010    2514
dtype: int64

/ lees df.stack?	,
/ WH de level param van ser.unstack wordt de columns van de df	,

In [385]: pop2.unstack() 	/ default= last level	,
/=
In [389]: pop2.unstack(level=-1)	/ last level	,
/= idg	,
In [389]: pop2.unstack(level=1)
Out[385]: 
year   2000  2010
state            
Cal    3387  3725
NY     1897  1937
Tex    2085  2514

In [390]: pop2.unstack(level=0)
Out[390]:
state   Cal    NY   Tex
year                   
2000   3387  1897  2085
2010   3725  1937  2514

In [393]: pop2.index.levels[0]
Out[393]: Index(['Cal', 'NY', 'Tex'], dtype='object', name='state')
In [394]: pop2.index.levels[-1]
Out[394]: Int64Index([2000, 2010], dtype='int64', name='year')

/ (139)

/ van multiindexed ser -> rangeindex df	,

/ multiindexed ser	,
In [405]: type(pop2)
Out[405]: pandas.core.series.Series
In [404]: pop2
Out[404]: 
state  year
Cal    2000    3387
       2010    3725
NY     2000    1897
       2010    1937
Tex    2000    2085
       2010    2514
dtype: int64

In [460]: pop2.index
Out[460]: 
MultiIndex(levels=[['Cal', 'NY', 'Tex'], [2000, 2010]],
           labels=[[0, 0, 1, 1, 2, 2], [0, 1, 0, 1, 0, 1]],
           names=['state', 'year'])
In [461]: pop2.columns
AttributeError: 'Series' object has no attribute 'columns'


/ 1313	. 

/ level is iets van multiindex	, en pop2 heeft een multiindex	,

In [483]: pop2.mean(axis=0,level='state')
Out[483]: 
state
Cal    3556.0
NY     1917.0
Tex    2299.5
dtype: float64

In [484]: pop2.mean(axis=0,level='year')
Out[484]: 
year
2000    2456.333333
2010    2725.333333
dtype: float64


/ 1313	. 

/ de values van de ser wordt ook een column, net als de levels van de multiindex	, 
/ er komt een rangeindex	,

/ eerst gen naam voor values uit de ser: 0

In [406]: tmp=pop2.reset_index()
Out[406]: tmp 
Out[406]: 
  state  year     0
0   Cal  2000  3387
1   Cal  2010  3725
2    NY  2000  1897
3    NY  2010  1937
4   Tex  2000  2085
5   Tex  2010  2514

In [488]: type(tmp)
Out[488]: pandas.core.frame.DataFrame

In [485]: tmp.index
Out[485]: RangeIndex(start=0, stop=6, step=1)

In [486]: tmp.columns
Out[486]: Index(['state', 'year', 0], dtype='object')

/ dus de levels van de multiindex zijn naar de columns gegaan	,

/ 1313	. 

/ nu geef naam voor values uit ser	,

In [407]: pop2_flat=pop2.reset_index(name='population')
In [409]: type(pop2_flat)
Out[409]: pandas.core.frame.DataFrame

In [408]: pop2_flat
Out[408]: 
  state  year  population
0   Cal  2000        3387
1   Cal  2010        3725
2    NY  2000        1897
3    NY  2010        1937
4   Tex  2000        2085
5   Tex  2010        2514

In [411]: pop2_flat.index
Out[411]: RangeIndex(start=0, stop=6, step=1)
/ dit is dus geen MultiIndex, zoals de ser pop2 en de df pop2_df2 hebben	,
/ maar een RangeIndex, zoals een ser die heeft, als hij geen multiindex heeft	,
/ we zien 0,1,... als de row index	, en we zien dat state en year nu columns zijn, naast de values uit de ser die nu een column population zijn	,
In [456]: pop2_flat.columns
Out[456]: Index(['state', 'year', 'population'], dtype='object')

In [489]: pop2_flat.mean(axis=0)
Out[489]: 
year          2005.000000
population    2590.833333
dtype: float64

/ 131313	. 

/ state is ook een column	, maar hij ziet aan type dat hij daarover geen 

In [498]: type(pop2_flat.iloc[:,0])
Out[498]: pandas.core.series.Series

In [499]: type(pop2_flat.iloc[:,0][0])
Out[499]: str

/ 13	. 

In [424]: pop2a=pop2_flat.set_index(['state','year'])
In [425]: type(pop2a)
Out[425]: pandas.core.frame.DataFrame
/ dus geen ser	,
/ wel heeft weer een multiindex	,
In [431]:  pop2a.index
Out[431]: 
MultiIndex(levels=[['Cal', 'NY', 'Tex'], [2000, 2010]],
           labels=[[0, 0, 1, 1, 2, 2], [0, 1, 0, 1, 0, 1]],
           names=['state', 'year'])
In [500]: pop2a.columns
Out[500]: Index(['population'], dtype='object')

In [432]: pop2a
Out[432]: 
            population
state year            
Cal   2000        3387
      2010        3725
NY    2000        1897
      2010        1937
Tex   2000        2085
      2010        2514

In [433]: pop2
Out[433]: 
state  year
Cal    2000    3387
       2010    3725
NY     2000    1897
       2010    1937
Tex    2000    2085
       2010    2514
dtype: int64

/ 1313	 

/ we hebben weer een multiindex, dus kunnen we weer level	,

In [501]: pop2a.mean(axis=0)
Out[501]: 
population    2590.833333
dtype: float64

In [502]: pop2a.mean(axis=0,level='state')
Out[502]: 
       population
state            
Cal        3556.0
NY         1917.0
Tex        2299.5


/ (140)

/ mean	,

/ de default axis=0,	 je berekent in de richting van de rows	, per column	, 

/ level is iets van een multiindex	,

In [441]: health_data
Out[441]: 
subject      Bob       Guido         Sue      
type          HR  Temp    HR  Temp    HR  Temp
year visit                                    
2013 1      54.0  36.5  37.0  37.4  29.0  37.0
     2      37.0  35.2  47.0  37.6  31.0  36.8
2014 1      42.0  36.7  35.0  35.5  43.0  37.1
     2      40.0  35.5  54.0  37.2  33.0  39.0

In [442]: health_data.mean(level='year',axis=0)
/=
In [442]: health_data.mean(level='year')
Out[442]: 
subject   Bob        Guido          Sue       
type       HR   Temp    HR   Temp    HR   Temp
year                                          
2013     45.5  35.85  42.0  37.50  30.0  36.90
2014     41.0  36.10  44.5  36.35  38.0  38.05

In [443]: health_data.mean(level='visit',axis=0)
Out[443]: 
subject   Bob        Guido          Sue       
type       HR   Temp    HR   Temp    HR   Temp
visit                                         
1        48.0  36.60  36.0  36.45  36.0  37.05
2        38.5  35.35  50.5  37.40  32.0  37.90

/ bereken de mean over de columns	,

In [444]: health_data.mean(level='type',axis=1)
Out[444]: 
type               HR       Temp
year visit                      
2013 1      40.000000  36.966667
     2      38.333333  36.533333
2014 1      40.000000  36.433333
     2      42.333333  37.233333

/ lees over sparse en dense ds	,
https://pandas.pydata.org/pandas-docs/stable/sparse.html

/ Intermezzo

/ mean slaat columns van type str over	,

In [504]: tmp2=pd.DataFrame(data=np.random.randint(20,size=(6,4)))
In [505]: tmp2
Out[505]: 
    0   1   2   3
0   3   1   3   1
1  19   4  19   1
2   5   9  17   2
3  19  18  18   3
4  11  15  16  12
5  11   9   9  12

In [506]: tmp2.index
Out[506]: RangeIndex(start=0, stop=6, step=1)
In [507]: tmp2.columns
Out[507]: RangeIndex(start=0, stop=4, step=1)

/ als hij over alle columns een mean kan berekenen, doet hij dat	,
In [513]: tmp2.mean()
Out[513]: 
0    11.333333
1    12.166667
2     7.333333
3     6.166667
dtype: float64

/ we hadden columns add	, maar zo drop je ze weer	,
In [557]: tmp2=tmp2.drop([5],axis=1)
In [558]: tmp2=tmp2.drop([4],axis=1)

/ we drop een rij	,
In [560]: tmp2=tmp2.drop([5],axis=0)

/ we add een column met strs	,
In [563]: tmp2[4]=pd.Series(list(string.ascii_letters[:5]))
/ Kan ook met pd.concat?
/ TODO

In [566]: tmp2
Out[566]: 
    0   1   2   3  4
0  11   1  14  16  a
1  16  17  14   1  b
2  19  18   0  13  c
3  10   8   1   4  d
4  12  19  10   7  e

/ we zien dat de column met strs wordt overgeslagen door mean	,
In [565]: tmp2.mean()
Out[565]: 
0    13.6
1    12.6
2     7.8
3     8.2
dtype: float64

In [567]: tmp2.index
Out[567]: Int64Index([0, 1, 2, 3, 4], dtype='int64')

In [568]: tmp2.columns
Out[568]: Int64Index([0, 1, 2, 3, 4], dtype='int64')

/ deze indexes waren RangeIndexs	, maar door add en drop worden het Int64Indexs	,
/ TODO
/ Kun je bij add niet een add aan de RangeIndex doen?
/ TODO

/ Einde Intermezzo

/ (142)

/ Intermezzo

In [571]: d={c:[str(c)+str(i) for i in range(3)] for c in 'ABC'}
Out[571]: d 
Out[571]: {'A': ['A0', 'A1', 'A2'], 'B': ['B0', 'B1', 'B2'], 'C': ['C0', 'C1', 'C2']}

In [574]: df=pd.DataFrame(d,range(3))
Out[574]: 
    A   B   C
0  A0  B0  C0
1  A1  B1  C1
2  A2  B2  C2

In [576]: df.index
Out[576]: RangeIndex(start=0, stop=3, step=1)

In [577]: df.columns
Out[577]: Index(['A', 'B', 'C'], dtype='object')

/ Einde Intermezzo

/ (142)

/ concat	,

/ 13	. 

/ lists,np.arrays	,

/ 1313	.

In [583]: x=np.arange(1,4)
In [585]: type(x)
Out[585]: numpy.ndarray

In [586]: y=np.arange(4,7)

In [592]: np.concatenate((x,y))
Out[592]: array([1, 2, 3, 4, 5, 6])

/ 1313	. 

In [593]: x=np.arange(1,5).reshape(2,2)

In [594]: x
Out[594]: 
array([[1, 2],
       [3, 4]])

In [595]: np.concatenate((x,x),axis=1)
Out[595]: 
array([[1, 2, 1, 2],
       [3, 4, 3, 4]])

In [596]: np.concatenate((x,x),axis=0)
Out[596]: 
array([[1, 2],
       [3, 4],
       [1, 2],
       [3, 4]])

/ np.concatenate(...) is een numpy.ndarray
/ ook als je hem 2 sers geeft	,

In [649]: res=np.concatenate((ser,ser))

In [650]: res 
Out[650]: array(['a', 'b', 'c', 'a', 'b', 'c'], dtype=object)

In [651]: type(res)
Out[651]: numpy.ndarray




/ 1313	 .

/ ser	,

In [612]: ser=pd.Series(np.array(list(string.ascii_letters[:3])),index=np.arange
     ...: (1,4))
In [613]: ser2=pd.Series(np.array(list(string.ascii_letters[3:6])),index=np.aran
     ...: ge(4,7))
In [614]: ser
Out[614]: 
1    a
2    b
3    c
dtype: object

In [615]: ser2
Out[615]: 
4    d
5    e
6    f
dtype: object

In [617]: ser3=pd.concat((ser,ser2))

In [618]: ser3
Out[618]: 
1    a
2    b
3    c
4    d
5    e
6    f
dtype: object

/ 1313	. 

/ df	,

In [620]: def make_df(cols,idx):
     ...:     d={c:[str(c)+str(i) for i in idx] for c in cols}
     ...:     return pd.DataFrame(d,idx)
     ...: 
     ...: 

In [622]: df=make_df(string.ascii_letters[:2],list(range(2)))
/=
In [624]: df=make_df('ab',[0,1])
In [623]: df
Out[623]: 
    a   b
0  a0  b0
1  a1  b1

/ 1313	. 

/ defs	,

In [624]: dfAB12=make_df('AB',[1,2])
In [800]: dfAB12
Out[800]: 
    A   B
1  A1  B1
2  A2  B2

In [626]: dfAB34=make_df('AB',[3,4])
In [627]: dfAB34
Out[627]: 
    A   B
3  A3  B3
4  A4  B4

In [810]: dfCD12=make_df('CD',[1,2])

In [811]: dfCD12
Out[811]: 
    C   D
1  C1  D1
2  C2  D2

In [812]: dfCD34=make_df('CD',[3,4])

In [813]: dfCD34
Out[813]: 
    C   D
3  C3  D3
4  C4  D4

/ 1313	.

/ concats,	

/////////////////////////////////////////////////////
/ bij axis=0 zijn column names van belang	,
/ bij axis=1 zijn indexes van belang	,

In [814]: pd.concat([dfAB12,dfAB12],axis=0)
Out[814]: 
    A   B
1  A1  B1
2  A2  B2
1  A1  B1
2  A2  B2

In [815]: pd.concat([dfAB12,dfAB12],axis=1)
Out[815]: 
    A   B   A   B
1  A1  B1  A1  B1
2  A2  B2  A2  B2

/ 1313	. 

In [817]: pd.concat([dfAB12,dfAB34],axis=0)
Out[817]: 
    A   B
1  A1  B1
2  A2  B2
3  A3  B3
4  A4  B4

In [818]: pd.concat([dfAB12,dfAB34],axis=1)
Out[818]: 
     A    B    A    B
1   A1   B1  NaN  NaN
2   A2   B2  NaN  NaN
3  NaN  NaN   A3   B3
4  NaN  NaN   A4   B4

In [819]: pd.concat([dfAB12,dfCD12],axis=0)
/home/eric/miniconda3/bin/ipython:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version
of pandas will change to not sort by default.

To accept the future behavior, pass 'sort=False'.

To retain the current behavior and silence the warning, pass 'sort=True'.

  #!/home/eric/miniconda3/bin/python
Out[819]: 
     A    B    C    D
1   A1   B1  NaN  NaN
2   A2   B2  NaN  NaN
1  NaN  NaN   C1   D1
2  NaN  NaN   C2   D2

In [820]: pd.concat([dfAB12,dfCD12],axis=1)
Out[820]: 
    A   B   C   D
1  A1  B1  C1  D1
2  A2  B2  C2  D2

In [821]: pd.concat([dfAB12,dfCD34],axis=0)
/home/eric/miniconda3/bin/ipython:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version
of pandas will change to not sort by default.

To accept the future behavior, pass 'sort=False'.

To retain the current behavior and silence the warning, pass 'sort=True'.

  #!/home/eric/miniconda3/bin/python
Out[821]: 
     A    B    C    D
1   A1   B1  NaN  NaN
2   A2   B2  NaN  NaN
3  NaN  NaN   C3   D3
4  NaN  NaN   C4   D4

In [822]: pd.concat([dfAB12,dfCD34],axis=1)
Out[822]: 
     A    B    C    D
1   A1   B1  NaN  NaN
2   A2   B2  NaN  NaN
3  NaN  NaN   C3   D3
4  NaN  NaN   C4   D4

/ 1313	.

/ verify_integrity	,

/ we willen niet 	,
In [823]: pd.concat([dfAB12,dfAB12],axis=0)
Out[823]: 
    A   B
1  A1  B1
2  A2  B2
1  A1  B1
2  A2  B2

/ doe daarom	,

In [668]: pd.concat((df,df),axis=0,verify_integrity=True)
ValueError: Indexes have overlapping values: Int64Index([1, 2], dtype='int64')

In [671]: try:
     ...:     pd.concat((df,df),axis=0,verify_integrity=True)
     ...: except ValueError as e:
     ...:     print('ValueError:',e)
     ...:     
     ...:     
ValueError: Indexes have overlapping values: Int64Index([1, 2], dtype='int64')

In [826]: pd.concat([dfAB12,dfAB34],axis=0,verify_integrity=True)
Out[764]: 
    A   B
1  A1  B1
2  A2  B2
3  A3  B3
4  A4  B4


/ 1313. 

/ andere oplossing: ignore de gegeven indexes	, en maak nieuwe	,

In [827]: pd.concat([dfAB12,dfAB12],axis=0,ignore_index=True)
Out[667]: 
    A   B
0  A1  B1
1  A2  B2
2  A1  B1
3  A2  B2

/ 1313.

/ andere oplossing, maak multiindexes	,

In [828]: pd.concat([dfAB12,dfAB12],axis=0,keys=['x','y'])
Out[677]: 
      A   B
x 1  A1  B1
  2  A2  B2
y 1  A1  B1
  2  A2  B2

/ 1313	. 

/ bij axis=0 spelen alleen column names een rol	,
/ join,axis=0: outer pakt alle columns, inner alleen de gemeenschappelijke	, 


In [830]: dfCBA12=make_df('CBA',[1,2])
In [831]: dfDCB34=make_df('DCB',[3,4])
In [837]: dfCBA12
Out[837]: 
    C   B   A
1  C1  B1  A1
2  C2  B2  A2

In [838]: dfDCB34
Out[838]: 
    D   C   B
3  D3  C3  B3
4  D4  C4  B4

In [839]: dfDCB12=make_df('DCB',[1,2])
In [840]: dfDCB12
Out[840]: 
    D   C   B
1  D1  C1  B1
2  D2  C2  B2


In [834]: pd.concat([dfCBA12,dfDCB34],axis=0,sort=False)
/=
In [835]: pd.concat([dfCBA12,dfDCB34],axis=0,sort=False,join='outer')
Out[834]: 
    C   B    A    D
1  C1  B1   A1  NaN
2  C2  B2   A2  NaN
3  C3  B3  NaN   D3
4  C4  B4  NaN   D4

In [836]: pd.concat([dfCBA12,dfDCB34],axis=0,sort=False,join='inner')
Out[836]: 
    C   B
1  C1  B1
2  C2  B2
3  C3  B3
4  C4  B4

/ 1313. 

/ bij axis=0 spelen inderdaad alleen de columnames een rol:

In [841]: pd.concat([dfCBA12,dfDCB12],axis=0,sort=False,join='outer')
Out[841]: 
    C   B    A    D
1  C1  B1   A1  NaN
2  C2  B2   A2  NaN
1  C1  B1  NaN   D1
2  C2  B2  NaN   D2

/ 1313	. 

/ bij axis=1 spelen alleen indexes een rol	,
/ join,axis=1: outer pakt alle indexes, inner alleen de gemeenschappelijke	, 

/ nu spelen de indexes een rol	,

In [844]: pd.concat([dfCBA12,dfDCB12],axis=1,sort=False,join='outer')
Out[844]: 
    C   B   A   D   C   B
1  C1  B1  A1  D1  C1  B1
2  C2  B2  A2  D2  C2  B2

In [845]: pd.concat([dfCBA12,dfDCB34],axis=1,sort=False,join='outer')
Out[845]: 
     C    B    A    D    C    B
1   C1   B1   A1  NaN  NaN  NaN
2   C2   B2   A2  NaN  NaN  NaN
3  NaN  NaN  NaN   D3   C3   B3
4  NaN  NaN  NaN   D4   C4   B4



In [842]: pd.concat([dfCBA12,dfDCB12],axis=1,sort=False,join='inner')
Out[842]: 
    C   B   A   D   C   B
1  C1  B1  A1  D1  C1  B1
2  C2  B2  A2  D2  C2  B2

In [843]: pd.concat([dfCBA12,dfDCB34],axis=1,sort=False,join='inner')
Out[843]: 
Empty DataFrame
Columns: [C, B, A, D, C, B]
Index: []


/ 1313	. 

/ zeg bij axis=0 welke columns je in de res wilt hebben	,

In [848]: pd.concat([dfCBA12,dfDCB34],axis=0,sort=False,join='outer')
Out[848]: 
    C   B    A    D
1  C1  B1   A1  NaN
2  C2  B2   A2  NaN
3  C3  B3  NaN   D3
4  C4  B4  NaN   D4

In [847]: pd.concat([dfCBA12,dfDCB34],axis=0,sort=False,join='outer',join_axes=[
     ...: dfCBA12.columns])
Out[847]: 
    C   B    A
1  C1  B1   A1
2  C2  B2   A2
3  C3  B3  NaN
4  C4  B4  NaN

/ 1313	. 

/ join_axis: welke columsn in res	,
/ TODO wat doet axis in join_axis? join_columns beter?

In [742]: res=pd.concat((df5,df6),join_axes=[df5.columns])
/=
In [742]: res=pd.concat((df5,df6),join_axes=[df5.columns],axis=0)

In [743]: res
Out[743]: 
     A   B   C
1   A1  B1  C1
2   A2  B2  C2
3  NaN  B3  C3
4  NaN  B4  C4

/ join_axis moet een array zijn	, het 1ste arg van .concat moet een iterable zijn	, (,) of [,] is OK	,

/ (146/147)

/ 1313	. 

/ merge	, = join als in db	,

/ defs	,

In [870]: dfDCB13=make_df('DCB',[1,3])
In [878]: dfCBA13=make_df('CBA',[1,3])


In [881]: dfCBA12
Out[881]: 
    C   B   A
1  C1  B1  A1
2  C2  B2  A2

In [882]: dfCBA13
Out[882]: 
    C   B   A
1  C1  B1  A1
3  C3  B3  A3

In [883]: dfDCB12
Out[883]: 
    D   C   B
1  D1  C1  B1
2  D2  C2  B2

In [884]: dfDCB13
Out[884]: 
    D   C   B
1  D1  C1  B1
3  D3  C3  B3


/ 131313	.




In [871]: pd.merge(dfCBA12,dfDCB13,how='inner')
Out[871]: 
    C   B   A   D
0  C1  B1  A1  D1

In [872]: pd.merge(dfCBA12,dfDCB13,how='outer')
Out[872]: 
    C   B    A    D
0  C1  B1   A1   D1
1  C2  B2   A2  NaN			
2  C3  B3  NaN   D3			

/ 131313	.
 
In [879]: pd.merge(dfCBA12,dfCBA13,how='outer')
Out[879]: 
    C   B   A
0  C1  B1  A1
1  C2  B2  A2
2  C3  B3  A3

In [880]: pd.merge(dfCBA12,dfCBA13,how='inner')
Out[880]: 
    C   B   A
0  C1  B1  A1

/ 1313	. 

/ (148)

/ many to one: fk van df3.group -> df4.group	,

In [914]: dfeg=pd.DataFrame({'e':['B','J','L','S'],'g':['A','E','E','H']})
In [913]: dfeh=pd.DataFrame({'e':['L','J','B','S'],'h':[4,8,12,14]})
In [912]: dfgs=pd.DataFrame({'g':['A','E','H'],'s':['C','G','S']})

In [915]: dfeg
Out[915]: 
   e  g
0  B  A
1  J  E
2  L  E
3  S  H

In [916]: dfeh
Out[916]: 
   e   h
0  L   4
1  J   8
2  B  12
3  S  14

In [917]: dfgs
Out[917]: 
   g  s
0  A  C
1  E  G
2  H  S

In [919]: dfegh=pd.merge(dfeg,dfeh)
/=
In [926]: pd.merge(dfeg,dfeh,on='e')
In [920]: dfegh
Out[920]: 
   e  g   h
0  B  A  12
1  J  E   8
2  L  E   4
3  S  H  14

In [922]: pd.merge(dfegh,dfgs)
/=
In [922]: pd.merge(dfegh,dfgs,on='g')
Out[922]: 
   e  g   h  s
0  B  A  12  C
1  J  E   8  G
2  L  E   4  G
3  S  H  14  S

/ 1313	. 

/ join on index	,

In [930]: dfiecg=dfeg.set_index('e')
In [931]: dfiech=dfeh.set_index('e')
In [932]: dfiecg
Out[932]: 
   g
e   
B  A
J  E
L  E
S  H
In [933]: dfiech
Out[933]: 
    h
e    
L   4
J   8
B  12
S  14

In [935]: pd.merge(dfiecg,dfiech,left_index=True,right_index=True)
Out[935]: 
   g   h
e       
B  A  12
J  E   8
L  E   4
S  H  14

In [937]: pd.merge(dfiecg,dfeh,left_index=True,right_on='e')
Out[937]: 
   g  e   h
2  A  B  12
1  E  J   8
0  E  L   4
3  H  S  14

/ 1313	. 

/ (155)

[eric@almond vanderplas]$ ls PythonDataScienceHandbook/notebooks/data/
BicycleWeather.csv     president_heights.csv  state-areas.csv
births.csv             Seattle2014.csv        state-population.csv
california_cities.csv  state-abbrevs.csv

/ pop= populatie per staat per jaar per under18/total	,
/ areas= oppervlakte per staat,
/ abbrevs=afkorting per staat,	

/ 1313.

/ defs	,

In [938]: pop=pd.read_csv('PythonDataScienceHandbook/notebooks/data/state-popula
     ...: tion.csv')

In [939]: pop
Out[939]: 
     state/region     ages  year   population
0              AL  under18  2012    1117489.0
1              AL    total  2012    4817528.0
2              AL  under18  2010    1130966.0
3              AL    total  2010    4785570.0
4              AL  under18  2011    1125763.0
5              AL    total  2011    4801627.0
6              AL    total  2009    4757938.0
7              AL  under18  2009    1134192.0
8              AL  under18  2013    1111481.0
9              AL    total  2013    4833722.0
10             AL    total  2007    4672840.0
11             AL  under18  2007    1132296.0
12             AL    total  2008    4718206.0
13             AL  under18  2008    1134927.0
14             AL    total  2005    4569805.0
15             AL  under18  2005    1117229.0
16             AL    total  2006    4628981.0
17             AL  under18  2006    1126798.0
18             AL    total  2004    4530729.0
19             AL  under18  2004    1113662.0
20             AL    total  2003    4503491.0
21             AL  under18  2003    1113083.0
22             AL    total  2001    4467634.0
23             AL  under18  2001    1120409.0
24             AL    total  2002    4480089.0
25             AL  under18  2002    1116590.0
26             AL  under18  1999    1121287.0
27             AL    total  1999    4430141.0
28             AL    total  2000    4452173.0
29             AL  under18  2000    1122273.0
...           ...      ...   ...          ...
2514          USA  under18  1999   71946051.0
2515          USA    total  2000  282162411.0
2516          USA  under18  2000   72376189.0
2517          USA    total  1999  279040181.0
2518          USA    total  2001  284968955.0
2519          USA  under18  2001   72671175.0
2520          USA    total  2002  287625193.0
2521          USA  under18  2002   72936457.0
2522          USA    total  2003  290107933.0
2523          USA  under18  2003   73100758.0
2524          USA    total  2004  292805298.0
2525          USA  under18  2004   73297735.0
2526          USA    total  2005  295516599.0
2527          USA  under18  2005   73523669.0
2528          USA    total  2006  298379912.0
2529          USA  under18  2006   73757714.0
2530          USA    total  2007  301231207.0
2531          USA  under18  2007   74019405.0
2532          USA    total  2008  304093966.0
2533          USA  under18  2008   74104602.0
2534          USA  under18  2013   73585872.0
2535          USA    total  2013  316128839.0
2536          USA    total  2009  306771529.0
2537          USA  under18  2009   74134167.0
2538          USA  under18  2010   74119556.0
2539          USA    total  2010  309326295.0
2540          USA  under18  2011   73902222.0
2541          USA    total  2011  311582564.0
2542          USA  under18  2012   73708179.0
2543          USA    total  2012  313873685.0

[2544 rows x 4 columns]

In [940]: areas=pd.read_csv('PythonDataScienceHandbook/notebooks/data/state-area
     ...: s.csv')

In [941]: areas
Out[941]: 
                   state  area (sq. mi)
0                Alabama          52423
1                 Alaska         656425
2                Arizona         114006
3               Arkansas          53182
4             California         163707
5               Colorado         104100
6            Connecticut           5544
7               Delaware           1954
8                Florida          65758
9                Georgia          59441
10                Hawaii          10932
11                 Idaho          83574
12              Illinois          57918
13               Indiana          36420
14                  Iowa          56276
15                Kansas          82282
16              Kentucky          40411
17             Louisiana          51843
18                 Maine          35387
19              Maryland          12407
20         Massachusetts          10555
21              Michigan          96810
22             Minnesota          86943
23           Mississippi          48434
24              Missouri          69709
25               Montana         147046
26              Nebraska          77358
27                Nevada         110567
28         New Hampshire           9351
29            New Jersey           8722
30            New Mexico         121593
31              New York          54475
32        North Carolina          53821
33          North Dakota          70704
34                  Ohio          44828
35              Oklahoma          69903
36                Oregon          98386
37          Pennsylvania          46058
38          Rhode Island           1545
39        South Carolina          32007
40          South Dakota          77121
41             Tennessee          42146
42                 Texas         268601
43                  Utah          84904
44               Vermont           9615
45              Virginia          42769
46            Washington          71303
47         West Virginia          24231
48             Wisconsin          65503
49               Wyoming          97818
50  District of Columbia             68
51           Puerto Rico           3515

In [944]: abbrevs=pd.read_csv('PythonDataScienceHandbook/notebooks/data/state-ab
     ...: brevs.csv')

In [945]: abbrevs
Out[945]: 
                   state abbreviation
0                Alabama           AL
1                 Alaska           AK
2                Arizona           AZ
3               Arkansas           AR
4             California           CA
5               Colorado           CO
6            Connecticut           CT
7               Delaware           DE
8   District of Columbia           DC
9                Florida           FL
10               Georgia           GA
11                Hawaii           HI
12                 Idaho           ID
13              Illinois           IL
14               Indiana           IN
15                  Iowa           IA
16                Kansas           KS
17              Kentucky           KY
18             Louisiana           LA
19                 Maine           ME
20               Montana           MT
21              Nebraska           NE
22                Nevada           NV
23         New Hampshire           NH
24            New Jersey           NJ
25            New Mexico           NM
26              New York           NY
27        North Carolina           NC
28          North Dakota           ND
29                  Ohio           OH
30              Oklahoma           OK
31                Oregon           OR
32              Maryland           MD
33         Massachusetts           MA
34              Michigan           MI
35             Minnesota           MN
36           Mississippi           MS
37              Missouri           MO
38          Pennsylvania           PA
39          Rhode Island           RI
40        South Carolina           SC
41          South Dakota           SD
42             Tennessee           TN
43                 Texas           TX
44                  Utah           UT
45               Vermont           VT
46              Virginia           VA
47            Washington           WA
48         West Virginia           WV
49             Wisconsin           WI
50               Wyoming           WY

/ 1313	. 

In [949]: res=pd.merge(pop,abbrevs,how='outer',left_on='state/region',right_on='
     ...: abbreviation')

In [950]: res
Out[950]: 
     state/region     ages  year   population    state abbreviation
0              AL  under18  2012    1117489.0  Alabama           AL
1              AL    total  2012    4817528.0  Alabama           AL
2              AL  under18  2010    1130966.0  Alabama           AL
3              AL    total  2010    4785570.0  Alabama           AL
4              AL  under18  2011    1125763.0  Alabama           AL
5              AL    total  2011    4801627.0  Alabama           AL
6              AL    total  2009    4757938.0  Alabama           AL
7              AL  under18  2009    1134192.0  Alabama           AL
8              AL  under18  2013    1111481.0  Alabama           AL
9              AL    total  2013    4833722.0  Alabama           AL
10             AL    total  2007    4672840.0  Alabama           AL
11             AL  under18  2007    1132296.0  Alabama           AL
12             AL    total  2008    4718206.0  Alabama           AL
13             AL  under18  2008    1134927.0  Alabama           AL
14             AL    total  2005    4569805.0  Alabama           AL
15             AL  under18  2005    1117229.0  Alabama           AL
16             AL    total  2006    4628981.0  Alabama           AL
17             AL  under18  2006    1126798.0  Alabama           AL
18             AL    total  2004    4530729.0  Alabama           AL
19             AL  under18  2004    1113662.0  Alabama           AL
20             AL    total  2003    4503491.0  Alabama           AL
21             AL  under18  2003    1113083.0  Alabama           AL
22             AL    total  2001    4467634.0  Alabama           AL
23             AL  under18  2001    1120409.0  Alabama           AL
24             AL    total  2002    4480089.0  Alabama           AL
25             AL  under18  2002    1116590.0  Alabama           AL
26             AL  under18  1999    1121287.0  Alabama           AL
27             AL    total  1999    4430141.0  Alabama           AL
28             AL    total  2000    4452173.0  Alabama           AL
29             AL  under18  2000    1122273.0  Alabama           AL
...           ...      ...   ...          ...      ...          ...
2514          USA  under18  1999   71946051.0      NaN          NaN
2515          USA    total  2000  282162411.0      NaN          NaN
2516          USA  under18  2000   72376189.0      NaN          NaN
2517          USA    total  1999  279040181.0      NaN          NaN
2518          USA    total  2001  284968955.0      NaN          NaN
2519          USA  under18  2001   72671175.0      NaN          NaN
2520          USA    total  2002  287625193.0      NaN          NaN
2521          USA  under18  2002   72936457.0      NaN          NaN
2522          USA    total  2003  290107933.0      NaN          NaN
2523          USA  under18  2003   73100758.0      NaN          NaN
2524          USA    total  2004  292805298.0      NaN          NaN
2525          USA  under18  2004   73297735.0      NaN          NaN
2526          USA    total  2005  295516599.0      NaN          NaN
2527          USA  under18  2005   73523669.0      NaN          NaN
2528          USA    total  2006  298379912.0      NaN          NaN
2529          USA  under18  2006   73757714.0      NaN          NaN
2530          USA    total  2007  301231207.0      NaN          NaN
2531          USA  under18  2007   74019405.0      NaN          NaN
2532          USA    total  2008  304093966.0      NaN          NaN
2533          USA  under18  2008   74104602.0      NaN          NaN
2534          USA  under18  2013   73585872.0      NaN          NaN
2535          USA    total  2013  316128839.0      NaN          NaN
2536          USA    total  2009  306771529.0      NaN          NaN
2537          USA  under18  2009   74134167.0      NaN          NaN
2538          USA  under18  2010   74119556.0      NaN          NaN
2539          USA    total  2010  309326295.0      NaN          NaN
2540          USA  under18  2011   73902222.0      NaN          NaN
2541          USA    total  2011  311582564.0      NaN          NaN
2542          USA  under18  2012   73708179.0      NaN          NaN
2543          USA    total  2012  313873685.0      NaN          NaN

[2544 rows x 6 columns]

In [956]: res=res.drop('abbreviation')
KeyError: "labels ['abbreviation'] not contained in axis"

In [956]: res=res.drop('abbreviation',1)
/ OK	,

In [957]: res.isnull().any()
Out[957]: 
state/region    False
ages            False
year            False
population       True
state            True
dtype: bool
/ Dus in pop zaten in de column population al nulls	, en met de join ontstaan er in state nulls	,

In [1088]: res['state'].isnull().head()
Out[1088]: 
0    False
1    False
2    False
3    False
4    False
Name: state, dtype: bool
In [1089]: res['state'].isnull().size
Out[1089]: 2544
/ Klopt, res['state'].isnull() is een ser met True en False, die net zo groot is als res['state']	,

//////////////////////////////////////////////////////////////////////
/ dit is de cruciale stap	,
In [1092]: res[res['state'].isnull()]     
/ is een DataFrame	, van [96 rows x 5 columns]	, dus
In [1093]: res[res['state'].isnull()].size
Out[1093]: 480

In [1095]: res[res['state'].isnull()].index.size
Out[1095]: 96
In [1097]: res[res['state'].isnull()].index
Out[1097]: 
Int64Index([2448, 2449, 2450, 2451, 2452, 2453, 2454, 2455, 2456, 2457, 2458,
            2459, 2460, 2461, 2462, 2463, 2464, 2465, 2466, 2467, 2468, 2469,
            2470, 2471, 2472, 2473, 2474, 2475, 2476, 2477, 2478, 2479, 2480,
            2481, 2482, 2483, 2484, 2485, 2486, 2487, 2488, 2489, 2490, 2491,
            2492, 2493, 2494, 2495, 2496, 2497, 2498, 2499, 2500, 2501, 2502,
            2503, 2504, 2505, 2506, 2507, 2508, 2509, 2510, 2511, 2512, 2513,
            2514, 2515, 2516, 2517, 2518, 2519, 2520, 2521, 2522, 2523, 2524,
            2525, 2526, 2527, 2528, 2529, 2530, 2531, 2532, 2533, 2534, 2535,
            2536, 2537, 2538, 2539, 2540, 2541, 2542, 2543],
           dtype='int64')
In [1098]: type(res[res['state'].isnull()].index)
Out[1098]: pandas.core.indexes.numeric.Int64Index
/ deze heeft geen .head() method	,
In [1099]: res[res['state'].isnull()].index[:5]
Out[1099]: Int64Index([2448, 2449, 2450, 2451, 2452], dtype='int64')

In [1102]: res[res['population'].isnull()].index.size
Out[1102]: 20
n [1103]: res[res['population'].isnull()].index
Out[1103]: 
Int64Index([2448, 2449, 2450, 2451, 2452, 2453, 2454, 2455, 2456, 2457, 2458,
            2459, 2460, 2461, 2462, 2463, 2464, 2465, 2466, 2467],
           dtype='int64')
In [1227]: type(res['population'].isnull())
Out[1227]: pandas.core.series.Series


/ Intermezzo

In [1118]: ser=res['state'].isnull()
In [1120]: type(ser)
Out[1120]: pandas.core.series.Series
In [1119]: ser.size
Out[1119]: 2544

In [1125]: sel=res[ser]
In [1126]: type(sel)
Out[1126]: pandas.core.frame.DataFrame
In [1127]: sel.index.size
Out[1127]: 96

/ 131313	.

In [1129]: np.zeros(2544,dtype=bool)
Out[1129]: array([False, False, False, ..., False, False, False])

In [1130]: ser2=pd.Series(np.zeros(2544,dtype=bool))
In [1131]: res[ser2]
Out[1131]: 
Empty DataFrame
Columns: [state/region, ages, year, population, state]
Index: []
/ Klopt	,
/ maar we kunnen ipv een pd.Series een np.ndarray geven	,
In [1132]: res[np.zeros(2544,dtype=bool)]
Out[1132]: 
Empty DataFrame
Columns: [state/region, ages, year, population, state]
Index: []

/ vergeet extra (...) niet,
In [1146]: arr=np.concatenate((np.zeros(2544//2,dtype=bool),np.ones(2544//2,dtyp
      ...: e=bool)))
In [1144]: type(res[arr])
Out[1144]: pandas.core.frame.DataFrame

In [1145]: res[arr].index.size
Out[1145]: 1272
/ klopt, de helft	,

/ 131313	. 

/ kan ook op Series:

In [1158]: res2=pd.Series(np.random.randint(1,10,7))
In [1159]: res2
Out[1159]: 
0    2
1    8
2    8
3    6
4    7
5    4
6    6
dtype: int64

In [1160]: ser2=[True,False,True,False,True,False,True]
In [1161]: res2[ser2]
Out[1161]: 
0    2
2    8
4    7
6    6
dtype: int64


/ 1313	 .

/ als we mask met een DataFrame, zien we iets anders: we zien alleen de selected items, maar allemaal, die niet selected krijgen NaN	, 
/ als we mask met een Series, zien we de selected, maar als we .where use, dan net als bij mask met een DataFrame	,

/ lees, 
https://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-where-mask

In [1190]: df2
Out[1190]: 
   n
0  2
1  8
2  8
3  6
4  7
5  4
6  6

In [1203]: type(df2)
Out[1203]: pandas.core.frame.DataFrame

In [1205]: lst2
Out[1205]: [True, False, True, False, True, False, True]

In [1206]: type(lst2)
Out[1206]: list

In [1204]: df2[lst2]
Out[1204]: 
   n
0  2
2  8
4  7
6  6

In [1209]: arr2=np.array(lst2)

In [1210]: df2[arr2]
Out[1210]: 
   n
0  2
2  8
4  7
6  6

In [1211]: ser2=pd.Series(arr2)

In [1212]: ser2
Out[1212]: 
0     True
1    False
2     True
3    False
4     True
5    False
6     True
dtype: bool

In [1213]: df2[ser2]
Out[1213]: 
   n
0  2
2  8
4  7
6  6

In [1220]: df2m=pd.DataFrame(ser2,columns='n')
In [1224]: df2m
Out[1224]: 
       n
0   True
1  False
2   True
3  False
4   True
5  False
6   True
In [1225]: df2[df2m]
Out[1225]: 
     n
0  2.0
1  NaN
2  8.0
3  NaN
4  7.0
5  NaN
6  6.0

/ we zien nu iets anders	,

/ maar	, 
/ lees	,
https://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-where-mask

In [1255]: df2.where(ser2)
Out[1255]: 
     n
0  2.0
1  NaN
2  8.0
3  NaN
4  7.0
5  NaN
6  6.0
/ met .where hetzelfde als mask met een DataFrame	,

In [1257]: df2.where(ser2,-df2)
Out[1257]: 
   n
0  2
1 -8
2  8
3 -6
4  7
5 -4
6  6
/ vervang NaN met de negatieve waarde	, 

/ 1313	. 

/ see (113)

In [1228]: area_dict={'Cal':4239,'Tex':6956,'New':1412,'Flo':1703,'Ill':1499}

In [1229]: pop_dict={'Cal':3833,'Tex':2644,'New':1965,'Flo':1955,'Ill':1288}

In [1230]: area_ser=pd.Series(area_dict)

In [1231]: pop_ser=pd.Series(pop_dict)

In [1232]: data=pd.DataFrame({'area':area_ser,'pop':pop_ser})

In [1233]: data
Out[1233]: 
     area   pop
Cal  4239  3833
Tex  6956  2644
New  1412  1965
Flo  1703  1955
Ill  1499  1288

In [1234]: data['dens']=data['pop']/data['area']

In [1235]: data
Out[1235]: 
     area   pop      dens
Cal  4239  3833  0.904223
Tex  6956  2644  0.380104
New  1412  1965  1.391643
Flo  1703  1955  1.147974
Ill  1499  1288  0.859239

In [1237]: data['dens']>1
Out[1237]: 
Cal    False
Tex    False
New     True
Flo     True
Ill    False
Name: dens, dtype: bool

In [1239]: type(data['dens']>1)
Out[1239]: pandas.core.series.Series

In [1238]: data[data['dens']>1]
Out[1238]: 
     area   pop      dens
New  1412  1965  1.391643
Flo  1703  1955  1.147974

/ we mask met een Series	, dus zien we alleen de selected	, 

In [1259]: data.where(data['dens']>1)
Out[1259]: 
       area     pop      dens
Cal     NaN     NaN       NaN
Tex     NaN     NaN       NaN
New  1412.0  1965.0  1.391643
Flo  1703.0  1955.0  1.147974
Ill     NaN     NaN       NaN
/ net als mask met een DataFrame	,

In [1243]: data[data['dens']>1,['pop']]
TypeError: 'Series' objects are mutable, thus they cannot be hashed
/ TODO


In [1241]: data.loc[data['dens']>1,['pop']]
Out[1241]: 
      pop
New  1965
Flo  1955



/ Einde Intermezzo



/ Intermezzo

/ wat is verschil tussen res.isnull() en res.isna()?
/ lees,	
https://stackoverflow.com/questions/29530232/how-to-check-if-any-value-is-nan-in-a-pandas-dataframe 

In [1024]: df3=pd.DataFrame(np.random.randn(4,4))

In [1025]: df3
Out[1025]: 
          0         1         2         3
0  0.974130  1.184097  1.060777 -0.109221
1  0.417819 -1.590416 -0.221495 -0.630952
2 -0.215118  0.948732 -1.235229  0.114139
3  0.375339 -1.103998 -0.548279 -1.433725

In [1027]: df3>.9
Out[1027]: 
       0      1      2      3
0   True   True   True  False
1  False  False  False  False
2  False   True  False  False
3  False  False  False  False

In [1028]: df3[df3>.9]
Out[1028]: 
         0         1         2   3
0  0.97413  1.184097  1.060777 NaN
1      NaN       NaN       NaN NaN
2      NaN  0.948732       NaN NaN
3      NaN       NaN       NaN NaN

In [1032]: df3[df3>.9]==np.nan
Out[1032]: 
       0      1      2      3
0  False  False  False  False
1  False  False  False  False
2  False  False  False  False
3  False  False  False  False
/ TODO

In [1033]: df3[df3>.9].isna()
/=
In [1034]: df3[df3>.9].isnull()
Out[1033]: 
       0      1      2     3
0  False  False  False  True
1   True   True   True  True
2   True  False   True  True
3   True   True   True  True



/ Einde Intermezzo

/ Intermezzo

/ list van indexes waar een column is nan of null	,

/ google
pandas indexes columns where isnull
/lees	,
https://stackoverflow.com/questions/44869327/find-index-of-all-rows-with-null-values-in-a-particular-column-in-pandas-datafra

In [1049]: res['state'].isnull().head()
Out[1049]: 
0    False
1    False
2    False
3    False
4    False
Name: state, dtype: bool

In [1050]: res[res['state'].isnull()].head()
Out[1050]: 
     state/region     ages  year  population state
2448           PR  under18  1990         NaN   NaN
2449           PR    total  1990         NaN   NaN
2450           PR    total  1991         NaN   NaN
2451           PR  under18  1991         NaN   NaN
2452           PR    total  1993         NaN   NaN
In [1052]: res[res['state'].isnull()].size
Out[1052]: 480

In [1054]: res[res['population'].isnull()].size
Out[1054]: 100

In [1059]: res['population'].size
Out[1059]: 2544

In [1061]: res 
...
[2544 rows x 5 columns]


In [1053]: res.size
Out[1053]: 12720
In [1062]: res.columns.size
Out[1062]: 5
In [1063]: res.index.size
Out[1063]: 2544

In [1066]: res[res['population'].isnull()].index
Out[1066]: 
Int64Index([2448, 2449, 2450, 2451, 2452, 2453, 2454, 2455, 2456, 2457, 2458,
            2459, 2460, 2461, 2462, 2463, 2464, 2465, 2466, 2467],
           dtype='int64')
In [1067]: res[res['population'].isnull()].index.tolist()
Out[1067]: 
[2448,
 2449,
 2450,
 2451,
 2452,
 2453,
 2454,
 2455,
 2456,
 2457,
 2458,
 2459,
 2460,
 2461,
 2462,
 2463,
 2464,
 2465,
 2466,
 2467]



/ Einde Intermezzo


/ 1313	. 

In [965]: type(res['population'])
Out[965]: pandas.core.series.Series
In [964]: res['population'].head()
Out[964]: 
0    1117489.0
1    4817528.0
2    1130966.0
3    4785570.0
4    1125763.0
Name: population, dtype: float64
In [968]: res['population'].size
Out[968]: 2544

In [970]: type(res['population'].isnull())
Out[970]: pandas.core.series.Series
In [971]: res['population'].isnull().head()
Out[971]: 
0    False
1    False
2    False
3    False
4    False
Name: population, dtype: bool
In [972]: res['population'].isnull().size
Out[972]: 2544

/ 1313	. 

/ Vraag: welke index heeft res['population'].isnull()?

/ 1313	. 

/ we proberen het op een andere manier	,

/ we maken een df, voor .query	,

In [987]: df=pd.DataFrame(res['population'].isnull())
In [992]: df.head()
Out[992]: 
   population
0       False
1       False
2       False
3       False
4       False

/ 131313	 

/ er is geen reden om dit te doen	, df2 is een DataFrame, net als res	, alleen met 1 column	, 

In [996]: ser=res['population']
In [999]: df2=pd.DataFrame(ser)
In [1004]: df2.head()
Out[1004]: 
   population
0   1117489.0
1   4817528.0
2   1130966.0
3   4785570.0
4   1125763.0
In [1003]: df2.iloc[0]
Out[1003]: 
population    1117489.0
Name: 0, dtype: float64

/ 1313	. 

/ (156)

/ weer terug	,

In [1265]: res[res['population'].isnull()].index.size
Out[1265]: 20

In [1266]: res[res['state'].isnull()].index.size
Out[1266]: 96

/ we zien alleen de selected entries, want	,
In [1267]: type(res['population'].isnull())
Out[1267]: pandas.core.series.Series

/ In boek: 

In [1285]: merged=res

/ we willen merged zien maar dan voor die waarvoor population is null of state is null:

In [1286]: ind=merged[merged['state'].isnull()].index

/ see (129)
In [1287]: merged.reindex(ind)
Out[1287]: 
     state/region     ages  year   population state
2448           PR  under18  1990          NaN   NaN
2449           PR    total  1990          NaN   NaN
2450           PR    total  1991          NaN   NaN
2451           PR  under18  1991          NaN   NaN
2452           PR    total  1993          NaN   NaN
2453           PR  under18  1993          NaN   NaN
2454           PR  under18  1992          NaN   NaN
2455           PR    total  1992          NaN   NaN
2456           PR  under18  1994          NaN   NaN
2457           PR    total  1994          NaN   NaN
2458           PR    total  1995          NaN   NaN
2459           PR  under18  1995          NaN   NaN
2460           PR  under18  1996          NaN   NaN
2461           PR    total  1996          NaN   NaN
2462           PR  under18  1998          NaN   NaN
2463           PR    total  1998          NaN   NaN
2464           PR    total  1997          NaN   NaN
2465           PR  under18  1997          NaN   NaN
2466           PR    total  1999          NaN   NaN
2467           PR  under18  1999          NaN   NaN
2468           PR    total  2000    3810605.0   NaN
2469           PR  under18  2000    1089063.0   NaN
2470           PR    total  2001    3818774.0   NaN
2471           PR  under18  2001    1077566.0   NaN
2472           PR    total  2002    3823701.0   NaN
2473           PR  under18  2002    1065051.0   NaN
2474           PR    total  2004    3826878.0   NaN
2475           PR  under18  2004    1035919.0   NaN
2476           PR    total  2003    3826095.0   NaN
2477           PR  under18  2003    1050615.0   NaN
...           ...      ...   ...          ...   ...
2514          USA  under18  1999   71946051.0   NaN
2515          USA    total  2000  282162411.0   NaN
2516          USA  under18  2000   72376189.0   NaN
2517          USA    total  1999  279040181.0   NaN
2518          USA    total  2001  284968955.0   NaN
2519          USA  under18  2001   72671175.0   NaN
2520          USA    total  2002  287625193.0   NaN
2521          USA  under18  2002   72936457.0   NaN
2522          USA    total  2003  290107933.0   NaN
2523          USA  under18  2003   73100758.0   NaN
2524          USA    total  2004  292805298.0   NaN
2525          USA  under18  2004   73297735.0   NaN
2526          USA    total  2005  295516599.0   NaN
2527          USA  under18  2005   73523669.0   NaN
2528          USA    total  2006  298379912.0   NaN
2529          USA  under18  2006   73757714.0   NaN
2530          USA    total  2007  301231207.0   NaN
2531          USA  under18  2007   74019405.0   NaN
2532          USA    total  2008  304093966.0   NaN
2533          USA  under18  2008   74104602.0   NaN
2534          USA  under18  2013   73585872.0   NaN
2535          USA    total  2013  316128839.0   NaN
2536          USA    total  2009  306771529.0   NaN
2537          USA  under18  2009   74134167.0   NaN
2538          USA  under18  2010   74119556.0   NaN
2539          USA    total  2010  309326295.0   NaN
2540          USA  under18  2011   73902222.0   NaN
2541          USA    total  2011  311582564.0   NaN
2542          USA  under18  2012   73708179.0   NaN
2543          USA    total  2012  313873685.0   NaN

[96 rows x 5 columns]

In [1288]: ind=merged[merged['population'].isnull()].index

In [1289]: merged.reindex(ind)
Out[1289]: 
     state/region     ages  year  population state
2448           PR  under18  1990         NaN   NaN
2449           PR    total  1990         NaN   NaN
2450           PR    total  1991         NaN   NaN
2451           PR  under18  1991         NaN   NaN
2452           PR    total  1993         NaN   NaN
2453           PR  under18  1993         NaN   NaN
2454           PR  under18  1992         NaN   NaN
2455           PR    total  1992         NaN   NaN
2456           PR  under18  1994         NaN   NaN
2457           PR    total  1994         NaN   NaN
2458           PR    total  1995         NaN   NaN
2459           PR  under18  1995         NaN   NaN
2460           PR  under18  1996         NaN   NaN
2461           PR    total  1996         NaN   NaN
2462           PR  under18  1998         NaN   NaN
2463           PR    total  1998         NaN   NaN
2464           PR    total  1997         NaN   NaN
2465           PR  under18  1997         NaN   NaN
2466           PR    total  1999         NaN   NaN
2467           PR  under18  1999         NaN   NaN

/ (157)

In [1292]: final=pd.merge(merged,areas,on='state',how='left')

/ state is een column met nulls	,

/ Intermezzo

postgres=# create table l(i int);
CREATE TABLE
postgres=# create table r(i int);
CREATE TABLE
postgres=# insert into l values(1),(2),(null);
INSERT 0 3
postgres=# insert into r values(1),(3),(null);
INSERT 0 3

postgres=# \pset null 'null'
Null display is "null".

postgres=# select *
from l left join r on l.i=r.i;
  i   |  i   
------+------
    1 |    1
    2 | null
 null | null
(3 rows)

postgres=# select *
from l right join r on l.i=r.i;
  i   |  i   
------+------
    1 |    1
 null |    3
 null | null
(3 rows)

postgres=# select *
from l full outer join r on l.i=r.i;
  i   |  i   
------+------
    1 |    1
    2 | null
 null | null
 null |    3
 null | null
(5 rows)

/ in postgresql 'outer join' kan niet, 	moet 'full outer join'	, 

In [1293]: final.isnull().any()
Out[1293]: 
state/region     False
ages             False
year             False
population        True
state             True
area (sq. mi)     True
dtype: bool

In [1294]: final.head()
Out[1294]: 
  state/region     ages  year  population    state  area (sq. mi)
0           AL  under18  2012   1117489.0  Alabama        52423.0
1           AL    total  2012   4817528.0  Alabama        52423.0
2           AL  under18  2010   1130966.0  Alabama        52423.0
3           AL    total  2010   4785570.0  Alabama        52423.0
4           AL  under18  2011   1125763.0  Alabama        52423.0
In [1295]: final.index.size
Out[1295]: 2544

In [1324]: type(final['area (sq. mi)'])
Out[1324]: pandas.core.series.Series

In [1325]: final['area (sq. mi)'].unique()
Out[1325]: 
array([5.24230e+04, 6.56425e+05, 1.14006e+05, 5.31820e+04, 1.63707e+05,
       1.04100e+05, 5.54400e+03, 1.95400e+03, 6.80000e+01, 6.57580e+04,
       5.94410e+04, 1.09320e+04, 8.35740e+04, 5.79180e+04, 3.64200e+04,
       5.62760e+04, 8.22820e+04, 4.04110e+04, 5.18430e+04, 3.53870e+04,
       1.24070e+04, 1.05550e+04, 9.68100e+04, 8.69430e+04, 4.84340e+04,
       6.97090e+04, 1.47046e+05, 7.73580e+04, 1.10567e+05, 9.35100e+03,
       8.72200e+03, 1.21593e+05, 5.44750e+04, 5.38210e+04, 7.07040e+04,
       4.48280e+04, 6.99030e+04, 9.83860e+04, 4.60580e+04, 1.54500e+03,
       3.20070e+04, 7.71210e+04, 4.21460e+04, 2.68601e+05, 8.49040e+04,
       9.61500e+03, 4.27690e+04, 7.13030e+04, 2.42310e+04, 6.55030e+04,
       9.78180e+04,         nan])

In [1330]: final['area (sq. mi)'].isnull().unique()
Out[1330]: array([False,  True])

In [1337]: final[final['area (sq. mi)'].isnull()].index.size
Out[1337]: 96
/ want omdat final['area (sq. mi)'].isnull() een Series is, is final[final['area (sq. mi)'].isnull()] alleen die waar final['area (sq. mi)'].isnull()==True	,

/ Intermezzo

/ we maken zelf een Series van 2544, met een aantal Trues, en nemen de final er op	,

In [1341]: ser=np.zeros(2544,dtype=bool)
In [1341]: ser[:25]=True                
In [1343]: final[ser].index
Out[1343]: 
Int64Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,
            17, 18, 19, 20, 21, 22, 23, 24],
           dtype='int64')

/ Einde Intermezzo


In [1303]: final['area (sq. mi)'].isnull().index.size
Out[1304]: 2544
/ klopt	,
In [1344]: final['area (sq. mi)'].index.unique()
Out[1344]: 
Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,
            ...
            2534, 2535, 2536, 2537, 2538, 2539, 2540, 2541, 2542, 2543],
           dtype='int64', length=2544)
In [1345]: final['area (sq. mi)'].unique()
Out[1345]: 
array([5.24230e+04, 6.56425e+05, 1.14006e+05, 5.31820e+04, 1.63707e+05,
       1.04100e+05, 5.54400e+03, 1.95400e+03, 6.80000e+01, 6.57580e+04,
       5.94410e+04, 1.09320e+04, 8.35740e+04, 5.79180e+04, 3.64200e+04,
       5.62760e+04, 8.22820e+04, 4.04110e+04, 5.18430e+04, 3.53870e+04,
       1.24070e+04, 1.05550e+04, 9.68100e+04, 8.69430e+04, 4.84340e+04,
       6.97090e+04, 1.47046e+05, 7.73580e+04, 1.10567e+05, 9.35100e+03,
       8.72200e+03, 1.21593e+05, 5.44750e+04, 5.38210e+04, 7.07040e+04,
       4.48280e+04, 6.99030e+04, 9.83860e+04, 4.60580e+04, 1.54500e+03,
       3.20070e+04, 7.71210e+04, 4.21460e+04, 2.68601e+05, 8.49040e+04,
       9.61500e+03, 4.27690e+04, 7.13030e+04, 2.42310e+04, 6.55030e+04,
       9.78180e+04,         nan])
In [1347]: final[final['area (sq. mi)']]
KeyError: '[52423. 52423. 52423. ...    nan    nan    nan] not in index'

In [1350]: final['area (sq. mi)'].isnull().unique()
Out[1350]: array([False,  True])
/ Deze kan wel	,

In [1351]: final[final['area (sq. mi)'].isnull()]  
...
2543          USA    total      ...          NaN            NaN

[96 rows x 6 columns]
In [1357]: final[final['area (sq. mi)'].isnull()]['area (sq. mi)'].unique()
Out[1357]: array([nan])

In [1359]: type(final[final['area (sq. mi)'].isnull()]['area (sq. mi)'])
Out[1359]: pandas.core.series.Series

In [1360]: type(final[final['area (sq. mi)'].isnull()])
Out[1360]: pandas.core.frame.DataFrame

/ op final[final['area (sq. mi)'].isnull()] kun je geen .unique() doen	,
/ Dus op een DataFrame kun je geen .unique() doen, op een Series wel	,

/ Einde Intermezzo

/ (157) 

/ weer terug	, 

/ 1313	. 

/ alle columns	,
In [1364]: final[final['area (sq. mi)'].isnull()]
...
2543          USA    total      ...          NaN            NaN
[96 rows x 6 columns]

/ 1 column	,
In [1365]: final['state'][final['area (sq. mi)'].isnull()]

/ Intermezzo

In [1379]: ser= final['state'].isin(['Montana'])
In [1380]: ser.unique()
Out[1380]: array([False,  True])

n [1383]: final[ser]
...
1295           MT    total      ...        Montana       147046.0

[48 rows x 6 columns]

/ Einde Intermezzo

In [1387]: final['state'][final['area (sq. mi)'].isnull()].unique()
Out[1387]: array([nan], dtype=object)
/ In het boek: array(['United States'], ...)
/ TODO

/ ook	,
In [1386]: ser= final['state'].isin(['United States'])
In [1386]: final[ser]
Out[1386]: 
Empty DataFrame
Columns: [state/region, ages, year, population, state, area (sq. mi)]
Index: []

/ Intermezzo

/ als axis=0 (default), rm hij elke rij waarin NaN of None in voorkomt	, 
/ als axis=1, rm hij elke column waarin NaN of None in voorkomt	, 

In [1406]: df
Out[1406]: 
   0     1    2
0  1     2  NaN
1  1  None    3

In [1404]: df.dropna(axis=0)
Out[1404]: 
Empty DataFrame
Columns: [0, 1, 2]
Index: []

In [1405]: df.dropna(axis=1)
Out[1405]: 
   0
0  1
1  1

/ Einde Intermezzo

/ 1313	. 

/ in merged zijn er 96 entries met state is NaN	,
In [1422]: merged.head()
Out[1422]: 
  state/region     ages  year  population    state
0           AL  under18  2012   1117489.0  Alabama
1           AL    total  2012   4817528.0  Alabama
2           AL  under18  2010   1130966.0  Alabama
3           AL    total  2010   4785570.0  Alabama
4           AL  under18  2011   1125763.0  Alabama
...
In [1425]: merged[merged['state'].isna()].index.size
Out[1425]: 96
/ door de join	, hebben die entries met state=NaN ook geen 'area (sq. mi)'	, 

/ 1313	. 

/ we gaan die 96 entries met state NaN, en daardoor 'area (sq. mi)' rm	,

n [1427]: final.dropna().index.size
Out[1427]: 2448
/ dit zijn er 96 minder dan 2544	,

In [1429]: final.dropna(inplace=True)
In [1430]: final.index.size
Out[1430]: 2448

/ 1313	. 

In [1441]: final2010=final.query('year==2010&ages==\'total\'')
In [1442]: final2010.index.size
Out[1442]: 51

In [1448]: final2010.head()
Out[1448]: 
    state/region   ages      ...             state  area (sq. mi)
3             AL  total      ...           Alabama        52423.0
91            AK  total      ...            Alaska       656425.0
101           AZ  total      ...           Arizona       114006.0
189           AR  total      ...          Arkansas        53182.0
197           CA  total      ...        California       163707.0
...
In [1449]: final2010.set_index('state').head()
Out[1449]: 
           state/region   ages  year  population  area (sq. mi)
state                                                          
Alabama              AL  total  2010   4785570.0        52423.0
Alaska               AK  total  2010    713868.0       656425.0
Arizona              AZ  total  2010   6408790.0       114006.0
Arkansas             AR  total  2010   2922280.0        53182.0
California           CA  total  2010  37333601.0       163707.0

/ de indexes 3,91,... zijn dus vervangen door Alabama, ...

/ we doen	,
In [1451]: final2010.set_index('state',inplace=True)

/ geef space na /	, zodat TAB final2010 geeft	,
In [1452]: density=final2010['population']/ final2010['area (sq. mi)']
In [1459]: density.size
Out[1459]: 51
In [1460]: density
Out[1460]: 
state
Alabama                   91.287603
Alaska                     1.087509
Arizona                   56.214497
Arkansas                  54.948667
...

In [1463]: density.head()
Out[1463]: 
state
Alaska           1.087509
Wyoming          5.768079
Montana          6.736171
North Dakota     9.537565
South Dakota    10.583512
dtype: float64

In [1464]: density.sort_values(inplace=True,ascending=False)

In [1465]: density.head()
Out[1465]: 
state
District of Columbia    8898.897059
New Jersey              1009.253268
Rhode Island             681.339159
Connecticut              645.600649
Massachusetts            621.815538
dtype: float64

In [1467]: density.tail()
Out[1467]: 
state
South Dakota    10.583512
North Dakota     9.537565
Montana          6.736171
Wyoming          5.768079
Alaska           1.087509
dtype: float64

/ 1313	 .

In [1468]: import seaborn as sns

In [1469]: planets=sns.load_dataset('planets')
In [1471]: planets.index.size
Out[1471]: 1035
In [1470]: planets.head()
Out[1470]: 
            method  number  orbital_period   mass  distance  year
0  Radial Velocity       1         269.300   7.10     77.40  2006
1  Radial Velocity       1         874.774   2.21     56.95  2008
2  Radial Velocity       1         763.000   2.60     19.84  2011
3  Radial Velocity       1         326.030  19.40    110.62  2007
4  Radial Velocity       1         516.220  10.50    119.47  2009

/ lees	,
https://stackoverflow.com/questions/30336324/seaborn-load-dataset
https://github.com/mwaskom/seaborn-data

In [1472]: planets['number'].unique()
Out[1472]: array([1, 2, 3, 5, 4, 6, 7])

In [1473]: planets[:100]
Out[1473]: 
             method  number  orbital_period    mass  distance  year
0   Radial Velocity       1      269.300000   7.100     77.40  2006
1   Radial Velocity       1      874.774000   2.210     56.95  2008
2   Radial Velocity       1      763.000000   2.600     19.84  2011
3   Radial Velocity       1      326.030000  19.400    110.62  2007
4   Radial Velocity       1      516.220000  10.500    119.47  2009
5   Radial Velocity       1      185.840000   4.800     76.39  2008
6   Radial Velocity       1     1773.400000   4.640     18.15  2002
7   Radial Velocity       1      798.500000     NaN     21.41  1996
8   Radial Velocity       1      993.300000  10.300     73.10  2008
9   Radial Velocity       2      452.800000   1.990     74.79  2010
10  Radial Velocity       2      883.000000   0.860     74.79  2010
11  Radial Velocity       1      335.100000   9.880     39.43  2009
12  Radial Velocity       1      479.100000   3.880     97.28  2008
13  Radial Velocity       3     1078.000000   2.530     14.08  1996
14  Radial Velocity       3     2391.000000   0.540     14.08  2001
15  Radial Velocity       3    14002.000000   1.640     14.08  2009
16  Radial Velocity       1        4.230785   0.472     15.36  1995
17  Radial Velocity       5       14.651000   0.800     12.53  1996
18  Radial Velocity       5       44.380000   0.165     12.53  2004
19  Radial Velocity       5     4909.000000   3.530     12.53  2002
20  Radial Velocity       5        0.736540     NaN     12.53  2011
21  Radial Velocity       5      261.200000   0.172     12.53  2007
22  Radial Velocity       3        4.215000   0.016      8.52  2009
23  Radial Velocity       3       38.021000   0.057      8.52  2009
24  Radial Velocity       3      123.010000   0.072      8.52  2009
25  Radial Velocity       1      116.688400     NaN     18.11  1996
...

/ lees	,
https://github.com/mwaskom/seaborn-data/blob/master/raw/planets.csv
/ method=discovery method,
/ count=number of planets in system	,

In [1479]: planets.dropna(axis=0).index.size
Out[1479]: 498
In [1481]: planets.dropna(axis=0).describe()
Out[1481]: 
          number  orbital_period     ...         distance         year
count  498.00000      498.000000     ...       498.000000   498.000000
mean     1.73494      835.778671     ...        52.068213  2007.377510
std      1.17572     1469.128259     ...        46.596041     4.167284
min      1.00000        1.328300     ...         1.350000  1989.000000
25%      1.00000       38.272250     ...        24.497500  2005.000000
50%      1.00000      357.000000     ...        39.940000  2009.000000
75%      2.00000      999.600000     ...        59.332500  2011.000000
max      6.00000    17337.500000     ...       354.000000  2014.000000

/ 13	. 

/ wat betekent count 75% number 2	?
/ dat betekent dat het 75%ste entry count 2 heeft,	

In [1497]: planets.dropna(axis=0).index[:100]
Out[1497]: 
Int64Index([  0,   1,   2,   3,   4,   5,   6,   8,   9,  10,  11,  12,  13,
             14,  15,  16,  17,  18,  19,  21,  22,  23,  24,  27,  28,  45,
             46,  48,  50,  51,  52,  55,  58,  61,  62,  63,  64,  65,  66,
             67,  76,  79,  80,  81,  82,  83,  84, 114, 115, 116, 117, 118,
            119, 120, 121, 122, 125, 126, 127, 128, 129, 130, 131, 132, 133,
            134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 147,
            149, 161, 166, 181, 198, 199, 200, 201, 202, 203, 204, 205, 206,
            207, 208, 209, 210, 211, 212, 213, 214, 215],
           dtype='int64')
/ het is dus de originele index	,
In [1500]: planets.dropna(axis=0).index[26]
Out[1500]: 46
In [1501]: planets.dropna(axis=0).index.size
Out[1501]: 498

In [1502]: 498*3/4
Out[1502]: 373.5

In [1503]: planets.dropna(axis=0).index[373]
Out[1503]: 502

In [1504]: planets.dropna(axis=0).loc[502,:]
Out[1504]: 
method            Radial Velocity
number                          2
orbital_period              194.3
mass                         0.85
distance                     43.4
year                         2007
Name: 502, dtype: object

/ die bij 50% heeft number=1:

In [1505]: 498*2/4
Out[1505]: 249.0

In [1506]: planets.dropna(axis=0).index[249]
Out[1506]: 372

In [1507]: planets.dropna(axis=0).loc[372,:]
Out[1507]: 
method            Radial Velocity
number                          1
orbital_period             1001.7
mass                         6.86
distance                    32.56
year                         2005
Name: 372, dtype: object

/ (162)

/ Intermezzo

/ je moet de column precies zo noemen als de keys in de dict	,

In [1513]: pd.DataFrame({'k':['a','b'],'v':range(2)},columns=['k','v'])
Out[1513]: 
   k  v
0  a  0
1  b  1

In [1514]: pd.DataFrame({'k':['a','b'],'v':range(2)},columns=['k','w'])
Out[1514]: 
   k    w
0  a  NaN
1  b  NaN


/ Einde Intermezzo

In [1524]: df=pd.DataFrame({'k':['a','b','c','a','b','c'],'v':range(6)},columns=
      ...: ['k','v'])

In [1525]: dfg=df.groupby('k')
In [1526]: dfg
Out[1526]: <pandas.core.groupby.groupby.DataFrameGroupBy object at 0x7f08fff5f128>

In [1527]: dfg.sum()
Out[1527]: 
   v
k   
a  3
b  5
c  7

/ (164)

In [1528]: planets.groupby('method')
Out[1528]: <pandas.core.groupby.groupby.DataFrameGroupBy object at 0x7f08fff56ac8>

In [1529]: planets.groupby('method')['orbital_period']
Out[1529]: <pandas.core.groupby.groupby.SeriesGroupBy object at 0x7f08ffefb160>

In [1530]: planets.groupby('method')['orbital_period'].median()
Out[1530]: 
method
Astrometry                         631.180000
Eclipse Timing Variations         4343.500000
Imaging                          27500.000000
Microlensing                      3300.000000
Orbital Brightness Modulation        0.342887
Pulsar Timing                       66.541900
Pulsation Timing Variations       1170.000000
Radial Velocity                    360.200000
Transit                              5.714932
Transit Timing Variations           57.011000
Name: orbital_period, dtype: float64

In [1535]: planets.query('method==\'Radial Velocity\'').index.size 
Out[1535]: 553
 
/ 7	. 

/ opnieuw	, 

In [28]: x=np.arange(0,12).reshape(3,4)

In [29]: x
Out[29]: 
array([[ 0,  1,  2,  3],
       [ 4,  5,  6,  7],
       [ 8,  9, 10, 11]])

In [21]: s=x[np.newaxis,:]

In [22]: s.shape
Out[22]: (1, 3)

In [31]: t=x[2,[2,0,1]] 		# is een 1-dim array	, zie beneden	,

In [32]: type(t)
Out[32]: numpy.ndarray

In [33]: t.shape
Out[33]: (3,)

In [34]: type(s)
Out[34]: numpy.ndarray

In [37]: t?
...

In [38]: t.ndim
Out[38]: 1

In [39]: s.ndim
Out[39]: 2

/ 13	. 

n [65]: t=np.random.multivariate_normal(mean,cov,100)

In [66]: type(t)
Out[66]: numpy.ndarray

In [67]: t.shape
Out[67]: (100, 2)

In [73]: t
Out[73]: 
array([[ 0.18108303, -0.94567406],
       [-0.15764726, -1.02197341],
       [-0.04641199,  1.15087363],
...

In [68]: %matplotlib
Using matplotlib backend: Qt5Agg

In [69]: import matplotlib.pyplot as plt

In [70]: import seaborn

In [71]: seaborn.set()

In [72]: plt.scatter(t[:,0],t[:,1])
Out[72]: <matplotlib.collections.PathCollection at 0x7ff4076cc3c8>

/ we zien de grafiek	,

/ 13	. 

In [75]: u=[1,2]
In [83]: u
Out[83]: [1, 2]
In [84]: type(u)
Out[84]: list
In [78]:  u.shape
/ ERR

In [79]: u=np.array(u)
In [86]: type(u)
Out[86]: numpy.ndarray
In [81]: u
Out[81]: array([1, 2])
In [80]: u.shape
Out[80]: (2,)

/ 13	. 

/ lees	,
https://stackoverflow.com/questions/29199585/indexerror-too-many-indices-numpy-array-with-1-row-and-2-columns

In [105]: v=np.array([1,2])

In [106]: v[:,:,np.newaxis]
IndexError: too many indices for array
/ klopt, van het antwoord array	, :,: vraagt om een 2-dim array	,

/ 1313	. 

/ de richtingen zijn 

	 /|----->c
  /	|
 V	|
a		V
    b

In [182]: u=np.array([1,2,3,4,5,6,7,8,9,10,11,12]).reshape(2,3,2)

n [188]: u
Out[188]: 
array([[[ 1,  2],
        [ 3,  4],
        [ 5,  6]],

       [[ 7,  8],
        [ 9, 10],
        [11, 12]]])

In [184]: u[0,:,:]
Out[184]: 
array([[1, 2],
       [3, 4],
       [5, 6]])

In [185]: u[:,0,:]
Out[185]: 
array([[1, 2],
       [7, 8]])

In [186]: u[:,:,0]
Out[186]: 
array([[ 1,  3,  5],
       [ 7,  9, 11]])

/ Hij ziet er zo uit:

					1 2
					3 4
					5 6
	7 8
	9 10
	1112

/ 1313	. 

In [189]: v=np.array([1,2,3,4,5,6]).reshape(3,2)

In [190]: v
Out[190]: 
array([[1, 2],
       [3, 4],
       [5, 6]])

/ 131313	. 

In [197]: b=v[:,np.newaxis,:]

	  1  2	
	 /|----->c
  /3| 4	
 V	|
a 5	V6
    b
/ de middelste var is altijd 0

In [199]: b[:,0,0]
Out[199]: array([1, 3, 5])

In [200]: b[:,0,1]
Out[200]: array([2, 4, 6])

In [201]: b[0,0,:]
Out[201]: array([1, 2])

In [202]: b[1,0,:]
Out[202]: array([3, 4])

In [203]: b[2,0,:]
Out[203]: array([5, 6])

/ klopt	, b wijst naar beneden	, dus v ligt op de grond	,  

/ 131313	. 

	 /| 1  2----->c
  /	| 3  4
 V	| 5  6
a		V
    b

/ b wijst naar beneden	, dus v[0,:,:] staat, maar gaat de grond in	,

In [204]: a=v[np.newaxis,:,:]

In [205]: a[0,:,0]
Out[205]: array([1, 3, 5])

In [206]: a[0,:,1]
Out[206]: array([2, 4, 6])

In [207]: a[0,0,:]
Out[207]: array([1, 2])

In [208]: a[0,1,:]
Out[208]: array([3, 4])

In [209]: a[0,2,:]
Out[209]: array([5, 6])

/ 131313	. 

/ v staat in linker zijvlak	, de grond in	,

	 /  1|----->c
  / 3	 |
 V5	  2|
 a  4	 V
  6    b

In [216]: c=v[:,:,np.newaxis]

In [217]: c[0,:,0]
Out[217]: array([1, 2])

In [218]: c[1,:,0]
Out[218]: array([3, 4])

In [219]: c[2,:,0]
Out[219]: array([5, 6])

In [220]: c[:,0,0]
Out[220]: array([1, 3, 5])

In [221]: c[:,1,0]
Out[221]: array([2, 4, 6])

/ 7	. 

/ Series	, DataFrames	,

/ het ziet er naar uit dat het niet uitmaakt of een series een explicit integer index heeft	 of niet	, [0:2]=0,1 

In [236]: d=pd.Series([.25,.5,.75,1])
In [239]: d2=pd.Series([.25,.5,.75,1],index=[0,1,2,3])			/ explicit integer index	,
In [253]: e=pd.Series([5,4,3,2],index=['a','b','c','d'])

In [260]:  d.index
Out[260]: RangeIndex(start=0, stop=4, step=1)

In [261]: d2.index
Out[261]: Int64Index([0, 1, 2, 3], dtype='int64')

/ we zien een verschil, maar ze gedragen zich hetzelfde	,

In [255]: e['a':'c']
Out[255]: 
a    5
b    4
c    3
dtype: int64

In [256]: e[0:2]
Out[256]: 
a    5
b    4
dtype: int64

In [262]:   d[0:2]
Out[262]: 
0    0.25
1    0.50
dtype: float64

In [263]:   d2[0:2]
Out[263]: 
0    0.25
1    0.50
dtype: float64

/ Dus of we nu ,index=[0,1,2,3] doen of niet	, a[0:2] is a[0] en a[1]	,
/ willen we hetzelfde als a['a':'c'], dan moeten we .loc use	,

In [264]: d.loc[0:2]
Out[264]: 
0    0.25
1    0.50
2    0.75
dtype: float64

In [265]: d2.loc[0:2]
Out[265]: 
0    0.25
1    0.50
2    0.75
dtype: float64

In [266]: e.loc[0:2]
/ ERR	,

In [267]: e.iloc[0:2]
Out[267]: 
a    5
b    4
dtype: int64
/ OK	,

/ 13	. 

(102)

/ data frames	,

/ we kunnen een data frame maken met 2 dicts	, of met 2 series	,

In [268]: pop_={'c':234,'t': 90,'n':789,'f':342,'i':30303}

In [269]: ar_={'c':23,'t': 899,'n':232,'f':9809,'i':53}

In [272]: pop=pd.Series(pop_)

In [273]: ar=pd.Series(ar_)

In [274]: pop
Out[274]: 
c      234
t       90
n      789
f      342
i    30303
dtype: int64

In [289]: pop.index
Out[289]: Index(['c', 't', 'n', 'f', 'i'], dtype='object')

/ we zien dat de index niet sorted is	, maar zoals opgegeven is	,

/ we kunnen een dataframe maken met de dicts of met de daarmee gemaakte series	,
/ de ordening van de index blijft behouden als we met de series doen, als we de dicts use	, dan wordt de index geordend	,

In [277]: states=pd.DataFrame({'pop':pop,'ar':ar})

In [292]: states
Out[292]: 
     pop    ar
c    234    23
t     90   899
n    789   232
f    342  9809
i  30303    53
/ dezelfde order nog in de index	,

In [279]: states2=pd.DataFrame({'pop':pop_,'ar':ar_})
In [293]: states2
Out[293]: 
     pop    ar
c    234    23
f    342  9809
i  30303    53
n    789   232
t     90   899
/ geordend!

/ we kunnen geen == want de indexes zijn niet gelijk geordend	, 

In [306]: states.sort_index() == states2
Out[306]: 
    pop    ar
c  True  True
f  True  True
i  True  True
n  True  True
t  True  True

/ lees	,
https://stackoverflow.com/questions/26552116/contract-of-pandas-dataframe-equals

/ 1313	. 

/ we gaan verder met states	, dus de data frame gemaakt met series	,

/ we hebben 2 indexen	,

/ DATAFRAME HAS 2 INDEXES	,
/ DATAFRAME HAS TWO INDEXES	,

In [308]: states.columns
Out[308]: Index(['pop', 'ar'], dtype='object')

In [309]: states.index
Out[309]: Index(['c', 't', 'n', 'f', 'i'], dtype='object')

In [312]:  states['c':'n']
Out[312]: 
   pop   ar
c  234   23
t   90  899
n  789  232
/ gewoon tussen c en n, inclusief	, 

/ maar niet inclusief	,
In [314]: states[0:2]
Out[314]: 
   pop   ar
c  234   23
t   90  899

In [317]: states.loc[0:2]  
/ ERR	, 

In [318]: states['c']
/ ERR	, 
/ want hij verwacht een column:

In [318]: states['pop']
Out[318]: 
c      234
t       90
n      789
f      342
i    30303
Name: pop, dtype: int64

In [320]: states['pop','ar']
/ ERR	,

In [321]: states['pop':'ar']
/ ERR	,

/ 1313	. 

/ zo kun je ook een data frame maken	, maar is toch dezelfde manier	,

In [323]: list_=[{'a':i,'b':i**2}for i in range(7)]

In [324]: list_
Out[324]: 
[{'a': 0, 'b': 0},
 {'a': 1, 'b': 1},
 {'a': 2, 'b': 4},
 {'a': 3, 'b': 9},
 {'a': 4, 'b': 16},
 {'a': 5, 'b': 25},
 {'a': 6, 'b': 36}]

In [325]: list=pd.DataFrame(list_)
Out[325]: 
   a   b
0  0   0
1  1   1
2  2   4
3  3   9
4  4  16
5  5  25
6  6  36

/ 1313	. 

/ google	,
pandas dataframe how to see multiple columns
/ lees	,
https://stackoverflow.com/questions/11285613/selecting-multiple-columns-in-a-pandas-dataframe`

In [341]: states.loc['t':'f','pop':'ar']
Out[341]: 
   pop    ar
t   90   899
n  789   232
f  342  9809

In [339]: states.loc['f','pop':'ar']
Out[339]: 
pop     342
ar     9809
Name: f, dtype: int64
/ bij 1 row print columns onder elkaar	, 

In [336]: states.loc[:,'pop':'ar']
Out[336]: 
     pop    ar
c    234    23
t     90   899
n    789   232
f    342  9809
i  30303    53

In [335]: states.iloc[:,0:2]
Out[335]: 
     pop    ar
c    234    23
t     90   899
n    789   232
f    342  9809
i  30303    53

In [369]:  states.loc[0,'pop','ar'] 
/ ERR to many indexers	,
In [368]: states.loc[:,['pop','ar']]
/ OK	,
In [367]: states.loc[:,'pop':'ar']
/ OK	,

/ 1313	. 

/ verschil .iloc en .loc als de indexes integers zijn	,

/ iloc staat voor implicit loc	, en 0:2=0,1	, 
/ loc staat voor explicit loc	, en 0:2=0,1,2	,


/ maar hierboven hadden we wel al list	,

In [358]: list
Out[358]: 
   a   b
0  0   0
1  1   1
2  2   4
3  3   9
4  4  16
5  5  25
6  6  36

In [362]: list.iloc[1:3,:]
Out[362]: 
   a  b
1  1  1
2  2  4

In [363]: list.loc[1:3,:]
Out[363]: 
   a  b
1  1  1
2  2  4
3  3  9

/ 131313	. 

/ .loc kan ints en strings	, .iloc kan alleen op ints	,

In [376]: list.loc[1:3,'a':'b']
Out[376]: 
   a  b
1  1  1
2  2  4
3  3  9

In [378]: list.iloc[1:3,'a':'b']
/ ERR	,
/ .iloc op strings kan niet	,



/ Intermezzo

In [355]: states3=pd.DataFrame({'pop':pop,'ar':ar},index=[0,1,2,3,4])

In [356]: states3
Out[356]: 
   pop  ar
0  NaN NaN
1  NaN NaN
2  NaN NaN
3  NaN NaN
4  NaN NaN
/ pop en ar zijn series	, die al een index hebben	, 'c', ...
/ TODO

/ Einde Intermezzo 

/ 1313	. 

/ 131313	. 

/ verschil explicit, implicit index	,
/ series met string index	,
/ explicit index : slice is inclusive	, 
/ implicit index: slice is exclusive	,
 
/ lees	,
https://pandas.pydata.org/pandas-docs/stable/indexing.html

In [268]: pop_={'c':234,'t': 90,'n':789,'f':342,'i':30303}
In [272]: pop=pd.Series(pop_)

In [465]: pop
Out[465]: 
c      234
t       90
n      789
f      342
i    30303
dtype: int64

In [466]: pop[1:3]
Out[466]: 
t     90
n    789
dtype: int64

In [467]: pop['t':'f']
Out[467]: 
t     90
n    789
f    342
dtype: int64

/ INDEXES SERIES

/ we hebben de series	,

In [514]: ser
Out[514]: 
10    a
11    b
12    c
13    d
dtype: object

In [515]: fls
Out[515]: 
0.1    a
0.2    b
0.3    c
0.4    d
dtype: object

In [516]: pop
Out[516]: 
c      234
t       90
n      789
f      342
i    30303
dtype: int64


/ google,
pandas series implicit slice
/ lees	,
https://stackoverflow.com/questions/36840877/slicing-series-in-pandas


/ 131313	. 

/ in een numpy array kun je geen index opgeven	, 
/ een index is daar altijd implicit	, dus niet inclusive	,

In [486]: x=np.array([3,5,7,9])

In [487]: x[1:3]
Out[487]: array([5, 7])


/ 131313	. 

/ als een index niet van type int is, is ['a':'c'] en [.1:.3] explicit, dus inclusive	, 
/ [1:3] is altijd implicit, ook als de explicit index van type int is	, 
/ 	behalve als explicit index van type float is, TODO

/ in een series is [1:3] implicit	, ook als de explicit index ints zijn	, dus niet inclusive	,
/ als je de explicit index wilt use, use dan .loc	,
/ .iloc[1:3] = [1:3]


In [463]: s={10:'a',11:'b',12:'c',13:'d'}
In [464]: ser=pd.Series(s)

In [458]: ser
Out[458]: 
10    a
11    b
12    c
13    d
dtype: object

In [459]: ser[10:12]
Out[459]: Series([], dtype: object)
/ ser[10:12] is implicit	, en die zijn er niet	,
/ bij pop is er een string index	, en is pop['c':'n'] de explicit index, dus inclusive	,
/ dus met [1:3] is altijd implicit, ook al is de explicit index van type integer	,

In [483]: ser[1:3]
Out[483]: 
11    b
12    c
dtype: object
/ implicit, niet inclusive	,

In [460]: ser.loc[10:12]
Out[460]: 
10    a
11    b
12    c
dtype: object
/ explicit	,

In [461]: ser.iloc[0:2]
Out[461]: 
10    a
11    b
dtype: object
/ .iloc[0:2] = [0:2]

/ 131313	. 

n [492]: fls
Out[492]: 
0.1    a
0.2    b
0.3    c
0.4    d
dtype: object

In [493]: fls[1:3]
Out[493]: Series([], dtype: object)
/ TODO
/ Niet als bij een explicit index van type string	,

In [513]:  fls[.1:.3]
Out[513]: 
0.1    a
0.2    b
0.3    c
dtype: object
/ dit is net als bij een explicit index van type string: ['c':'n'] is ook explicit, dus inclusive	,

In [508]: fls.loc[.1:.3]
Out[508]: 
0.1    a
0.2    b
0.3    c
dtype: object


In [510]: fls.iloc[1:3]
Out[510]: 
0.2    b
0.3    c
dtype: object


/ 131313	. 

In [500]: pop
Out[500]: 
c      234
t       90
n      789
f      342
i    30303
dtype: int64

In [503]:  pop[1:3]
Out[503]: 
t     90
n    789
dtype: int64
/ implicit index	,

In [544]: pop['c':'n']
Out[544]: 
c    234
t     90
n    789
dtype: int64
/ explicit index	,

In [501]: pop.iloc[1:3]
Out[501]: 
t     90
n    789
dtype: int64

In [502]: pop.loc['t':'i']
Out[502]: 
t       90
n      789
f      342
i    30303
dtype: int64

In [498]: pop.loc[1:3]
/ ERR, ints zijn niet de explicit index
TypeError: cannot do slice indexing on <class 'pandas.core.indexes.base.Index'> with these indexers [1] of <class 'int'>


/ Einde INDEXES SERIES

/ INDEXES SERIES

https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Index.html
/ boek(100)

https://www.numpy.org/devdocs/user/basics.types.html

In [554]: pd.Index?
...
Examples
--------
>>> pd.Index([1, 2, 3])
Int64Index([1, 2, 3], dtype='int64')

>>> pd.Index(list('abc'))
Index(['a', 'b', 'c'], dtype='object')

See Also
---------
RangeIndex : Index implementing a monotonic integer range
CategoricalIndex : Index of :class:`Categorical` s.
MultiIndex : A multi-level, or hierarchical, Index
IntervalIndex : an Index of :class:`Interval` s.
DatetimeIndex, TimedeltaIndex, PeriodIndex
Int64Index, UInt64Index,  Float64Index

In [554]: pd.Index?

In [555]: pd.Index([1,2,3])
Out[555]: Int64Index([1, 2, 3], dtype='int64')

In [556]: pd.Index(['a','b'])
Out[556]: Index(['a', 'b'], dtype='object')

In [557]: pd.Index([.1])
Out[557]: Float64Index([0.1], dtype='float64')



/ Einde INDEXES SERIES

/ INDEXES DATAFRAMES

/ als we [] use, en 1 ding erin	,
/ slices, explicit of implicit,   ['c':'n'] of [0:2], slaan altijd op de rows	,
/ direct ['ar'] of [['pop',ar']] slaan altijd op een column	,

/ ['c':'n',:] of [0:2,'ar'] kan niet	,
/ use dan .loc, of .iloc	,

In [565]: states
Out[565]: 
     pop    ar
c    234    23
t     90   899
n    789   232
f    342  9809
i  30303    53

In [563]: states['c':'n']
Out[563]: 
   pop   ar
c  234   23
t   90  899
n  789  232

In [564]: states[0:2]
Out[564]: 
   pop   ar
c  234   23
t   90  899

In [569]: states['ar']
Out[569]: 
c      23
t     899
n     232
f    9809
i      53
Name: ar, dtype: int64

In [572]: states[0:2,:]
/ ERR
In [573]: states[:,['pop','ar']]
/ ERR
In [575]: states['c':'n','ar']
/ ERR
/ use .loc, .iloc	, in dat geval	,

In [576]: states.loc['c':'n','ar']
Out[576]: 
c     23
t    899
n    232
Name: ar, dtype: int64

In [578]: states.iloc[0:2,0:1]
Out[578]: 
   pop
c  234
t   90


/ Einde INDEXES DATAFRAMES


/ 1313	. 

/ als we niet .loc of .iloc use, dus alleen [], dan kun je alleen een column opgeven, of een row met implicit index	, 
/ heeft de dataframe ints als row index, dan kan df[1] of df[1:3] niet	,

In [416]: states
Out[416]: 
     pop    ar
c    234    23
t     90   899
n    789   232
f    342  9809
i  30303    53

n [417]: states[1:3]
Out[417]: 
   pop   ar
t   90  899
n  789  232
/ exclusive	,

In [426]: states['pop']
Out[426]: 
c      234
t       90
n      789
f      342
i    30303
Name: pop, dtype: int64




/ 1313	. 

/ als van een data frame beide indexen int zijn, zie je non inclusief van iloc op beide indexes	,

In [323]: list__=[{0:i,1:i**2,2:i**3}for i in range(7)]

In [380]: list2=pd.DataFrame(list__)

In [381]: list2
Out[381]: 
   0   1    2
0  0   0    0
1  1   1    1
2  2   4    8
3  3   9   27
4  4  16   64
5  5  25  125
6  6  36  216

In [389]: list2.loc[2:5,0:2]
Out[389]: 
   0   1    2
2  2   4    8
3  3   9   27
4  4  16   64
5  5  25  125

In [390]: list2.iloc[2:5,0:2]
Out[390]: 
   0   1
2  2   4
3  3   9
4  4  16

 
/ 13.	 

/ boek(113)

/ fancy indexing	,

/ fancy indexing is explicit , so inclusive	,
/ we kunnen dat ook zien door .loc te use	, 

/ fancy indexing betreft rows	,

In [601]: states
Out[601]: 
     pop    ar
c    234    23
t     90   899
n    789   232
f    342  9809
i  30303    53

In [603]: states[states['pop']<=789]
Out[603]: 
   pop    ar
c  234    23
t   90   899
n  789   232
f  342  9809

/ maar zoals altijd	,
In [604]: states[states['pop']<=789,'ar']
/ ERR	,
In [604]: states.loc[states['pop']<=789,'ar']
Out[604]: 
c      23
t     899
n     232
f    9809
Name: ar, dtype: int64
/ we zien hier nogmaals, dat fancy indexing de explicit index use	,

/ (115)

/ ufuncs	,

In [608]: rng=np.random.RandomState(0)

/ op rng kun je allerlei methods doen, 
/ bijv,	
In [610]: ser_=rng.randint(0,10,4)
In [631]: ser=pd.Series(ser_)

In [635]: df_=rng.randint(0,10,(3,4))

In [636]: df_
Out[636]: 
array([[0, 7, 3, 3],
       [0, 0, 9, 4],
       [4, 5, 8, 8]])

In [637]: df=pd.DataFrame(df_,columns=['a','b','c','d'])

In [644]: df.columns
Out[644]: Index(['a', 'b', 'c', 'd'], dtype='object')

In [645]: df.index
Out[645]: RangeIndex(start=0, stop=3, step=1)

/ we zien 2 indexes	, de laatste is een implicit , non inclusive,	

/ we kunnen ook index expliciet geven	, 
In [647]: df=pd.DataFrame(df_,columns=['a','b','c','d'],index=['c','f','i'])

In [653]: df
Out[653]: 
   a  b  c  d
c  0  7  3  3
f  0  0  9  4
i  4  5  8  8

In [651]: np.exp(df)
Out[651]: 
          a            b            c            d
c   1.00000  1096.633158    20.085537    20.085537
f   1.00000     1.000000  8103.083928    54.598150
i  54.59815   148.413159  2980.957987  2980.957987

In [652]: df/2
Out[652]: 
     a    b    c    d
c  0.0  3.5  1.5  1.5
f  0.0  0.0  4.5  2.0
i  2.0  2.5  4.0  4.0

In [654]: df*np.pi/4
Out[654]: 
          a         b         c         d
c  0.000000  5.497787  2.356194  2.356194
f  0.000000  0.000000  7.068583  3.141593
i  3.141593  3.926991  6.283185  6.283185

In [656]: np.sin(df*np.pi/4)
Out[656]: 
              a         b             c             d
c  0.000000e+00 -0.707107  7.071068e-01  7.071068e-01
f  0.000000e+00  0.000000  7.071068e-01  1.224647e-16
i  1.224647e-16 -0.707107 -2.449294e-16 -2.449294e-16

/ (128)

In [657]: i_=[('c',2000),('c',2010),('ny',2000),('ny',2010),('t',2000),('t',2010)
     ...: ]

In [658]: pop_=[33,37,18,19,20,25]

In [659]: pop=pd.Series(pop_,i_)

In [660]: pop
Out[660]: 
(c, 2000)     33
(c, 2010)     37
(ny, 2000)    18
(ny, 2010)    19
(t, 2000)     20
(t, 2010)     25
dtype: int64

In [662]: i=pd.MultiIndex.from_tuples(i_)

In [663]: i
Out[663]: 
MultiIndex(levels=[['c', 'ny', 't'], [2000, 2010]],
           labels=[[0, 0, 1, 1, 2, 2], [0, 1, 0, 1, 0, 1]])

In [664]: pop.index
Out[664]: 
Index([('c', 2000), ('c', 2010), ('ny', 2000), ('ny', 2010), ('t', 2000),
       ('t', 2010)],
      dtype='object')

In [667]: pop=pop.reindex(i)

In [668]: pop
Out[668]: 
c   2000    33
    2010    37
ny  2000    18
    2010    19
t   2000    20
    2010    25
dtype: int64

In [669]: pop.index
Out[669]: 
MultiIndex(levels=[['c', 'ny', 't'], [2000, 2010]],
           labels=[[0, 0, 1, 1, 2, 2], [0, 1, 0, 1, 0, 1]])

In [670]: pop[:,2010]
Out[670]: 
c     37
ny    19
t     25
dtype: int64

/ pop is een series	,

/ (130)


In [673]: pop_df=pop.unstack()

In [675]: type(pop_df)
Out[675]: pandas.core.frame.DataFrame

In [674]: pop_df
Out[674]: 
    2000  2010
c     33    37
ny    18    19
t     20    25

In [676]: pop_df.stack()
Out[676]: 
c   2000    33
    2010    37
ny  2000    18
    2010    19
t   2000    20
    2010    25
dtype: int64

In [677]: pop_df.stack() == pop
Out[677]: 
c   2000    True
    2010    True
ny  2000    True
    2010    True
t   2000    True
    2010    True
dtype: bool

In [678]: pop_df.stack().equals(pop)
Out[678]: True

/ TODO == of .equals	?

/ (131)

/ we hebben een index, nl. pop.index	, en we nemen er een column bij	, de kolommen vormen ook een index, dus die maken we 1 groter	,

In [682]: pop_df2=pd.DataFrame({'total':pop,'under18':[15,16,9,10,10,11]})

In [683]: pop_df2
Out[683]: 
         total  under18
c  2000     33       15
   2010     37       16
ny 2000     18        9
   2010     19       10
t  2000     20       10
   2010     25       11

In [684]: pop_df2.index
Out[684]: 
MultiIndex(levels=[['c', 'ny', 't'], [2000, 2010]],
           labels=[[0, 0, 1, 1, 2, 2], [0, 1, 0, 1, 0, 1]])

In [685]: pop_df2.columns
Out[685]: Index(['total', 'under18'], dtype='object')

/ 1313	. 

In [691]: f_u18= pop_df2['total']/pop_df2['under18']

In [692]: f_u18
Out[692]: 
c   2000    2.200000
    2010    2.312500
ny  2000    2.000000
    2010    1.900000
t   2000    2.000000
    2010    2.272727
dtype: float64

In [693]: f_u18.unstack()
Out[693]: 
    2000      2010
c    2.2  2.312500
ny   2.0  1.900000
t    2.0  2.272727

/ 1313	. 

/ Intermezzo

In [694]: rng=np.random.RandomState(0)

In [695]: rng.rand(4,2)
Out[695]: 
array([[0.5488135 , 0.71518937],
       [0.60276338, 0.54488318],
       [0.4236548 , 0.64589411],
       [0.43758721, 0.891773  ]])

In [699]: rng=np.random.RandomState(0)

In [700]: rng.rand(4,2)
Out[700]: 
array([[0.5488135 , 0.71518937],
       [0.60276338, 0.54488318],
       [0.4236548 , 0.64589411],
       [0.43758721, 0.891773  ]])

/ Einde Intermezzo

/ een andere manier om een MultiIndex te maken, niet met tuples is	,

In [708]: pd.DataFrame(rng.rand(4,2),index=[['a','a','b','b'],[1,2,1,2]],columns
     ...: =['data1','data2'])
Out[708]: 
        data1     data2
a 1  0.196582  0.368725
  2  0.820993  0.097101
b 1  0.837945  0.096098
  2  0.976459  0.468651

/ maar deze manier is indirect	, 

/ het kan ook direct	, met .from_arrays	, ipv. from_tuples	,

In [712]:  j=pd.MultiIndex.from_arrays([['a','a','b','b'],[1,2,1,2]])

In [713]: j
Out[713]: 
MultiIndex(levels=[['a', 'b'], [1, 2]],
           labels=[[0, 0, 1, 1], [0, 1, 0, 1]])

/ eerst deden we	,

In [714]: i=pd.MultiIndex.from_tuples([('a',1),('a',2),('b',1),('b',2)])

In [715]: i
Out[715]: 
MultiIndex(levels=[['a', 'b'], [1, 2]],
           labels=[[0, 0, 1, 1], [0, 1, 0, 1]])

/ of zo, het makkelijkst	,

In [718]: k=pd.MultiIndex.from_product([['a','b'],[1,2]])

In [719]: k
Out[719]: 
MultiIndex(levels=[['a', 'b'], [1, 2]],
           labels=[[0, 0, 1, 1], [0, 1, 0, 1]])

/ of helemaal direct	, maar is wel meer werk als .from_product	,

In [731]: l=pd.MultiIndex(levels=[['a','b'],[1,2]],labels=[[0,0,1,1],[0,1,0,1]])
     ...: 
In [732]: l
Out[732]: 
MultiIndex(levels=[['a', 'b'], [1, 2]],
           labels=[[0, 0, 1, 1], [0, 1, 0, 1]])

In [734]: pd.DataFrame(rng.randint(0,10,4),index=k)
Out[734]: 
     0
a 1  2
  2  3
b 1  3
  2  2

In [735]: pd.DataFrame(rng.randint(1000,2000,4),index=k)
Out[735]: 
        0
a 1  1942
  2  1739
b 1  1148
  2  1209

/ 13	. 

/ pd.merge werkt op de columns	, net als joins in SQL
/ pd.merge werkt zoals natural join	, of join using	, 


In [766]: df1=pd.DataFrame({'e':['b','j','l','s'],'f':[1,2,3,4],'g':['a','e','e','h']})

In [767]: df2=pd.DataFrame({'e':['b','j','l','s'],'f':[1,2,3,4],'h':[1,2,3,4]})

In [768]: df1.merge(df2)
Out[768]: 
   e  f  g  h
0  b  1  a  1
1  j  2  e  2
2  l  3  e  3
3  s  4  h  4

In [769]: df2=pd.DataFrame({'e':['b','j','l','s'],'f':[1,12,3,14],'h':[1,2,3,4]})

In [770]: df1.merge(df2)
Out[770]: 
   e  f  g  h
0  b  1  a  1
1  l  3  e  3

/ (168)

/ maar df op (165)	,

In [773]: df=pd.DataFrame({'key':['A','B','C','A','B','C'],
     ...:     'data1':range(6),
     ...:     'data2':rng.randint(0,10,6)})
     ...:     
/ TODO columns attr van pd.DataFrame doen we niet	,

In [774]: df
Out[774]: 
  key  data1  data2
0   A      0      2
1   B      1      3
2   C      2      0
3   A      3      0
4   B      4      6
5   C      5      0

In [777]: df.groupby('key').sum()
Out[777]: 
     data1  data2
key              
A        3      2
B        5      9
C        7      0

In [778]: df.groupby('key').describe()
Out[778]: 
    data1                          ...  data2                      
    count mean      std  min   25% ...    min   25%  50%   75%  max
key                                ...                             
A     2.0  1.5  2.12132  0.0  0.75 ...    0.0  0.50  1.0  1.50  2.0
B     2.0  2.5  2.12132  1.0  1.75 ...    3.0  3.75  4.5  5.25  6.0
C     2.0  3.5  2.12132  2.0  2.75 ...    0.0  0.00  0.0  0.00  0.0

[3 rows x 16 columns]

/ we zien niet alles van data1 en data2,

In [779]: df.groupby('key').describe()['data1']
Out[779]: 
     count  mean      std  min   25%  50%   75%  max
key                                                 
A      2.0   1.5  2.12132  0.0  0.75  1.5  2.25  3.0
B      2.0   2.5  2.12132  1.0  1.75  2.5  3.25  4.0
C      2.0   3.5  2.12132  2.0  2.75  3.5  4.25  5.0

In [789]: df.groupby('key').describe()['data2']
Out[789]: 
     count  mean       std  min   25%  50%   75%  max
key                                                  
A      2.0   1.0  1.414214  0.0  0.50  1.0  1.50  2.0
B      2.0   4.5  2.121320  3.0  3.75  4.5  5.25  6.0
C      2.0   0.0  0.000000  0.0  0.00  0.0  0.00  0.0

In [780]: df.groupby('key').aggregate({'data1':min,'data2':max})
Out[780]: 
     data1  data2
key              
A        0      2
B        1      6
C        2      0

In [811]: def filter_func1(df):
     ...:     return df['data1'].std()>1.5
     ...: 

In [785]: def filter_func2(df):
     ...:     return df['data2'].std()>1.5
     ...: 

/ zonder groupby	,
In [805]: df['data2'].std()
Out[805]: 2.401388487243717

In [808]: df.groupby('key').std()
Out[808]: 
       data1     data2
key                   
A    2.12132  1.414214
B    2.12132  2.121320
C    2.12132  0.000000

In [809]: df.groupby('key')['data1'].std()
Out[809]: 
key
A    2.12132
B    2.12132
C    2.12132
Name: data1, dtype: float64

In [810]: df.groupby('key')['data2'].std()
Out[810]: 
key
A    1.414214
B    2.121320
C    0.000000
Name: data2, dtype: float64

In [820]: df.groupby('key').filter(filter_func1)
Out[820]: 
  key  data1  data2
0   A      0      2
1   B      1      3
2   C      2      0
3   A      3      0
4   B      4      6
5   C      5      0

In [821]: df.groupby('key').filter(filter_func2)
Out[821]: 
  key  data1  data2
1   B      1      3
4   B      4      6

/ een filter fct krijgt 3 dfs	,
  key  data1  data2
0   A      0      2
3   A      3      0
  key  data1  data2
1   B      1      3
4   B      4      6
  key  data1  data2
2   C      2      0
5   C      5      0
/ en hij filters die voldoen eruit,	 en doet die dan bij elkaar	,
/ 

/ dus deze filter fct wordt per group 
In [811]: def filter_func1(df):
     ...:     return df['data1'].std()>1.5
     ...: 

/ Intermezzo

/ 13	. 

/ een filter fct krijgt een kleine df, volgens de groupby	, 
/ een filter fct krijgt geen DataFrameGroupBy	,

n [830]: def fct(x):
     ...:     print(type(x))
     ...:     return True
     ...: 

In [831]: df.groupby('key').filter(fct)
<class 'pandas.core.frame.DataFrame'>
<class 'pandas.core.frame.DataFrame'>
<class 'pandas.core.frame.DataFrame'>
Out[831]: 
  key  data1  data2
0   A      0      2
1   B      1      3
2   C      2      0
3   A      3      0
4   B      4      6
5   C      5      0

/ een filter fct moet een Bool return	,

/ 13	. 

In [840]: def fct(x):
     ...:     print(x)
     ...:     return True
     ...: 
     ...: 
     ...: 
     ...: 
     ...: 
     ...: 

In [841]: df.groupby('key').filter(fct)
  key  data1  data2
0   A      0      2
3   A      3      0
  key  data1  data2
1   B      1      3
4   B      4      6
  key  data1  data2
2   C      2      0
5   C      5      0
Out[841]: 
  key  data1  data2
0   A      0      2
1   B      1      3
2   C      2      0
3   A      3      0
4   B      4      6
5   C      5      0

/ 13	. 

In [842]: def fct(df):
     ...:     print(df)
     ...:     print(df.describe())
     ...:     return True
     ...: 
     ...: 

In [843]: df.groupby('key').filter(fct)
  key  data1  data2
0   A      0      2
3   A      3      0
         data1     data2
count  2.00000  2.000000
mean   1.50000  1.000000
std    2.12132  1.414214
min    0.00000  0.000000
25%    0.75000  0.500000
50%    1.50000  1.000000
75%    2.25000  1.500000
max    3.00000  2.000000
  key  data1  data2
1   B      1      3
4   B      4      6
         data1    data2
count  2.00000  2.00000
mean   2.50000  4.50000
std    2.12132  2.12132
min    1.00000  3.00000
25%    1.75000  3.75000
50%    2.50000  4.50000
75%    3.25000  5.25000
max    4.00000  6.00000
  key  data1  data2
2   C      2      0
5   C      5      0
         data1  data2
count  2.00000    2.0
mean   3.50000    0.0
std    2.12132    0.0
min    2.00000    0.0
25%    2.75000    0.0
50%    3.50000    0.0
75%    4.25000    0.0
max    5.00000    0.0
Out[843]: 							/ return True doet dit WH	,
  key  data1  data2
0   A      0      2
1   B      1      3
2   C      2      0
3   A      3      0
4   B      4      6
5   C      5      0

/ we zien hierboven een describe() op een df	, niet op een DataFrameGroupBy	,

/ 13	. 

/ zo ziet .describe eruit op een dataframe,	

In [854]: df.describe()
Out[854]: 
          data1     data2
count  6.000000  6.000000
mean   2.500000  1.833333
std    1.870829  2.401388
min    0.000000  0.000000
25%    1.250000  0.000000
50%    2.500000  1.000000
75%    3.750000  2.750000
max    5.000000  6.000000

/ zo ziet describe() eruit op een DataFrameGroupBy	,

In [855]: df.groupby('key').describe()
Out[855]: 
    data1                          ...  data2                      
    count mean      std  min   25% ...    min   25%  50%   75%  max
key                                ...                             
A     2.0  1.5  2.12132  0.0  0.75 ...    0.0  0.50  1.0  1.50  2.0
B     2.0  2.5  2.12132  1.0  1.75 ...    3.0  3.75  4.5  5.25  6.0
C     2.0  3.5  2.12132  2.0  2.75 ...    0.0  0.00  0.0  0.00  0.0




/ 13	. 

In [834]: df.groupby('key')
Out[834]: <pandas.core.groupby.groupby.DataFrameGroupBy object at 0x7ff406b76a58>


In [832]: df.groupby('key')['data1']
Out[832]: <pandas.core.groupby.groupby.SeriesGroupBy object at 0x7ff406b3e6d8>

In [837]: df['data1'].groupby('key')
/ ERR	,


/ Einde Intermezzo

/ (167)

In [871]: df
Out[871]: 
  key  data1  data2
0   A      0      2
1   B      1      3
2   C      2      0
3   A      3      0
4   B      4      6
5   C      5      0

In [870]: df.groupby('key').transform(lambda x:x)
Out[870]: 
   data1  data2
0      0      2
1      1      3
2      2      0
3      3      0
4      4      6
5      5      0

In [876]: def fct2(df):
     ...:     print(df)
     ...:     return True
     ...: 
     ...: 

In [877]: df.groupby('key').filter(fct2)
  key  data1  data2
0   A      0      2
3   A      3      0
  key  data1  data2
1   B      1      3
4   B      4      6
  key  data1  data2
2   C      2      0
5   C      5      0
Out[877]: 
  key  data1  data2
0   A      0      2
1   B      1      3
2   C      2      0
3   A      3      0
4   B      4      6
5   C      5      0



In [872]: df.groupby('key').transform(lambda x:x-x.mean())
Out[872]: 
   data1  data2
0   -1.5    1.0
1   -1.5   -1.5
2   -1.5    0.0
3    1.5   -1.0
4    1.5    1.5
5    1.5    0.0
/ dus in group A is mean data1=1.5	, in B mean data1=2.5, in C mean data1=3.5	, 
/ en daarom zien we bij data1 bij 0: 0-1.5=-1.5 en bij 3: 3-1.5=1.5	, ...

/ 13	. 

/ met .apply kun je self made fcts op de groups loslaten	, ze moeten een df nemen, en een Pandas object of een scalar return	,

/ 1313	. 

In [878]: def fct(df):
     ...:     return True
     ...: 
     ...: 

In [879]: df.groupby('key').apply(fct)
Out[879]: 
key
A    True
B    True
C    True
dtype: bool

/ 1313	. 

In [882]: def fct(df):
     ...:     return df
     ...: 
     ...: 
     ...: 
     ...: 

In [883]: df.groupby('key').apply(fct)
Out[883]: 
  key  data1  data2
0   A      0      2
1   B      1      3
2   C      2      0
3   A      3      0
4   B      4      6
5   C      5      0


/ 1313	. 

In [880]: def fct(df):
     ...:     df['data1']+=df['data2'].sum()
     ...:     return df
     ...: 
     ...: 

In [881]: df.groupby('key').apply(fct)
Out[881]: 
  key  data1  data2
0   A      2      2
1   B     10      3
2   C      2      0
3   A      5      0
4   B     13      6
5   C      5      0

/ dus de group B heeft data2.sum()=3+6=9	, en die tel je op bij elke B	,

/ 1313	. 

In [900]: df.groupby('key').filter(lambda df:True)
Out[900]: 
  key  data1  data2
0   A      0      2
1   B      1      3
2   C      2      0
3   A      3      0
4   B      4      6
5   C      5      0

/ in een lambda schrijf je geen return	,

/ 1313	. 

/ DataFrame.apply is een andere als DataFrameGroupBy.apply	,

In [961]: df2.apply?
...
Parameters
----------
func : function
    Function to apply to each column or row.
axis : {0 or 'index', 1 or 'columns'}, default 0
    Axis along which the function is applied:

    * 0 or 'index': apply function to each column.
    * 1 or 'columns': apply function to each row.

In [953]: df2=pd.DataFrame({'data1':range(0,6),'data2':rng.randint(0,10,6)})
/ range(0,6) of np.arange(0,6)

In [954]: df2
Out[954]: 
   data1  data2
0      0      0
1      1      8
2      2      5
3      3      9
4      4      0
5      5      9

In [962]: fct??
...
def fct(df):
    df['data1']+=df['data2']
    return df


In [955]: df2.apply(fct,axis=1)
Out[955]: 
   data1  data2
0      0      0
1      9      8
2      7      5
3     12      9
4      4      0
5     14      9
In [960]:  df2
Out[960]: 
   data1  data2
0      0      0
1      9      8
2      7      5
3     12      9
4      4      0
5     14      9

/ 1313	 

/ DataFrame.apply	,

/ Deze verandert het DataFrame,	daarom maken we een copy	,

In [995]: df2
Out[995]: 
   data1  data2
0      0      0
1      9      8
2      7      5
3     12      9
4      4      0
5     14      9

In [991]: df2_=df2.copy();df2_.apply(lambda x:x.sum())
/=
In [989]: df2_=df2.copy();df2_.apply(lambda x:x.sum(),axis=0)
Out[991]: 
data1    46
data2    31
dtype: int64
In [989]: df2_=df2.copy();df2_.apply(lambda x:x.sum(),axis=1)
Out[989]: 
0     0
1    17
2    12
3    21
4     4
5    23
dtype: int64

In [992]: df2_=df2.copy();df2_.apply(lambda x:x/x.sum())
Out[992]: 
      data1     data2
0  0.000000  0.000000
1  0.195652  0.258065
2  0.152174  0.161290
3  0.260870  0.290323
4  0.086957  0.000000
5  0.304348  0.290323
In [993]: df2_=df2.copy();df2_.apply(lambda x:x/x.sum(),axis=1)
Out[993]: 
      data1     data2
0       NaN       NaN
1  0.529412  0.470588
2  0.583333  0.416667
3  0.571429  0.428571
4  1.000000  0.000000
5  0.608696  0.391304

/ 1313	. 

/ DataFrameGroupBy.apply	,

/ deze laat het DataFrame onveranderd	,

/ deze apply werkt alleen in de richting van rijen, ahw. axis=0	, 

In [996]:  df
Out[996]: 
  key  data1  data2
0   A      0      2
1   B      1      3
2   C      2      0
3   A      3      0
4   B      4      6
5   C      5      0

In [998]: g=df.groupby('key')
In [1000]: g.apply?

Examples
--------

>>> df = pd.DataFrame({'A': 'a a b'.split(), 'B': [1,2,3], 'C': [4,6, 5]})
>>> g = df.groupby('A')

From ``df`` above we can see that ``g`` has two groups, ``a``, ``b``.
Calling ``apply`` in various ways, we can get different grouping results:

Example 1: below the function passed to ``apply`` takes a dataframe as
its argument and returns a dataframe. ``apply`` combines the result for
each group together into a new dataframe:

>>> g.apply(lambda x: x / x.sum()) 	# lambda return een df	,
          B    C
0  0.333333  0.4
1  0.666667  0.6
2  1.000000  1.0

Example 2: The function passed to ``apply`` takes a dataframe as
its argument and returns a series.  ``apply`` combines the result for
each group together into a new dataframe:

>>> g.apply(lambda x: x.max() - x.min())	# lambda returns een series	,
   B  C
A
a  1  2
b  0  0

Example 3: The function passed to ``apply`` takes a dataframe as
its argument and returns a scalar. ``apply`` combines the result for
each group together into a series, including setting the index as
appropriate:

>>> g.apply(lambda x: x.C.max() - x.B.min()) # lambda return een scalar	,
A
a    5
b    2
dtype: int64

/ 131313	 .

/ Example1

In [963]: df3=pd.DataFrame({'A':'a a b'.split(),'B':[1,2,3],'C':[4,6,5]})
In [1002]: g3=df3.groupby('A')

In [964]: df3
Out[964]: 
   A  B  C
0  a  1  4
1  a  2  6
2  b  3  5

In [1044]: df3.sum()
Out[1044]: 
A    aab
B      6
C     15
dtype: object

/ df3.sum() bestaat	, ook op deel df's	, die straks ontstaan bij groupby	,

/ 13131313

In [1003]:  g3.apply(lambda df:df.sum())
Out[1003]: 
    A  B   C
A           
a  aa  3  10
b   b  3   5

/ dus we zien df.sum applied op deel dfs	,

In [1008]:  g3.apply(lambda df:df+df.sum())
Out[1008]: 
     A  B   C
0  aaa  4  14
1  aaa  5  16
2   bb  6  10

//////////////////////////////////////////
/ omdat er niet df.sum() staat, maar df+df.sum() komt de hele df weer tevoorschijn	,

/ 13131313

In [1010]: type( g3.apply(lambda df:df/df.sum()))
Out[1010]: pandas.core.frame.DataFrame

In [1007]:  g3.apply(lambda df:df/df.sum())
Out[1007]: 
          B    C
0  0.333333  0.4
1  0.666667  0.6
2  1.000000  1.0

In [1011]: type( g3.apply(lambda df:df/df.sum()))
Out[1011]: pandas.core.frame.DataFrame

/ we zien dat vanwege df in df/df.sum() de hele df er weer staat	, 
/ we zien dat bij / column A is weggevallen	,  bij + was hij er nog	, bij * gebeurt dat ook	,

/ dat zien we ook als we debug	,

In [1029]: def fct(df):
      ...:     print('start')
      ...:     print(df)
      ...:     print('end')
      ...:     return df/df.sum()

In [1030]: g3.apply(fct)
start
   A  B  C
0  a  1  4
1  a  2  6
end
start
   A  B  C
0  a  1  4
1  a  2  6
end
start
   B  C
0  1  4
1  2  6
end
start
   B  C
0  1  4
1  2  6
end
start
   B  C
2  3  5
end
Out[1030]: 
          B    C
0  0.333333  0.4
1  0.666667  0.6
2  1.000000  1.0

/ er onstaan 2 dfs	, 
   B  C
0  1  4
1  2  6
/ en	,
   B  C
2  3  5

/ 13131313

/ we zien hierboven dat df/df.sum() overgeslagen wordt bij de string column	, 
/ vind een ufunc die juist wel voor strings goed gaat, en voor ints niet	,
/ TODO

/ lees	,
https://towardsdatascience.com/pandas-tips-and-tricks-33bcc8a40bb9

In [1118]: df4.key.str.isupper()
Out[1118]: 
0    False
1    False
2    False
Name: key, dtype: bool


/ 13131313	. 

In [1101]: df6
Out[1101]: 
   11  13
0   1   4
1   2   5
2   3   6

In [1102]: sum(df6)
Out[1102]: 24

/ TODO

/ Example2

In [1105]: df3
Out[1105]: 
   A  B  C
0  a  1  4
1  a  2  6
2  b  3  5

In [1108]: def fct(df):
      ...:     print(type(df))
      ...:     print(df)
      ...:     print(type(df.max()-df.min()))
      ...:     print(df.max()-df.min())
      ...:     return df.max()-df.min()

In [1109]: g3.apply(fct)
<class 'pandas.core.frame.DataFrame'>
   B  C
0  1  4
1  2  6
<class 'pandas.core.series.Series'>
B    1
C    2
dtype: int64
<class 'pandas.core.frame.DataFrame'>
   B  C
0  1  4
1  2  6
<class 'pandas.core.series.Series'>
B    1
C    2
dtype: int64
<class 'pandas.core.frame.DataFrame'>
   B  C
2  3  5
<class 'pandas.core.series.Series'>
B    0
C    0
dtype: int64
Out[1109]: 
   B  C
A      
a  1  2
b  0  0

/ dus inderdaad 2 Series , horizontaal , bij mekaar genomen tot een df	,

/ Example 3	.

/ 13	. 

/ (168)


In [1122]: df
Out[1122]: 
  key  data1  data2
0   A      0      2
1   B      1      3
2   C      2      0
3   A      3      0
4   B      4      6
5   C      5      0

/ 1313	. 

/ group by 

/ je labelt de rijen zelf	, je kijkt niet naar de key column	,

In [1123]: g=df.groupby([0,1,0,1,2,0])

In [1124]: g.sum()
Out[1124]: 
   data1  data2
0      7      2
1      4      3
2      4      6

In [1129]: g=df.groupby([3,3,3,3,4,4])

In [1130]: g.sum()
Out[1130]: 
   data1  data2
3      6      5
4      9      6

In [1131]: g=df.groupby(['a','a','b','a','a','b'])

In [1132]: g.sum()
Out[1132]: 
   data1  data2
a      8     11
b      7      0

/ Intermezzo

/ fancy indexing is iets anders	,

In [1137]: a=rng.randint(0,100,10)
In [1138]: a
Out[1138]: array([61, 83, 33, 32, 70, 85, 31, 13, 71, 56])

In [1140]: a[[1,2,1,2,1,2,1,3]]
Out[1140]: array([83, 33, 83, 33, 83, 33, 83, 32]


/ Einde Intermezzo

/ Intermezzo

In [1143]: df
Out[1143]: 
  key  data1  data2
0   A      0      2
1   B      1      3
2   C      2      0
3   A      3      0
4   B      4      6
5   C      5      0

/ 1313	. 

/ group vlg de key column	,

In [1125]: g=df.groupby('key')

In [1126]: g.sum()
Out[1126]: 
     data1  data2
key              
A        3      2
B        5      9
C        7      0

In [1144]: df.groupby('key')['data1']
Out[1144]: <pandas.core.groupby.groupby.SeriesGroupBy object at 0x7ff406a26470>

In [1145]: df.groupby('key')['data1'].sum()
Out[1145]: 
key
A    3
B    5
C    7
Name: data1, dtype: int64

In [1147]: df.groupby('key')['data1'].describe()
Out[1147]: 
     count  mean      std  min   25%  50%   75%  max
key                                                 
A      2.0   1.5  2.12132  0.0  0.75  1.5  2.25  3.0
B      2.0   2.5  2.12132  1.0  1.75  2.5  3.25  4.0
C      2.0   3.5  2.12132  2.0  2.75  3.5  4.25  5.0

/ 13	. 

/ 169	.

/ see ook (159)

/ lees	,
https://github.com/mwaskom/seaborn-data
/ ->
http://seaborn.pydata.org/

/ dus planets, titanic zijn seaborn samples	,

In [1149]: import seaborn as sns
In [1150]: titanic=sns.load_dataset('titanic')
In [1154]: planets=sns.load_dataset('planets')

/ lees	,
https://stackoverflow.com/questions/30336324/seaborn-load-dataset
https://github.com/mwaskom/seaborn-data

In [1154]: type(planets)
Out[1154]: pandas.core.frame.DataFrame

In [1161]: decade=(planets['year']//10)*10

In [1162]: decade
Out[1162]: 
0       2000
1       2000
2       2010
...
/ tientallen	,

In [1165]: decade_=decade.astype(str)+'s'
In [1165]: decade_
Out[1164]: 
0       2000s
1       2000s
2       2010s
...
In [1166]: type(decade_)
Out[1166]: pandas.core.series.Series

In [1167]: decade_.name
Out[1167]: 'year'

In [1168]: decade_.name='decade'


/ we oef wat	,



In [1169]: g=planets.groupby(decade_)
In [1180]: type(g)
Out[1180]: pandas.core.groupby.groupby.DataFrameGroupBy
In [1169]: g[ 'number']
Out[1169]: <pandas.core.groupby.groupby.SeriesGroupBy object at 0x7ff405e16f60>

In [1170]: g[ 'number'].sum()
Out[1170]: 
decade
1980s       1
1990s      61
2000s     587
2010s    1199
Name: number, dtype: int64

In [1181]:  g=planets.groupby(['method',decade_])

In [1182]: type(g)
Out[1182]: pandas.core.groupby.groupby.DataFrameGroupBy

In [1184]: type(g['number'])
Out[1184]: pandas.core.groupby.groupby.SeriesGroupBy

In [1187]: type(g['number'].sum())
Out[1187]: pandas.core.series.Series
In [1183]: ser=g['number'].sum()
In [1183]: ser
Out[1183]: 
method                         decade
Astrometry                     2010s       2
Eclipse Timing Variations      2000s       5
                               2010s      10
Imaging                        2000s      29
                               2010s      21
Microlensing                   2000s      12
                               2010s      15
Orbital Brightness Modulation  2010s       5
Pulsar Timing                  1990s       9
                               2000s       1
                               2010s       1
Pulsation Timing Variations    2000s       1
Radial Velocity                1980s       1
                               1990s      52
                               2000s     475
                               2010s     424
Transit                        2000s      64
                               2010s     712
Transit Timing Variations      2010s       9
Name: number, dtype: int64

In [1188]: type(ser.unstack())
Out[1188]: pandas.core.frame.DataFrame
In [1189]: df7=ser.unstack()
/=
In [1189]: df7=ser.unstack(level=-1)		/ altijd	,
/=
In [1189]: df7=ser.unstack(level=1)			/ in dit geval	,
In [1189]: df7
Out[1189]: 
decade                         1980s  1990s  2000s  2010s
method                                                   
Astrometry                       NaN    NaN    NaN    2.0
Eclipse Timing Variations        NaN    NaN    5.0   10.0
Imaging                          NaN    NaN   29.0   21.0
Microlensing                     NaN    NaN   12.0   15.0
Orbital Brightness Modulation    NaN    NaN    NaN    5.0
Pulsar Timing                    NaN    9.0    1.0    1.0
Pulsation Timing Variations      NaN    NaN    1.0    NaN
Radial Velocity                  1.0   52.0  475.0  424.0
Transit                          NaN    NaN   64.0  712.0
Transit Timing Variations        NaN    NaN    NaN    9.0

/ Intermezzo

In [1198]: ser.unstack?

level : int, string, or list of these, default last level
    Level(s) to unstack, can pass level name
fill_value : replace NaN with this value if the unstack produces
    missing values

/ dat zien we hierboven ook, de laatste level	, level=-1, decade,  wordt unstacked van index af	,
/ we kunnen ook de 1ste, level=0 unstack	,

In [1199]: ser.unstack(level=0)
Out[1199]: 
method  Astrometry            ...              Transit Timing Variations
decade                        ...                                       
1980s          NaN            ...                                    NaN
1990s          NaN            ...                                    NaN
2000s          NaN            ...                                    NaN
2010s          2.0            ...                                    9.0
 
/ 13	. 

/ pivot tables

/ (170)

In [1204]: titanic.groupby('sex')
Out[1204]: <pandas.core.groupby.groupby.DataFrameGroupBy object at 0x7ff405e2afd0>

In [1205]: titanic.groupby('sex')['survived']
Out[1205]: <pandas.core.groupby.groupby.SeriesGroupBy object at 0x7ff405e079b0>
In [1212]: titanic.groupby('sex')[['survived']]
Out[1212]: <pandas.core.groupby.groupby.DataFrameGroupBy object at 0x7ff405e16cc0>


/ let op verschil: ['survived'] en [['survived']]	,

In [1210]: type(titanic.groupby('sex')['survived'].mean())
Out[1210]: pandas.core.series.Series
In [1206]: ser8=titanic.groupby('sex')['survived'].mean()
In [1206]: ser8
Out[1206]: 
sex
female    0.742038
male      0.188908
Name: survived, dtype: float64

In [1209]: type(titanic.groupby('sex')[['survived']].mean())
Out[1209]: pandas.core.frame.DataFrame
In [1208]: df8=titanic.groupby('sex')[['survived']].mean()
In [1208]: df8
Out[1208]: 
        survived
sex             
female  0.742038
male    0.188908

/ Intermezzo

/ stack= stack in de index	,

/ stack: df-> ser
/ de columns komen in de index, achteraan	, 
/ met stack(level=...) kun je geven welk level in de columns je wilt stack	,

In [1243]: ser8=titanic.groupby('sex')['survived'].mean()
In [1244]: ser8
Out[1244]: 
sex
female    0.742038
male      0.188908
Name: survived, dtype: float64

In [1208]: df8=titanic.groupby('sex')[['survived']].mean()
In [1241]: ser8_=df8.stack()
/ of	,
In [1241]: ser8_=df8.stack(level=0)	 / level = level in de columns die je wilt 
																		/ stack	, en dat is er in dit geval maar 1	,
In [1242]: ser8_
Out[1242]: 
sex             
female  survived    0.742038
male    survived    0.188908
dtype: float64

In [1245]: ser8.index.nlevels
Out[1245]: 1
In [1246]: ser8_.index.nlevels
Out[1246]: 2



/ 13	. 

/ unstack(level=...) geeft aan welk level in de columns je wilt unstack naar de columns	, WH komt in laatste level in de columns	,

In [1232]: ser8_.unstack(level=-1)
/ of	,
In [1232]: ser8_.unstack()
Out[1232]: 
        survived
sex             
female  0.742038
male    0.188908

n [1237]: ser8_.unstack(level=0)
Out[1237]: 
sex         female      male
survived  0.742038  0.188908

/ 13	. 

ser8_=titanic.groupby('sex')[['survived']].mean().stack() 
/ is een andere series als 
ser8=titanic.groupby('sex')['survived'].mean()

In [1258]: ser8
Out[1258]: 
sex
female    0.742038
male      0.188908
Name: survived, dtype: float64

In [1257]: ser8_
Out[1257]: 
sex             
female  survived    0.742038
male    survived    0.188908
dtype: float64

In [1253]: ser8.index.nlevels
Out[1253]: 1

In [1254]: ser8_.index.nlevels
Out[1254]: 2

In [1259]: ser8.name
Out[1259]: 'survived'

In [1260]: ser8_.name

In [1261]: ser8.index
Out[1261]: Index(['female', 'male'], dtype='object', name='sex')

In [1264]: ser8_.index
Out[1264]: 
MultiIndex(levels=[['female', 'male'], ['survived']],
           labels=[[0, 1], [0, 0]],
           names=['sex', None])


/ 13	. 

/ hoe kunnen we zelf zulke series maken	?

/ zoals ser8	,

/ met index naam	,
In [1275]:  pd.Series([.1,.2],name='foo',index=pd.Index(['bar','baz'],name='gee'))
Out[1275]: 
gee
bar    0.1
baz    0.2
Name: foo, dtype: float64

/ zonder index naam	,
In [1269]: pd.Series([1,2],name='foo',index=['bar','baz']) 
Out[1269]: 
bar    1
baz    2
Name: foo, dtype: int64

/ zoals ser8_	,

In [1279]: pd.Series([.1,.2],index=pd.MultiIndex(levels=[['bar','baz'],['goo']],labels=[[0,1],[0,0]],names=['gee','hee']))
Out[1279]: 
gee  hee
bar  goo    0.1
baz  goo    0.2
dtype: float64

In [1280]: pd.Series([.1,.2],index=pd.MultiIndex(levels=[['bar','baz'],['goo','hoo']],labels=[[0,1],[0,1]],names=['gee','hee']))
Out[1280]: 
gee  hee
bar  goo    0.1
baz  hoo    0.2
dtype: float64

In [1281]: pd.Series([.1,.2],index=pd.MultiIndex(levels=[['bar','baz'],['goo','hoo']],labels=[[0,1],[0,1]],names=['gee','hee']),name='foo')
Out[1280]: 
gee  hee
bar  goo    0.1
baz  hoo    0.2
Name: foo, dtype: float64

/ Einde Intermezzo

/ 1313	. 

/ we gaan verder op (171)	,

/ Intermezzo

/ 13	. 

/ aantal rijen	,

In [1300]: len(titanic.index)
Out[1300]: 891

/ je moet een column pakken zonder na values	,
In [1298]:  titanic['survived'].count()
Out[1298]: 891

In [1299]: titanic.count()
Out[1299]: 
survived       891
pclass         891
sex            891
age            714
sibsp          891
parch          891
fare           891
embarked       889
class          891
who            891
adult_male     891
deck           203
embark_town    889
alive          891
alone          891
dtype: int64
/ columns hebben null values	,






/ Einde Intermezzo

/ Intermezzo 

In [1302]: df9=pd.DataFrame({'a':float('NaN')},index=['foo'])
/ je moet in index geven	,

In [1304]: len(df9)
Out[1304]: 1

In [1305]: df9['a'].count()
Out[1305]: 0

In [1306]: df9.count()
Out[1306]: 
a    0
dtype: int64

/ Einde Intermezzo 

/ Misc

/ 1313	. 

In [1315]: type(titanic.sum())
Out[1315]: pandas.core.series.Series
In [1314]: titanic.sum()
Out[1314]: 
survived                                                    342
pclass                                                     2057
sex           malefemalefemalefemalemalemalemalemalefemalefe...
age                                                     21205.2
sibsp                                                       466
parch                                                       340
fare                                                    28693.9
class         ThirdFirstThirdFirstThirdThirdFirstThirdThirdS...
who           manwomanwomanwomanmanmanmanchildwomanchildchil...
adult_male                                                  537
alive         noyesyesyesnonononoyesyesyesyesnononoyesnoyesn...
alone                                                       537
dtype: object

/ 1313	. 

In [1308]: type(titanic['survived'])
Out[1308]: pandas.core.series.Series
In [1307]: titanic['survived']
Out[1307]: 
0      0
1      1
2      1
...
In [1309]:  titanic['survived'].sum()
Out[1309]: 342
/ aantal overleefd	,

In [1310]:  titanic['survived'].sum()/titanic['survived'].count()
Out[1310]: 0.3838383838383838
/ ongeveer 1/3	,

/ 1313	. 

/ .groupby gaat verloren door .apply	,
In [1326]: titanic.groupby('survived').apply(lambda x:x)
In [1342]: dfb=titanic.apply(lambda x:x)
In [1343]: dfa.equals(dfb)
Out[1343]: True
/ TODO

/ 1313	.

In [1334]: titanic.groupby('survived').count()
Out[1334]: 
          pclass  sex  age  sibsp  ...    deck  embark_town  alive  alone
survived                           ...                                   
0            549  549  424    549  ...      67          549    549    549
1            342  342  290    342  ...     136          340    342    342

In [1347]: titanic.groupby('survived')['sex'].count()
Out[1347]: 
survived
0    549
1    342
Name: sex, dtype: int64


In [1344]: titanic.groupby('sex').count()
Out[1344]: 
        survived  pclass  age  sibsp  ...    deck  embark_town  alive  alone
sex                                   ...                                   
female       314     314  261    314  ...      97          312    314    314
male         577     577  453    577  ...     106          577    577    577

In [1346]: titanic.groupby('sex')['survived'].count()
Out[1346]: 
sex
female    314
male      577
Name: survived, dtype: int64

/ 1313	. 

In [1391]: titanic.groupby('sex').descibe()
/ ERR	,

In [1360]: titanic.groupby('survived')['sex'].describe()
Out[1360]: 
         count unique     top freq
survived                          
0          549      2    male  468
1          342      2  female  233

In [1361]: titanic.groupby('sex')['survived'].describe()
Out[1361]: 
        count      mean       std  min  25%  50%  75%  max
sex                                                       
female  314.0  0.742038  0.438211  0.0  0.0  1.0  1.0  1.0
male    577.0  0.188908  0.391775  0.0  0.0  0.0  0.0  1.0

/ 1313	. 

In [1373]: titanic.columns
Out[1373]: 
Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',
       'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town',
       'alive', 'alone'],
      dtype='object')

In [1389]: titanic.describe?
Describing a ``DataFrame``. By default only numeric fields
are returned.

>>> df = pd.DataFrame({ 'object': ['a', 'b', 'c'],
...                     'numeric': [1, 2, 3],
...                     'categorical': pd.Categorical(['d','e','f'])
...                   })
/ TODO

/ Dus df.describe() geeft alleen numeric columns	,
/ tenzij je include='all' meegeeft,	 


n [1368]:  titanic.describe()
Out[1368]: 
         survived      pclass     ...           parch        fare
count  891.000000  891.000000     ...      891.000000  891.000000
mean     0.383838    2.308642     ...        0.381594   32.204208
std      0.486592    0.836071     ...        0.806057   49.693429
min      0.000000    1.000000     ...        0.000000    0.000000
25%      0.000000    2.000000     ...        0.000000    7.910400
50%      0.000000    3.000000     ...        0.000000   14.454200
75%      1.000000    3.000000     ...        0.000000   31.000000
max      1.000000    3.000000     ...        6.000000  512.329200

In [1372]:  titanic.describe().columns
Out[1372]: Index(['survived', 'pclass', 'age', 'sibsp', 'parch', 'fare'], dtype='object')
/ dit zijn dus de numeric columns	,

In [1423]: titanic.describe(include='all')
Out[1423]: 
          survived      pclass   sex  ...    embark_town  alive  alone
count   891.000000  891.000000   891  ...            889    891    891
unique         NaN         NaN     2  ...              3      2      2
top            NaN         NaN  male  ...    Southampton     no   True
freq           NaN         NaN   577  ...            644    549    537
mean      0.383838    2.308642   NaN  ...            NaN    NaN    NaN
std       0.486592    0.836071   NaN  ...            NaN    NaN    NaN
min       0.000000    1.000000   NaN  ...            NaN    NaN    NaN
25%       0.000000    2.000000   NaN  ...            NaN    NaN    NaN
50%       0.000000    3.000000   NaN  ...            NaN    NaN    NaN
75%       1.000000    3.000000   NaN  ...            NaN    NaN    NaN
max       1.000000    3.000000   NaN  ...            NaN    NaN    NaN


/ per column	,
In [1369]:  titanic.describe()['age']
Out[1369]: 
count    714.000000
mean      29.699118
std       14.526497
min        0.420000
25%       20.125000
50%       28.000000
75%       38.000000
max       80.000000
Name: age, dtype: float64

/ 1313	. 

/ welke entries hebben field age NaN	?

In [1406]: sera=titanic['age']
In [1407]: sera
Out[1407]: 
0      22.0
1      38.0
2      26.0
3      35.0
4      35.0
5       NaN
6      54.0
...

In [1411]: sera[sera.apply(math.isnan)==True]
/ of	,
In [1411]: sera[sera.apply(math.isnan)]
/ of	,
In [1415]: sera[sera.isna()]									/ <-
Out[1411]: 
5     NaN
17    NaN
19    NaN
26    NaN
...
888   NaN
Name: age, Length: 177, dtype: float64


In [1588]: sera[sera.apply(math.isnan)==False]
/ of	,
In [1595]: sera[~sera.apply(math.isnan)]
/ of	,
In [1596]:  sera[~sera.isna()]
Out[1588]: 
0      22.0
1      38.0
2      26.0
3      35.0
...
890    32.0
Name: age, Length: 714, dtype: float64

/ 131313	. 

/ Toepassing

In [1646]: titanic['fare'].isna()                  
Out[1646]: 
0      False
1      False
2      False
...
890    False
Name: fare, Length: 891, dtype: bool

In [1647]: titanic['fare'][titanic['fare'].isna()]             
Out[1647]: Series([], Name: fare, dtype: float64)

In [1647]: titanic['fare'][~titanic['fare'].isna()]            
...
890      7.7500
Name: fare, Length: 891, dtype: float64

/ Einde 131313	.

 

In [1415]: sera[sera.isna()].count()
Out[1415]: 0
/ Dat is zo bij NaN	, die tellen niet mee	,

In [1416]: sera[sera.isna()].describe()
Out[1416]: 
count    0.0
mean     NaN
std      NaN
min      NaN
25%      NaN
50%      NaN
75%      NaN
max      NaN
Name: age, dtype: float64

In [1417]: len(sera[sera.isna()])
Out[1417]: 177

/ 1313	. 

In [1424]: len(titanic)
Out[1424]: 891

In [1425]: ser_s=titanic['survived']
In [1426]: ser_s[ser_s.isna()]
Out[1426]: Series([], Name: survived, dtype: int64)
/ leeg , dus geen NaN	,

In [1427]: ser_e=titanic['sex']
In [1428]: ser_e[ser_e.isna()]
Out[1428]: Series([], Name: sex, dtype: object)
/ leeg , dus geen NaN	,

In [1429]: len(ser_s)
Out[1429]: 891
In [1430]: len(ser_e)
Out[1430]: 891

In [1432]: ser_e.count()
Out[1432]: 891
In [1433]: ser_s.count()
Out[1433]: 891
/ omdat geen NaNs	,

In [1439]: ser_e.describe()
Out[1439]: 
count      891
unique       2
top       male
freq       577
Name: sex, dtype: object

In [1440]: ser_s.describe()
Out[1440]: 
count    891.000000
mean       0.383838
std        0.486592
min        0.000000
25%        0.000000
50%        0.000000
75%        1.000000
max        1.000000
Name: survived, dtype: float64


In [1437]: ser_e[ser_e=='male'].count()
Out[1437]: 577

In [1438]: len(ser_e[ser_e=='male'])
Out[1438]: 577
In [1444]: len(ser_e[ser_e=='female'])
Out[1444]: 314

In [1442]: ser_s[ser_s==0].count()
Out[1442]: 549
In [1443]: ser_s[ser_s==1].count()
Out[1443]: 342

In [1445]: titanic.groupby('sex').describe(include='all')
Out[1445]: 
       adult_male                         ...   who                    
            count unique    top freq mean ...   min  25%  50%  75%  max
sex                                       ...                          
female        314      1  False  314  NaN ...   NaN  NaN  NaN  NaN  NaN
male          577      2   True  537  NaN ...   NaN  NaN  NaN  NaN  NaN

[2 rows x 154 columns]
/ TODO is dit nuttig?

In [1454]: titanic.groupby('sex')['survived'].describe()
Out[1454]: 
        count      mean       std  min  25%  50%  75%  max
sex                                                       
female  314.0  0.742038  0.438211  0.0  0.0  1.0  1.0  1.0
male    577.0  0.188908  0.391775  0.0  0.0  0.0  0.0  1.0
/ of	,
In [1455]: titanic.groupby('sex')['survived'].count()
Out[1455]: 
sex
female    314
male      577
Name: survived, dtype: int64
/ 'survived' op zich speelt geen rol, omdat we count() doen, het enigste wat we willen is een veld die geen NaNs heeft,	

In [1456]: titanic.groupby('survived')['sex'].count()
Out[1456]: 
survived
0    549
1    342
Name: sex, dtype: int64
/ 'sex' op zich speelt geen rol, omdat we count() doen, het enigste wat we willen is een veld die geen NaNs heeft,	

In [1459]: titanic.groupby(['survived','sex']).columns
/ ERR, .columns kan niet op een group	,

/ 1313	. 

In [1463]: titanic.groupby(['survived','sex'])['age'].count()
Out[1463]: 
survived  sex   
0         female     64
          male      360
1         female    197
          male       93
Name: age, dtype: int64
/ we hebben hierboven gezien dat er 177 NaNs bij age	, en dat klopt precies: 64+360+197+93+177=891	,

In [1466]: titanic.groupby(['survived','sex'])['pclass'].count()
/ of	,
In [1466]: titanic.groupby(['survived','sex'])['class'].count()
Out[1466]: 
survived  sex   
0         female     81
          male      468
1         female    233
          male      109
Name: pclass, dtype: int64
/ Deze is OK	,
In [1467]: titanic['pclass'].count()
/ of	,
In [1469]:  titanic['class'].count()
Out[1467]: 891
/ Geen NaNs	,
/ dit is dus een goede onderverdeling van titanic in survived en sex	,

In [1472]: titanic.groupby(['survived','sex'])['class'].aggregate('mean')
/ ERR, class is geen numeric type	, 

/ 1313	. 

In [1860]:  titanic.groupby(['survived','sex']).describe()
In [1862]:  titanic.groupby(['survived','sex']).mean()
...
/ zijn allemaal of dfs	, net als in SQL	,

/ 1313	. 


In [1460]: titanic.groupby(['survived','sex']).describe().columns
Out[1460]: 
MultiIndex(levels=[['age', 'fare', 'parch', 'pclass', 'sibsp'], ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']],
           labels=[[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4], [0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7]])
In [1474]: titanic.groupby(['survived','sex']).describe(include='all').columns
Out[1474]: 
MultiIndex(levels=[['adult_male', 'age', 'alive', 'alone', 'class', 'deck', 'embark_town', 'embarked', 'fare', 'parch', 'pclass', 'sibsp', 'who'], ['count', 'unique', 'top', 'freq', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']],
           labels=[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]])
/ TODO

In [1479]: titanic.groupby(['survived','sex'])['class'].apply(lambda x:x)
/=
In [1480]:   titanic['class'].apply(lambda x:x)
ut[1479]: 
0       Third
1       First
2       Third
3       First
...
/ 

In [1478]: titanic.groupby(['survived','sex'])['class'].count()
Out[1478]: 
survived  sex   
0         female     81
          male      468
1         female    233
          male      109
Name: class, dtype: int64

In [1486]: ser_t=titanic['class'].apply(lambda x:x)
In [1487]: ser_t2=titanic.groupby(['survived','sex'])['class'].apply(lambda x:x)

In [1488]: ser_t
Out[1488]: 
0       Third
1       First
2       Third
...
Name: class, Length: 891, dtype: category
Categories (3, object): [First, Second, Third]

In [1488]: ser_t2
Out[1488]: 
0       Third
1       First
2       Third
...
Name: class, Length: 891, dtype: category
Categories (3, object): [First, Second, Third]

In [1492]: ser_t.equals(ser_t2)
Out[1492]: False
/ TODO
In [1493]: ser_t==ser_t2
Out[1493]: 
0      True
1      True
2      True
Name: class, Length: 891, dtype: bool

In [1494]: type(ser_t==ser_t2)
Out[1494]: pandas.core.series.Series

In [1499]: ser_T=ser_t==ser_t2

In [1498]: ser_T[ser_T==False]
Out[1498]: Series([], Name: class, dtype: bool)
/ of	,
In [1499]: len(ser_T[ser_T])
Out[1499]: 891

/ 1313	. 

In [1501]: titanic.groupby(['survived','sex']).sum()
Out[1501]: 
                 pclass       age  sibsp  ...          fare  adult_male  alone
survived sex                              ...                                 
0        female     231   1603.00     98  ...     1864.9752         0.0   27.0
         male      1159  11382.50    206  ...    10277.7447       449.0  347.0
1        female     447   5683.00    120  ...    12101.6876         0.0   99.0
         male       220   2536.67     42  ...     4449.5418        88.0   64.0

[4 rows x 7 columns]
/ we zien 7 columns	,
In [1505]: titanic.groupby(['survived','sex']).sum().columns
Out[1505]: Index(['pclass', 'age', 'sibsp', 'parch', 'fare', 'adult_male', 'alone'], dtype='object')
In [1506]: titanic.groupby(['survived','sex']).mean().columns
Out[1506]: Index(['pclass', 'age', 'sibsp', 'parch', 'fare', 'adult_male', 'alone'], dtype='object')
/ dezelfde columns	,

In [1507]: titanic.groupby(['survived','sex']).describe().columns
Out[1507]: 
MultiIndex(levels=[['age', 'fare', 'parch', 'pclass', 'sibsp'], ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']],
           labels=[[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4], [0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7]])


/ .describe() heeft ook colums (in de index): adult_male, alone	, dit zijn beide van type bool	,
/ object, category zien we niet in .describe() en .sum()	,

In [1512]: titanic.dtypes
Out[1512]: 
survived          int64
pclass            int64
sex              object
age             float64
sibsp             int64
parch             int64
fare            float64
embarked         object
class          category
who              object
adult_male         bool
deck           category
embark_town      object
alive            object
alone              bool

/ google
pandas dataframe type of columns
/ lees	,
https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.dtypes.html->
https://pandas.pydata.org/pandas-docs/stable/basics.html#basics-dtypes

The main types stored in pandas objects are float, int, bool, datetime64[ns] and datetime64[ns, tz], timedelta[ns], category and object. In addition these dtypes have item sizes, e.g. int64 and int32. See link: Series with TZ,  for more detail on datetime64[ns, tz] dtypes.

In [1513]:  titanic['deck']
Out[1513]: 
0      NaN
1        C
2      NaN
3        C
5      NaN
6        E
9      NaN
10       G
11       C
...
Name: deck, Length: 891, dtype: category
Categories (7, object): [A, B, C, D, E, F, G]

/ 1313	. 

In [2052]: g=titanic.groupby(['sex', 'class'])
In [2056]: d=g.describe()

In [2059]: d
Out[2059]: 
                 age                             ...  survived               
               count       mean        std   min ...       25%  50%  75%  max
sex    class                                     ...                         
female First    85.0  34.611765  13.612052  2.00 ...       1.0  1.0  1.0  1.0
       Second   74.0  28.722973  12.872702  2.00 ...       1.0  1.0  1.0  1.0
       Third   102.0  21.750000  12.729964  0.75 ...       0.0  0.5  1.0  1.0
male   First   101.0  41.281386  15.139570  0.92 ...       0.0  0.0  1.0  1.0
       Second   99.0  30.740707  14.793894  0.67 ...       0.0  0.0  0.0  1.0
       Third   253.0  26.507589  12.159514  0.42 ...       0.0  0.0  0.0  1.0

[6 rows x 48 columns]

In [2060]: d.columns
Out[2060]: 
MultiIndex(levels=[['age', 'fare', 'parch', 'pclass', 'sibsp', 'survived'], ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']],
           labels=[[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5], [0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7]])

In [2061]: d.index
Out[2061]: 
MultiIndex(levels=[['female', 'male'], ['First', 'Second', 'Third']],
           labels=[[0, 0, 0, 1, 1, 1], [0, 1, 2, 0, 1, 2]],
           names=['sex', 'class'])

/ we zien inderdaad geen namen bij de columns	,

In [2066]: descsur=d['survived']
In [2069]: descsur
Out[2069]: 
               count      mean       std  min  25%  50%  75%  max
sex    class                                                     
female First    94.0  0.968085  0.176716  0.0  1.0  1.0  1.0  1.0
       Second   76.0  0.921053  0.271448  0.0  1.0  1.0  1.0  1.0
       Third   144.0  0.500000  0.501745  0.0  0.0  0.5  1.0  1.0
male   First   122.0  0.368852  0.484484  0.0  0.0  0.0  1.0  1.0
       Second  108.0  0.157407  0.365882  0.0  0.0  0.0  0.0  1.0
       Third   347.0  0.135447  0.342694  0.0  0.0  0.0  0.0  1.0

/ heeft dezelfde index als d	,
In [2067]: descsur.index
Out[2067]: 
MultiIndex(levels=[['female', 'male'], ['First', 'Second', 'Third']],
           labels=[[0, 0, 0, 1, 1, 1], [0, 1, 2, 0, 1, 2]],
           names=['sex', 'class'])

In [2068]: descsur.columns
Out[2068]: Index(['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'], dtype='object')

/ je kunt van sur de sum of mean berekenen, 

In [2071]: descsur.aggregate('sum')
Out[2071]: 
count    891.000000
mean       3.050844
std        2.142970
min        0.000000
25%        2.000000
50%        2.500000
75%        4.000000
max        6.000000
dtype: float64

In [2070]: descsur.aggregate('mean')
Out[2070]: 
count    148.500000
mean       0.508474
std        0.357162
min        0.000000
25%        0.333333
50%        0.416667
75%        0.666667
max        1.000000
dtype: float64

/ klopt	, als je sur['count'] optelt of middelt, of sur['mean'], dan krijg je de antwoorden 	, 
/ maar dat heeft WH geen betekenis, en dat doet het boek ook niet	, die laat het bij wat je in descsur ziet	,

/ g.describe()['survived'] = g['survived'].describe()

/ wij hebben g.describe()['survived'], het boek doet g['survived'].describe()	, al pakken zijn maar 1 kolom van .describe() nl mean	,
/ kijk bij ons in descsur naar de mean kolom	,

In [2102]: sur=g['survived']

In [2103]: m=sur.aggregate('mean')
In [2103]: m
Out[2103]: 
sex     class 
female  First     0.968085
        Second    0.921053
        Third     0.500000
male    First     0.368852
        Second    0.157407
        Third     0.135447
Name: survived, dtype: float64

/ .unstack pakt default de last level	,

In [2107]: m.unstack()
/=
In [2107]: m.unstack(level=-1)
Out[2107]: 
class      First    Second     Third
sex                                 
female  0.968085  0.921053  0.500000
male    0.368852  0.157407  0.135447

In [2122]: m.unstack().columns
Out[2122]: CategoricalIndex(['First', 'Second', 'Third'], categories=['First', 'Second', 'Third'], ordered=False, name='class', dtype='category')

/ dit komt omdat:

In [2120]: titanic.dtypes
Out[2120]: 
survived          int64
pclass            int64
sex              object
age             float64
sibsp             int64
parch             int64
fare            float64
embarked         object
class          category
who              object
adult_male         bool
deck           category
embark_town      object
alive            object
alone              bool
dtype: object

/ Waarom is sex een string, en class en category?
/ TODO
/ want hier staat het zelfs:

/ lees	,
https://pandas.pydata.org/pandas-docs/stable/categorical.html

Categoricals are a pandas data type corresponding to categorical variables in statistics. A categorical variable takes on a limited, and usually fixed, number of possible values (categories; levels in R). Examples are gender, social class, blood type, country affiliation, observation time or rating via Likert scales.



/ 13	. 

/ pivot tables	,

/ 1313	. 

In [2110]: surpv=titanic.pivot_table('survived',index='sex', columns='class')

In [2111]: type(surpv)
Out[2111]: pandas.core.frame.DataFrame

In [2112]: surpv
Out[2112]: 
class      First    Second     Third
sex                                 
female  0.968085  0.921053  0.500000
male    0.368852  0.157407  0.135447



/ 1313	. 

In [1522]:  titanic['age']
Out[1522]: 
0      22.0
1      38.0
2      26.0
3      35.0
4      35.0
5       NaN
6      54.0
7       2.0
...
In [1519]: age=pd.cut(titanic['age'],[0,18,80])
In [1520]: type(age)
Out[1520]: pandas.core.series.Series
In [1521]: age
Out[1521]: 
0      (18, 80]
1      (18, 80]
2      (18, 80]
3      (18, 80]
4      (18, 80]
5           NaN
6      (18, 80]
7       (0, 18]
...

In [1527]: df10=titanic.groupby(['sex',age])['survived'].describe()
Out[1527]: df10  
Out[1527]: 
                 count      mean       std  min  25%  50%  75%  max
sex    age                                                         
female (0, 18]    68.0  0.676471  0.471301  0.0  0.0  1.0  1.0  1.0
       (18, 80]  193.0  0.782383  0.413698  0.0  1.0  1.0  1.0  1.0
male   (0, 18]    71.0  0.338028  0.476405  0.0  0.0  0.0  1.0  1.0
       (18, 80]  382.0  0.180628  0.385214  0.0  0.0  0.0  0.0  1.0


/ tellen:

In [1554]:  type(titanic['age'].apply(math.isnan))
Out[1554]: pandas.core.series.Series
In [1553]: titanic['age'].apply(math.isnan)
Out[1553]: 
0      False
1      False
2      False
3      False
4      False
5       True
6      False
...
In [1538]: len(titanic['age'][titanic['age'].apply(math.isnan)])
Out[1538]: 177

/ dit is WH fancy indexing	,
/ titanic['age'] is een series	,
In [1562]: titanic['age'][0]
Out[1562]: 22.0
In [1563]: titanic['age'][1]
Out[1563]: 38.0

/ Intermezzo

In [1568]: ser=pd.Series([1,2,3])
In [1578]: ser2=pd.Series([True,False,True])

In [1579]: ser[ser2]
Out[1579]: 
0    1
2    3
dtype: int64



/ Einde Intermezzo


/ 68+193+71+382+177=891	,

/ vergl	,

In [1539]:  titanic.groupby(['sex','age'])['survived'].describe()
Out[1539]: 
              count      mean       std  min   25%  50%   75%  max
sex    age                                                        
female 0.75     2.0  1.000000  0.000000  1.0  1.00  1.0  1.00  1.0
       1.00     2.0  1.000000  0.000000  1.0  1.00  1.0  1.00  1.0
       2.00     6.0  0.333333  0.516398  0.0  0.00  0.0  0.75  1.0
       3.00     2.0  0.500000  0.707107  0.0  0.25  0.5  0.75  1.0
       4.00     5.0  1.000000  0.000000  1.0  1.00  1.0  1.00  1.0
       5.00     4.0  1.000000  0.000000  1.0  1.00  1.0  1.00  1.0
       6.00     2.0  0.500000  0.707107  0.0  0.25  0.5  0.75  1.0
       7.00     1.0  1.000000       NaN  1.0  1.00  1.0  1.00  1.0
       8.00     2.0  0.500000  0.707107  0.0  0.25  0.5  0.75  1.0
...

In [1543]: type(df10)
Out[1543]: pandas.core.frame.DataFrame
In [1544]: df10.index
Out[1544]: 
MultiIndex(levels=[['female', 'male'], [(0, 18], (18, 80]]],
           labels=[[0, 0, 1, 1], [0, 1, 0, 1]],
           names=['sex', 'age'])
In [1546]: df10.columns
Out[1546]: Index(['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'], dtype='object')

/ 1313	.

/ fare=tarief	,

In [1550]: titanic['fare']
Out[1550]: 
0        7.2500
1       71.2833
2        7.9250
3       53.1000
4        8.0500
5        8.4583
...



In [2511]: fare=pd.cut(titanic['fare'],2)

In [2512]: fare
Out[2512]: 
0       (-0.512, 256.165]
1       (-0.512, 256.165]
...
889     (-0.512, 256.165]
890     (-0.512, 256.165]
Name: fare, Length: 891, dtype: category
Categories (2, interval[float64]): [(-0.512, 256.165] < (256.165, 512.329]]

In [2517]: pd.cut?
...
bins : int, sequence of scalars, or pandas.IntervalIndex
    The criteria to bin by.

    * int : Defines the number of equal-width bins in the range of `x`. The
      range of `x` is extended by .1% on each side to include the minimum
      and maximum values of `x`.


/ 13	. 

/ multiindex in ser	,

/ 1313	. 

n [2553]: idx=pd.MultiIndex.from_product([['a','b'],[1,2]])

In [2554]: idx
Out[2554]: 
MultiIndex(levels=[['a', 'b'], [1, 2]],
           labels=[[0, 0, 1, 1], [0, 1, 0, 1]])

In [2555]: ser=pd.Series([5,9,3,7],index=idx)

In [2556]: ser
Out[2556]: 
a  1    5
   2    9
b  1    3
   2    7
dtype: int64

In [2557]: ser['a',2]
Out[2557]: 9

/ 1313	. 

In [2569]: bs=pd.cut(np.arange(100,200),[100-1,125,150,175,200])
In [2569]: bs                                                   
[(99, 125], (99, 125], (99, 125], (99, 125], (99, 125], ..., (175, 200], (175, 200], (175, 200], (175, 200], (175, 200]]
Length: 100
Categories (4, interval[int64]): [(99, 125] < (125, 150] < (150, 175] < (175, 200]]

In [2568]: ser=pd.Series(bs)
In [2568]: ser
Out[2568]: 
0      (99, 125]
1      (99, 125]
...
98    (175, 200]
99    (175, 200]
Length: 100, dtype: category
Categories (4, interval[int64]): [(99, 125] < (125, 150] < (150, 175] < (175, 200]]

/ 1313	.

In [2578]: cats=pd.cut([1,7,5,3,3,5,7],[0,5,10])
In [2580]: cats
Out[2580]: 
[(0, 5], (5, 10], (0, 5], (0, 5], (0, 5], (0, 5], (5, 10]]
Categories (2, interval[int64]): [(0, 5] < (5, 10]]

In [2579]: type(cats)
Out[2579]: pandas.core.arrays.categorical.Categorical

In [2583]: ser=pd.Series(['a','z','f','g','h','x','y'],index=cats)

In [2584]: ser
Out[2584]: 
(0, 5]     a
(5, 10]    z
(0, 5]     f
(0, 5]     g
(0, 5]     h
(0, 5]     x
(5, 10]    y
dtype: object

In [2585]: ser.index
Out[2585]: CategoricalIndex([(0, 5], (5, 10], (0, 5], (0, 5], (0, 5], (0, 5], (5, 10]], categories=[(0, 5], (5, 10]], ordered=True, dtype='category')

/ lees,
https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.Interval.html

In [2622]: ser.loc[pd.Interval(5,10)]
Out[2622]: 
(5, 10]    z
(5, 10]    y
dtype: object

In [2623]: ser.loc[pd.Interval(0,5)]
Out[2623]: 
(0, 5]    a
(0, 5]    f
(0, 5]    g
(0, 5]    h
(0, 5]    x
dtype: object

In [2624]: ser.loc[pd.Interval(0,5):pd.Interval(5,10)]
KeyError: "Cannot get left slice bound for non-unique label: Interval(0, 5, closed='right')"

/ daarom	,

In [2625]: ser
Out[2625]: 
(0, 5]     a
(5, 10]    z
(0, 5]     f
(0, 5]     g
(0, 5]     h
(0, 5]     x
(5, 10]    y
dtype: object

In [2627]: ser.groupby(ser.index).describe()
Out[2627]: 
        count unique top freq
(0, 5]      5      5   x    1
(5, 10]     2      2   y    1

In [2628]: ser.groupby(ser.index).sum()
Out[2628]: 
(0, 5]     afghx
(5, 10]       zy
dtype: object

In [2629]: ser.groupby(ser.index).count()
Out[2629]: 
(0, 5]     5
(5, 10]    2
dtype: int64

///////////////////////////////////////////////////////////////
In [2635]: cnt.loc[pd.Interval(0,5):pd.Interval(5,10)]
Out[2635]: 
(0, 5]     5
(5, 10]    2
dtype: int64

/ 1313	. 

/ ander vb	,

/ we willen zoals op (172), maar dan zelf maken op een series	,

/ slaat dit ergens op?


In [2729]: np.arange(0,24,4)
Out[2729]: array([ 0,  4,  8, 12, 16, 20])
/ pd.cut maakt intervallen (0,4],...,(16,20]	,
/ daarom moeten np.arange(1,21) nemen	, np.arange is juist [,...), verwarrend	,
array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
       18, 19, 20])


In [2728]: pd.cut(np.arange(1,21),np.arange(0,24,4))
Out[2728]: 
[(0, 4], (0, 4], (0, 4], (0, 4], (4, 8], ..., (12, 16], (16, 20], (16, 20], (16, 20], (16, 20]]
Length: 20
Categories (5, interval[int64]): [(0, 4] < (4, 8] < (8, 12] < (12, 16] < (16, 20]]

In [2732]: cats=pd.cut(np.arange(1,21),np.arange(0,24,4))

In [2735]: ser=pd.Series(np.arange(1,21),cats)

In [2739]: rng.randint(1,21,20)
Out[2737]: 
array([20, 11, 17,  2,  1,  6,  3, 16,  4, 15,  6, 12, 20,  7,  7, 20,  7,
        3,  7,  6])
/ zo te zien net als np.arange(1,21) 	,

/ TODO

/ 1313	. 

/ we willen zoals op (172), maar dan zelf maken op een series	,

/ ander voorbeeld	,


In [2757]: cats=pd.cut(rng.randint(1,21,20),np.arange(0,24,4))

In [2759]: cats.value_counts()
Out[2759]: 
(0, 4]      7
(4, 8]      4
(8, 12]     3
(12, 16]    3
(16, 20]    3
dtype: int64

In [2760]: ser=pd.Series(index=cats)
Out[2760]: 
(8, 12]    NaN
(0, 4]     NaN
(4, 8]     NaN
(0, 4]     NaN
(4, 8]     NaN
(16, 20]   NaN
(0, 4]     NaN
(16, 20]   NaN
(16, 20]   NaN
(4, 8]     NaN
(8, 12]    NaN
(0, 4]     NaN
(4, 8]     NaN
(12, 16]   NaN
(8, 12]    NaN
(0, 4]     NaN
(0, 4]     NaN
(12, 16]   NaN
(12, 16]   NaN
(0, 4]     NaN
dtype: float64
/ je moet wel de values van de series geven	, nu hebben we alleen een index	,

In [3120]: ser=pd.Series([1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4],index=cats2)

In [3121]: ser
Out[3121]: 
(12, 16]    1
(0, 4]      2
(8, 12]     3
(0, 4]      4
(0, 4]      1
(12, 16]    2
(16, 20]    3
(16, 20]    4
(8, 12]     1
(0, 4]      2
(0, 4]      3
(12, 16]    4
(4, 8]      1
(12, 16]    2
(4, 8]      3
(16, 20]    4
(16, 20]    1
(0, 4]      2
(12, 16]    3
(0, 4]      4
dtype: int64

In [3123]: ser.index
Out[3123]: 
CategoricalIndex([(12, 16],   (0, 4],  (8, 12],   (0, 4],   (0, 4], (12, 16],
                  (16, 20], (16, 20],  (8, 12],   (0, 4],   (0, 4], (12, 16],
                    (4, 8], (12, 16],   (4, 8], (16, 20], (16, 20],   (0, 4],
                  (12, 16],   (0, 4]],
                 categories=[(0, 4], (4, 8], (8, 12], (12, 16], (16, 20]], ordered=True, dtype='category')

/ we zien alleen dat de values niets met de cats te maken hebben	,

/ 1313	. 

In [3150]: ser=pd.Series([1,3,5,7,9,11,13,15,17,19,2,4,6,8,10,12,14,16,18,20])
In [3151]: ser
Out[3151]: 
0      1
1      3
2      5
3      7
4      9
5     11
6     13
7     15
8     17
9     19
10     2
11     4
12     6
13     8
14    10
15    12
16    14
17    16
18    18
19    20
dtype: int64

In [3153]: cats=pd.cut(ser.values,[1,5,10,15,20])

In [3154]: cats
Out[3154]: 
[NaN, (1, 5], (1, 5], (5, 10], (5, 10], ..., (10, 15], (10, 15], (15, 20], (15, 20], (15, 20]]
Length: 20
Categories (4, interval[int64]): [(1, 5] < (5, 10] < (10, 15] < (15, 20]]

In [3157]: cats.codes
Out[3157]: 
array([-1,  0,  0,  1,  1,  2,  2,  2,  3,  3,  0,  0,  1,  1,  1,  2,  2,
        3,  3,  3], dtype=int8)
/ Dat is in welk interval hij valt	,

In [3159]:  cats.describe()
Out[3159]: 
            counts  freqs
categories               
(1, 5]           4   0.20
(5, 10]          5   0.25
(10, 15]         5   0.25
(15, 20]         5   0.25
NaN              1   0.05

/ dit kan ook	, maar is het zinvol?

In [3161]:  ser=pd.Series(cats)

In [3162]: ser
Out[3162]: 
0          NaN
1       (1, 5]
2       (1, 5]
3      (5, 10]
4      (5, 10]
5     (10, 15]
6     (10, 15]
7     (10, 15]
8     (15, 20]
9     (15, 20]
10      (1, 5]
11      (1, 5]
12     (5, 10]
13     (5, 10]
14     (5, 10]
15    (10, 15]
16    (10, 15]
17    (15, 20]
18    (15, 20]
19    (15, 20]
dtype: category
Categories (4, interval[int64]): [(1, 5] < (5, 10] < (10, 15] < (15, 20]]

In [3163]: ser.count()
Out[3163]: 19

In [3164]: ser.describe()
Out[3164]: 
count           19
unique           4
top       (15, 20]
freq             5
dtype: object


/ GEVONDEN ZOALS PIVOT TABLES

/ 1313	. 

In [3150]: ser=pd.Series([1,3,5,7,9,11,13,15,17,19,2,4,6,8,10,12,14,16,18,20])
In [3153]: cats=pd.cut(ser.values,[1,5,10,15,20])
In [3720]: type(cats)
Out[3720]: pandas.core.arrays.categorical.Categorical
n [3716]: cats.describe()
Out[3716]: 
            counts  freqs
categories               
(1, 5]           4   0.20
(5, 10]          5   0.25
(10, 15]         5   0.25
(15, 20]         5   0.25
NaN              1   0.05

/ we repair cats	, want cats is met pd.cut gemaakt, en deze maakt intervals (1,5], dus de 1ste values 1 valt erbuiten, en we zien NaN	,
In [3175]: ser[0]=pd.Interval(10,15)

In [3182]: cats2=pd.Categorical(rng.randint(1,4,20))
In [3720]: type(cats2)
Out[3720]: pandas.core.arrays.categorical.Categorical
In [3719]: cats2.describe()
Out[3719]: 
            counts  freqs
categories               
1               11   0.55
2                7   0.35
3                2   0.10

In [3186]: cats
Out[3186]: 
[(10, 15], (1, 5], (1, 5], (5, 10], (5, 10], ..., (10, 15], (10, 15], (15, 20], (15, 20], (15, 20]]
Length: 20
Categories (4, interval[int64]): [(1, 5] < (5, 10] < (10, 15] < (15, 20]]

In [3187]: cats2
Out[3187]: 
[2, 3, 1, 1, 2, ..., 1, 1, 2, 3, 3]
Length: 20
Categories (3, int64): [1, 2, 3]

/ cats zijn categories van intervals, cats2 van ints	,

In [3183]: pd.DataFrame({'cats':cats,'values':rng.randint(1,20,20),'cats2':cats2
      ...: })
Out[3183]: 
        cats  values cats2
0   (10, 15]      15     2
1     (1, 5]       8     3
2     (1, 5]      13     1
3    (5, 10]      12     1
4    (5, 10]      13     2
5   (10, 15]      16     3
6   (10, 15]      12     1
7   (10, 15]      14     3
8   (15, 20]      15     3
9   (15, 20]      19     2
10    (1, 5]       5     3
11    (1, 5]       2     1
12   (5, 10]      18     1
13   (5, 10]      18     2
14   (5, 10]      17     3
15  (10, 15]      10     1
16  (10, 15]      17     1
17  (15, 20]       3     2
18  (15, 20]      16     3
19  (15, 20]      18     3

In [3185]: df.dtypes
Out[3185]: 
cats      category
values       int64
cats2     category
dtype: object

/ values zijn ints,cats2 zijn ook ints, maar gezien als categories	,

/ Dit voorbeeld ligt niet voor de hand	, die intervals	,

/ lees	,
https://pandas.pydata.org/pandas-docs/stable/advanced.html

/ HIER BEGINT ECHT GEVONDEN ZOALS PIVOT TABLES

In [3188]: cats1=pd.Categorical(rng.randint(1,4,20))
In [3189]: df=pd.DataFrame({'cats1':cats1,'values':rng.randint(1,20,20),'cats2':
      ...: cats2})
In [3190]: df
Out[3190]: 
   cats1  values cats2
0      2      18     2
1      3       4     3
2      2       8     1
3      3      10     1
4      3       4     2
5      3       8     3
6      2      17     1
7      1       3     3
8      1       5     3
9      2       5     2
10     1       7     3
11     1       1     1
12     2      18     1
13     1       6     2
14     2      15     3
15     3       9     1
16     3       3     1
17     1      18     2
18     2      16     3
19     3      17     3

/ Intermezzo

In [3766]: res=df.groupby(['cats1','cats2'])['values'].describe()
In [3766]: res2=df.groupby(['cats1','cats2'])['values'].mean()
/ zijn beide dfs	, met dezelfde index	,

In [3766]: res=df.groupby(['cats1','cats2'])['values'].describe()
In [3770]: type(res)
Out[3770]: pandas.core.frame.DataFrame
In [3767]: res
Out[3767]: 
             count       mean       std   min    25%   50%    75%   max
cats1 cats2                                                            
1     1        4.0   8.250000  6.800735   1.0   3.25   8.5  13.50  15.0
      2        2.0  18.500000  0.707107  18.0  18.25  18.5  18.75  19.0
2     1        3.0  11.000000  5.567764   6.0   8.00  10.0  13.50  17.0
      2        3.0  11.333333  5.131601   7.0   8.50  10.0  13.50  17.0
      3        1.0   2.000000       NaN   2.0   2.00   2.0   2.00   2.0
3     1        4.0  11.000000  6.928203   5.0   5.00  11.0  17.00  17.0
      2        2.0  12.000000  9.899495   5.0   8.50  12.0  15.50  19.0
      3        1.0  18.000000       NaN  18.0  18.00  18.0  18.00  18.0
n [3771]: res.index
Out[3771]: 
MultiIndex(levels=[[1, 2, 3], [1, 2, 3]],
           labels=[[0, 0, 1, 1, 1, 2, 2, 2], [0, 1, 0, 1, 2, 0, 1, 2]],
           names=['cats1', 'cats2'])
In [3772]: res.index.get_level_values(0)
Out[3772]: CategoricalIndex([1, 1, 2, 2, 2, 3, 3, 3], categories=[1, 2, 3], ordered=False, name='cats1', dtype='category')

In [3773]: res.index.get_level_values(1)
Out[3773]: CategoricalIndex([1, 2, 1, 2, 3, 1, 2, 3], categories=[1, 2, 3], ordered=False, name='cats2', dtype='category')


In [3768]: res2=df.groupby(['cats1','cats2'])['values'].mean()

In [3769]: res2
Out[3769]: 
cats1  cats2
1      1         8.250000
       2        18.500000
2      1        11.000000
       2        11.333333
       3         2.000000
3      1        11.000000
       2        12.000000
       3        18.000000
Name: values, dtype: float64

In [3775]:  type(res2)
Out[3775]: pandas.core.series.Series

In [3776]: res2.index
Out[3776]: 
MultiIndex(levels=[[1, 2, 3], [1, 2, 3]],
           labels=[[0, 0, 1, 1, 1, 2, 2, 2], [0, 1, 0, 1, 2, 0, 1, 2]],
           names=['cats1', 'cats2'])

In [3777]: res.index.get_level_values(0)
Out[3777]: CategoricalIndex([1, 1, 2, 2, 2, 3, 3, 3], categories=[1, 2, 3], ordered=False, name='cats1', dtype='category')

In [3778]: res.index.get_level_values(1)
Out[3778]: CategoricalIndex([1, 2, 1, 2, 3, 1, 2, 3], categories=[1, 2, 3], ordered=False, name='cats2', dtype='category')


/ Einde Intermezzo


In [3218]: res=df.groupby(['cats1','cats2'])['values'].mean().unstack()
In [3221]:  res
Out[3221]: 
cats2          1     2          3
cats1                            
1       1.000000  12.0   5.000000
2      14.333333  11.5  15.500000
3       7.333333   4.0   9.666667
In [3219]: res.columns
Out[3219]: CategoricalIndex([1, 2, 3], categories=[1, 2, 3], ordered=False, name='cats2', dtype='category')
In [3220]: res.index
Out[3220]: CategoricalIndex([1, 2, 3], categories=[1, 2, 3], ordered=False, name='cats1', dtype='category')

/ 1313	. 

/ multiindex	, en unstack	,

In [3188]: cats1=pd.Categorical(rng.randint(1,4,20))		/ randoms uit [1,4)
In [3189]: df=pd.DataFrame({'cats1':cats1,'values':rng.randint(1,20,20),'cats2':
      ...: cats2})

/ omdat cats1 en cast2 categoricals zijn, krijgen we met groupby een CategoricalIndex	,

In [3232]: res=df.groupby(['cats1','cats2'])['values'].describe()
In [3233]: res
Out[3233]: 
             count       mean       std   min    25%   50%    75%   max
cats1 cats2                                                            
1     1        1.0   1.000000       NaN   1.0   1.00   1.0   1.00   1.0
      2        2.0  12.000000  8.485281   6.0   9.00  12.0  15.00  18.0
      3        3.0   5.000000  2.000000   3.0   4.00   5.0   6.00   7.0
2     1        3.0  14.333333  5.507571   8.0  12.50  17.0  17.50  18.0
      2        2.0  11.500000  9.192388   5.0   8.25  11.5  14.75  18.0
      3        2.0  15.500000  0.707107  15.0  15.25  15.5  15.75  16.0
3     1        3.0   7.333333  3.785939   3.0   6.00   9.0   9.50  10.0
      2        1.0   4.000000       NaN   4.0   4.00   4.0   4.00   4.0
      3        3.0   9.666667  6.658328   4.0   6.00   8.0  12.50  17.0
In [3764]: type(res)
Out[3764]: pandas.core.frame.DataFrame
In [3234]: res.index.get_level_values(0)
Out[3234]: CategoricalIndex([1, 1, 1, 2, 2, 2, 3, 3, 3], categories=[1, 2, 3], ordered=False, name='cats1', dtype='category')
In [3235]: res.index.get_level_values(1)
Out[3235]: CategoricalIndex([1, 2, 3, 1, 2, 3, 1, 2, 3], categories=[1, 2, 3], ordered=False, name='cats2', dtype='category')

/ 13	. 

/ multiindex, unstack	,

In [4216]: age=pd.cut(titanic['age'],[0,18,80])
In [4217]: age
Out[4217]: 
0      (18, 80]
1      (18, 80]
...
In [4221]: type(age)
Out[4221]: pandas.core.series.Series

In [4224]: m=titanic.groupby(['sex',age,'class'])['survived'].mean()
In [4246]: type(m)
Out[4246]: pandas.core.series.Series
In [4225]: m
Out[4225]: 
sex     age       class 
female  (0, 18]   First     0.909091
                  Second    1.000000
                  Third     0.511628
        (18, 80]  First     0.972973
                  Second    0.900000
                  Third     0.423729
male    (0, 18]   First     0.800000
                  Second    0.600000
                  Third     0.215686
        (18, 80]  First     0.375000
                  Second    0.071429
                  Third     0.133663
Name: survived, dtype: float64

In [4226]: n=m.unstack()
In [4247]: type(n)
Out[4247]: pandas.core.frame.DataFrame
In [4227]: n
Out[4227]: 
class               First    Second     Third
sex    age                                   
female (0, 18]   0.909091  1.000000  0.511628
       (18, 80]  0.972973  0.900000  0.423729
male   (0, 18]   0.800000  0.600000  0.215686
       (18, 80]  0.375000  0.071429  0.133663
/ PRECIES ALS PIVOT TABLE (172) 

/ groter	,

In [4231]: m=titanic.groupby(['sex',age,fare,'class'])['survived'].mean()
/ series	,
In [4237]: n=m.unstack(level=[-2,-1])
/ df	,
In [4237]: n
Out[4237]: 
fare            (-0.512, 256.165]                     (256.165, 512.329]
class                       First    Second     Third              First
sex    age                                                              
female (0, 18]           0.900000  1.000000  0.511628                1.0
       (18, 80]          0.971429  0.900000  0.423729                1.0
male   (0, 18]           0.800000  0.600000  0.215686                NaN
       (18, 80]          0.369565  0.071429  0.133663                0.5

In [4244]: m.index
Out[4244]: 
MultiIndex(levels=[['female', 'male'], [(0, 18], (18, 80]], [(-0.512, 256.165], (256.165, 512.329]], ['First', 'Second', 'Third']],
           labels=[[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1], [0, 1, 2, 0, 0, 1, 2, 0, 0, 1, 2, 0, 1, 2, 0]],
           names=['sex', 'age', 'fare', 'class'])
In [4245]: m.columns
/ ERR, zijn er niet	,

In [4242]: n.index
Out[4242]: 
MultiIndex(levels=[['female', 'male'], [(0, 18], (18, 80]]],
           labels=[[0, 0, 1, 1], [0, 1, 0, 1]],
           names=['sex', 'age'])

In [4243]: n.columns
Out[4243]: 
MultiIndex(levels=[[(-0.512, 256.165], (256.165, 512.329]], ['First', 'Second', 'Third']],
           labels=[[0, 0, 0, 1], [0, 1, 2, 0]],
           names=['fare', 'class'])
/ PRECIES ALS PIVOT TABLE (172)






/ 13	. 

In [4213]: df.dtypes
Out[4213]: 
cats1     category
values       int64
cats2     category
dtype: object

In [4203]: m=df.groupby(['cats1','cats2'])['values'].mean()
In [4203]: m
Out[4203]: 
cats1  cats2
1      1         8.250000
       2        18.500000
2      1        11.000000
       2        11.333333
       3         2.000000
3      1        11.000000
       2        12.000000
       3        18.000000
Name: values, dtype: float64
In [4205]: m.index
Out[4205]: 
MultiIndex(levels=[[1, 2, 3], [1, 2, 3]],
           labels=[[0, 0, 1, 1, 1, 2, 2, 2], [0, 1, 0, 1, 2, 0, 1, 2]],
           names=['cats1', 'cats2'])
In [4206]: m.index.get_level_values(0)
Out[4206]: CategoricalIndex([1, 1, 2, 2, 2, 3, 3, 3], categories=[1, 2, 3], ordered=False, name='cats1', dtype='category')
In [4207]: m.index.get_level_values(1)
Out[4207]: CategoricalIndex([1, 2, 1, 2, 3, 1, 2, 3], categories=[1, 2, 3], ordered=False, name='cats2', dtype='category')

In [4209]: n
Out[4209]: 
cats2      1          2     3
cats1                        
1       8.25  18.500000   NaN
2      11.00  11.333333   2.0
3      11.00  12.000000  18.0

In [4210]: n.index
Out[4210]: CategoricalIndex([1, 2, 3], categories=[1, 2, 3], ordered=False, name='cats1', dtype='category')

In [4211]: n.columns
Out[4211]: CategoricalIndex([1, 2, 3], categories=[1, 2, 3], ordered=False, name='cats2', dtype='category')




/ maar kunnen we ook de values kolom,	

In [3238]: cats3=pd.cut(df['values'],[1,5,10,15,20])
In [3265]: type(cats3)
Out[3265]: pandas.core.series.Series
In [3239]: cats3
Out[3239]: 
0     (15, 20]
1       (1, 5]
2      (5, 10]
3      (5, 10]
4       (1, 5]
5      (5, 10]
6     (15, 20]
7       (1, 5]
8       (1, 5]
9       (1, 5]
10     (5, 10]
11         NaN
12    (15, 20]
13     (5, 10]
14    (10, 15]
15     (5, 10]
16      (1, 5]
17    (15, 20]
18    (15, 20]
19    (15, 20]
Name: values, dtype: category
Categories (4, interval[int64]): [(1, 5] < (5, 10] < (10, 15] < (15, 20]]

In [3245]: df.groupby(cats3)['cats1'].count()
Out[3245]: 
values
(1, 5]      6
(5, 10]     6
(10, 15]    1
(15, 20]    6
Name: cats1, dtype: int64

In [3248]: cnt.index
Out[3248]: CategoricalIndex([(1, 5], (5, 10], (10, 15], (15, 20]], categories=[(1, 5], (5, 10], (10, 15], (15, 20]], ordered=True, name='values', dtype='category')




/ 1313	. 

In [3188]: cats1=pd.Categorical(rng.randint(1,4,20))
In [3182]: cats2=pd.Categorical(rng.randint(1,4,20))
In [3238]: cats3a=pd.cut(df['values'].values,[1,5,10,15,20]) / 'n Categorical
In [3238]: cats3=pd.cut(df['values'],[1,5,10,15,20])	/ 'n Series	,
In [3359]: values=df['values']       / 'n Series               
In [3322]:  df.columns
Out[3322]: Index(['cats1', 'values', 'cats2'], dtype='object')


In [3257]: df.groupby(cats3)['cats1','cats2' ].count()
Out[3257]: 
          cats1  cats2
values                
(1, 5]        6      6
(5, 10]       6      6
(10, 15]      1      1
(15, 20]      6      6

/ 1313	. 

In [3281]: cats3=pd.cut(df['values'].values,[1,5,10,15,20])
In [3282]: type(cats3)
Out[3282]: pandas.core.arrays.categorical.Categorical

/ we moeten .values	, omdat df['values'] een series is, is pd.cut(df['values'], ...) dat ook	,

In [3287]: df.groupby([cats1,cats3])['values' ].count()
Out[3287]: 
1  (1, 5]      2
   (5, 10]     2
   (15, 20]    1
2  (1, 5]      1
   (5, 10]     1
   (10, 15]    1
   (15, 20]    4
3  (1, 5]      3
   (5, 10]     3
   (15, 20]    1
Name: values, dtype: int64

In [3288]: df.groupby([cats1,cats3])['values' ].count().unstack()
Out[3288]: 
   (1, 5]  (5, 10]  (10, 15]  (15, 20]
1     2.0      2.0       NaN       1.0
2     1.0      1.0       1.0       4.0
3     3.0      3.0       NaN       1.0

/ 1313	. 

/ OK	,
/ de 1ste moet altijd '...'	, 
In [3343]: df.pivot_table('values','cats1','cats2')
/ of	,
In [3349]: df.pivot_table('values',[cats1],'cats2')
/ of	,
In [3349]: df.pivot_table('values',pd.Series(cats1),'cats2')
/ of	,
In [3349]: df.pivot_table('values',[pd.Series(cats1)],'cats2')
/ of	,
In [3350]: df.pivot_table('values','cats1',[cats2])
/ of	,
In [3350]: df.pivot_table('values','cats1',pd.Series(cats2))
/ of	,
In [3350]: df.pivot_table('values','cats1',[pd.Series(cats2)])
Out[3350]: 
           1     2          3
1   1.000000  12.0   5.000000
2  14.333333  11.5  15.500000
3   7.333333   4.0   9.666667
/ klopt	, dit zijn de gemiddelden over cats1 en cats2	,

In [3344]: df
Out[3344]: 
   cats1  values cats2
0      2      18     2
1      3       4     3
2      2       8     1
3      3      10     1
4      3       4     2
5      3       8     3
6      2      17     1
7      1       3     3
8      1       5     3
9      2       5     2
10     1       7     3
11     1       1     1
12     2      18     1
13     1       6     2
14     2      15     3
15     3       9     1
16     3       3     1
17     1      18     2
18     2      16     3
19     3      17     3

/ Dit is ERR	,
In [3353]: df.pivot_table([values],'cats1','cats2')
/ of	,
In [3354]: df.pivot_table('values',cats1,'cats2')
/ of	,
In [3354]: df.pivot_table('values','cats1',cats2)

/ 13	. 

/ Series -> Categorial
.values

In [3385]: fare=pd.cut(titanic['fare'],2)
In [3386]: fare_cats=fare.values

In [3388]: age_cats=age.values

In [3389]:  titanic.pivot_table('survived',age,'class')
/ OK, want age is een series	,
In [3391]:  titanic.pivot_table('survived',age_cats,'class')
/ ERR,
In [3391]:  titanic.pivot_table('survived',[age_cats],'class')
/ OK	,

In [3392]:  titanic.pivot_table('survived',['sex',age_cats],[fare_cats,'class'])
      ...: 
Out[3392]: 
                (-0.512, 256.165]        ...         (256.165, 512.329]
class                       First        ...                      First
sex                                      ...                           
female (0, 18]           0.900000        ...                        1.0
       (18, 80]          0.971429        ...                        1.0
male   (0, 18]           0.800000        ...                        NaN
       (18, 80]          0.369565        ...                        0.5

[4 rows x 4 columns]



///////////////////////////////////////  
/ Einde GEVONDEN ZOALS PIVOT TABLES




/ 1313	. 


In [2762]: piv.index
Out[2762]: 
MultiIndex(levels=[['female', 'male'], [(0, 18], (18, 80]]],
           labels=[[0, 0, 1, 1], [0, 1, 0, 1]],
           names=['sex', 'age'])

n [2766]: ser.index
Out[2766]: 
CategoricalIndex([ (8, 12],   (0, 4],   (4, 8],   (0, 4],   (4, 8], (16, 20],
                    (0, 4], (16, 20], (16, 20],   (4, 8],  (8, 12],   (0, 4],
                    (4, 8], (12, 16],  (8, 12],   (0, 4],   (0, 4], (12, 16],
                  (12, 16],   (0, 4]],
                 categories=[(0, 4], (4, 8], (8, 12], (12, 16], (16, 20]], ordered=True, dtype='category')

/ hele andere index	,

/ maar als we 	,

In [2910]: %history -g piv

2771: piv=titanic.pivot_table('survived',age,'class')
In [2903]: piv
Out[2903]: 
class        First    Second     Third
age                                   
(0, 18]   0.875000  0.793103  0.351064
(18, 80]  0.635294  0.416667  0.199234

In [2904]: piv.index
Out[2904]: CategoricalIndex([(0, 18], (18, 80]], categories=[(0, 18], (18, 80]], ordered=True, name='age', dtype='category')


/ 1313	. 


In [2796]: m=titanic.groupby(['sex','class'])['survived'].aggregate('mean')
In [2802]: m.index.get_level_values(0)
Out[2802]: Index(['female', 'female', 'female', 'male', 'male', 'male'], dtype='object', name='sex')
In [2803]: m.index.get_level_values(1)
Out[2803]: CategoricalIndex(['First', 'Second', 'Third', 'First', 'Second', 'Third'], categories=['First', 'Second', 'Third'], ordered=False, name='class', dtype='category')

/ makkelijker	,
In [2805]: m=titanic.groupby(['class'])['survived'].aggregate('mean')
In [2810]: type(m)
Out[2810]: pandas.core.series.Series
In [2806]: m
Out[2806]: 
class
First     0.629630
Second    0.472826
Third     0.242363
Name: survived, dtype: float64
In [2808]: m.index
Out[2808]: CategoricalIndex(['First', 'Second', 'Third'], categories=['First', 'Second', 'Third'], ordered=False, name='class', dtype='category')

In age=pd.cut(titanic['age'],[0,18,80])
In [2820]: type(titanic['age'])
Out[2820]: pandas.core.series.Series

In [2812]: m=titanic.groupby(age)['survived'].aggregate('mean')
In [2827]: type(m)
Out[2827]: pandas.core.series.Series
In [2813]: m
Out[2813]: 
age
(0, 18]     0.503597
(18, 80]    0.382609
Name: survived, dtype: float64
In [2828]: m.index
Out[2828]: CategoricalIndex([(0, 18], (18, 80]], categories=[(0, 18], (18, 80]], ordered=True, name='age', dtype='category')

In [2834]: rng.randint(0,21,20)
Out[2834]: 
array([20, 10, 10,  3,  5,  9,  8, 17, 19,  8, 10,  1, 14,  5, 16,  3,  7,
        1,  8,  0])

/ 1313	. 

In [2910]: titanic.dtypes
Out[2910]: 
survived          int64
pclass            int64
sex              object
age             float64
sibsp             int64
parch             int64
fare            float64
embarked         object
class          category
who              object
adult_male         bool
deck           category
embark_town      object
alive            object
alone              bool
dtype: object

/ sex is een string, class een category	,

In [2915]: titanic.groupby('sex')['survived'].describe().index
Out[2915]: Index(['female', 'male'], dtype='object', name='sex')

In [2916]: titanic.groupby('class')['survived'].describe().index
Out[2916]: CategoricalIndex(['First', 'Second', 'Third'], categories=['First', 'Second', 'Third'], ordered=False, name='class', dtype='category')

/ dus .groupby maakt een CategoricalIndex als het type een categorical is	, 

In [2918]: titanic['class'].dtype
Out[2918]: CategoricalDtype(categories=['First', 'Second', 'Third'], ordered=False)
In [2919]: titanic['sex'].dtype
Out[2919]: dtype('O')

/ 1313	. 

/ lees	,
https://www.postgresql.org/docs/9.6/datatype-enum.html


/ 1313	. 

/ pd.cut geeft een series voor een series, en anders een categorical	,

/ zelf maken	,

In [2901]: type(titanic['age'])
Out[2901]: pandas.core.series.Series
In [2840]: age=pd.cut(titanic['age'],[0,18,80])
In [2845]: type(age)
Out[2845]: pandas.core.series.Series
In [2841]: age
Out[2841]: 
0      (18, 80]
1      (18, 80]
...
889    (18, 80]
890    (18, 80]
Name: age, Length: 891, dtype: category
Categories (2, interval[int64]): [(0, 18] < (18, 80]]

In [2890]: type(age.values)
Out[2890]: pandas.core.arrays.categorical.Categorical
In [2850]: age.values
Out[2850]: 
[(18, 80], (18, 80], (18, 80], (18, 80], (18, 80], ..., (18, 80], (18, 80], NaN, (18, 80], (18, 80]]
Length: 891
Categories (2, interval[int64]): [(0, 18] < (18, 80]]

In [2891]: type(age.value_counts())
Out[2891]: pandas.core.series.Series
In [2859]: age.value_counts()
Out[2859]: 
(18, 80]    575
(0, 18]     139
Name: age, dtype: int64

In [2888]: age.describe()
Out[2888]: 
count          714
unique           2
top       (18, 80]		/= meest voorkomende	,
freq           575
Name: age, dtype: object

/ ander vb,	

/ een pd.Categorical heeft en np.ndarray	, use .get_values() 

In [2757]: cats=pd.cut(rng.randint(1,21,20),np.arange(0,24,4))
In [2889]: type(cats)
Out[2889]: pandas.core.arrays.categorical.Categorical
In [2851]: cats
Out[2851]: 
[(8, 12], (0, 4], (4, 8], (0, 4], (4, 8], ..., (0, 4], (0, 4], (12, 16], (12, 16], (0, 4]]
Length: 20
Categories (5, interval[int64]): [(0, 4] < (4, 8] < (8, 12] < (12, 16] < (16, 20]]

In [2896]: cats.value_counts()
Out[2896]: 
(0, 4]      7
(4, 8]      4
(8, 12]     3
(12, 16]    3
(16, 20]    3
dtype: int64

In [2900]: type(cats.get_values())
Out[2900]: numpy.ndarray
In [2899]: cats.get_values()
Out[2899]: 
array([Interval(8, 12, closed='right'), Interval(0, 4, closed='right'),
       Interval(4, 8, closed='right'), Interval(0, 4, closed='right'),
       Interval(4, 8, closed='right'), Interval(16, 20, closed='right'),
       Interval(0, 4, closed='right'), Interval(16, 20, closed='right'),
       Interval(16, 20, closed='right'), Interval(4, 8, closed='right'),
       Interval(8, 12, closed='right'), Interval(0, 4, closed='right'),
       Interval(4, 8, closed='right'), Interval(12, 16, closed='right'),
       Interval(8, 12, closed='right'), Interval(0, 4, closed='right'),
       Interval(0, 4, closed='right'), Interval(12, 16, closed='right'),
       Interval(12, 16, closed='right'), Interval(0, 4, closed='right')],
      dtype=object)

In [2894]: ser=pd.Series(cats)
In [2853]: ser
Out[2853]: 
0      (8, 12]
1       (0, 4]
2       (4, 8]
...
17    (12, 16]
18    (12, 16]
19      (0, 4]
dtype: category
Categories (5, interval[int64]): [(0, 4] < (4, 8] < (8, 12] < (12, 16] < (16, 20]]

In [2860]: ser.value_counts()
Out[2860]: 
(0, 4]      7
(4, 8]      4
(16, 20]    3
(12, 16]    3
(8, 12]     3
dtype: int64

/ of weer anders	,

In [2864]: ser2=pd.Series(rng.randint(1,21,20))
In [2865]: ser2
Out[2865]: 
0      8
1     16
...
19    17
dtype: int64

/ 13	. 

/ (173)

In [3400]: titanic.pivot_table(index='sex',columns='class',aggfunc={'survived':'
      ...: sum','fare':'mean'})
Out[3400]: 
              fare                       survived             
class        First     Second      Third    First Second Third
sex                                                           
female  106.125798  21.970121  16.118810       91     70    72
male     67.226127  19.741782  12.661633       45     17    47

In [3406]:  titanic.pivot_table('survived','sex','class')
/ of	,
In [3405]: titanic.pivot_table(index='sex',columns='class',aggfunc={'survived':'
      ...: mean'})
Out[3405]: 
        survived                    
class      First    Second     Third
sex                                 
female  0.968085  0.921053  0.500000
male    0.368852  0.157407  0.135447

In [3403]:  titanic.pivot_table('survived','sex','class',margins=True)
Out[3403]: 
class      First    Second     Third       All
sex                                           
female  0.968085  0.921053  0.500000  0.742038
male    0.368852  0.157407  0.135447  0.188908
All     0.629630  0.472826  0.242363  0.383838

In [3409]: titanic.pivot_table(index='sex',columns='class',aggfunc={'survived':'
      ...: mean'},margins=True)
/ ERR
/ TODO

/ 13	.

/ lees	,
https://stackoverflow.com/questions/30336324/seaborn-load-dataset
https://github.com/mwaskom/seaborn-data
/ hier zijn titanic.csv	, planets.csv	,

/ maar births.csv in	,
https://github.com/jakevdp/data-CDCbirths

In [3412]: !curl -O https://raw.githubusercontent.com/jakevdp/data-CDCbirths/mas
      ...: ter/births.csv
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100  258k  100  258k    0     0   438k      0 --:--:-- --:--:-- --:--:--  438k

In [3413]: births=pd.read_csv('births.csv')

In [3415]:  len(births)
Out[3415]: 15547

/ Intermezzo

/ google	,
difference raw.githubusercontent.com github.com
/ lees	,
https://stackoverflow.com/questions/39065921/what-do-raw-githubusercontent-com-urls-represent

raw.githubusercontent.com returns the raw content of files stored in github, so the they can be downloaded simply to your computer. For example, it the page represents a ruby install script, then you will get a ruby install script that your ruby installation will understand. If you download the github.com file, you will actually be downloading a web page with buttons and comments and which displays your wanted script in the middle -- it's human-readable, but for the computer, it is not a script that can be executed or code that can be compiled, but a web page to be displayed. That web page has a button called Raw that sends you to the corresponding content on raw.githubusercontent.com.

In [3412]: !curl -O https://github.com/jakevdp/data-CDCbirths/master/births.csv
/ NIETS	,
/ TODO
/ Ga naar	,
https://github.com/jakevdp/data-CDCbirths
/ click births.csv	,
https://github.com/jakevdp/data-CDCbirths/blob/master/births.csv
/ click Raw	,
https://raw.githubusercontent.com/jakevdp/data-CDCbirths/master/births.csv

/ Einde Intermezzo

/ 10*( births['year']//10) geeft precies evenveel rijen als in births	,

In [3426]: births['decade']=10*( births['year']//10)
In [3427]: births.head()
Out[3427]: 
   year  month  day gender  births  decade
0  1969      1  1.0      F    4046    1960
1  1969      1  1.0      M    4440    1960
2  1969      1  2.0      F    4454    1960
3  1969      1  2.0      M    4548    1960
4  1969      1  3.0      F    4548    1960
...

In [3428]: births.pivot_table('births',index='decade',columns='gender',aggfunc='sum')
Out[3428]: 
gender         F         M
decade                    
1960     1753634   1846572
1970    16263075  17121550
1980    18310351  19243452
1990    19479454  20420553
2000    18229309  19106428

/ 13	. 

In [3430]: %matplotlib
Using matplotlib backend: Qt5Agg

In [3431]: import matplotlib.pyplot as plt

/ Eerder: In [1149]: import seaborn as sns
In [3432]: sns
Out[3432]: <module 'seaborn' from '/home/eric/miniconda3/lib/python3.6/site-packages/seaborn/__init__.py'>

In [3433]: sns.set()

In [3434]: births.pivot_table('births',index='year',columns='gender',aggfunc='
      ...: sum').plot()
Out[3434]: <matplotlib.axes._subplots.AxesSubplot at 0x7ff403ead160>

In [3435]: plt.ylabel('total births per year')
Out[3435]: Text(33.8472,0.5,'total births per year')
/ langs verticale as	,
/ maak het window iets breder	,

/ Intermezzo 

/ lees,	
https://en.wikipedia.org/wiki/Quartile

A quartile is a type of quantile. The first quartile (Q1) is defined as the middle number between the smallest number and the median of the data set. The second quartile (Q2) is the median of the data. The third quartile (Q3) is the middle value between the median and the highest value of the data set.


In [3445]: ser=pd.Series(np.arange(0,20))

In [3446]: ser
Out[3446]: 
0      0
1      1
2      2
3      3
4      4
5      5
6      6
7      7
8      8
9      9
10    10
11    11
12    12
13    13
14    14
15    15
16    16
17    17
18    18
19    19
dtype: int64

In [3447]: quartiles=np.percentile(ser,[25,50,75])
In [3448]: quartiles
Out[3448]: array([ 4.75,  9.5 , 14.25])


In [3477]: np.percentile([1,3,4,100],[25,50,75])
Out[3477]: array([ 2.5,  3.5, 28. ])
In [3481]: np.percentile([1,3,4,100],[25,50,75],interpolation='midpoint')
Out[3481]: array([ 2. ,  3.5, 52. ])

In [3476]: np.percentile([1,3,4,5,100],[25,50,75])
Out[3476]: array([3., 4., 5.])
In [3482]: np.percentile([1,3,4,5,100],[25,50,75],interpolation='midpoint')
Out[3482]: array([3., 4., 5.])

In [3479]: np.percentile([1,3,4,5,6,100],[25,50,75],interpolation='linear')
Out[3479]: array([3.25, 4.5 , 5.75])
In [3480]: np.percentile([1,3,4,5,6,100],[25,50,75],interpolation='midpoint')
Out[3480]: array([3.5, 4.5, 5.5])

In [3485]: np.percentile([1,3,4,5,6,7,100],[25,50,75],interpolation='linear')
Out[3485]: array([3.5, 5. , 6.5])
In [3484]: np.percentile([1,3,4,5,6,7,100],[25,50,75],interpolation='midpoint')
Out[3484]: array([3.5, 5. , 6.5])

In [3487]: np.percentile([1,3,4,5,6,7,8,100],[25,50,75],interpolation='linear')
Out[3487]: array([3.75, 5.5 , 7.25])
In [3488]: np.percentile([1,3,4,5,6,7,8,100],[25,50,75],interpolation='midpoint')
Out[3488]: array([3.5, 5.5, 7.5])

/ Intermezzo

/ lees	,
https://en.wikipedia.org/wiki/Interquartile_range

/ lees	,
https://stackoverflow.com/questions/45666970/what-is-sigma-clipping-how-do-you-know-when-to-apply-it

p1 = sp.stats.norm.ppf(0.25)  # first quartile of standard normal distribution
p2 = sp.stats.norm.ppf(0.75)  # third quartile
In [4252]: p1
Out[4252]: -0.6744897501960817
In [4254]: p2
Out[4254]: 0.6744897501960817
In [4256]: p2-p1
Out[4256]: 1.3489795003921634
sig = 1  # standard deviation of the standard normal distribution  
factor = sig / (p2 - p1)
print(factor)  # 0.74130110925280102
In the standard normal distribution sig==1 and the interquartile range is 1.35. So 0.74 is the correction factor to turn the interquartile range into sigma. Of course, this is only true for the normal distribution.

/ we gaan het doen

In [3494]: import scipy as sp

In [3497]: sp.stats.norm.cdf?
Cumulative distribution function of the given RV.
sp.stats.norm.ppf?
Percent point function (inverse of `cdf`) at q of the given RV.

In [3499]:  sp.stats.norm.ppf(0.25)
Out[3499]: -0.6744897501960817

In [3502]:  sp.stats.norm.ppf(0.5)
Out[3502]: 0.0

In [3501]:  sp.stats.norm.ppf(0.75)
Out[3501]: 0.6744897501960817

/ klokvorm	

--------------------------------------------------------
		-1   -.67..  	0   .67...	 1

/ Dus het lijkt me dat je .67.. -> 1 en -.67 -> -1, dus *1/.67...= 1.482602218505602
/ quartiles[0]=25%	, quartiles[2]=75%	,
/ dus voor de normale verd: quartiles[2]-quartiles[0]=1.35	,en 1/1.35=.74 en .74*(quartile[2]-quartiles[0])=1=std	,

/ 13	. 

/ lees	,
https://www.statisticshowto.datasciencecentral.com/calculators/interquartile-range-calculator/

/ Einde Intermezzo

/ we hadden	,

In [3517]: quartiles=np.percentile(births['births'],[25,50,75])
In [3518]: quartiles
Out[3518]: array([4358. , 4814. , 5289.5])

In [3519]: mu=quartiles[1]
In [3522]: sig=.74*(quartiles[2]-quartiles[0])
/=
In [3522]: sig=(quartiles[2]-quartiles[0])/(2*.67...=quartile_std_n[2]-quartile_stdn[0]
In [3523]: sig
Out[3523]: 689.31

In [3630]: mu+5*sig
Out[3630]: 8260.55
In [3632]: mu-5*sig
Out[3632]: 1367.4500000000003

/ Dus births2 heeft births tussen 1767.45 en 8260.55	, 

/ in het boek laten we birth voortaan wat bij ons birth2, wij laten birth2	,


In [3534]: births2=births.query('(births > @mu-5*@sig)&(births<@mu+5*@sig)')
In [3535]:  births2
Out[3535]: 
       year  month   day gender  births  decade
0      1969      1   1.0      F    4046    1960
1      1969      1   1.0      M    4440    1960
...
15065  1988     12  31.0      F    4435    1980
15066  1988     12  31.0      M    4698    1980
[14610 rows x 6 columns]

In [3626]: len(births)
Out[3626]: 15547
In [3627]: len(births2)
Out[3627]: 14610

In [3600]: ct= pd.concat([births,births2])
In [3610]: dd=ct.drop_duplicates(keep=False)
In [3613]: len(dd)
Out[3613]: 937
In [3612]: len(births)-len(births2)
Out[3612]: 937
/ births die niet in births2	, dus die births < 1767.45 en > 8260.55	, 

In [3623]: dd=ct.drop_duplicates(keep='first')
In [3624]: len(dd)
Out[3624]: 15547
In [3625]: len(births)
Out[3625]: 15547
In [3648]: dd.equals(births)
Out[3648]: True

/ 13	 

In [3659]: day=births2['day']        
In [3659]: day[day.apply(math.isnan)]
/=
In [4261]: day[np.isnan(day)]
Out[3659]: Series([], Name: day, dtype: float64)

/ Intermezzo

/ fancy indexing met boolean array	,

In [4264]: day=births['day']
In [4263]: np.isnan(day)
Out[4263]: 
0        False
1        False
...
15545     True
15546     True
Name: day, Length: 15547, dtype: bool

In [4264]: day[np.isnan(day)]
Out[4264]: 
15067   NaN
15068   NaN
...
15545   NaN
15546   NaN
Name: day, Length: 480, dtype: float64


/ Einde Intermezzo



In [3681]: b=births[births['day'].apply(math.isnan)]
/=
In [4275]: b=births[np.isnan(births['day'])]
In [3681]: b[b['births']<=mu+5*sig]
Out[3681]: 
Empty DataFrame
Columns: [year, month, day, gender, births, decade]
Index: []
/ Dus alle births met day is NaN hebben births>mu+5*sig	, dus zitten NIET in births2	,
/ dus kunnen we day van string naar int	,
/ bij ons is day een float	,
In [3689]: births2['day'].dtype
Out[3689]: dtype('float64')
/ TODO
/ year en month hebben al dtype int64	,

In [3691]: births2['day'].astype(int).dtype
Out[3691]: dtype('int64')

In [3695]: births2['day']=births2['day'].astype(int)
/home/eric/miniconda3/bin/ipython:1: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  #!/home/eric/miniconda3/bin/python

/ Maar het is wel gedaan	,
In [4317]: births2.dtypes
Out[4317]: 
year       int64
month      int64
day        int64
gender    object
births     int64
decade     int64
dtype: object
In [3696]: births2['day'].head()
Out[3696]: 
0    1
1    1
2    2
3    2
4    3
Name: day, dtype: int64


In [4380]: s_in=10000*births2.year+100*births2.month+births2.day
In [4381]: s_in
Out[4381]: 
0        19690101
1        19690101
...
15066    19881231
Length: 14610, dtype: int64
/ series	,
In [4384]: s_in.dtype
Out[4384]: dtype('int64')
In [4385]: type(s_in[0])
Out[4385]: numpy.int64

In [4386]: s=pd.to_datetime(s_in,format='%Y%m%d')
In [4389]: s
Out[4389]: 
0       1969-01-01
1       1969-01-01
...
15066   1988-12-31
Length: 14610, dtype: datetime64[ns]
In [4387]: s.dtype
Out[4387]: dtype('<M8[ns]')
In [4388]: type(s[0])
Out[4388]: pandas._libs.tslibs.timestamps.Timestamp


/ nu	,
In [3709]: births2.index
Out[3709]: 
Int64Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,
                9,
            ...
            15057, 15058, 15059, 15060, 15061, 15062, 15063, 15064, 15065,
            15066],
           dtype='int64', length=14610)

/ we veranderen	,
In [3710]: births2.index=s
In [3711]: idx=births2.index
In [3711]: idx
Out[3711]: 
DatetimeIndex(['1969-01-01', '1969-01-01', '1969-01-02', '1969-01-02',
               '1969-01-03', '1969-01-03', '1969-01-04', '1969-01-04',
               '1969-01-05', '1969-01-05',
               ...
               '1988-12-27', '1988-12-27', '1988-12-28', '1988-12-28',
               '1988-12-29', '1988-12-29', '1988-12-30', '1988-12-30',
               '1988-12-31', '1988-12-31'],
              dtype='datetime64[ns]', length=14610, freq=None)
In [4401]:  idx.dayofweek
Out[4401]: 
Int64Index([2, 2, 3, 3, 4, 4, 5, 5, 6, 6,
            ...
            1, 1, 2, 2, 3, 3, 4, 4, 5, 5],
           dtype='int64', length=14610)
/ NIET: idx['dayofweek']

In [4409]: births2['dayofweek']=idx.dayofweek
/home/eric/miniconda3/bin/ipython:1: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  #!/home/eric/miniconda3/bin/python
/ TODO

/ of	,
In [4409]: births2['dayofweek']=idx.dayofweek+1
/ dan zien we dayofweek 1,2,...,7

In [4413]: births2.groupby(['dayofweek','decade'])['births'].mean()
Out[4413]: 
dayofweek  decade
0          1960      5063.826923
           1970      4689.097701
           1980      5276.907249
1          1960      5286.096154
           1970      4885.252399
           1980      5503.842553
2          1960      5074.622642
           1970      4750.376200
           1980      5367.642553
3          1960      4978.288462
           1970      4696.923372
           1980      5333.485106
4          1960      5107.884615
           1970      4782.095785
           1980      5393.087234
5          1960      4651.057692
           1970      4207.784483
           1980      4483.901064
6          1960      4342.346154
           1970      3979.278736
           1980      4308.120469
Name: births, dtype: float64

In [4414]: births2.groupby(['dayofweek','decade'])['births'].mean().unstack()
Out[4414]: 
decade            1960         1970         1980
dayofweek                                       
0          5063.826923  4689.097701  5276.907249
1          5286.096154  4885.252399  5503.842553
2          5074.622642  4750.376200  5367.642553
3          4978.288462  4696.923372  5333.485106
4          5107.884615  4782.095785  5393.087234
5          4651.057692  4207.784483  4483.901064
6          4342.346154  3979.278736  4308.120469
/=
In [4415]: births2.pivot_table('births',index='dayofweek',columns='decade',aggfunc='mean')
Out[4415]: 
decade            1960         1970         1980
dayofweek                                       
0          5063.826923  4689.097701  5276.907249
1          5286.096154  4885.252399  5503.842553
2          5074.622642  4750.376200  5367.642553
3          4978.288462  4696.923372  5333.485106
4          5107.884615  4782.095785  5393.087234
5          4651.057692  4207.784483  4483.901064
6          4342.346154  3979.278736  4308.120469

/ select distinct 
In [4419]: births2['dayofweek'].unique()
Out[4419]: array([2, 3, 4, 5, 6, 0, 1])

In [4467]: df2=births2.groupby(['dayofweek','decade'])['births'].mean().unstack()

In [4468]: df3.plot()
Out[4468]: <matplotlib.axes._subplots.AxesSubplot at 0x7ff4026f7470>

/ als we 
In [4409]: births2['dayofweek']=idx.dayofweek
In [4469]: plt.gca().set_xticklabels(['Mon','Tue','Wed','Thu','Fri','Sat','Sun'])
Out[4469]: 
[Text(-1,0,'Mon'),
 Text(0,0,'Tue'),
 Text(1,0,'Wed'),
 Text(2,0,'Thu'),
 Text(3,0,'Fri'),
 Text(4,0,'Sat'),
 Text(5,0,'Sun')]
/ of als we	,
In [4409]: births2['dayofweek']=idx.dayofweek+1
/ dan	,
In [4469]: plt.gca().set_xticklabels(['Mon','Tue','Wed','Thu','Fri','Sat','Sun'])
Out[4469]: 
[Text(0,0,'Mon'),
 Text(1,0,'Tue'),
 Text(2,0,'Wed'),
 Text(3,0,'Thu'),
 Text(4,0,'Fri'),
 Text(5,0,'Sat'),
 Text(6,0,'Sun')]
/ In beide gevallen klopt het niet	, hij begint met Tue	, 
/ we moeten 	,
In [4473]: plt.gca().set_xticklabels([0,'Mon','Tue','Wed','Thu','Fri','Sat','Sun'])
Out[4473]: 
[Text(0,0,'0'),
 Text(1,0,'Mon'),
 Text(2,0,'Tue'),
 Text(3,0,'Wed'),
 Text(4,0,'Thu'),
 Text(5,0,'Fri'),
 Text(6,0,'Sat'),
 Text(7,0,'Sun')]
/ TODO

/ 13	. 

/ in .pivot_table geeft hij geen columns op, dus deze 2 zijn hetzelfde	,

In [4486]: b=births2.groupby([idx.month,idx.day])['births'].mean()
/=
In [4487]: b=births2.pivot_table('births',[births2.index.month,births2.index.day])
In [4487]: b
Out[4488]: 
         births
1  1   4009.225
   2   4247.400
...
   30  4644.225 	-- 30 nov	,
...         ...
12 2   4830.300
   3   4758.500
...
   31  4859.200

[366 rows x 1 columns]

In [4532]: b.loc[1]
/=
In [4532]: b.loc[1,]
/=
In [4532]: b.loc[1,:]
Out[4531]: 
      births
1   4009.225
2   4247.400
3   4500.900
4   4571.350
5   4603.625
6   4668.150
7   4706.925
8   4629.650
9   4537.775
10  4591.700
11  4675.150
12  4700.800
13  4730.050
14  4816.200
15  4733.650
16  4665.025
17  4654.650
18  4707.325
19  4731.525
20  4767.525
21  4790.250
22  4742.800
23  4666.750
24  4653.200
25  4698.000
26  4715.900
27  4747.025
28  4771.800
29  4702.300
30  4644.225
31  4598.275
/ maar 
In [4534]: b.loc[1,:31]
/ ERR
/ TODO

/ in b komt ook de index (2,29) voor,
/ we moeten dus een schrikkeljaar kiezen 	,

In [4549]: pd.datetime(2012,2,29).month
Out[4549]: 2
In [4548]: pd.datetime(2013,2,29).month
ValueError: day is out of range for month
/ kies dus 2012	,

In [4565]: l=[pd.datetime(2012,m,d)for(m,d)in b.index]
/ een list	,
In [4568]: l[:2]
Out[4568]: [datetime.datetime(2012, 1, 1, 0, 0), datetime.datetime(2012, 1, 2, 0, 0)]
/ een list kent geen .loc	,
In [4569]: pd.Series(l).loc[:10]
Out[4569]: 
0    2012-01-01
1    2012-01-02
2    2012-01-03
3    2012-01-04
4    2012-01-05
5    2012-01-06
6    2012-01-07
7    2012-01-08
8    2012-01-09
9    2012-01-10
10   2012-01-11
dtype: datetime64[ns]

In [4570]: b.index=l

In [4571]: b
Out[4571]: 
2012-01-01    4009.225
2012-01-02    4247.400
...
In [4572]: fig,ax=plt.subplots(figsize=(12,4))
/ we zien de assen	,
In [4574]: b.plot(ax=ax)
/ we zien de grafiek	,

/ EINDE (178) 

/ Hieronder staan Intermezzos	, 

/ We gaan verder op VERVOLG (178)











/ Intermezzo

/ verschil births en births2	?
/ lees	,
https://stackoverflow.com/questions/48647534/python-pandas-find-difference-between-two-data-frames

n [3539]: pd.concat([births,births2]).drop_duplicates(keep=False)
Out[3539]: 
       year  month   day gender  births  decade
62     1969      1  99.0      F      26    1960	/ WH births=26 te weinig	,
63     1969      1  99.0      M      38    1960
120    1969      2  29.0      F      50    1960
...
15517  2007     10   NaN      F  180912    2000
15518  2007     10   NaN      M  189157    2000
15519  2007     11   NaN      F  173513    2000



In [3544]:  births.iloc[62]
Out[3544]: 
year      1969
month        1
day         99
gender       F
births      26
decade    1960
Name: 62, dtype: object

In [3545]:  births2.iloc[62]
Out[3545]: 
year      1969
month        2
day          1
gender       F
births    4394
decade    1960
Name: 64, dtype: object



/ Einde Intermezzo






/ TODO

/ Einde Intermezzo






















/ MISC

/ Intermezzo

/ dfs

/ 1313	. 

In [1626]: df11
Out[1626]: 
  key  data1  data2
0   A      0      2
1   B      1      3
2   C      2      0
3   A      3      0
4   B      4      6
5   C      5      0

In [1627]: df11.unstack()
Out[1627]: 
key    0    A
       1    B
       2    C
       3    A
       4    B
       5    C
data1  0    0
       1    1
       2    2
       3    3
       4    4
       5    5
data2  0    2
       1    3
       2    0
       3    0
       4    6
       5    0
dtype: object

/ 1313	.

In [1635]: a=pd.Series({'A':11,'B':12,'C':13,'A':21,'B':22,'C':23})

In [1636]: b=pd.Series({'A':31,'B':32,'C':33,'A':41,'B':42,'C':43})

In [1631]: df12=pd.DataFrame({'area':a,'pop':b})

In [1639]: df12
Out[1639]: 
   area  pop
A    21   41
B    22   42
C    23   43
/ we zien om dat A,B,C de index zijn, uniek is, en hij de laatste pakt	,

In [1641]: df12.columns
Out[1641]: Index(['area', 'pop'], dtype='object')

In [1640]: df12.index
Out[1640]: Index(['A', 'B', 'C'], dtype='object')

In [1638]: df12['area']['A']
Out[1638]: 21
/ Dus je moet eerst de column geven; dat zijn we niet gewend	, maar toch wel logisch	,

In [1662]: s=df12['area']
/ een ser	,
/ is GEEN copy 	,

In [1665]: s['B']=np.NaN
/ of	,
In [1665]: s['B']=None
In [1830]: s
Out[1830]: 
A    21.0
B     NaN
C    23.0
Name: area, dtype: float64

In [1666]: df12
Out[1666]: 
   area  pop
A  21.0   41
B   NaN   42
C  23.0   43

In [1667]: s.isna()
Out[1667]: 
A    False
B     True
C    False
Name: area, dtype: bool
/ ook een ser	,

In [1670]: s[~s.isna()]
Out[1670]: 
A    21.0
C    23.0
Name: area, dtype: float64
/ ook een ser	,

In [1682]: s[{'A':False,'B':False,'C':False}]
Out[1682]: 
A    21.0
B     NaN
C    23.0
Name: area, dtype: float64
/ Doet NIETS	,

In [1744]: s[pd.Series({'A':False,'B':False,'C':True})]
Out[1744]: 
C    23.0
Name: area, dtype: float64

In [1742]: s[s]
Out[1742]: 
area
 21.0   NaN
NaN     NaN
 23.0   NaN
Name: area, dtype: float64

In [1760]: s.index
Out[1760]: Index(['A', 'B', 'C'], dtype='object')


In [1761]: s[s].index
Out[1761]: Float64Index([21.0, 22.0, 23.0], dtype='float64', name='area')
/ Daarom zien we area bovenin de index	, 

/ google	,
pandas how to remove name from index
/ lees	,
https://stackoverflow.com/questions/29765548/remove-index-name-in-pandas
/ als je de name attr van een index wilt rm, doe dan	,
In [1779]: del df12.index.name
/ of	,
In [1784]: df12.index.name=None
/ of
In [1789]: s.index=pd.Index(['A', 'B', 'C'], dtype='object')
/ of	,
n [1791]: s.index=pd.Index(['A', 'B', 'C'])

/ zo kun je ook de Series maken	,
In [1799]: t=pd.Series([21.,22.,23.],index=['A','B','C'])
In [1801]: t.index
Out[1801]: Index(['A', 'B', 'C'], dtype='object')

/ Einde Intermezzo




/ Intermezzo

/ s[:,np.newaxis] is een numpy.ndarray	, 
/ s[0:2], s['A':'C'] is een Serial	, een slice	,
/ s[[0,2]], s[['A','C']] is een Serial	, fancy indexing,

In [1693]: ser
Out[1693]: 
0    1
1    2
2    3
dtype: int64

In [1690]: ser[:,np.newaxis]
Out[1690]: 
array([[1],
       [2],
       [3]])

In [1695]: type(ser)
Out[1695]: pandas.core.series.Series

In [1694]: type(ser[:,np.newaxis])
Out[1694]: numpy.ndarray
In [1719]: ser[:,np.newaxis].ndim
Out[1719]: 2
/ het is geen Series meer!

/ dus de huidige array verschijnt op de plaats van de :	,
/ je kunt maar 1 keer : geven	, dus ser[:,np.newaxis,np.newaxis] is ook okay	,

In [1722]: s[0:2]
Out[1722]: 
A    21.0
B     NaN
Name: area, dtype: float64

In [1723]: s['A':'C']
Out[1723]: 
A    21.0
B     NaN
C    23.0
Name: area, dtype: float64

In [1724]: type(s[0:2])
Out[1724]: pandas.core.series.Series

In [1732]: s[[1,2]]
Out[1732]: 
B     NaN
C    23.0
Name: area, dtype: float64

In [1733]: s[['A','B']]
Out[1733]: 
A    21.0
B     NaN
Name: area, dtype: float64

In [1734]: s[['A':'B']]
/ ERR	,

In [1735]: s[[True,True,False]]
Out[1735]: 
A    21.0
B     NaN
Name: area, dtype: float64


/ Einde Intermezzo

/ Intermezzo

In [1840]: s=pd.Series([21.,None,23.],index=['A','B','C'])

In [1850]: s
Out[1850]: 
A    21.0
B     NaN
C    23.0
dtype: float64

In [1852]: t=~s.isna()

In [1853]: t
Out[1853]: 
A     True
B    False
C     True
dtype: bool

In [1854]: s[s]
Out[1854]: 
 21.0   NaN
NaN     NaN
 23.0   NaN
dtype: float64

In [1855]: s[s].index
Out[1855]: Float64Index([21.0, nan, 23.0], dtype='float64')

In [1856]: s[t]
Out[1856]: 
A    21.0
C    23.0
dtype: float64

In [1857]: s[t].index
Out[1857]: Index(['A', 'C'], dtype='object')

/ TODO STACKOVERFLOW



/ Einde Intermezzo
 

/ Intermezzo

/ MultiIndex	,

/ (130)

/ 1313	. 

/ stack, unstack	,

/ onthoud: stack = series	, beginnen beide met s	,

/ 1313	.

Signature: df12.stack(level=-1, dropna=True)
Docstring:
Stack the prescribed level(s) from columns to index.


In [1922]: df12
Out[1922]: 
   area  pop
A  21.0   41
B  22.0   42
C  23.0   43


/ er is nu maar 1 level in de column	,
In [1926]: s12=df12.stack()
/=
In [1926]: s12=df12.stack(level=0)
/=
In [1926]: s12=df12.stack(level=-1)

In [1928]: s12
Out[1928]: 
A  area    21.0
   pop     41.0
B  area    22.0
   pop     42.0
C  area    23.0
   pop     43.0
dtype: float64

/ een Series	,

In [1930]: s12.index
Out[1930]: 
MultiIndex(levels=[['A', 'B', 'C'], ['area', 'pop']],
           labels=[[0, 0, 1, 1, 2, 2], [0, 1, 0, 1, 0, 1]])

/ 1313	. 

Unstack, a.k.a. pivot, Series with MultiIndex to produce DataFrame.
The level involved will automatically get sorted.
Parameters
----------
level : int, string, or list of these, default last level
    Level(s) to unstack, can pass level name

In [1944]: s12.unstack(level=0)
Out[1944]: 
         A     B     C
area  21.0  22.0  23.0
pop   41.0  42.0  43.0

In [1945]: s12.unstack(level=1)
/=
In [1945]: s12.unstack(level=-1)
Out[1945]: 
   area   pop
A  21.0  41.0
B  22.0  42.0
C  23.0  43.0

/ 1313	. 

In [1948]: s15=pd.Series(np.arange(1,9),index=pd.MultiIndex.from_product([['foo','bar'],['a','b'],['1','2']]))

In [1949]: s15
Out[1949]: 
foo  a  1    1
        2    2
     b  1    3
        2    4
bar  a  1    5
        2    6
     b  1    7
        2    8
dtype: int64

In [1950]: s15.index
Out[1950]: 
MultiIndex(levels=[['bar', 'foo'], ['a', 'b'], ['1', '2']],
           labels=[[1, 1, 1, 1, 0, 0, 0, 0], [0, 0, 1, 1, 0, 0, 1, 1], [0, 1, 0, 1, 0, 1, 0, 1]])
/ we zien dat de levels worden sorted, dus ['bar','foo'] 	,

In [1951]: s15.unstack(level=0)
Out[1951]: 
     bar  foo
a 1    5    1
  2    6    2
b 1    7    3
  2    8    4

In [1952]: s15.unstack(level=1)
Out[1952]: 
       a  b
bar 1  5  7
    2  6  8
foo 1  1  3
    2  2  4

In [1955]: u15=s15.unstack(level=[0,1])
In [1955]: u15
Out[1955]: 
  foo    bar   
    a  b   a  b
1   1  3   5  7
2   2  4   6  8

In [1969]: type(u15)
Out[1969]: pandas.core.frame.DataFrame

In [1970]: u15.columns
Out[1970]: 
MultiIndex(levels=[['bar', 'foo'], ['a', 'b']],
           labels=[[1, 1, 0, 0], [0, 1, 0, 1]])

In [1972]: df12.columns
Out[1972]: Index(['area', 'pop'], dtype='object')

In [1958]: s15.unstack(level=[0,2])
Out[1958]: 
  foo    bar   
    1  2   1  2
a   1  2   5  6
b   3  4   7  8

In [1966]: s15.unstack(level=[0,1,2])
/ ERR	,
AttributeError: 'Int64Index' object has no attribute 'remove_unused_levels'

/ 1313	. 

/ fancy indexing kan alleen met numpy.array	, niet bij lists uit Python	,

In [2019]: a=np.array(['a',4,.21,3])

In [2020]: a
Out[2020]: array(['a', '4', '0.21', '3'], dtype='<U4')

In [2021]: a[[1,2]]
Out[2021]: array(['4', '0.21'], dtype='<U4')
/ dit is fancy indexing	,

In [2022]:  a[1:2]
Out[2022]: array(['4'], dtype='<U4')
/ dit is een slice	, is weer een numpy.array	,


/ 131313	.

In [2012]: a
Out[2012]: ['a', 4, 0.21, 3]

In [2015]: a[[0,1]]
TypeError: list indices must be integers or slices, not list

In [2024]: a[1:2]
Out[2024]: [4]
/ slice kan wel	, is weer een list


/ 1313	. 

/ fancy indexing bij series	,

/ s['A'] is een item	, s['A':'C'] is een slice, en ook weer een series	, s[['A','C']] is fancy indexing, en ook weer een series	,

In [2001]: s
Out[2001]: 
A    21.0
B     NaN
C    23.0
dtype: float64

In [2005]: s.index
Out[2005]: Index(['A', 'B', 'C'], dtype='object')

In [2002]: s['A']
Out[2002]: 21.0

s['A'].index
AttributeError: 'numpy.float64' object has no attribute 'index'


In [2003]: s[['A']]
Out[2003]: 
A    21.0
dtype: float64

In [2007]: s[['A']].index
Out[2007]: Index(['A'], dtype='object')

In [2004]: s[['A','B','C']].equals(s)
Out[2004]: True


/ 1313	. 

/ Hetzelfde zien we bij	,

/ multiindex series	, we kunnen item pakken , en fancy indexing	, maar slices TODO

In [2027]: s15
Out[2027]: 
foo  a  1    1
        2    2
     b  1    3
        2    4
bar  a  1    5
        2    6
     b  1    7
        2    8
dtype: int64


In [1987]: s15['foo']
Out[1987]: 
a  1    1
   2    2
b  1    3
   2    4
dtype: int64

In [2000]: s15.index
Out[2000]: 
MultiIndex(levels=[['bar', 'foo'], ['a', 'b'], ['1', '2']],
           labels=[[1, 1, 1, 1, 0, 0, 0, 0], [0, 0, 1, 1, 0, 0, 1, 1], [0, 1, 0, 1, 0, 1, 0, 1]])


In [1988]: s15['foo'].index
Out[1988]: 
MultiIndex(levels=[['a', 'b'], ['1', '2']],
           labels=[[0, 0, 1, 1], [0, 1, 0, 1]])

In [1989]: s15[['foo']]
Out[1989]: 
foo  a  1    1
        2    2
     b  1    3
        2    4
dtype: int64

In [1990]: s15[['foo']].index
Out[1990]: 
MultiIndex(levels=[['bar', 'foo'], ['a', 'b'], ['1', '2']],
           labels=[[1, 1, 1, 1], [0, 0, 1, 1], [0, 1, 0, 1]])

In [1999]: s15[['foo','bar']].equals(s15)
Out[1999]: True

/ Hoe slice	,
s15['foo':'bar']
/ ERR



/ 1313	. 

In [1925]: u12=df12.unstack()

In [1927]: u12
Out[1927]: 
area  A    21.0
      B    22.0
      C    23.0
pop   A    41.0
      B    42.0
      C    43.0
dtype: float64


In [1929]: u12.index
Out[1929]: 
MultiIndex(levels=[['area', 'pop'], ['A', 'B', 'C']],
           labels=[[0, 0, 0, 1, 1, 1], [0, 1, 2, 0, 1, 2]])
/ TODO

/ 1313	. 

In [1979]: g=titanic.groupby(['survived','sex'])

In [1891]: d=g.describe()

/ 'n item	, ook een df, maar de columns=Index	,
In [1892]: d['age']
Out[1892]: 
          count       mean        std   min   25%   50%   75%   max
survived                                                           
0         424.0  30.626179  14.172110  1.00  21.0  28.0  39.0  74.0
1         290.0  28.343690  14.950952  0.42  19.0  28.0  36.0  80.0

/ fancy indexing	, ook een df, maar de columns=MultiIndex, die van d	, 
In [1893]: d[['age']]
Out[1893]: 
            age                                                    
          count       mean        std   min   25%   50%   75%   max
survived                                                           
0         424.0  30.626179  14.172110  1.00  21.0  28.0  39.0  74.0
1         290.0  28.343690  14.950952  0.42  19.0  28.0  36.0  80.0

In [1894]: d['age'].columns
Out[1894]: Index(['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'], dtype='object')

In [1895]: d[['age']].columns
Out[1895]: 
MultiIndex(levels=[['age', 'fare', 'parch', 'pclass', 'sibsp'], ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']],
           labels=[[0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 2, 3, 4, 5, 6, 7]])

/ dit snappen we nu	, 8 keer 'age'	, en dan afzonderlijk 'count', 'mean', ...

In [1896]: d[['age','fare']].columns
Out[1896]: 
MultiIndex(levels=[['age', 'fare', 'parch', 'pclass', 'sibsp'], ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']],
           labels=[[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], [0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7]])

/ dus 8 keer 'age', 8 keer 'fare', en bij elk afzonderlijk 'count', 'mean'	, ...

/ Einde Intermezzo
 

/ Intermezzo

Categoricals are a pandas data type corresponding to categorical variables in statistics. A categorical variable takes on a limited, and usually fixed, number of possible values (categories; levels in R). Examples are gender, social class, blood type, country affiliation, observation time or rating via Likert scales.

/ In Java WH enum	,

/ lees	,
https://en.wikipedia.org/wiki/Dummy_variable_(statistics)
/ see ANOVA model with one qualitative variable: ze nemen 1 dummy minder dan dat er mogelijkheden zijn voor de category	,
https://www.statisticshowto.datasciencecentral.com/dummy-variables/
http://www.restore.ac.uk/srme/www/fac/soc/wie/research-new/srme/modules/mod3/7/index.html
https://dss.princeton.edu/online_help/analysis/dummy_variables.htm

If you have a nominal variable that has more than two levels, you need to create multiple dummy variables to "take the place of" the original nominal variable. For example, imagine that you wanted to predict depression from year in school: freshman, sophomore, junior, or senior. Obviously, "year in school" has more than two levels.

What you need to do is to recode "year in school" into a set of dummy variables, each of which has two levels. The first step in this process is to decide the number of dummy variables. This is easy; it's simply k-1, where k is the number of levels of the original variable.

You could also create dummy variables for all levels in the original variable, and simply drop one from each analysis.

In this instance, we would need to create 4-1=3 dummy variables. In order to create these variables, we are going to take 3 of the levels of "year of school", and create a variable corresponding to each level, which will have the value of yes or no (i.e., 1 or 0). In this instance, we can create a variable called "sophomore," "junior," and "senior." Each instance of "year of school" would then be recoded into a value for "sophomore," "junior," and "senior." If a person were a junior, then "sophomore" would be equal to 0, "junior" would be equal to 1, and "senior" would be equal to 0.

In our example, "freshman" was not coded so that we could determine if being a sophomore, junior, or senior predicts a different depressive level than being a freshman. Consequently, if the variable, "junior" was significant in our regression, with a positive beta coefficient, this would mean that juniors are significantly more depressed than freshman. Alternatively, we could have decided to not code "senior," if we thought that being a senior is qualitatively different from being of another year.

/ Einde Intermezzo
 
/ Intermezzo

/ pandas.concat contacts indexes, pandas.join de columns	,

In [2155]: s2
Out[2155]: 
A    11
B    12
C    13
dtype: int64

In [2159]:  t
Out[2159]: 
A     True
B    False
C     True
dtype: bool

/ De indexes zijn gelijk	,

In [2158]: s2[t]
Out[2158]: 
A    11
C    13
dtype: int64

In [2172]: s3=pd.concat([s2,pd.Series({'D':14})])
In [2173]: s3
Out[2173]: 
A    11
B    12
C    13
D    14
dtype: int64

In [2174]: t2=pd.concat([t,pd.Series({'D':True})])
In [2176]: t2
Out[2176]: 
A     True
B    False
C     True
D     True
dtype: bool

/ de index is te klein, en weet dus niet wat hij met D van s3 moet doen	,
In [2186]: s3[t]
IndexingError: Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match

/ de index is te groot, maar dat geeft niet	,
In [2193]: s[t2]
Out[2193]: 
A    21.0
C    23.0
dtype: float64


/ Einde Intermezzo

/ Intermezzo

/ lees	,
https://pandas.pydata.org/pandas-docs/stable/indexing.html
/ Boolean indexing




/ Einde Intermezzo

/ Intermezzo

In [2211]: s14=pd.Series(np.arange(100,200))
In [2216]: c14=pd.cut(s14,[100-1,125,150,175,200])

In [2217]: c14
Out[2217]: 
0      (99, 125]
1      (99, 125]
2      (99, 125]
...
97    197
98    198
99    199
Length: 100, dtype: int64

In [2221]:  type(c14)
Out[2221]: pandas.core.series.Series
/ dezelfde index als s14	,

In [2286]:  c14.dtype
Out[2286]: 
CategoricalDtype(categories=[(99, 125], (125, 150], (150, 175], (175, 200]]
              ordered=True)


In [2240]: r14=pd.Series(rs.randint(100,200,100))

In [2288]: r14.dtype
Out[2288]: dtype('int64')

In [2232]: l14=s14<150

In [2287]: l14.dtype
Out[2287]: dtype('bool')


/ l14 is een boolean series	, r14 en c14 niet	,

In [2252]:  l14
Out[2252]: 
0      True
1      True
...
98    False
  99    False
Length: 100, dtype: bool

In [2253]:  s14[l14] 
Out[2253]: 
0     100
1     101
2     102
...
48    148
49    149
dtype: int64
/ Toont alleen waarvoor True	, dus in dit geval de helft	,

In [2257]: s14[r14]
/ ERR	,

In [2258]: s14[c14]
Out[2258]: 
(99, 125]    NaN
(99, 125]    NaN
...
(175, 200]   NaN
(175, 200]   NaN
Length: 100, dtype: float64
/ TODO

In [2275]: pt=titanic.pivot_table('survived',index='sex',columns='class')       
In [2274]: pt
Out[2274]: 
class      First    Second     Third
sex                                 
female  0.968085  0.921053  0.500000
male    0.368852  0.157407  0.135447
/ gemiddelde per sex en per class	,

/ gemiddelde per sex en age ..., en class	,

In [2275]: age=pd.cut(titanic['age'],[0,18,80])
In [2276]: age
Out[2276]: 
0      (18, 80]
1      (18, 80]
...
888         NaN
889    (18, 80]
890    (18, 80]
Name: age, Length: 891, dtype: category
Categories (2, interval[int64]): [(0, 18] < (18, 80]]

In [2277]: type(age)
Out[2277]: pandas.core.series.Series

In [2278]: age.index
Out[2278]: RangeIndex(start=0, stop=891, step=1)

In [2285]: age.dtype
Out[2285]: 
CategoricalDtype(categories=[(0, 18], (18, 80]]
              ordered=True)

In [2294]: titanic.groupby(['sex','class'])['survived'].aggregate('mean')
Out[2294]: 
sex     class 
female  First     0.968085
        Second    0.921053
        Third     0.500000
male    First     0.368852
        Second    0.157407
        Third     0.135447
Name: survived, dtype: float64

In [2295]: age
Out[2295]: 
0      (18, 80]
1      (18, 80]
...
890    (18, 80]
Name: age, Length: 891, dtype: category
Categories (2, interval[int64]): [(0, 18] < (18, 80]]

In [2297]:  age.dtype
Out[2297]: 
CategoricalDtype(categories=[(0, 18], (18, 80]]
              ordered=True)

In [2296]: titanic.groupby(['sex','class',age])['survived'].aggregate('mean')
Out[2296]: 
sex     class   age     
female  First   (0, 18]     0.909091
                (18, 80]    0.972973
        Second  (0, 18]     1.000000
                (18, 80]    0.900000
        Third   (0, 18]     0.511628
                (18, 80]    0.423729
male    First   (0, 18]     0.800000
                (18, 80]    0.375000
        Second  (0, 18]     0.600000
                (18, 80]    0.071429
        Third   (0, 18]     0.215686
                (18, 80]    0.133663
Name: survived, dtype: float64


/ lees	,
https://stackoverflow.com/questions/48162201/pandas-number-of-unique-values-and-sort-by-the-number-of-unique

In [2306]: titanic.groupby('age').describe()
Out[2306]: 
       fare                                   ...  survived                
      count        mean         std       min ...       25%  50%   75%  max
age                                           ...                          
0.42    1.0    8.516700         NaN    8.5167 ...      1.00  1.0  1.00  1.0
0.67    1.0   14.500000         NaN   14.5000 ...      1.00  1.0  1.00  1.0
...
74.00   1.0    7.775000         NaN    7.7750 ...      0.00  0.0  0.00  0.0
80.00   1.0   30.000000         NaN   30.0000 ...      1.00  1.0  1.00  1.0
/ we zien de NaN niet in de group age	,
/ TODO
/ Het duurt even voordat het antwoord komt	,

/ klopt	, 
In [2321]: np.sort(titanic['age'].unique())
Out[2321]: 
array([ 0.42,  0.67,  0.75,  0.83,  0.92,  1.  ,  2.  ,  3.  ,  4.  ,
        5.  ,  6.  ,  7.  ,  8.  ,  9.  , 10.  , 11.  , 12.  , 13.  ,
       14.  , 14.5 , 15.  , 16.  , 17.  , 18.  , 19.  , 20.  , 20.5 ,
       21.  , 22.  , 23.  , 23.5 , 24.  , 24.5 , 25.  , 26.  , 27.  ,
       28.  , 28.5 , 29.  , 30.  , 30.5 , 31.  , 32.  , 32.5 , 33.  ,
       34.  , 34.5 , 35.  , 36.  , 36.5 , 37.  , 38.  , 39.  , 40.  ,
       40.5 , 41.  , 42.  , 43.  , 44.  , 45.  , 45.5 , 46.  , 47.  ,
       48.  , 49.  , 50.  , 51.  , 52.  , 53.  , 54.  , 55.  , 55.5 ,
       56.  , 57.  , 58.  , 59.  , 60.  , 61.  , 62.  , 63.  , 64.  ,
       65.  , 66.  , 70.  , 70.5 , 71.  , 74.  , 80.  ,   nan])

In [2327]: len(titanic['age'][titanic['age'].isna()])
Out[2327]: 177

In [2336]: titanic.groupby(age).describe()
Out[2336]: 
         survived                        ...      fare                    
            count      mean       std    ...       50%       75%       max
age                                      ...                              
(0, 18]     139.0  0.503597  0.501795    ...     20.25  32.19375  262.3750
(18, 80]    575.0  0.382609  0.486447    ...     14.40  33.76040  512.3292
[2 rows x 48 columns]
/ heel snel	,
/ totaal 714	, klopt, want met 177 nan is dat 891 	,

/ Dus age	, 
In [2338]: age.dtype
Out[2338]: 
CategoricalDtype(categories=[(0, 18], (18, 80]]
              ordered=True)

////////////////////////////
/ kun je alleen use in een groupby	, niet als een index	,
/ dus titanic[age] is ERR	, titanic.groupby(age) is OK	,
/ titanic.groupby('age') is ook OK, maar duurt lang	,
/ TODO

/ Einde Intermezzo

/ Intermezzo

/ categories	,

/ lees	,
https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.unique.html

In [2347]: age=pd.cut(titanic['age'],[0,18,80])
In [2348]: age
Out[2348]: 
0      (18, 80]
1      (18, 80]
...
888         NaN
889    (18, 80]
890    (18, 80]
Name: age, Length: 891, dtype: category
Categories (2, interval[int64]): [(0, 18] < (18, 80]]

In [2349]:  age.dtype
Out[2349]: 
CategoricalDtype(categories=[(0, 18], (18, 80]]
              ordered=True)

/ op een series zoals age, geef je .dtype	, 
/ op een df use je .dtypes	,

In [2355]: titanic.dtypes
Out[2355]: 
survived          int64
pclass            int64
sex              object
age             float64
sibsp             int64
parch             int64
fare            float64
embarked         object
class          category
who              object
adult_male         bool
deck           category
embark_town      object
alive            object
alone              bool
dtype: object

In [2358]: titanic['deck'].dtype
Out[2358]: CategoricalDtype(categories=['A', 'B', 'C', 'D', 'E', 'F', 'G'], ordered=False)

In [2364]: f=pd.cut( titanic['fare'],[0,50,100]) 
In [2368]: f
Out[2368]: 
0        (0, 50]
1      (50, 100]
...
27	 		NaN
...
/ als de fare >100, is f NaN	,

In [2369]: f.dtype
Out[2369]: 
CategoricalDtype(categories=[(0, 50], (50, 100]]
              ordered=True)

/ is al een categorial type	,
In [2373]: titanic['deck']
Out[2373]: 
0      NaN
1        C
...
890    NaN
Name: deck, Length: 891, dtype: category
Categories (7, object): [A, B, C, D, E, F, G]

/ je hebt 7 categorieen	,
/ dan werkt pd.cut niet	, want je kunt geen intervallen maken	,
/ TODO

/ we zien categorieen (0,50] , maar ook 'A'	, 

/ 1313	. 

/ we kunnen ze ook zelf maken	,

In [2374]:  pd.Categorical(list('abac'))
Out[2374]: 
[a, b, a, c]
Categories (3, object): [a, b, c]

In [2377]:  pd.Categorical(list('abac'),ordered=True)
Out[2377]: 
[a, b, a, c]
Categories (3, object): [a < b < c]

/ 1313	. 

/ lees	,
https://pandas.pydata.org/pandas-docs/stable/generated/pandas.api.types.CategoricalDtype.html

/ CategoricalDtype= categorical data type	,

In [7]: import pandas as pd

In [2398]: t = pd.api.types.CategoricalDtype(categories=['b', 'a'], ordered=True
      ...: )
/ OK	,
In [2398]: t = pandas.api.types.CategoricalDtype(categories=['b', 'a'], ordered=True
/ ERR
NameError: name 'pandas' is not defined
/ TODO

In [2399]: from pandas.api.types import CategoricalDtype
In [2400]: t =CategoricalDtype(categories=['b', 'a'], ordered=True)

/ t is een type die als values 2 categorieen heeft: 'b' en 'a'	, 'b' is een categorie en 'a' ook	,

In [2404]: s=pd.Series(list('abac'),dtype=t)

In [2405]: s
Out[2405]: 
0      a
1      b
2      a
3    NaN
dtype: category
Categories (2, object): [b < a]

/ 1313	. 

/ lees	,
https://pandas.pydata.org/pandas-docs/stable/categorical.html

/ 131313	.

In [2389]: s = pd.Series(list('abca'), dtype="category")

In [2390]: s
Out[2390]: 
0    a
1    b
2    c
3    a
dtype: category
Categories (3, object): [a, b, c]

In [2391]: s.dtype
Out[2391]: CategoricalDtype(categories=['a', 'b', 'c'], ordered=False)

/ TODO
https://pandas.pydata.org/pandas-docs/stable/categorical.html

/ Herinner	, 

In [2414]: idx=pd.MultiIndex.from_product([[1,2],[3,4]])

In [2415]: ser=pd.Series(list('abcd'),index=idx)

In [2416]: ser
Out[2416]: 
1  3    a
   4    b
2  3    c
   4    d
dtype: object

In [2417]: idx
Out[2417]: 
MultiIndex(levels=[[1, 2], [3, 4]],
           labels=[[0, 0, 1, 1], [0, 1, 0, 1]])


/ Einde Herinner	, 

/ 1313	. 

In [2347]: age=pd.cut(titanic['age'],[0,18,80])
In [2407]: df17=titanic.groupby(age).describe()
In [2410]: df17.index
Out[2410]: CategoricalIndex([(0, 18], (18, 80]], categories=[(0, 18], (18, 80]], ordered=True, name='age', dtype='category')

/ zelf maken	,

/ 131313	. 

In [2424]: idx=pd.CategoricalIndex([1,2,3,4])

In [2425]: idx
Out[2425]: CategoricalIndex([1, 2, 3, 4], categories=[1, 2, 3, 4], ordered=False, dtype='category')

/ 131313	. 
In [2423]: idx=pd.CategoricalIndex([(0,18],(18,80]])
/ ERR	,

/ lees	,
https://pandas.pydata.org/pandas-docs/stable/categorical.html
Categorical Index

/ 131313	. 

In [2474]:  raw_cat = pd.Categorical(["a","b","c","a"])

In [2475]: raw_cat
Out[2475]: 
[a, b, c, a]
Categories (3, object): [a, b, c]
/ Hij maakt zelf de cats ogv de data list	,



In [2476]:  raw_cat2 = pd.Categorical(["a","b","c","a"], categories=["b","c","d"
      ...: ])

In [2478]: raw_cat2
Out[2478]: 
[NaN, b, c, NaN]
Categories (3, object): [b, c, d]

In [2477]:  raw_cat3 = pd.Categorical(["a","b","c","a"], categories=["b","c","d"
      ...: ],ordered=False)

In [2479]: raw_cat3
Out[2479]: 
[NaN, b, c, NaN]
Categories (3, object): [b, c, d]
/ TODO

/ 131313	. 

/ maakt de cats ogv de data list	,

In [2480]: pd.Categorical(rng.randint(1,10,5))
Out[2480]: 
[9, 3, 9, 7, 7]
Categories (3, int64): [3, 7, 9]

In [2509]: pd.Categorical(categories=[4,2,3,1])
TypeError: __init__() missing 1 required positional argument: 'values'
/////////////////////////////////////////
/ dus een Categorical is een list die categories bevat	,
/ als je alleen values geeft, dan leidt hij de categories eruit af	,


/ 131313	. 

In [2481]: raw_cat2
Out[2481]: 
[NaN, b, c, NaN]
Categories (3, object): [b, c, d]

In [2482]: s=pd.Series(raw_cat2)

In [2483]: s
Out[2483]: 
0    NaN
1      b
2      c
3    NaN
dtype: category
Categories (3, object): [b, c, d]

In [2498]: type(raw_cat2)
Out[2498]: pandas.core.arrays.categorical.Categorical
In [2499]: type(s)
Out[2499]: pandas.core.series.Series

In [2495]: s.dtype
Out[2495]: CategoricalDtype(categories=['b', 'c', 'd'], ordered=False)
In [2497]: raw_cat2.dtype
Out[2497]: CategoricalDtype(categories=['b', 'c', 'd'], ordered=False)

/ Het verschil tussen een Categorical en een Series is WH dat een Categorical een list heeft en een Series een map 	,

/ 131313	. 

In [2500]: df = pd.DataFrame({'A': list('abca'), 'B': list('bccd')}, dtype="cate
      ...: gory")
In [2501]: df
Out[2501]: 
   A  B
0  a  b
1  b  c
2  c  c
3  a  d
In [2507]: df['A'].dtype
Out[2507]: CategoricalDtype(categories=['a', 'b', 'c'], ordered=False)

In [2508]: df.dtypes
Out[2508]: 
A    category
B    category
dtype: object
/ vager	,

/ 131313	 .


/ TODO Afmaken	, 

/ 131313	. 


In [2426]: cats = pd.Categorical([1,2,3,4], categories=[4,2,3,1])
In [2428]: df = pd.DataFrame({"strings":list('abcd'), "values":[4,3,2,1]}, index=cats)

In [2429]: df
Out[2429]: 
  strings  values
1       a       4
2       b       3
3       c       2
4       d       1

In [2430]: df.index
Out[2430]: CategoricalIndex([1, 2, 3, 4], categories=[4, 2, 3, 1], ordered=False, dtype='category')

In [2431]: df.sort_index()
Out[2431]: 
  strings  values
4       d       1
2       b       3
3       c       2
1       a       4









/ Einde Intermezzo

/ Intermezzo

/ CATEGORIES 

/ lees	,
https://pandas.pydata.org/pandas-docs/stable/categorical.html

/ 13	. 

/ maak een categorical: een ding met een np.ndarray, waarvan de item type CategoricalDType hebben , het zijn Categories zeggen we	,

In [2921]: cat=pd.Categorical(list('abcd'),categories=list('abc'))

In [2922]: cat
Out[2922]: 
[a, b, c, NaN]
Categories (3, object): [a, b, c]

In [2932]: cat.dtype
Out[2932]: CategoricalDtype(categories=['a', 'b', 'c'], ordered=False)

In [2953]: cat.values
AttributeError: 'Categorical' object has no attribute 'values'
/ TODO

In [2923]: cat.get_values()
Out[2923]: array(['a', 'b', 'c', nan], dtype=object)

In [2924]: type(cat.get_values())
Out[2924]: numpy.ndarray

/ bij een Series is het precies andersom: .values OK	, .get_values() ERR	,


/ 13	.  

In [2925]: ser=pd.Series(cat)

In [2926]: ser
Out[2926]: 
0      a
1      b
2      c
3    NaN
dtype: category
Categories (3, object): [a, b, c]

In [2927]: ser.dtype
Out[2927]: CategoricalDtype(categories=['a', 'b', 'c'], ordered=False)

In [2928]: ser.values
Out[2928]: 
[a, b, c, NaN]
Categories (3, object): [a, b, c]

In [2929]: ser.values()
TypeError: 'Categorical' object is not callable
/ TODO

In [2930]: ser.get_values()
Out[2930]: array(['a', 'b', 'c', nan], dtype=object)

In [2931]: type(ser.get_values())
Out[2931]: numpy.ndarray

/ 13	.

In [2956]: df=pd.DataFrame(list('abcd'))

In [2958]: df['B']=cat

In [2959]: df
Out[2959]: 
   0    B
0  a    a
1  b    b
2  c    c
3  d  NaN

In [2960]: df.dtypes
Out[2960]: 
0      object
B    category
dtype: object

/ 13	. 

/ als je alleen values geeft, dus geen categories=, dan wordt de type daarvan gen	,

In [2961]: ser=pd.Series(list('abcd'),dtype='category')
In [2966]: ser.dtype
Out[2966]: CategoricalDtype(categories=['a', 'b', 'c', 'd'], ordered=False)

/ 13	. 

/ hierboven: categories= 	, 
/ nu nog anders, met .astype	,

In [2968]: ser=pd.Series(list('abcd'))
In [2971]: cat_type=CategoricalDtype(categories=list('abc'))
In [2976]: ser=ser.astype(cat_type)
In [2976]: ser
Out[2976]: 
0      a
1      b
2      c
3    NaN
dtype: category
Categories (3, object): [a < b < c]
In [2980]: ser.dtype
Out[2980]: CategoricalDtype(categories=['a', 'b', 'c'], ordered=True)

/ 13	.

/ zo kan het ook	,

In [3026]: pd.Categorical.from_codes([1,1,1,1,0],categories=['train','test'])
Out[3026]: 
[test, test, test, test, train]
Categories (2, object): [train, test]

/ 13	. 

In [3027]: ser=pd.Series(list('abcd'))

In [3028]: ser
Out[3028]: 
0    a
1    b
2    c
3    d
dtype: object

In [3029]: ser=ser.astype('category')

In [3030]: ser
Out[3030]: 
0    a
1    b
2    c
3    d
dtype: category
Categories (4, object): [a, b, c, d]

In [3033]: ser=ser.astype('str')
/ OK	,
In [3035]: ser=ser.astype('category')

In [3036]: np.asarray(ser)
Out[3036]: array(['a', 'b', 'c', 'd'], dtype=object)

/ 13	. 

A CategoricalDtype can be used in any place pandas expects a dtype. For example pandas.read_csv(), pandas.DataFrame.astype(), or in the Series constructor.

Note As a convenience, you can use the string 'category' in place of a CategoricalDtype when you want the default behavior of the categories being unordered, and equal to the set values present in the array. In other words, dtype='category' is equivalent to dtype=CategoricalDtype().

/ 13	. 

/ lees,	
https://pandas.pydata.org/pandas-docs/version/0.23.0/whatsnew.html

/ 13	. 

In [3066]: cat = pd.Categorical(list('acc')+[np.nan], categories=list('bac'))

In [3067]: cat
Out[3067]: 
[a, c, c, NaN]
Categories (3, object): [b, a, c]

/ 13	. 

In [3068]: s=pd.Series(list('abcd'),dtype='category')

In [3069]: s
Out[3069]: 
0    a
1    b
2    c
3    d
dtype: category
Categories (4, object): [a, b, c, d]

In [3070]: s.cat
Out[3070]: <pandas.core.arrays.categorical.CategoricalAccessor object at 0x7ff403a12e10>

In [3071]: s.cat.categories
Out[3071]: Index(['a', 'b', 'c', 'd'], dtype='object')
/ TODO

In [3072]: s=pd.Series(list('abcd'),dtype='str')

In [3073]: s.cat
AttributeError: Can only use .cat accessor with a 'category' dtype

/ 13	. 

In [3102]: cats = pd.Categorical([11,12,13,14], categories=[14,12,13,11])

In [3097]: strings=list('abcd')

In [3098]: values=[4,3,2,1]

In [3099]: df=pd.DataFrame({'strings':strings,'values':values},index=cats)

In [3103]: df=pd.DataFrame({'strings':strings,'values':values},index=cats)

In [3104]: df.index
Out[3104]: CategoricalIndex([11, 12, 13, 14], categories=[14, 12, 13, 11], ordered=False, dtype='category')

In [3105]: df
Out[3105]: 
   strings  values
11       a       4
12       b       3
13       c       2
14       d       1

In [3106]: df.sort_index()
Out[3106]: 
   strings  values
14       d       1
12       b       3
13       c       2
11       a       4

/ Intermezzo

/ DTYPES

/ 13	. 

/ van een np.ndarray is type  np.ndarray	, en dtype de type van de items	, bijv dtype('int32')
/ je kunt ook zelf dtypes maken	,

In [3926]: a=np.array([1,2,3,4])
In [3940]: type(a)
Out[3940]: numpy.ndarray
In [3939]: a.dtype
Out[3939]: dtype('int64')
In [3941]:  a=a.astype('int32')
/ of	,
In [3949]:  a=a.astype('>i4')
In [3942]: a
Out[3942]: array([1, 2, 3, 4], dtype=int32)
/ als dtype=int64 zegt hij dat niet	,
In [3947]: type(a)
Out[3947]: numpy.ndarray
In [3948]: a.dtype
Out[3948]: dtype('int32')

/ 13	. 

/ lees	,
https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.dtype.byteorder.html
https://docs.scipy.org/doc/numpy-1.14.5/reference/arrays.dtypes.html

In [3978]: np.version.full_version
Out[3978]: '1.14.5'


In [3970]: np.dtype('<i4').byteorder
Out[3970]: '='
/ native	,

In [3971]: np.dtype('>i4').byteorder
Out[3971]: '>'

In [3991]: a=np.array(['foo','12','foobarbaz'])
In [3992]: a
Out[3992]: array(['foo', '12', 'foobarbaz'], dtype='<U9')

/ unicode string	, lengte is 2 

In [3996]: a.dtype.isnative
Out[3996]: True
In [3997]: a.dtype.byteorder
Out[3997]: '='

/ 13	. 

In [4012]: a
Out[4012]: array([1, 2, 3, 4])
In [4013]: a.dtype
Out[4013]: dtype('int64')
In [4014]: a.dtype.alignment
Out[4014]: 8
In [4015]: a=a.astype('int32')
In [4016]: a.dtype.alignment
Out[4016]: 4
In [4017]: a=a.astype('int16')
In [4018]: a.dtype.alignment
Out[4018]: 2

In [4021]: a=np.array(['foobarbaz'])
In [4022]: a.dtype.alignment
Out[4022]: 4											/ altijd	,
In [4023]: a.dtype
Out[4023]: dtype('<U9')


/ 13	. 

In [4003]: a.dtype?

Examples
--------
Using array-scalar type:

>>> np.dtype(np.int16)
dtype('int16')

Structured type, one field name 'f1', containing int16:

>>> np.dtype([('f1', np.int16)])
dtype([('f1', '<i2')])

Structured type, one field named 'f1', in itself containing a structured
type with one field:

>>> np.dtype([('f1', [('f1', np.int16)])])
dtype([('f1', [('f1', '<i2')])])

Structured type, two fields: the first field contains an unsigned int, the
second an int32:

>>> np.dtype([('f1', np.uint), ('f2', np.int32)])
dtype([('f1', '<u4'), ('f2', '<i4')])

Using array-protocol type strings:

>>> np.dtype([('a','f8'),('b','S10')])
dtype([('a', '<f8'), ('b', '|S10')])

Using comma-separated field formats.  The shape is (2,3):

>>> np.dtype("i4, (2,3)f8")
dtype([('f0', '<i4'), ('f1', '<f8', (2, 3))])

Using tuples.  ``int`` is a fixed type, 3 the field's shape.  ``void``
is a flexible type, here of size 10:

>>> np.dtype([('hello',(int,3)),('world',np.void,10)])
dtype([('hello', '<i4', 3), ('world', '|V10')])

Subdivide ``int16`` into 2 ``int8``'s, called x and y.  0 and 1 are
the offsets in bytes:

>>> np.dtype((np.int16, {'x':(np.int8,0), 'y':(np.int8,1)}))
dtype(('<i2', [('x', '|i1'), ('y', '|i1')]))

Using dictionaries.  Two fields named 'gender' and 'age':

>>> np.dtype({'names':['gender','age'], 'formats':['S1',np.uint8]})
dtype([('gender', '|S1'), ('age', '|u1')])

Offsets in bytes, here 0 and 25:

>>> np.dtype({'surname':('S25',0),'age':(np.uint8,25)})
dtype([('surname', '|S25'), ('age', '|u1')])

/ lees	,
https://docs.scipy.org/doc/numpy-1.14.5/reference/arrays.dtypes.html

/ we doen zelf	,

In [4038]: dty2=np.dtype([('name', np.unicode_, 16),('grades', np.float64, (2,))])
In [4039]: dty2
Out[4039]: dtype([('name', '<U16'), ('grades', '<f8', (2,))])
n [4042]: a=np.array([('foo',(3,7)),('bar',(7,13))],dtype=dty2)
In [4043]: a
Out[4043]: 
array([('foo', [ 3.,  7.]), ('bar', [ 7., 13.])],
      dtype=[('name', '<U16'), ('grades', '<f8', (2,))])
In [4055]: a[0]
Out[4055]: ('foo', [3., 7.])
In [4056]: type(a[0])
Out[4056]: numpy.void
In [4057]: a[0]['name']
Out[4057]: 'foo'
In [4058]: a[0]['grades']
Out[4058]: array([3., 7.])


In [4025]: dty=np.dtype([('f1',np.int16)])
In [4031]: a=np.array([7,13],dtype=dty) 
In [4032]: a
Out[4032]: array([( 7,), (13,)], dtype=[('f1', '<i2')])
In [4047]: a[0]
Out[4047]: (7,)
In [4050]: a[0]['f1']
Out[4050]: 7
In [4052]: type(a[0])
Out[4052]: numpy.void
In [4053]: type(a[0]['f1'])
Out[4053]: numpy.int16


/ lees	,
https://docs.scipy.org/doc/numpy-1.14.5/reference/arrays.scalars.html#arrays-scalars

/ 13	. 

/ we maken zelf een CategoricalDType	,
/ aan een np.ndarray kunnen we deze dtype niet geven	, 
/ wel aan een pd.Series	,
/ TODO

In [4061]: dty13=CategoricalDtype(categories=[4,13,7,9],ordered=False)
In [4063]: np.array([4,4,7,7,13,9],dtype=dty13)
TypeError: data type not understood

In [4069]: s=pd.Series([4,13,19],dtype=dty13)
In [4069]: s
Out[4069]: 
0     4.0
1    13.0
2     NaN
dtype: category
Categories (4, int64): [4, 13, 7, 9]
In [4081]: type(s)
Out[4081]: pandas.core.series.Series

In [4079]: c=s.values
In [4080]: type(c)
Out[4080]: pandas.core.arrays.categorical.Categorical

In [4087]: a=s.get_values()
In [4088]: type(a)
Out[4088]: numpy.ndarray
In [4089]: a
Out[4089]: array([ 4., 13., nan])

In [4092]: s.dtype
Out[4092]: CategoricalDtype(categories=[4, 13, 7, 9], ordered=False)
In [4090]: c.dtype
Out[4090]: CategoricalDtype(categories=[4, 13, 7, 9], ordered=False)
In [4091]: a.dtype
Out[4091]: dtype('float64')

/ dit klopt met , als je andersom	, 
/ als je een pd.Categorical maakt, heeft deze een dtype CategoricalDType	, 
In [4093]: c2=pd.Categorical([7,7,3])
In [4094]: c2.dtype
Out[4094]: CategoricalDtype(categories=[3, 7], ordered=False)
/////////////////////////////////////////
/ ook is de dtype van het numpy array geen CategoricalDType, maar float64	, dus het numpy array weet helemaal niets over categories	, de Categorical die het array bevat wel	, 

/ Einde DTYPES

/ 13	. 

/ CATEGORICALINDEX

/ we geven een categorical als index, en we krijgen een categoricalindex.
/ wat is het verschil tussen die twee?
/ TODO

In [4162]: c3=pd.Categorical([11,12,13,14])
In [4163]: s3=pd.Series([11,11,13,13,13],index=c3)
In [4165]: s3
Out[4165]: 
11    11
12    11
13    13
14    13
dtype: int64
In [4166]: s3[11]
Out[4166]: 11
In [4167]: s3[12]
Out[4167]: 11
In [4174]:  c3
Out[4174]: 
[11, 12, 13, 14]
Categories (4, int64): [11, 12, 13, 14]
In [4175]: s3.index
Out[4175]: CategoricalIndex([11, 12, 13, 14], categories=[11, 12, 13, 14], ordered=False, dtype='category')
/ we zien het verschil, maar waar zit het hem precies in?
/ TODO
In [4176]: c3.categories
Out[4176]: Int64Index([11, 12, 13, 14], dtype='int64')
In [4177]: s3.index.categories
Out[4177]: Int64Index([11, 12, 13, 14], dtype='int64')
/ deze zijn weer gelijk	,
/ TODO


/ bij floats moet je [] om de float heen zetten bij deref	,
In [4115]: c=pd.Categorical([4.,13.,np.nan],categories=[4.,13.,9.,7.])
In [4104]: c.index
AttributeError: 'Categorical' object has no attribute 'index'
/ maar dat ga ik ook niet doen, ik ga c als index ...
In [4098]: s2=pd.Series(index=c)
In [4107]: s2
Out[4107]: 
 4.0    NaN
 13.0   NaN
NaN     NaN
dtype: float64
In [4111]: idx=s2.index
In [4111]: idx
Out[4099]: CategoricalIndex([4.0, 13.0, nan], categories=[4, 13, 7, 9], ordered=False, dtype='category')
In [4106]: type(c)
Out[4106]: pandas.core.arrays.categorical.Categorical
/ Dus s2.index=c -> NIET s2.index.equals(c)	, 
In [4125]: idx.get_values()
Out[4125]: array([ 4., 13., nan])
In [4122]: idx.categories
Out[4122]: Float64Index([4.0, 13.0, 9.0, 7.0], dtype='float64')
In [4158]: s2[[4.]]
Out[4158]: 
4.0   NaN
dtype: float64
/ zet dus [] om 4. heen 	,

/ 13	. 

In [4184]: np.arange(0,24,4)
Out[4184]: array([ 0,  4,  8, 12, 16, 20])
In [4188]: i=pd.cut(rng.randint(1,21,20),np.arange(0,24,4))
In [4191]: s=pd.Series(rng.randint(1,21,20),index=i)
In [4192]: s
Out[4192]: 
(16, 20]    11
(16, 20]    11
(0, 4]       1
(4, 8]       3
(0, 4]       2
(12, 16]    14
(0, 4]      20
(0, 4]      16
(0, 4]      18
(16, 20]     5
(12, 16]     8
(4, 8]       7
(12, 16]    10
(16, 20]    16
(16, 20]    19
(12, 16]    11
(16, 20]    19
(0, 4]       3
(0, 4]      18
(4, 8]       4
dtype: int64
/ Geen unieke index!
/ Maar	,
In [4194]: s[pd.Interval(4,8)]
Out[4194]: 
(4, 8]    3
(4, 8]    7
(4, 8]    4
dtype: int64
In [4197]: s[pd.Interval(0,4)]
Out[4197]: 
(0, 4]     1
(0, 4]     2
(0, 4]    20
(0, 4]    16
(0, 4]    18
(0, 4]     3
(0, 4]    18
dtype: int64
In [4196]: s.groupby(s.index).describe()
Out[4196]: 
          count       mean       std  min   25%   50%    75%   max
(0, 4]      7.0  11.142857  8.649250  1.0   2.5  16.0  18.00  20.0
(4, 8]      3.0   4.666667  2.081666  3.0   3.5   4.0   5.50   7.0
(8, 12]     0.0        NaN       NaN  NaN   NaN   NaN    NaN   NaN
(12, 16]    4.0  10.750000  2.500000  8.0   9.5  10.5  11.75  14.0
(16, 20]    6.0  13.500000  5.504544  5.0  11.0  13.5  18.25  19.0





/ Einde CATEGORICALINDEX




/ 13	. 

In [3797]: c = pd.Categorical([11,12,13,14], categories=[14,12,13,11])
In [3798]: c
Out[3798]: 
[11, 12, 13, 14]
Categories (4, int64): [14, 12, 13, 11]
In [3800]: type(c)
Out[3800]: pandas.core.arrays.categorical.Categorical
In [3901]: c.dtype
Out[3901]: CategoricalDtype(categories=[14, 12, 13, 11], ordered=False)
In [3912]: c.categories
Out[3912]: Int64Index([14, 12, 13, 11], dtype='int64')
In [3913]: c.describe()
Out[3913]: 
            counts  freqs
categories               
14               1   0.25
12               1   0.25
13               1   0.25
11               1   0.25
In [3919]: v=c.get_values()
In [3919]: v
Out[3919]: array([11, 12, 13, 14])
In [3921]: type(v)
Out[3921]: numpy.ndarray



















In [3801]: s=pd.Series(c)
In [3804]: s.dtype
Out[3804]: CategoricalDtype(categories=[14, 12, 13, 11], ordered=False)
In [3802]: s.cat
Out[3802]: <pandas.core.arrays.categorical.CategoricalAccessor object at 0x7ff402b6cac8>
In [3803]: s.cat.categories
Out[3803]: Int64Index([14, 12, 13, 11], dtype='int64')

In [3895]: dty=s.dtype
In [3896]: dty.categories
Out[3896]: Int64Index([14, 12, 13, 11], dtype='int64')
In [3898]: dty.type
Out[3898]: pandas.core.dtypes.dtypes.CategoricalDtypeType




/ Einde Intermezzo

/ Intermezzo

/ dtype	,

/ lees	,
https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.ftypes.html#pandas.DataFrame.ftypes

In [3809]: a=rs.randn(100,4)

In [3810]: a
Out[3810]: 
array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ],
       [ 1.86755799, -0.97727788,  0.95008842, -0.15135721],
       [-0.10321885,  0.4105985 ,  0.14404357,  1.45427351],
...
In [3811]: a[a<.8]=np.nan
In [3815]: a
Out[3815]: 
array([[1.76405235,        nan, 0.97873798, 2.2408932 ],
       [1.86755799,        nan, 0.95008842,        nan],
       [       nan,        nan,        nan, 1.45427351],
       [       nan,        nan,        nan,        nan],
...
In [3819]: np.isnan(a)
Out[3819]: 
array([[False,  True, False, False],
       [False,  True, False,  True],
       [ True,  True,  True, False],
...

In [3859]: a[np.isnan(a)]
Out[3859]: 
array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
...
In [3860]: a[~np.isnan(a)]
Out[3860]: 
array([1.76405235, 0.97873798, 2.2408932 , 1.86755799, 0.95008842,
       1.45427351, 1.49407907, 0.8644362 , 2.26975462, 1.53277921,
       1.46935877, 1.23029068, 1.20237985, 1.9507754 , 1.13940068,
...
In [3862]: len(a[~np.isnan(a)])
Out[3862]: 80
In [3863]: len(a[np.isnan(a)])
Out[3863]: 320
/ klopt	, 










/ Einde Intermezzo

/ Intermezzo

/ fancy indexing	,

/ lees	,
https://www.scipy-lectures.org/intro/numpy/array_object.html

NumPy arrays can be indexed with slices, but also with boolean or integer arrays (masks). This method is called fancy indexing. It creates copies not views.

/ je kunt index op True/False, maar ook op implicit indexes	,

In [3829]: b=np.array([1,2,3,4])
In [3830]: b
Out[3830]: array([1, 2, 3, 4])
In [3831]: b[[True,False,True,False]]
Out[3831]: array([1, 3])
In [3833]: b[[0,3,2,1]]
Out[3833]: array([1, 4, 3, 2])

In [3835]: b>2
Out[3835]: array([False, False,  True,  True])
In [3836]: b[b>2]
Out[3836]: array([3, 4])

In [3837]: b.index
/ ERR	,

/ lees	,
https://docs.scipy.org/doc/numpy-1.13.0/user/basics.indexing.html





/ Einde Intermezzo

/ Intermezzo

/ where	,

In [3843]: x=np.arange(9.).reshape(3,3)
In [3844]: x
Out[3844]: 
array([[0., 1., 2.],
       [3., 4., 5.],
       [6., 7., 8.]])

In [3845]: np.where(x>5)
Out[3845]: (array([2, 2, 2]), array([0, 1, 2]))

In [3846]: x[np.where(x>5)]
Out[3846]: array([6., 7., 8.])

In [3847]: np.where(x>4)
Out[3847]: (array([1, 2, 2, 2]), array([2, 0, 1, 2]))

In [3848]: x[np.where(x>4)]
Out[3848]: array([5., 6., 7., 8.])

In [3849]: np.where(x<5)
Out[3849]: (array([0, 0, 0, 1, 1]), array([0, 1, 2, 0, 1]))

In [3851]: np.where(x<5,x,-1)
Out[3851]: 
array([[ 0.,  1.,  2.],
       [ 3.,  4., -1.],
       [-1., -1., -1.]])

In [3852]: np.isin(x,[3,4,7])
Out[3852]: 
array([[False, False, False],
       [ True,  True, False],
       [False,  True, False]])

In [3853]: np.where(np.isin(x,[3,4,7]))
Out[3853]: (array([1, 1, 2]), array([0, 1, 1]))

/ vergl,

In [3854]: x>5
Out[3854]: 
array([[False, False, False],
       [False, False, False],
       [ True,  True,  True]])

In [3855]: x[x>5]
Out[3855]: array([6., 7., 8.])

/ dus x>5 gaat iets anders, maar

In [3846]: x[np.where(x>5)]
/=
In [3855]: x[x>5]





/ Einde Intermezzo

/ Intermezzo

/ lees	,
https://stackoverflow.com/questions/48647534/python-pandas-find-difference-between-two-data-frames

In [3579]: df
Out[3579]: 
   a
0  1
1  2
2  3

In [3580]: df2
Out[3580]: 
   a
0  2
1  3
2  4

In [3572]: pd.concat([df,df2])
Out[3572]: 
   a
0  1
1  2
2  3
0  2
1  3
2  4

/ we zien links de index van de origineel	,

In [3573]: pd.concat([df,df2]).drop_duplicates()
Out[3573]: 
   a
0  1
1  2
2  3
2  4

In [3574]: pd.concat([df,df2]).drop_duplicates(keep=False)
Out[3574]: 
   a
0  1
2  4

In [3577]: pd.concat([df,df2]).drop_duplicates(keep='first')
Out[3577]: 
   a
0  1
1  2
2  3
2  4

In [3578]: pd.concat([df,df2]).drop_duplicates(keep='last')
Out[3578]: 
   a
0  1
0  2
1  3
2  4



/ Einde Intermezzo

/ Intermezzo

/ lees	,
https://docs.scipy.org/doc/numpy-1.14.5/reference/arrays.dtypes.html
/ M betekent datetime	,

/ lees	,
https://docs.scipy.org/doc/numpy-1.14.5/reference/arrays.datetime.html
https://en.wikipedia.org/wiki/ISO_8601


In [4280]: dt=np.datetime64('2005-02-25T12:35:23')
In [5417]: type(dt)
Out[5417]: numpy.datetime64
In [4282]: dt.dtype
Out[4282]: dtype('<M8[s]')
/ de unit is sec	,

In [4284]: dt=np.datetime64('2005-02-25T12:35:23.567')
In [4285]: dt.dtype
Out[4285]: dtype('<M8[ms]')

In [4286]: dt=np.datetime64('2005-02-25')
In [4287]: dt.dtype
Out[4287]: dtype('<M8[D]')

In [4288]: dt=np.datetime64('2005-02-25T12:35:23.5679')
In [4289]: dt.dtype
Out[4289]: dtype('<M8[us]')
In [5414]: print(dt)
2005-02-25T12:35:23.567900

In [4303]: dt=np.datetime64('2005-02-25T12:35:23-08:00') / het is 12:35:23 in tz -8	,
/home/eric/miniconda3/bin/ipython:1: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future
  #!/home/eric/miniconda3/bin/python
In [4304]: dt
Out[4304]: numpy.datetime64('2005-02-25T20:35:23')		/ utc	, het is 20:35:23 in tz utc	, 
/ we zien 20 ipv 12	,
/ 12:35:23 in timezone -8 uur = 20:35:23 in UTC 
/ lees	,
https://www.postgresql.org/docs/9.6/datatype-datetime.html
/ -8:00 is PST
/ maar postgres print in locale tz, dus +01	, dus hier 21:35:23+01

/ 13	. 

In [4338]: ts=pd.to_datetime(19690101,format='%Y%m%d')
In [5419]: type(ts)
Out[5419]: pandas._libs.tslibs.timestamps.Timestamp
In [4341]: ts
Out[4341]: Timestamp('1969-01-01 00:00:00')
In [4342]: pd.Series(ts).dtype
Out[4342]: dtype('<M8[ns]')
/ TODO

In [4343]: pd.Series(1).dtype
Out[4343]: dtype('int64')
In [4346]: s=pd.Series([1,2])
In [4347]: s.dtype
Out[4347]: dtype('int64')
In [4348]: type(s[0])
Out[4348]: numpy.int64

/ Einde Intermezzo

/ 13	. 

/ VERVOLG (178)

In [4575]: data=['peter','Paul','MARY','gUIDO']
In [4576]: [s.capitalize() for s in data]
Out[4576]: ['Peter', 'Paul', 'Mary', 'Guido']

In [4577]: data=['peter','Paul','MARY','gUIDO',None]
In [4578]: [s.capitalize() for s in data]
AttributeError: 'NoneType' object has no attribute 'capitalize'

In [4579]: pd.Series(data).str.capitalize()
Out[4579]: 
0    Peter
1     Paul
2     Mary
3    Guido
4     None
dtype: object

/ voor code completion	,
In [4580]: ser=pd.Series(data)
In [4581]: ser.str.TAB
...
In [4581]: ser.str.lower()
Out[4581]: 
0    peter
1     paul
2     mary
3    guido
4     None
dtype: object

In [4582]: ser.str.len()
Out[4582]: 
0    5.0
1    4.0
2    4.0
3    5.0
4    NaN
dtype: float64

In [4583]: ser.str.startswith('g')
Out[4583]: 
0    False
1    False
2    False
3     True
4     None
dtype: object

In [4586]: monte=['Graham Chapman', 'John Cleese','Terry Gilliam','Eric Idle','Terry Jones','Michael Palin']
In [4589]: monte=pd.Series(monte)

In [4590]: monte.str.split()
Out[4590]: 
0    [Graham, Chapman]
1       [John, Cleese]
2     [Terry, Gilliam]
3         [Eric, Idle]
4       [Terry, Jones]
5     [Michael, Palin]
dtype: object

In [4592]: monte.str.extract('([A-Za-z]+)')
Out[4592]: 
         0
0   Graham
1     John
2    Terry
3     Eric
4    Terry
5  Michael

In [4793]: monte.str.findall(r'^[^AEIOU].*[^aeiou]$')
/=
In [4793]: monte.str.findall('^[^AEIOU].*[^aeiou]$')
Out[4793]: 
0    [Graham Chapman]
1                  []
2     [Terry Gilliam]
3                  []
4       [Terry Jones]
5     [Michael Palin]
dtype: object
/ de r voor r'..' is hier niet nodig	,

In [4796]: monte.str.split()
In [4798]: type(monte.str.split())
Out[4798]: pandas.core.series.Series
Out[4796]: 
0    [Graham, Chapman]
1       [John, Cleese]
2     [Terry, Gilliam]
3         [Eric, Idle]
4       [Terry, Jones]
5     [Michael, Palin]
dtype: object
In [4797]: monte.str.split().str[-1]
Out[4797]: 
0    Chapman
1     Cleese
2    Gilliam
3       Idle
4      Jones
5      Palin
dtype: object

In [4803]: ser=pd.Series(['B|C|D','B|D','A|C','B|D','B|C','B|C|D'])

In [4804]: ser.str.get_dummies('|')
Out[4804]: 
   A  B  C  D
0  0  1  1  1
1  0  1  0  1
2  1  0  1  0
3  0  1  0  1
4  0  1  1  0
5  0  1  1  1

/ 13	. 

/ (184) 

/ ga naar 
https://github.com/sameergarg/scala-elasticsearch/blob/master/conf/recipeitems-latest.json-full.zip
/ en click Download button	,
[eric@almond vanderplas]$ unzip  ~/Downloads/recipeitems-latest.json-full.zip 
[eric@almond vanderplas]$ ls -ltrh
total 136M
-rw-r--r--. 1 eric eric 136M Jul 28  2015 recipeitems-latest.json
...

In [4813]: try:
      ...:     recipes=pd.read_json('recipeitems-latest.json')
      ...: except ValueError as e:
      ...:     print('ValueError: ',e)
      ...:     
ValueError:  Trailing data

/ lees	,
https://docs.python.org/3/library/io.html#io.IOBase.readline
/ readline leest 1 regel	,

In [4821]: with open('recipeitems-latest.json')as f:
      ...:     line=f.readline()
      ...: pd.read_json(line).shape
      ...: 
      ...: 
Out[4821]: (2, 12)

/ op fs	,
[eric@almond vanderplas]$ head recipeitems-latest.json 
{ "_id" : { "$oid" : "5160756b96cc62079cc2db15" }, 
	"name" : "Drop Biscuits and Sausage Gravy", 
	"ingredients" : "Biscuits\n3 cups All-purpose Flour\n2 Tablespoons Baking Powder\n1/2 teaspoon Salt\n1-1/2 stick (3/4 Cup) Cold Butter, Cut Into Pieces\n1-1/4 cup Butermilk\n SAUSAGE GRAVY\n1 pound Breakfast Sausage, Hot Or Mild\n1/3 cup All-purpose Flour\n4 cups Whole Milk\n1/2 teaspoon Seasoned Salt\n2 teaspoons Black Pepper, More To Taste", 
	"url" : "http://thepioneerwoman.com/cooking/2013/03/drop-biscuits-and-sausage-gravy/", 
	"image" : "http://static.thepioneerwoman.com/cooking/files/2013/03/bisgrav.jpg", 		"ts" : { "$date" : 1365276011104 }, 
		"cookTime" : "PT30M", 
		"source" : "thepioneerwoman", 
	"recipeYield" : "12", 
	"datePublished" : "2013-03-11", 
	"prepTime" : "PT10M", 
	"description" : "Late Saturday afternoon, after Marlboro Man had returned home with the soccer-playing girls, and I had returned home with the..." 
}
...

/ in ipython	,
In [4842]:  with open('recipeitems-latest.json')as fp:
      ...:     line=fp.readline()
      ...:  json=pd.read_json(line)

In [4855]: type(json)
Out[4855]: pandas.core.frame.DataFrame
In [4859]: json.columns
Out[4859]: 
Index(['_id', 'name', 'ingredients', 'url', 'image', 'ts', 'cookTime',
       'source', 'recipeYield', 'datePublished', 'prepTime', 'description'],
      dtype='object')
In [4854]: json.index
Out[4854]: Index(['$date', '$oid'], dtype='object')

In [4858]: json['_id']
Out[4858]: 
$date                         NaN
$oid     5160756b96cc62079cc2db15
Name: _id, dtype: object

In [4860]: json['name']
Out[4860]: 
$date    Drop Biscuits and Sausage Gravy
$oid     Drop Biscuits and Sausage Gravy
Name: name, dtype: object

In [4861]: json['ingredients']
Out[4861]: 
$date    Biscuits\n3 cups All-purpose Flour\n2 Tablespo...
$oid     Biscuits\n3 cups All-purpose Flour\n2 Tablespo...
Name: ingredients, dtype: object
...
In [4863]: json['ts']
Out[4863]: 
$date    1.365276e+12
$oid              NaN
Name: ts, dtype: float64
...
In [4862]:  json['recipeYield']
Out[4862]: 
$date    12
$oid     12
Name: recipeYield, dtype: int64

/ 1313	. 

/ de recipeitems-latest.json is een file met op elke regel een json entry, maar ze zijn niet verbonden	, 
$ less recipeitems-latest.json
{...}
{...}
...

/ we use eerst ; als scheidingsteken	,

/ wat is het effect van de strip() method?

In [5042]: with open('recipeitems-latest.json')as f:
      ...:     d=(l for l in f)
      ...:     j='[{0}]'.format(';'.join(d))
      ...:     
/ duurt even	, want 30Mb	,

In [5041]: j[:1000]
Out[5041]: '[{ "_id" : { "$oid" : "5160756b96cc62079cc2db15" }, "name" : "Drop Biscuits and Sausage Gravy", "ingredients" : "Biscuits\\n3 cups All-purpose Flour\\n2 Tablespoons Baking Powder\\n1/2 teaspoon Salt\\n1-1/2 stick (3/4 Cup) Cold Butter, Cut Into Pieces\\n1-1/4 cup Butermilk\\n SAUSAGE GRAVY\\n1 pound Breakfast Sausage, Hot Or Mild\\n1/3 cup All-purpose Flour\\n4 cups Whole Milk\\n1/2 teaspoon Seasoned Salt\\n2 teaspoons Black Pepper, More To Taste", "url" : "http://thepioneerwoman.com/cooking/2013/03/drop-biscuits-and-sausage-gravy/", "image" : "http://static.thepioneerwoman.com/cooking/files/2013/03/bisgrav.jpg", "ts" : { "$date" : 1365276011104 }, "cookTime" : "PT30M", "source" : "thepioneerwoman", "recipeYield" : "12", "datePublished" : "2013-03-11", "prepTime" : "PT10M", "description" : "Late Saturday afternoon, after Marlboro Man had returned home with the soccer-playing girls, and I had returned home with the..." }\n;{ "_id" : { "$oid" : "5160756d96cc62079cc2db16" }, "name" : "Hot Roast Beef '

In [5042]: with open('recipeitems-latest.json')as f:
      ...:     d=(l.strip()for l in f)
      ...:     j='[{0}]'.format(';'.join(d))
      ...:     

In [5043]: j[:1000]
Out[5043]: '[{ "_id" : { "$oid" : "5160756b96cc62079cc2db15" }, "name" : "Drop Biscuits and Sausage Gravy", "ingredients" : "Biscuits\\n3 cups All-purpose Flour\\n2 Tablespoons Baking Powder\\n1/2 teaspoon Salt\\n1-1/2 stick (3/4 Cup) Cold Butter, Cut Into Pieces\\n1-1/4 cup Butermilk\\n SAUSAGE GRAVY\\n1 pound Breakfast Sausage, Hot Or Mild\\n1/3 cup All-purpose Flour\\n4 cups Whole Milk\\n1/2 teaspoon Seasoned Salt\\n2 teaspoons Black Pepper, More To Taste", "url" : "http://thepioneerwoman.com/cooking/2013/03/drop-biscuits-and-sausage-gravy/", "image" : "http://static.thepioneerwoman.com/cooking/files/2013/03/bisgrav.jpg", "ts" : { "$date" : 1365276011104 }, "cookTime" : "PT30M", "source" : "thepioneerwoman", "recipeYield" : "12", "datePublished" : "2013-03-11", "prepTime" : "PT10M", "description" : "Late Saturday afternoon, after Marlboro Man had returned home with the soccer-playing girls, and I had returned home with the..." };{ "_id" : { "$oid" : "5160756d96cc62079cc2db16" }, "name" : "Hot Roast Beef S'

/ we zien de \n niet meer achter};

/ 1313	. 

/ UITEINDELIJK	,

In [5044]: with open('recipeitems-latest.json')as f:
      ...:     d=(l.strip()for l in f)
      ...:     j='[{0}]'.format(','.join(d))
      ...:     
      ...:     

In [5045]: r=pd.read_json(j)

In [5046]: r.index
Out[5046]: RangeIndex(start=0, stop=173278, step=1)

In [5047]: r.columns
Out[5047]: 
Index(['_id', 'cookTime', 'creator', 'dateModified', 'datePublished',
       'description', 'image', 'ingredients', 'name', 'prepTime',
       'recipeCategory', 'recipeInstructions', 'recipeYield', 'source',
       'totalTime', 'ts', 'url'],
      dtype='object')

In [5048]: r[0]
/ ERR	,
In [5049]: r.iloc[0]
/=
In [5049]: r.loc[0]
Out[5049]: 
_id                                {'$oid': '5160756b96cc62079cc2db15'}
cookTime                                                          PT30M
creator                                                             NaN
dateModified                                                        NaN
datePublished                                                2013-03-11
description           Late Saturday afternoon, after Marlboro Man ha...
image                 http://static.thepioneerwoman.com/cooking/file...
ingredients           Biscuits\n3 cups All-purpose Flour\n2 Tablespo...
name                                    Drop Biscuits and Sausage Gravy
prepTime                                                          PT10M
recipeCategory                                                      NaN
recipeInstructions                                                  NaN
recipeYield                                                          12
source                                                  thepioneerwoman
totalTime                                                           NaN
ts                                             {'$date': 1365276011104}
url                   http://thepioneerwoman.com/cooking/2013/03/dro...
Name: 0, dtype: object

In [5083]: r.dtypes
Out[5083]: 
_id                   object
cookTime              object
creator               object
dateModified          object
datePublished         object
description           object
image                 object
ingredients           object
name                  object
prepTime              object
recipeCategory        object
recipeInstructions    object
recipeYield           object
source                object
totalTime             object
ts                    object
url                   object
dtype: object
In [5086]: type(r['ingredients'][0])
Out[5086]: str
In [5087]: type(r['ts'][0])
Out[5087]: dict

/ r['ingredients'] is een series	,

In [5089]: r['ingredients'].str.len()
/ 'n series	,
Out[5088]: 
0         315
1         516
...
173276    277
173277    499
Name: ingredients, Length: 173278, dtype: int64

In [5091]: r['ingredients'].str.len().describe()
/ een series	,
Out[5091]: 
count    173278.000000
mean        244.617926
std         146.705285
min           0.000000
25%         147.000000
50%         221.000000
75%         314.000000
max        9067.000000
Name: ingredients, dtype: float64

In [5095]: r['ingredients'].str.len().values
Out[5095]: array([315, 516, 566, ..., 137, 277, 499])
In [5097]: r['ingredients'].str.len().values.argmax()
Out[5097]: 135598
In [5099]: r['name'][r['ingredients'].str.len().values.argmax()]
Out[5099]: 'Carrot Pineapple Spice &amp; Brownie Layer Cake with Whipped Cream &amp; Cream Cheese Frosting and Marzipan Carrots'
/ deze naam duidt op veel ingredienten	,
/ inderdaad	,
In [5108]: len(r['ingredients'][r['ingredients'].str.len().values.argmax()])
Out[5108]: 9067
/ klopt, see describe()	,
In [5100]: r['ingredients'][r['ingredients'].str.len().values.argmax()]
Out[5100]: '1 cup carrot juice2 cups (280 g) all purpose flour1/2 cup (65 g) almond meal or almond flour1 tablespoon baking powder1 teaspoon baking soda3/4 teaspoon fine sea salt1 teaspoon gro...

In [5109]: r.description.str.contains('[Bb]reakfast')
/ series	,
Out[5109]: 
0         False
...
4          True
...
173276      NaN
173277    False
Name: description, Length: 173278, dtype: object
In [5127]: r.description.str.contains('[Bb]reakfast').sum()
Out[5127]: 3524

In [5128]: r['ingredients'].str.contains('[Cc]innamon').sum()
Out[5128]: 10526
/ misspelled	,
In [5129]: r['ingredients'].str.contains('[Cc]inamon').sum()
Out[5129]: 11

/ 13	. 

/ (187)

In [5204]: g=((s,r.ingredients.str.contains(s,re.IGNORECASE)) for s in spice_list)
In [5200]: d=dict(g)
/ g is een generator, en je kunt maar 1 keer hem uitlezen	, dus dit kun je maar 1 keer doen	,
In [5206]: f=pd.DataFrame(d)


In [5210]: d
Out[5210]: 
{'salt': 0         False
 1         False
 2          True
...
 173276     True
 173277     True
 Name: ingredients, Length: 173278, dtype: bool, 'pepper': 0         False
 1         False
 2          True
...
 173276     True
 173277    False
 Name: ingredients, Length: 173278, dtype: bool, 'oregano': 0         False
 1         False
 2         False
...
...
 173276    False
 173277    False
 Name: ingredients, Length: 173278, dtype: bool, 'cumin': 0         False
 1         False
 2          True
...
 173276    False
 173277    False
 Name: ingredients, Length: 173278, dtype: bool}

In [5291]: type(d['salt'])
Out[5291]: pandas.core.series.Series
/ See ZELF DICT

/////////////////////////////////////////////////////////////
/ in een df is een column een series, dus het klopt	,

In [5212]:  f
Out[5212]: 
         salt  pepper  oregano   sage  parsley  rosemary  tarragon  thyme  paprika  cumin
0       False   False    False   True    False     False     False  False    False  False
1       False   False    False  False    False     False     False  False    False  False
...
173276   True    True    False  False    False     False     False  False    False  False
173277   True   False    False  False    False     False     False  False    False  False

[173278 rows x 10 columns]

In [5298]: sel=f.query('parsley & paprika & tarragon')
In [5298]: sel
Out[5298]: 
         salt  pepper  oregano   sage  parsley  rosemary  tarragon  thyme  paprika  cumin
2069    False    True    False  False     True     False      True  False     True  False
74964   False   False    False  False     True     False      True  False     True  False
93768    True    True    False   True     True     False      True  False     True  False
113926   True    True    False  False     True     False      True  False     True  False
137686   True    True    False  False     True     False      True  False     True  False
140530   True    True    False  False     True     False      True   True     True  False
158475   True    True    False  False     True     False      True  False     True   True
158486   True    True    False  False     True     False      True  False     True  False
163175   True    True     True  False     True     False      True  False     True  False
165243   True    True    False  False     True     False      True  False     True  False

In [5303]: sel.describe()
Out[5303]: 
        salt pepper oregano   sage parsley rosemary tarragon  thyme paprika  cumin
count     10     10      10     10      10       10       10     10      10     10
unique     2      2       2      2       1        1        1      2       1      2
top     True   True   False  False    True    False     True  False    True  False
freq       8      9       9      9      10       10       10      9      10      9

In [5307]: sel.index
Out[5307]: 
Int64Index([2069, 74964, 93768, 113926, 137686, 140530, 158475, 158486, 163175,
            165243],
           dtype='int64')

In [5306]: r.name[sel.index]
Out[5306]: 
2069      All cremat with a Little Gem, dandelion and wa...
74964                         Lobster with Thermidor butter
93768      Burton's Southern Fried Chicken with White Gravy
113926                     Mijo's Slow Cooker Shredded Beef
137686                     Asparagus Soup with Poached Eggs
140530                                 Fried Oyster Po’boys
158475                Lamb shank tagine with herb tabbouleh
158486                 Southern fried chicken in buttermilk
163175            Fried Chicken Sliders with Pickles + Slaw
165243                        Bar Tartine Cauliflower Salad
Name: name, dtype: object

/ 1313	. 

/ kunnen we van sel.index een True/False array maken, en die gebruiken voor fancy indexing?
In [5328]: z=np.zeros(len(r),dtype=bool)
In [5317]: arr=sel.index.get_values()
In [5332]: for i in arr:z[i]=True
In [5347]: z
Out[5347]: array([False, False, False, ..., False, False, False])
In [5334]: z.sum()
Out[5334]: 10

In [5335]:  r.name[z]
Out[5335]: 
2069      All cremat with a Little Gem, dandelion and wa...
74964                         Lobster with Thermidor butter
93768      Burton's Southern Fried Chicken with White Gravy
113926                     Mijo's Slow Cooker Shredded Beef
137686                     Asparagus Soup with Poached Eggs
140530                                 Fried Oyster Po’boys
158475                Lamb shank tagine with herb tabbouleh
158486                 Southern fried chicken in buttermilk
163175            Fried Chicken Sliders with Pickles + Slaw
165243                        Bar Tartine Cauliflower Salad
Name: name, dtype: object

/ FANCY INDEXING

/ we kunnen fancy index met	

Int64Index([2069, 74964, 93768, 113926, 137686, 140530, 158475, 158486, 163175,
            165243],
           dtype='int64')
/ of	,
In [5347]: z
Out[5347]: array([False, False, False, ..., False, False, False])
In [5334]: z.sum()
Out[5334]: 10

/ Einde FANCY INDEXING


/ Einde VERVOLG (178)

/ TIME SERIES

/ 1313	. 

/ python manier	,

In [5493]: import dateutil
In [5494]: d=dateutil.parser.parse('4th of July,2015')
In [5495]: d
Out[5495]: datetime.datetime(2015, 7, 4, 0, 0)
In [5496]: d.strftime('%A')
Out[5496]: 'Saturday'

/ 1313	. 

/ pandas manier	,

In [5600]: dt=pd.to_datetime('2018-12-28T12:13:14')   
In [5601]: dt
Out[5601]: Timestamp('2018-12-28 12:13:14')
/ tz-naive	,

/ zonder tz	,

In [5605]: idx=pd.to_timedelta(np.arange(12),'D')
In [5607]: idx
Out[5607]: 
TimedeltaIndex([ '0 days',  '1 days',  '2 days',  '3 days',  '4 days',
                 '5 days',  '6 days',  '7 days',  '8 days',  '9 days',
                '10 days', '11 days'],
               dtype='timedelta64[ns]', freq=None)

In [5612]: dt.to_datetime64()
Out[5612]: numpy.datetime64('2018-12-28T12:13:14.000000000')

In [5613]: dt.to_datetime64()+idx
/ of	,
In [5614]: dt+idx
Out[5613]: 
DatetimeIndex(['2018-12-28 12:13:14', '2018-12-29 12:13:14',
               '2018-12-30 12:13:14', '2018-12-31 12:13:14',
               '2019-01-01 12:13:14', '2019-01-02 12:13:14',
               '2019-01-03 12:13:14', '2019-01-04 12:13:14',
               '2019-01-05 12:13:14', '2019-01-06 12:13:14',
               '2019-01-07 12:13:14', '2019-01-08 12:13:14'],
              dtype='datetime64[ns]', freq=None)

/ 1313	.

/ met tz	,

/ PANDAS TIMESTAMP WITH TZ + DATETIMEINDEX MAKES UTC , RECOVER

In [5600]: dt=pd.to_datetime('2018-12-28T12:13:14')   
In [5632]: dtams=dt.tz_localize('Europe/Amsterdam')
In [5633]: dtams
Out[5633]: Timestamp('2018-12-28 12:13:14+0100', tz='Europe/Amsterdam')

In [5635]: dtams.to_datetime64()
Out[5635]: numpy.datetime64('2018-12-28T11:13:14.000000000')
/ 12 -> 11
20135 In [5605]: idx=pd.to_timedelta(np.arange(12),'D')

In [5636]: dtams+idx
/=
In [5638]: dtams.to_datetime64()+idx
Out[5636]: 
DatetimeIndex(['2018-12-28 11:13:14', '2018-12-29 11:13:14',
               '2018-12-30 11:13:14', '2018-12-31 11:13:14',
               '2019-01-01 11:13:14', '2019-01-02 11:13:14',
               '2019-01-03 11:13:14', '2019-01-04 11:13:14',
               '2019-01-05 11:13:14', '2019-01-06 11:13:14',
               '2019-01-07 11:13:14', '2019-01-08 11:13:14'],
              dtype='datetime64[ns]', freq=None)

/ we zien dat de tz in dtams niet gezien wordt	,

In [5641]: dtams
Out[5641]: Timestamp('2018-12-28 12:13:14+0100', tz='Europe/Amsterdam')
In [5640]: np.timedelta64(1,'D')
Out[5640]: numpy.timedelta64(1,'D')
In [5642]: dtams+np.timedelta64(1,'D')
Out[5642]: Timestamp('2018-12-29 12:13:14+0100', tz='Europe/Amsterdam')

In [5649]: tdidx=pd.TimedeltaIndex([0,1],unit='D')
In [5655]: tdidx
Out[5655]: TimedeltaIndex(['0 days', '1 days'], dtype='timedelta64[ns]', freq=None)
In [5652]: tdidx.get_values()
Out[5652]: array([             0, 86400000000000], dtype='timedelta64[ns]')
In [5653]: dtams+np.timedelta64(0,'ns')
Out[5653]: Timestamp('2018-12-28 12:13:14+0100', tz='Europe/Amsterdam')
In [5654]: dtams+np.timedelta64(86400000000000,'ns')
Out[5654]: Timestamp('2018-12-29 12:13:14+0100', tz='Europe/Amsterdam')
In [5656]: dtidx=dtams+tdidx
In [5656]: dtidx
Out[5656]: DatetimeIndex(['2018-12-28 11:13:14', '2018-12-29 11:13:14'], dtype='datetime64[ns]', freq=None)
/ we zien weer 12 -> 11	, de tz is weg,	
/ TODO
In [5659]: dtidx.get_values()
Out[5659]: 
array(['2018-12-28T11:13:14.000000000', '2018-12-29T11:13:14.000000000'],
      dtype='datetime64[ns]')
/ maar we kunnen herstellen	,
In [5661]: dttzidx=dtidx.tz_localize('utc').tz_convert('Europe/Amsterdam')
In [5661]: dttzidx
Out[5661]: DatetimeIndex(['2018-12-28 12:13:14+01:00', '2018-12-29 12:13:14+01:00'], dtype='datetime64[ns, Europe/Amsterdam]', freq=None)
In [5667]: dttzidx.get_values().dtype
Out[5667]: dtype('<M8[ns]')
In [5668]: dttzidx.tz
Out[5668]: <DstTzInfo 'Europe/Amsterdam' LMT+0:20:00 STD>

/ Einde PANDAS TIMESTAMP WITH TZ + DATETIMEINDEX MAKES UTC , RECOVER

/ 1313	. 

In [5674]: ts=pd.to_datetime('2018-12-28T12:13:14')
In [5675]: ts
Out[5675]: Timestamp('2018-12-28 12:13:14')
In [5670]: tdidx=pd.to_timedelta(np.arange(12),'D')
In [5673]: tdidx
Out[5673]: 
TimedeltaIndex([ '0 days',  '1 days',  '2 days',  '3 days',  '4 days',
                 '5 days',  '6 days',  '7 days',  '8 days',  '9 days',
                '10 days', '11 days'],
               dtype='timedelta64[ns]', freq=None)
In [5676]: dtidx=ts+tdidx

In [5677]: dtidx
Out[5677]: 
DatetimeIndex(['2018-12-28 12:13:14', '2018-12-29 12:13:14',
               '2018-12-30 12:13:14', '2018-12-31 12:13:14',
               '2019-01-01 12:13:14', '2019-01-02 12:13:14',
               '2019-01-03 12:13:14', '2019-01-04 12:13:14',
               '2019-01-05 12:13:14', '2019-01-06 12:13:14',
               '2019-01-07 12:13:14', '2019-01-08 12:13:14'],
              dtype='datetime64[ns]', freq=None)
In [5680]: dttzidx=dtidx.tz_localize('UTC').tz_convert('Europe/Amsterdam')
In [5681]: dttzidx
Out[5681]: 
DatetimeIndex(['2018-12-28 13:13:14+01:00', '2018-12-29 13:13:14+01:00',
               '2018-12-30 13:13:14+01:00', '2018-12-31 13:13:14+01:00',
               '2019-01-01 13:13:14+01:00', '2019-01-02 13:13:14+01:00',
               '2019-01-03 13:13:14+01:00', '2019-01-04 13:13:14+01:00',
               '2019-01-05 13:13:14+01:00', '2019-01-06 13:13:14+01:00',
               '2019-01-07 13:13:14+01:00', '2019-01-08 13:13:14+01:00'],
              dtype='datetime64[ns, Europe/Amsterdam]', freq=None)

In [5685]: dtser=pd.Series(np.arange(12),index=dtidx)
In [5686]: dttzser=pd.Series(np.arange(12),index=dttzidx)
In [5687]: dtser
Out[5687]: 
2018-12-28 12:13:14     0
2018-12-29 12:13:14     1
2018-12-30 12:13:14     2
2018-12-31 12:13:14     3
2019-01-01 12:13:14     4
2019-01-02 12:13:14     5
2019-01-03 12:13:14     6
2019-01-04 12:13:14     7
2019-01-05 12:13:14     8
2019-01-06 12:13:14     9
2019-01-07 12:13:14    10
2019-01-08 12:13:14    11
dtype: int64
In [5688]: dttzser
Out[5688]: 
2018-12-28 13:13:14+01:00     0
2018-12-29 13:13:14+01:00     1
2018-12-30 13:13:14+01:00     2
2018-12-31 13:13:14+01:00     3
2019-01-01 13:13:14+01:00     4
2019-01-02 13:13:14+01:00     5
2019-01-03 13:13:14+01:00     6
2019-01-04 13:13:14+01:00     7
2019-01-05 13:13:14+01:00     8
2019-01-06 13:13:14+01:00     9
2019-01-07 13:13:14+01:00    10
2019-01-08 13:13:14+01:00    11
dtype: int64

/ slices	,
In [5689]: dtser['2018-12']
Out[5689]: 
2018-12-28 12:13:14    0
2018-12-29 12:13:14    1
2018-12-30 12:13:14    2
2018-12-31 12:13:14    3
dtype: int64
In [5690]: dttzser['2018-12']
Out[5690]: 
2018-12-28 13:13:14+01:00    0
2018-12-29 13:13:14+01:00    1
2018-12-30 13:13:14+01:00    2
2018-12-31 13:13:14+01:00    3
dtype: int64

In [5691]: dtser['2018-12-28':'2018-12-30']
Out[5691]: 
2018-12-28 12:13:14    0
2018-12-29 12:13:14    1
2018-12-30 12:13:14    2
dtype: int64
In [5692]: dttzser['2018-12-28':'2018-12-30']
Out[5692]: 
2018-12-28 13:13:14+01:00    0
2018-12-29 13:13:14+01:00    1
2018-12-30 13:13:14+01:00    2
dtype: int64

/ 13	. 

/ (193)

/ See VERSCHIL DATETIMEINDEX PERIODINDEX TIMEDELTAINDEX

/ (194)

/ naast .date_range zijn er ook .period_range en .timedelta_range	,

/ 1313	. 

/ .date_range met end, of met periods	,

In [5727]: dtidx=pd.date_range('2015-07-03','2015-07-10')
/=
In [5734]: dtidx=pd.date_range('2015-07-03',end='2015-07-10')
In [5728]: dtidx
Out[5728]: 
DatetimeIndex(['2015-07-03', '2015-07-04', '2015-07-05', '2015-07-06',
               '2015-07-07', '2015-07-08', '2015-07-09', '2015-07-10'],
              dtype='datetime64[ns]', freq='D')
In [5732]: dtidx=pd.date_range('2015-07-03',periods=8)

In [5733]: dtidx
Out[5733]: 
DatetimeIndex(['2015-07-03', '2015-07-04', '2015-07-05', '2015-07-06',
               '2015-07-07', '2015-07-08', '2015-07-09', '2015-07-10'],
              dtype='datetime64[ns]', freq='D')

/ .period_range	, met end of met periods

In [5738]: prMidx=pd.period_range('2015-07',periods=8,freq='M')
/ of	,
In [5738]: prMidx=pd.period_range('2015-07-01',periods=8,freq='M')

In [5739]: prMidx
Out[5739]: 
PeriodIndex(['2015-07', '2015-08', '2015-09', '2015-10', '2015-11', '2015-12',
             '2016-01', '2016-02'],
            dtype='period[M]', freq='M')

In [5740]: prMidx=pd.period_range('2015-07-01','2016-02',freq='M')
In [5741]: prMidx
Out[5741]: 
PeriodIndex(['2015-07', '2015-08', '2015-09', '2015-10', '2015-11', '2015-12',
             '2016-01', '2016-02'],
            dtype='period[M]', freq='M')

/ .timedelta_range	,

In [5742]: tdidx=pd.timedelta_range(0,periods=8,freq='H')
In [5743]: tdidx
Out[5743]: 
TimedeltaIndex(['00:00:00', '01:00:00', '02:00:00', '03:00:00', '04:00:00',
                '05:00:00', '06:00:00', '07:00:00'],
               dtype='timedelta64[ns]', freq='H')

/ (195)

/ D (day) vs B (business day)
In [5747]: pd.date_range('2018',freq='D',periods=7)
Out[5747]: 
DatetimeIndex(['2018-01-01', '2018-01-02', '2018-01-03', '2018-01-04',
               '2018-01-05', '2018-01-06', '2018-01-07'],
              dtype='datetime64[ns]', freq='D')

In [5748]: pd.date_range('2018',freq='B',periods=7)
Out[5748]: 
DatetimeIndex(['2018-01-01', '2018-01-02', '2018-01-03', '2018-01-04',
               '2018-01-05', '2018-01-08', '2018-01-09'],
              dtype='datetime64[ns]', freq='B')

/ M,Q,A staan default op end	, MS, QS, AS staan op start	,

/ Q (quarter end)

In [5744]: pd.date_range('2018',freq='Q',periods=8)	
/=
In [5775]: pd.date_range('2018',freq='Q-DEC',periods=8)
/=
In [5775]: pd.date_range('2018',freq='Q-MAR',periods=8) 	/ TODO
Out[5744]: 
DatetimeIndex(['2018-03-31', '2018-06-30', '2018-09-30', '2018-12-31',
               '2019-03-31', '2019-06-30', '2019-09-30', '2019-12-31'],
              dtype='datetime64[ns]', freq='Q-DEC')

In [5777]: pd.date_range('2018',freq='Q',periods=8)
Out[5777]: 
DatetimeIndex(['2018-03-31', '2018-06-30', '2018-09-30', '2018-12-31',
               '2019-03-31', '2019-06-30', '2019-09-30', '2019-12-31'],
              dtype='datetime64[ns]', freq='Q-DEC')
In [5778]: pd.date_range('2018',freq='BQ',periods=8)
Out[5778]: 
DatetimeIndex(['2018-03-30', '2018-06-29', '2018-09-28', '2018-12-31',
               '2019-03-29', '2019-06-28', '2019-09-30', '2019-12-31'],
              dtype='datetime64[ns]', freq='BQ-DEC')
/ klopt	, 30 mrt is vrijdag, 29 jun is vrijdag	,

In [5779]: pd.date_range('2018',freq='BQS',periods=8)
Out[5779]: 
DatetimeIndex(['2018-01-01', '2018-04-02', '2018-07-02', '2018-10-01',
               '2019-01-01', '2019-04-01', '2019-07-01', '2019-10-01'],
              dtype='datetime64[ns]', freq='BQS-JAN')
/ klopt,	1 jan is maandag, 2 april is maandag	,

/ freq mix	,
In [5781]: pd.date_range('2018',freq='D4H',periods=8)
Out[5781]: 
DatetimeIndex(['2018-01-01 00:00:00', '2018-01-02 04:00:00',
               '2018-01-03 08:00:00', '2018-01-04 12:00:00',
               '2018-01-05 16:00:00', '2018-01-06 20:00:00',
               '2018-01-08 00:00:00', '2018-01-09 04:00:00'],
              dtype='datetime64[ns]', freq='28H')

/ pandas.tseries.offsets.BDay	,
In [5782]: pd.date_range('2018',freq=pd.tseries.offsets.BDay(),periods=8)
Out[5782]: 
DatetimeIndex(['2018-01-01', '2018-01-02', '2018-01-03', '2018-01-04',
               '2018-01-05', '2018-01-08', '2018-01-09', '2018-01-10'],
              dtype='datetime64[ns]', freq='B')

/ 1313	. 

/ lees	,
https://docs.scipy.org/doc/numpy-1.14.5/reference/arrays.datetime.html

/ 5 jan is vr	, en 8 jan maandag	,
In [5783]: np.busday_offset('2018-01-05',1)
Out[5783]: numpy.datetime64('2018-01-08')

/ 1313	. 

/ lees	,
http://pandas.pydata.org/pandas-docs/version/0.12/timeseries.html

Q-DEC define regular calendar quarters:

In [5750]: p = pd.Period('2012Q1', freq='Q-DEC')
In [5751]: p.asfreq('D','s')
Out[5751]: Period('2012-01-01', 'D')
In [5752]: p.asfreq('D','e')
Out[5752]: Period('2012-03-31', 'D')
In [5753]: p.asfreq('M','e')
Out[5753]: Period('2012-03', 'M')
In [5754]: p.asfreq('M','s')
Out[5754]: Period('2012-01', 'M')

In [5755]: p = pd.Period('2012Q4', freq='Q-MAR')
In [5756]: p.asfreq('D','s')
Out[5756]: Period('2012-01-01', 'D')
In [5757]: p.asfreq('D','e')
Out[5757]: Period('2012-03-31', 'D')
In [5758]: p.asfreq('M','s')
Out[5758]: Period('2012-01', 'M')
In [5759]: p.asfreq('M','e')
Out[5759]: Period('2012-03', 'M')

/ 1313	. 

/ de 1ste zondag is 7 jan	, 
In [5767]: pd.date_range('2018',freq='W',periods=8)
/=
In [5768]: pd.date_range('2018',freq='W-SUN',periods=8)
Out[5768]: 
DatetimeIndex(['2018-01-07', '2018-01-14', '2018-01-21', '2018-01-28',
               '2018-02-04', '2018-02-11', '2018-02-18', '2018-02-25'],
              dtype='datetime64[ns]', freq='W-SUN')

/ de 1ste maandag is 1 jan	,
In [5769]: pd.date_range('2018',freq='W-MON',periods=8)
Out[5769]: 
DatetimeIndex(['2018-01-01', '2018-01-08', '2018-01-15', '2018-01-22',
               '2018-01-29', '2018-02-05', '2018-02-12', '2018-02-19'],
              dtype='datetime64[ns]', freq='W-MON')


/ Einde TIME SERIES

/ Intermezzo

/ regular expressions	,

/ lees	,
https://docs.python.org/3/library/re.html

/ over r voor een string	,

Regular expressions use the backslash character ('\') to indicate special forms or to allow special characters to be used without invoking their special meaning. This collides with Python’s usage of the same character for the same purpose in string literals; for example, to match a literal backslash, one might have to write '\\\\' as the pattern string, because the regular expression must be \\, and each backslash must be expressed as \\ inside a regular Python string literal.

The solution is to use Python’s raw string notation for regular expression patterns; backslashes are not handled in any special way in a string literal prefixed with 'r'. So r"\n" is a two-character string containing '\' and 'n', while "\n" is a one-character string containing a newline. Usually patterns will be expressed in Python code using this raw string notation.

/ lees python boek(161)
'C:\new\text.dat'
/ hier is \n newline en \t tab	,
/ je kunt	,
'C:\\new\\text.dat'
/ of	,
r'C:\new\text.dat'

/ lees	,
https://docs.python.org/3/howto/regex.html

/ 1313	. 

/ lees	,
https://stackoverflow.com/questions/33582162/backslashes-in-python-regular-expressions
In [4626]: s='a\\\n\tc'
In [4627]: print(s)
a\
	c
/ \\ prints \ , omdat de 1ste \ de 2de \ escapes	, maar in \n is de \ niet escaped, dus wordt \n print, dwz newline	, ook wordt \t print	,

In [4632]: s='a\\\\n\\tc'
In [4633]: print(s)
a\\n\tc

In [4643]: s=r'a\nb\tc'
In [4645]: print(s)
a\nb\tc

/ re.match
/ TODO



/ 1313	. 

/ lees	,
https://pandas.pydata.org/pandas-docs/stable/text.html

/ 1313	. 

/ lees	,
https://regexone.com/references/python

In [4663]: r= r"([a-zA-Z]+) (\d+)"
In [4664]: r
Out[4664]: '([a-zA-Z]+) (\\d+)'
In [4672]: print(r)
([a-zA-Z]+) (\d+)
In [4673]: m=re.search(regex,'June 24')
In [4673]: m
Out[4673]: <_sre.SRE_Match object; span=(0, 7), match='June 24'>
In [4688]: type(m)
Out[4688]: _sre.SRE_Match
In [4677]: m.start()
Out[4677]: 0
In [4678]: m.end()
Out[4678]: 7
In [4679]: m.group(0)
Out[4679]: 'June 24'
In [4680]: m.group(1)
Out[4680]: 'June'
In [4681]: m.group(2)
Out[4681]: '24'
In [4682]: m.groups()
Out[4682]: ('June', '24')

In [4683]: l=re.findall(r,'June 24, August 9, Dec 12')
In [4685]: l
Out[4685]: [('June', '24'), ('August', '9'), ('Dec', '12')]
In [4686]: type(l)
Out[4686]: list

In [4694]: s=re.sub(r,r'\2 of \1','June 24, August 9, Dec 12')
In [4695]: s
Out[4695]: '24 of June, 9 of August, 12 of Dec'

/ of je compiles eerst	,

In [4709]: r=re.compile(r'([a-zA-Z]+) (\d+)')
In [4712]: m=r.search('June 24')
In [4713]: m.groups()
Out[4713]: ('June', '24')
In [4719]: m=r.match('June 24')
In [4720]: m.groups()
Out[4720]: ('June', '24')
In [4710]: l=r.findall('June 24, August 9, Dec 12')
In [4711]: l
Out[4711]: [('June', '24'), ('August', '9'), ('Dec', '12')]

/ Is er verschil tussen .match en .search?
/ TODO

In [4696]: r=re.compile(r'(\w+) World')
In [4698]: m=r.search('Hello World is the easiest')
In [4705]: type(m)
Out[4705]: _sre.SRE_Match
In [4699]: m.groups()
Out[4699]: ('Hello',)
In [4700]: m.start()
Out[4700]: 0
In [4701]: m.end()
Out[4701]: 11
In [4702]: m.group(0)
Out[4702]: 'Hello World'
In [4704]: m.group(2)
IndexError: no such group

/ 13	. 
/ zelf	,

In [4729]:  r=re.compile(r'\d+ World')
In [4733]: m=r.match('232742342 World')
In [4734]: m
Out[4734]: <_sre.SRE_Match object; span=(0, 15), match='232742342 World'>
In [4735]: m.string
Out[4735]: '232742342 World'

In [4736]: re.match(r'\d+ World','2342342 World')
Out[4737]: <_sre.SRE_Match object; span=(0, 13), match='2342342 World'>

In [4738]: re.match(r'\\d+ World','\d World')
Out[4739]: <_sre.SRE_Match object; span=(0, 8), match='\\d World'>

In [4755]: re.match(r'\\d+ World','\d\d\d World')
/ NIET	,
In [4762]: re.match(r'(\\d)+ World','\d\d\d World')
Out[4762]: <_sre.SRE_Match object; span=(0, 12), match='\\d\\d\\d World'>

In [4766]: m
Out[4766]: <_sre.SRE_Match object; span=(0, 12), match='\\d\\d\\d World'>
In [4767]: m.groups()
Out[4767]: ('\\d', 'World')
/ TODO Ik had '\\d\\d\\d' verwacht	,

In [4770]: m=re.match(r'a+ World','aaaaaaaaaaaaa World')
In [4771]: m
Out[4771]: <_sre.SRE_Match object; span=(0, 19), match='aaaaaaaaaaaaa World'>
/ maar als je \\d neemt ipv a, moeten we () omheen: group	,
/ TODO

////////////////////////
In [4789]: re.match(r'\n+ World','\n\n World')
Out[4789]: <_sre.SRE_Match object; span=(0, 8), match='\n\n World'>
In [4790]: re.match(r'\t+ World','\t\t World')
Out[4790]: <_sre.SRE_Match object; span=(0, 8), match='\t\t World'>
/ \n en \t zijn 1 char	, is anders als \d	,
/ we hoeven ook geen () er om heen	,

In [4788]: re.match(r'(\n)+ World','\n\n World')
Out[4788]: <_sre.SRE_Match object; span=(0, 8), match='\n\n World'>
/ TODO









/ 13	. 

In [4656]: s3 = pd.Series(['A', 'B', 'C', 'Aaba', 'Baca','', np.nan, 'CABA', 'dog', 'cat'])
In [4657]: s3
Out[4657]: 
0       A
1       B
2       C
3    Aaba
4    Baca
5        
6     NaN
7    CABA
8     dog
9     cat
dtype: object

In [4660]: s3.str.replace('^.a|dog', 'XX-XX ', case=False)
/ verschil	,
In [4660]: s3.str.replace('(^.a)|(dog)', 'XX-XX ', case=False)
Out[4660]: 
0           A
1           B
2           C
3    XX-XX ba
4    XX-XX ca
5            
6         NaN
7    XX-XX BA
8      XX-XX 
9     XX-XX t
dtype: object

/ Einde Intermezzo

/ Intermezzo

/ io	,

[eric@almond vanderplas]$ cat 1.txt 
foo
bar
baz

/ 1313	. 

/ lees	,
https://docs.python.org/3/library/io.html#io.IOBase.readline

/ .readline() leest een regel	, in dit geval de 1ste van de file	,

In [4835]:  with open('1.txt')as fp:
      ...:     l=fp.readline()
      ...:  print(l)
      ...: 
      ...: 
      ...: 
foo




/ 1313	. 

/ lees	,
https://stackoverflow.com/questions/3277503/how-to-read-a-file-line-by-line-into-a-list

In [4826]: open('1.txt').read()
Out[4826]: 'foo\nbar\nbaz\n'
In [4827]: open('1.txt').read().split('\n')
Out[4827]: ['foo', 'bar', 'baz', '']

In [4829]: with open('1.txt')as fp:
      ...:     l=fp.readlines()
      ...: l
      ...: 
      ...: 
      ...:     
Out[4829]: ['foo\n', 'bar\n', 'baz\n']

/ lees	,
https://stackabuse.com/read-a-file-line-by-line-in-python/

In [4833]: with open('1.txt')as fp:
      ...:     l=fp.readline()
      ...:     print(l)
      ...:     while l:
      ...:         l=fp.readline()
      ...:         print(l)
      ...:         
      ...:    
foo

bar

baz
/ TODO

/ 1313	. 

/ we maken zelf json (foutief, dit zijn 3 regels):

$ cat 1.json
{"id":"12",
  "name":"foo",
  "desc":"bar baz"
}

/ lees	,
https://www.cyberciti.biz/faq/unix-howto-read-line-by-line-from-file/

/ lees	,
https://www.shellhacks.com/bash-read-file-line-by-line-while-read-line-loop/

[eric@almond vanderplas]$ while read line;do echo $line;done<1.json
{"id":"12",
"name":"foo",
"desc":"bar baz"
}

/ google
bash read two lines from file
/ lees	,
https://stackoverflow.com/questions/8314499/read-n-lines-at-a-time-using-bash         

/ 1313	. 

[eric@almond vanderplas]$ cat 1.json 
{"id":"12", "name":"foo", "desc":"foo desc" }
{"id":"13", "name":"bar", "desc":"bar desc" }

In [4876]: with open('1.json')as fp:
      ...:     line=fp.readline()
      ...: 
      ...:     
In [4877]: line
Out[4877]: '{"id":"12", "name":"foo", "desc":"foo desc" }\n'
In [4878]: pd.read_json(line)
ValueError: If using all scalar values, you must pass an index

/ we moeten een index laten maken	, 	,
$ less 1.json	
{"id":{"n":"12"}, "name":"foo", "ts":{"m":"121"},"desc":"foo desc" }
{"id":{"n":"13"}, "name":"bar", "ts":{"m":"234"},"desc":"bar desc" }

In [4897]: with open('1.json')as fp:
      ...:     line=fp.readline()
			...
In [4898]: df=pd.read_json(line)
In [4899]: df
Out[4899]: 
     id name     ts      desc
m   NaN  foo  121.0  foo desc
n  12.0  foo    NaN  foo desc

/ dit is toch niet de bedoeling	, straks gaan we een index maken op de array manier	,

/ we zien dat {"id":{"n":"12"} leidt tot column id en index n	, 
/ OK	,

/ maar we kunnen GEEN multiindex maken:
{"id":{"n":{"o":"12"}}, "name":"foo", "ts":{"m":"121"},"desc":"foo desc" }

/ 1313	. 

/ je kunt ook zo een index laten maken	,

In [4874]: pd.DataFrame({'a':13,'b':7})
ValueError: If using all scalar values, you must pass an index
In [4882]: pd.DataFrame({'a':[13],'b':[7]})
Out[4882]: 
    a  b
0  13  7
In [4905]: pd.DataFrame({'a':[7,13],'b':[-3,-5]})
Out[4905]: 
    a  b
0   7 -3
1  13 -5


/ 1313	. 

[eric@almond vanderplas]$ cat 2.txt 
foo
bar
baz

In [4941]: with open('2.txt')as fp:
      ...:     d=(l for l in fp)
      ...:     for i in d:print(i)
      ...:     
foo

bar

baz
/ de items hebben zelf al een \n	, print geeft er ook nog eens een	,
In [4942]: type(d)
Out[4942]: generator
/ in with wordt elk stmt 1 keer gedaan	,

/ 1313	. 

/ python boek(90)

/ lees	,
https://wiki.python.org/moin/Generators

In [4971]: d=(l for l in open('2.txt'))
      ...: 

In [4972]: next(d)
Out[4972]: 'foo\n'

In [4973]: print(next(d))
bar


In [4974]: next(d)
Out[4974]: 'baz\n'

In [4975]: next(d)
---------------------------------------------------------------------------
StopIteration                             Traceback (most recent call last)
<ipython-input-4975-9b2daf1403f5> in <module>()
----> 1 next(d)

StopIteration: 



/ 131313	.

In [4968]: with open('2.txt')as fp:
      ...:     d=(l for l in fp)
      ...:     #for i in d:print(i)
      ...:     print(next(d))
      ...:     print(next(d))
      ...:     print(next(d))
      ...:     print(next(d))
      ...:         
      ...:     
foo

bar

baz

---------------------------------------------------------------------------
StopIteration                             Traceback (most recent call last)
<ipython-input-4968-e7ce4d93c279> in <module>()
      5     print(next(d))
      6     print(next(d))
----> 7     print(next(d))
      8 
      9 

StopIteration: 

/ we moeten print(next(d)) doen in with	, met next(d) zien we helemaal niets	,
/ TODO

/ 1313	. 

[eric@almond vanderplas]$ cat 2.txt 
foo
bar
baz

In [4982]: ','.join(('foo\n','bar\n'))
Out[4982]: 'foo\n,bar\n'

In [4983]: ','.join(['foo\n','bar\n'])
Out[4983]: 'foo\n,bar\n'

/ 131313	. 

In [4984]: with open('2.txt')as f:
      ...:     g=(l for l in f)
      ...:     s=','.join(g)
      ...:     

In [4985]: s
Out[4985]: 'foo\n,bar\n,baz\n'

/ 131313	. 

/ maar we willen er [] omheen, 

In [4986]: with open('2.txt')as f:
      ...:     g=(l for l in f)
      ...:     s='[{0}]'.format(','.join(g))
      ...:     
      ...:     

In [4987]: s
Out[4987]: '[foo\n,bar\n,baz\n]'

/ 1313	. 

/ we willen pd.read_json use	, dus moeten we json file maken	,

/ 1313	. 

/ deze 2 zijn OK	,
[eric@almond vanderplas]$ cat 1.json
{"id":{"n":"12"}, "name":"foo", "ts":{"m":"121"},"desc":"foo desc" }
{"id":{"n":"13"}, "name":"bar", "ts":{"m":"234"},"desc":"bar desc" }

[eric@almond vanderplas]$ cat 1a.json 
{"id":"12", "name":"foo", "ts":"121","desc":"foo desc" }
{"id":"13", "name":"bar", "ts":"234","desc":"bar desc" }

In [5007]: with open('1.json')as f:
      ...:     g=(l.strip()for l in f)
      ...:     s=r'[{0}]'.format(','.join(g))
      ...:     
In [5008]: s
Out[5008]: '[{"id":{"n":"12"}, "name":"foo", "ts":{"m":"121"},"desc":"foo desc" },{"id":{"n":"13"}, "name":"bar", "ts":{"m":"234"},"desc":"bar desc" }]'
In [5009]: j=pd.read_json(s)
In [5010]: j
Out[5010]: 
       desc           id name            ts
0  foo desc  {'n': '12'}  foo  {'m': '121'}
1  bar desc  {'n': '13'}  bar  {'m': '234'}

In [5011]: with open('1a.json')as f:
      ...:     g=(l.strip()for l in f)
      ...:     s=r'[{0}]'.format(','.join(g))
      ...:     
In [5012]: s
Out[5012]: '[{"id":"12", "name":"foo", "ts":"121","desc":"foo desc" },{"id":"13", "name":"bar", "ts":"234","desc":"bar desc" }]'
In [5013]: j=pd.read_json(s)
In [5014]: j
Out[5014]: 
       desc  id name   ts
0  foo desc  12  foo  121
1  bar desc  13  bar  234

/ 1313	. 

/ een json entry staat altijd tussen {}	, je kunt een array van deze hebben, ook een array van 1 zo een	, dus [{...}]	,
/ het [{...] moet tussen ''	voor .read_json	, 

/ we oef	,

In [4990]: s
Out[4990]: '["id":12\n,"name":"foo"\n,"sex":"female"\n]'
In [4991]: j=pd.read_json(s)
ValueError: Unexpected character found when decoding array value (2)
/ want er moeten {} omheen		,

In [5029]: pd. read_json('[{"id":{"n":12\n},"name":"foo\n","sex":"female\n"}]')
Out[5029]: 
          id   name       sex
0  {'n': 12}  foo\n  female\n
/ array van 1 {...}	,

In [5025]: pd. read_json('{"id":{"n":12\n},"name":"foo"\n,"sex":"female"\n}')
Out[5025]: 
   id name     sex
n  12  foo  female
/ hij geeft niets om \n erachter	,

In [5027]: pd. read_json('{"id":{"n":12\n},"name":"foo\n","sex":"female\n"}')
Out[5027]: 
   id   name       sex
n  12  foo\n  female\n

In [5006]:  pd.read_json('["id":{"n":"12"},"name":"foo","sex":"female"]')
ValueError: Unexpected character found when decoding array value (2)

In [5005]:  pd.read_json('{"id":{"n":"12"},"name":"foo","sex":"female"}')
Out[5005]: 
   id name     sex
n  12  foo  female

/ 1313	. 

///////////
/ READ_JSON HAS TO CREATE INDEX FOR THE DATAFRAME
/ we moeten op een een of andere manier een index maken, dit kan met een extra diepte in de json, of met een array	,

In [5035]: pd. read_json('{"id":12,"name":"foo","sex":"female"}')
ValueError: If using all scalar values, you must pass an index

/ array manier	,
In [5034]: pd. read_json('[{"id":12,"name":"foo","sex":"female"}]')
Out[5034]: 
   id name     sex
0  12  foo  female


In [5036]:   pd. read_json('{"id":{"n":12},"name":"foo","sex":"female"}')
Out[5036]: 
   id name     sex
n  12  foo  female

/ een voorbeeld met meerdere rows	, array manier	,
In [5034]: pd. read_json('[{"id":12,"name":"foo","sex":"female"},{"id":13,"name":"bar","sex":"male"}]')
Out[5081]: 
   id name     sex
0  12  foo  female
1  13  bar    male



/ 13	.

/ 1313	.

/ we hadden een WH foutieve methode om een index te maken, ipv met array	,

$ cat 1b.json
{"id":{"n":"12"}, "name":"foo", "ts":{"m":"121"},"desc":"foo desc" }

In [5073]: with open('1b.json')as f:
      ...:     g=(l.strip()for l in f)
      ...:     s='{0}'.format(','.join(g))
      ...:     
/ of	,
In [5073]: with open('1b.json')as f:
      ...:     s=f.readline() 
In [5074]: s
Out[5074]: '{"id":{"n":"12"}, "name":"foo", "ts":{"m":"121"},"desc":"foo desc" }'
In [5075]: pd.read_json(s)
Out[5075]: 
     id name     ts      desc
m   NaN  foo  121.0  foo desc
n  12.0  foo    NaN  foo desc

/ Dit is niet de bedoeling, maar krijgen we ook niet op de array manier, see READ_JSON HAS TO CREATE INDEX FOR THE DATAFRAME

/ 1313	. 

/ we moeten zonder [] 1 {} hebben	,  anders 'trailing data'	,

$ cat 1a.json

[eric@almond vanderplas]$ cat 1a.json
{"id":"12", "name":"foo", "ts":"121","desc":"foo desc" }
{"id":"13", "name":"bar", "ts":"234","desc":"bar desc" }

In [5078]: with open('1a.json')as f:
      ...:     g=(l.strip()for l in f)
      ...:     s='{0}'.format(','.join(g))
      ...:     
In [5079]: s
Out[5079]: '{"id":"12", "name":"foo", "ts":"121","desc":"foo desc" },{"id":"13", "name":"bar", "ts":"234","desc":"bar desc" }'

In [5081]: pd.read_json(s)
ValueError: Trailing data

/ Einde Intermezzo

/ Intermezzo

/ sum op bools	,

In [5118]: pd.Series([True,False,True])
Out[5118]: 
0     True
1    False
2     True
dtype: bool
In [5120]: pd.Series([True,False,True]).sum()
Out[5120]: 2

In [5119]: pd.DataFrame({'a':[True,False]})
/ of	,
In [5124]: pd.DataFrame({'a':(True,False)})
Out[5119]: 
       a
0   True
1  False
/ OK, omdat hij een index kan maken	,

In [5124]: pd.DataFrame({'a':12,'b':13})
ValueError: If using all scalar values, you must pass an index

In [5125]: pd.DataFrame({'a':{True,False}})
Out[5125]: 
               a
0  {False, True}
1  {False, True}
/ TODO

/ Einde Intermezzo

/ Intermezzo

/ dict	,

In [5137]: dict({"id":12,"name":"foo"})
Out[5137]: {'id': 12, 'name': 'foo'}
/ OK	,

In [5153]:  dict(name='foo',age=13)
Out[5153]: {'name': 'foo', 'age': 13}
/ OK	,

[eric@almond vanderplas]$ cat 3.json 
{"id":12,"name":"foo"}
[eric@almond vanderplas]$ cat 3.txt 
"name":"foo"
"age":13
[eric@almond vanderplas]$ cat 3a.txt 
name:"foo"
age:13

In [5154]: g=(l for l in open('3a.txt'))
In [5155]: s='{0}'.format(','.join(g))
In [5156]: s
Out[5156]: 'name:"foo"\n,age:13\n'

/ 13	. 

In [5187]: spice_list=['salt','pepper','oregano','sage','parsley','rosemary','tarragon','thyme','paprika','cumin']
In [5188]: spice_list
Out[5188]: 
['salt',
 'pepper',
 'oregano',
 'sage',
 'parsley',
 'rosemary',
 'tarragon',
 'thyme',
 'paprika',
 'cumin']

In [5190]: dict((s,'foo') for s in spice_list)
/ of	,
In [5192]: g=((s,'foo') for s in spice_list)		/ 1 extra ()
In [5193]: dict(g)
Out[5190]: 
{'salt': 'foo',
 'pepper': 'foo',
 'oregano': 'foo',
 'sage': 'foo',
 'parsley': 'foo',
 'rosemary': 'foo',
 'tarragon': 'foo',
 'thyme': 'foo',
 'paprika': 'foo',
 'cumin': 'foo'}

/ 13	. 

In [5228]: d3=dict({'a':[True,False,True],'b':[False,False,False],'c':[True,True,True]})

In [5230]: d3.keys()
Out[5230]: dict_keys(['a', 'b', 'c'])
In [5231]: d3.values()
Out[5231]: dict_values([[True, False, True], [False, False, False], [True, True, True]])

In [5232]: pd.DataFrame(d3)
Out[5232]: 
       a      b     c
0   True  False  True
1  False  False  True
2   True  False  True

/ 13	 .



/ Einde Intermezzo

/ Intermezzo

/ hoe maak je random array van bools?
/ en een dict net als bij VERVOLG (178), we maken hem bij ZELF DICT hieronder	,

/ np.random is basis, ook voor 
rng=np.random.RandomState(0) 
/ en hiermee	,
rng.randint(0,10,8)

/ 131313	. 

/ lees	,
https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.random.choice.html

Generate a uniform random sample from np.arange(5) of size 3:
In [5253]: np.random.choice(5,3)
/ np.arange start altijd met 0	, dus np.random.choice(5,...) is een keuze van 3 uit 0,..,4
#This is equivalent to np.random.randint(0,5,3)
/ Wat is de rol van RandomState hierin?
/ TODO

In [5263]: np.random.choice([True,False],8)
Out[5263]: array([ True,  True,  True, False, False, False,  True, False])

In [5268]: np.random.choice([True,False],100,p=[.1,.9])
Out[5268]: 
array([False, False, False, False,  True, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False,  True, False,
       False, False,  True, False,  True, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
        True,  True,  True, False, False, False, False, False, False,
       False,  True, False,  True, False, False, False, False, False,
        True, False,  True, False, False, False, False,  True, False,
       False, False, False, False, False, False, False, False, False,
        True])

In [5269]: np.random.choice([True,False],100,p=[.1,.9]).sum()
Out[5269]: 9
/ 9 Trues	,

In [5271]: pd.Series(np.random.choice([True,False],100,p=[.1,.9])).describe()
Out[5271]: 
count       100
unique        2
top       False
freq         88
dtype: object
/ Dus 12 Trues	,

/ 1313	. 

In [5279]: d3=dict({'a':np.random.choice([True,False],10),'b':np.random.choice([True,False],10),'c':np.random.choice([True,False],10)})

In [5280]: d3
Out[5280]: 
{'a': array([False,  True,  True, ...,  True,  True,  True]),
 'b': array([ True, False,  True, ...,  True,  True, False]),
 'c': array([False,  True, False, ...,  True,  True, False])}

/ ZELF DICT
In [5279]: d3s=dict({'a':pd.Series(np.random.choice([True,False],10)),'b':pd.Series(np.random.choice([True,False],10)),'c':pd.Series(np.random.choice([True,False],10))})
In [5295]: d3s
Out[5295]: 
{'a': 0     True
 1    False
 2     True
 3     True
 4    False
 5    False
 6    False
 7     True
 8     True
 9    False
 dtype: bool, 'b': 0     True
 1     True
 2    False
 3    False
 4     True
 5    False
 6    False
 7     True
 8    False
 9     True
 dtype: bool, 'c': 0     True
 1    False
 2    False
 3    False
 4     True
 5     True
 6     True
 7     True
 8    False
 9    False
 dtype: bool}





/ Einde Intermezzo

/ Intermezzo

/ bash

/ lees	,
https://stackoverflow.com/questions/8314499/read-n-lines-at-a-time-using-bash
exec 5< input-file.txt
exec 5<&-


/ Einde Intermezzo

/ Intermezzo

/ timestamps timezones	, 

/ 13	. 

/ 2018-12-15 20:19:30.000123+01 betekent: in tz +01 is het 20:19:30	, dat is altijd zo	,

/ numpy.datetime64 is tz unaware	, je kunt een tz geven, en numpy schrijft tstz over naar utc	,
Out[5353]: numpy.datetime64('2018-12-15T20:19:30.00123')

/ pythons datetime.datetime laat tz staan in tstz	, schrijft NIET om naar utc	, zoals nympy.datetime64 doet	,
2018-12-15 11:19:30.000123-07:53

/ postgres schrijft tstz over naar locale tz	,
2018-12-15 20:19:30.000123+01

/ 13	. 

/ datetime in python 

/ lees	,
https://docs.python.org/3/library/datetime.html

/ now	, 
In [5348]: import datetime
In [5349]: datetime.datetime.now()
Out[5349]: datetime.datetime(2018, 12, 28, 10, 13, 56, 131693)
In [5350]: print(datetime.datetime.now())
2018-12-28 10:14:17.444568
/ dit is tz unaware	,

In [5353]: np.datetime64('2005-02-25T12:35:23-08:00')
/home/eric/miniconda3/bin/ipython:1: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future
  #!/home/eric/miniconda3/bin/python
Out[5353]: numpy.datetime64('2005-02-25T20:35:23')
/ geeft time in UTC	,
/ dat staat hieronder	,

/ 1313	. 

/ lees	,
https://www.numpy.org/devdocs/reference/arrays.datetime.html

///////////////////////////////
/ numpy.datetime64 schrijft tstz over naar utc	,
/ maar tz is deprecated in numpy?
/ TODO

Changes with NumPy 1.11
In prior versions of NumPy, the datetime64 type always stored times in UTC. By default, creating a datetime64 object from a string or printing it would convert from or to local time:

# old behavior
>>>> np.datetime64('2000-01-01T00:00:00')
numpy.datetime64('2000-01-01T00:00:00-0800')  # note the timezone offset -08:00

/ Dus de schrijver is pacific tz	, de tijd die hij opgeeft is in localtime en wordt in utc gegeven, dus is -08	,

A consensus of datetime64 users agreed that this behavior is undesirable and at odds with how datetime64 is usually used (e.g., by pandas). For most use cases, a timezone naive datetime type is preferred, similar to the datetime.datetime type in the Python standard library. Accordingly, datetime64 no longer assumes that input is in local time, nor does it print local times:

>>>> np.datetime64('2000-01-01T00:00:00')
numpy.datetime64('2000-01-01T00:00:00')

/ Dus de schrijver is pacific tz	, en de tijd die hij opgeeft kent geen tz	, 


For backwards compatibility, datetime64 still parses timezone offsets, which it handles by converting to UTC. However, the resulting datetime is timezone naive:

>>>
>>> np.datetime64('2000-01-01T00:00:00-08')
DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future
numpy.datetime64('2000-01-01T08:00:00') 

/ je kunt nog wel een tz geven	, de tijd wordt dan naar utc geschreven, old behavior dus , van voor 1.11	,  

/ 1313	. 

/ pythons datetime.datetime laat tz staan in tstz	, schrijft NIET om naar utc	, zoals nympy.datetime64 doet	,

/ lees	,
https://stackoverflow.com/questions/7065164/how-to-make-an-unaware-datetime-timezone-aware-in-python

In general, to make a naive datetime timezone-aware, use the localize method:

import datetime
import pytz

unaware = datetime.datetime(2011, 8, 15, 8, 15, 12, 0)
aware = datetime.datetime(2011, 8, 15, 8, 15, 12, 0, pytz.UTC)

now_aware = pytz.utc.localize(unaware)
assert aware == now_aware
For the UTC timezone, it is not really necessary to use localize since there is no daylight savings time calculation to handle:

now_aware = unaware.replace(tzinfo=pytz.UTC)
works. (.replace returns a new datetime; it does not modify unaware.)


/ 1313	. 

/ lees	,
http://pytz.sourceforge.net/

In [5359]: import pytz

In [5368]: pytz.all_timezones
Out[5368]: ['Africa/Abidjan', 'Africa/Accra', 'Africa/Addis_Ababa', 'Africa/Algiers', 'Africa/Asmara', 'Africa/Asmera', 'Africa/Bamako', 'Africa/Bangui', 'Africa/Banjul', 'Africa/Bissau', 'Africa/Blantyre', 'Africa/Brazzaville', 'Africa/Bujumbura', 'Africa/Cairo', 'Africa/Casablanca', 'Africa/Ceuta', 'Africa/Conakry', 'Africa/Dakar', 'Africa/Dar_es_Salaam', 'Africa/Djibouti', 'Afric...,'Europe/Amsterdam',...

In [5379]: type(pytz.timezone('Europe/Berlin'))
Out[5379]: pytz.tzfile.Europe/Berlin

In [5384]: print(datetime.datetime(2018,8,15,11,19,30,123456,pytz.timezone('UTC')))
2018-08-15 11:19:30.123456+00:00
In [5383]: print(datetime.datetime(2018,8,15,11,19,30,123456,pytz.timezone('US/Pacific')))
2018-08-15 11:19:30.123456-07:53
In [5381]: print(datetime.datetime(2018,8,15,11,19,30,123456,pytz.timezone('US/Eastern')))
2018-08-15 11:19:30.123456-04:56
In [5380]: print(datetime.datetime(2018,8,15,11,19,30,123456,tzinfo=pytz.timezone('Europe/Berlin
      ...: ')))
2018-08-15 11:19:30.123456+00:53
In [5376]: print(datetime.datetime(2018,8,15,11,19,30,123456,pytz.timezone('Europe/Amsterdam')))
      ...: 
2018-08-15 11:19:30.123456+00:20

/ 1313	. 

/ self	,

/ python's datetime en change timezone	,

In [5387]: dt=datetime.datetime(2018,12,15,11,19,30,123)
In [5389]: print(dt)
2018-12-15 11:19:30.000123
In [5393]: dtpac=dt.replace(tzinfo=pytz.timezone('US/Pacific'))
In [5406]: dtams=dtpac.astimezone(pytz.timezone('Europe/Amsterdam'))
In [5407]: print(dtpac)
2018-12-15 11:19:30.000123-07:53
In [5408]: print(dtams)
2018-12-15 20:12:30.000123+01:00

/ 13	. 

/ datetime in postgres	, timezones	,

////////////////////
/ postgres schrijft tstz over naar locale tijd	,

/ lees	,
https://www.postgresql.org/docs/9.6/datatype-datetime.html
/ -8:00 is PST

test=> show time zone;
     TimeZone     
------------------
 Europe/Amsterdam
(1 row)

test=> select now();
              now              
-------------------------------
 2018-12-28 10:19:18.080758+01
(1 row)

test=> select timestamptz '2004-12-19 10:23:54';
      timestamptz       
------------------------
 2004-12-19 10:23:54+01
(1 row)

test=> select timestamptz '2004-10-19 10:23:54';
      timestamptz       
------------------------
 2004-10-19 10:23:54+02
(1 row)
/ +2, want op 19 oct was het zomertijd	, 

test=> select timestamptz '2004-12-19 10:23:54-08';
      timestamptz       
------------------------
 2004-12-19 19:23:54+01
(1 row)
/ 10:23:54 in UTC-8 is 18:23:54 in UTC = 19:23:54 in UTC+1=Amsterdam

/ Einde Intermezzo

/ Intermezzo

/ lees	,
https://www.numpy.org/devdocs/reference/arrays.datetime.html

/ lees	,
https://en.wikipedia.org/wiki/ISO_8601

/ T staat WH voor time	,
/ Z staat voor zero	,

/ 1313	. 

In [5430]: dt=np.datetime64('2018-12-28T12:23:59.123456789')
In [5431]: dt
Out[5431]: numpy.datetime64('2018-12-28T12:23:59.123456789')
In [5432]: print(dt)
2018-12-28T12:23:59.123456789
/ dit is WH tz unaware dt	,

In [5435]: dt=np.datetime64('2018-12-28T12:23:59.123456789+01')
/home/eric/miniconda3/bin/ipython:1: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future
  #!/home/eric/miniconda3/bin/python
In [5436]: dt
Out[5436]: numpy.datetime64('2018-12-28T11:23:59.123456789')
/ numpy prints dttz altijd in utc	,

In [5459]: dt=np.datetime64('2018-12-28T12:13:14Z')
/=
In [5459]: dt=np.datetime64('2018-12-28T12:13:14+00')
/home/eric/miniconda3/bin/ipython:1: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future
  #!/home/eric/miniconda3/bin/python
In [5460]: dt
Out[5460]: numpy.datetime64('2018-12-28T12:13:14')
/ Z staat voor zero	, 

In [5467]: np.datetime64('2018-01-01')==np.datetime64('2018')
Out[5467]: True
In [5468]: np.datetime64('2018-01-01')==np.datetime64('2018-01')
Out[5468]: True
In [5471]: np.datetime64('2018-01-01T00:00:00Z')==np.datetime64('2018-01')
/home/eric/miniconda3/bin/ipython:1: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future
  #!/home/eric/miniconda3/bin/python
Out[5471]: True
In [5475]: np.datetime64('2018-01-01T00Z')==np.datetime64('2018-01')
/home/eric/miniconda3/bin/ipython:1: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future
  #!/home/eric/miniconda3/bin/python
Out[5475]: True

In [5433]: dt=np.datetime64('2018-12-28T12:23:59.123456789123')
In [5434]: print(dt)
1969-11-21T04:22:16.931854453379
/ TODO

/ 1313	.

In [5438]: dt=np.datetime64('2018-12-28','ms')
In [5439]: dt
Out[5439]: numpy.datetime64('2018-12-28T00:00:00.000')
In [5440]: print(dt)
2018-12-28T00:00:00.000

In [5445]: a=np.array(['2018-12-28'],dtype='datetime64[ms]')
In [5446]: a.dtype
Out[5446]: dtype('<M8[ms]')
In [5447]: print(a)
['2018-12-28T00:00:00.000']
In [5448]: a
Out[5448]: array(['2018-12-28T00:00:00.000'], dtype='datetime64[ms]')

In [5456]: a=np.arange('2018-12-01','2018-12-02',dtype='datetime64[h]')
In [5457]: a
Out[5457]: 
array(['2018-12-01T00', '2018-12-01T01', '2018-12-01T02', '2018-12-01T03',
       '2018-12-01T04', '2018-12-01T05', '2018-12-01T06', '2018-12-01T07',
       '2018-12-01T08', '2018-12-01T09', '2018-12-01T10', '2018-12-01T11',
       '2018-12-01T12', '2018-12-01T13', '2018-12-01T14', '2018-12-01T15',
       '2018-12-01T16', '2018-12-01T17', '2018-12-01T18', '2018-12-01T19',
       '2018-12-01T20', '2018-12-01T21', '2018-12-01T22', '2018-12-01T23'],
      dtype='datetime64[h]')

/ 1313	. 

In [5476]: td=np.datetime64('2018-12-28')- np.datetime64('2018-11-28')
In [5477]: td
Out[5477]: numpy.timedelta64(30,'D')

In [5478]: td=np.datetime64('2018-12-28T15')- np.datetime64('2018-11-28')
In [5479]: td
Out[5479]: numpy.timedelta64(735,'h')

In [5485]: dt=np.datetime64('2018-12-01T15')+np.timedelta64(23,'h')
In [5486]: dt
Out[5486]: numpy.datetime64('2018-12-02T14','h')

In [5487]: td=np.timedelta64(1,'Y')
In [5489]: td2=np.timedelta64(td,'M')
In [5491]: td2
Out[5491]: numpy.timedelta64(12,'M')
In [5492]: td3=np.timedelta64(a,'D')
TypeError: Cannot cast NumPy timedelta64 scalar from metadata [Y] to [D] according to the rule 'same_kind'

/ 1313	. 

/ units	, 
Code	Meaning	Time span (relative)	Time span (absolute)
Y	year	+/- 9.2e18 years	[9.2e18 BC, 9.2e18 AD]
M	month	+/- 7.6e17 years	[7.6e17 BC, 7.6e17 AD]
W	week	+/- 1.7e17 years	[1.7e17 BC, 1.7e17 AD]
D	day	+/- 2.5e16 years	[2.5e16 BC, 2.5e16 AD]
And here are the time units:
Code	Meaning	Time span (relative)	Time span (absolute)
h	hour	+/- 1.0e15 years	[1.0e15 BC, 1.0e15 AD]
m	minute	+/- 1.7e13 years	[1.7e13 BC, 1.7e13 AD]
s	second	+/- 2.9e11 years	[2.9e11 BC, 2.9e11 AD]
ms	millisecond	+/- 2.9e8 years	[ 2.9e8 BC, 2.9e8 AD]
us	microsecond	+/- 2.9e5 years	[290301 BC, 294241 AD]
ns	nanosecond	+/- 292 years	[ 1678 AD, 2262 AD]
ps	picosecond	+/- 106 days	[ 1969 AD, 1970 AD]
fs	femtosecond	+/- 2.6 hours	[ 1969 AD, 1970 AD]
as	attosecond	+/- 9.2 seconds	[ 1969 AD, 1970 AD]

/ 1313	. 

/ busday 
/ TODO

/ 13

/ datetime in pandas	,

/ lees	,
https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.tz_convert.html
https://stackoverflow.com/questions/42826388/using-time-zone-in-pandas-to-datetime
https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.tz_localize.html
https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.Timestamp.html

/ 1313	. 

/ .to_datetime	,

/ .tz_localize geeft een tz-naive dt een tz	, gewoon erbij zetten	,
/ .tz_convert schrijft de dt om naar de nieuwe tz	,

In [5586]: dt=pd.to_datetime('2018-12-28T12:13:14')
In [5596]: dt
Out[5596]: Timestamp('2018-12-28 12:13:14')
In [5595]: type (dt)
Out[5595]: pandas._libs.tslibs.timestamps.Timestamp
/ dt is tz-naive	, 
In [5587]: dtams=dt.tz_localize('Europe/Amsterdam')
In [5592]: dtams
Out[5592]: Timestamp('2018-12-28 12:13:14+0100', tz='Europe/Amsterdam')
In [5588]: dtpac=dt.tz_localize('US/Pacific')
In [5594]: dtpac
Out[5594]: Timestamp('2018-12-28 12:13:14-0800', tz='US/Pacific')
In [5589]: dtams2=dtpac.tz_convert('Europe/Amsterdam')
In [5593]: dtams2
Out[5593]: Timestamp('2018-12-28 21:13:14+0100', tz='Europe/Amsterdam')
In [5591]: dtams2-dtams
Out[5591]: Timedelta('0 days 09:00:00')

In [5627]: dtams.to_datetime64()
Out[5627]: numpy.datetime64('2018-12-28T11:13:14.000000000')
/ 12 is 11 geworden	, UTC  
In [5623]: dtams.tz
Out[5623]: <DstTzInfo 'Europe/Amsterdam' CET+1:00:00 STD>


In [5597]: dt=pd.to_datetime('2018-12-28T12:13:14+01')
In [5598]: dt
Out[5598]: Timestamp('2018-12-28 11:13:14')
/ +01 wordt niet gezien, dt is een tz-naive Timestamp	,

/ 1313	.

/ Timestamp

In [5599]: pd.Timestamp('2018-12-28T12:13:14')
Out[5599]: Timestamp('2018-12-28 12:13:14')










/ Einde Intermezzo

/ Intermezzo

/ VERSCHIL DATETIMEINDEX PERIODINDEX TIMEDELTAINDEX

/ .to_datetime(): 
/ als je hem een date geeft, krijg je een Timestamp	,
/ als je hem een array van dates geeft, krijg je een DatetimeIndex	,

/ google
difference datetimeindex periodindex	,
/ lees	,
https://github.com/pandas-dev/pandas/issues/18850 

In [5693]: pd.date_range('2016-01-01', periods=3)
Out[5693]: DatetimeIndex(['2016-01-01', '2016-01-02', '2016-01-03'], dtype='datetime64[ns]', freq='D')

: pd.date_range?
...
freq : str or DateOffset, default 'D' (calendar daily)
tz : str or tzinfo, optional

/ lees	,
https://pandas.pydata.org/pandas-docs/stable/timeseries.html#timeseries-offset-aliases

/ 1313	. 

/ verschil tussen een datetime index en een period index	, 

In [5698]: pd.date_range('2016-01-01', periods=3,freq='H')
Out[5698]: 
DatetimeIndex(['2016-01-01 00:00:00', '2016-01-01 01:00:00',
               '2016-01-01 02:00:00'],
              dtype='datetime64[ns]', freq='H')

In [5702]: dtidx=pd.date_range('2016-01-01', periods=3,freq='M')
In [5703]: dtidx
Out[5703]: DatetimeIndex(['2016-01-31', '2016-02-29', '2016-03-31'], dtype='datetime64[ns]', freq='M')
In [5704]: priMdx=dtidx.to_period('M')
In [5705]: priMdx
Out[5705]: PeriodIndex(['2016-01', '2016-02', '2016-03'], dtype='period[M]', freq='M')
In [5706]: prDidx=dtidx.to_period('D')
In [5708]: prDidx
Out[5708]: PeriodIndex(['2016-01-31', '2016-02-29', '2016-03-31'], dtype='period[D]', freq='D')
In [5715]: dtidx[0]
Out[5715]: Timestamp('2016-01-31 00:00:00', freq='M')

/ WH in DatetimeIndex zijn er Timestamps, die exact een tijdstip zijn	, in PeriodIndex zijn er Periods, die een dag zijn bijv	,

In [5717]: dtidx-dtidx[0]
Out[5717]: TimedeltaIndex(['0 days', '29 days', '60 days'], dtype='timedelta64[ns]', freq=None)

In [5718]: (dtidx-dtidx[0])[0]
Out[5718]: Timedelta('0 days 00:00:00')
In [5719]: (dtidx-dtidx[0])[1]
Out[5719]: Timedelta('29 days 00:00:00')

/ 1313	. 

/ verschil tussen een period index en een timedelta index	,

In [5720]: dtidx=pd.date_range('2016-01-01',periods=3,freq='D')
In [5721]: dtidx
Out[5721]: DatetimeIndex(['2016-01-01', '2016-01-02', '2016-01-03'], dtype='datetime64[ns]', freq='D')
In [5722]: (dtidx-dtidx[0])[1]
Out[5722]: Timedelta('1 days 00:00:00')

In [5723]: prDidx=dtidx.to_period('D')
In [5724]: prDidx
Out[5724]: PeriodIndex(['2016-01-01', '2016-01-02', '2016-01-03'], dtype='period[D]', freq='D')
In [5726]: prDidx[0]
Out[5726]: Period('2016-01-01', 'D')

In [5724]: prDidx
Out[5724]: PeriodIndex(['2016-01-01', '2016-01-02', '2016-01-03'], dtype='period[D]', freq='D')
In [5725]: (dtidx-dtidx[0])
Out[5725]: TimedeltaIndex(['0 days', '1 days', '2 days'], dtype='timedelta64[ns]', freq=None)

/ Hier zien we het verschil tussen een period index en een timedelta index	,


/ lees	,
https://pandas.pydata.org/pandas-docs/stable/timeseries.html#timeseries-offset-aliases

/ Einde Intermezzo

/ VERVOLG (218)

/ dit is na alle Intermezzo's na VERVOLG (178)	,

In [5786]: plt.style.use('classic')

In [5790]: plt.style.use?    
->
In [5788]: plt.style.available
Out[5788]: 
['seaborn-muted',
 'seaborn-white',
 'seaborn-dark-palette',
 'classic',
 'seaborn-bright',
 'tableau-colorblind10',
 'seaborn-whitegrid',
 'seaborn-notebook',
 'bmh',
 'seaborn',
 'fivethirtyeight',
 'seaborn-deep',
 'seaborn-paper',
 'ggplot',
 'seaborn-dark',
 'Solarize_Light2',
 'seaborn-talk',
 'seaborn-pastel',
 'seaborn-poster',
 '_classic_test',
 'seaborn-ticks',
 'grayscale',
 'seaborn-colorblind',
 'fast',
 'dark_background',
 'seaborn-darkgrid']

/ 1313	. 

In [5816]: quit
[eric@almond vanderplas]$ ipython

In [1]: %matplotlib
Using matplotlib backend: Qt5Agg

/ plt.show() hoeft niet	, 

In [6]: import numpy as np
In [7]: x=np.linspace(0,10,101)
In [9]: plt.plot(x,np.cos(x))
Out[9]: [<matplotlib.lines.Line2D at 0x7f750403c9e8>]
/ we zien de grafiek in assenstelsel in een window	,
In [10]: plt.plot(x,np.sin(x))
Out[10]: [<matplotlib.lines.Line2D at 0x7f74ffc67278>]
/ we zien ook deze grafiek in het assenstelsel in het window	,

/ als je het window weg click	, en je doet opnieuw	,
In [10]: plt.plot(x,np.sin(x))
/ dan komt we weer een window, met assenstelsel en grafiek	,


/ 1313	.

In [13]: x
Out[13]: 
array([ 0.        ,  1.11111111,  2.22222222,  3.33333333,  4.44444444,
        5.55555556,  6.66666667,  7.77777778,  8.88888889, 10.        ])
/ 10 samples geeft 9 intervallen	,

In [5795]: x
Out[5795]: array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])
/ 11 is het aantal samples	,
/ 11 samples geeft 10 intervallen	,

/ hoe grafieken uit een assenstelsel verwijderen?
/ TODO

/ 1313	. 

/ als we  
In [10]: plt.plot(x,np.sin(x))
/ dan zien we figure (in een apart window)	, 
/ hoe kunnen we dit figure te pakken krijgen?
In [65]: plt.gcf()
/ TODO doe het een keer	,

/ maar we beginnen juist met een figure	, en als we dan plt.plot doen, verschijnt die in deze figure	,

In [17]: fig=plt.figure()
/ we zien een window met een assenstelsel	,

In [18]: plt.plot(x,np.sin(x))
Out[18]: [<matplotlib.lines.Line2D at 0x7f74ff42ea58>]
In [19]: plt.plot(x,np.cos(x))
Out[19]: [<matplotlib.lines.Line2D at 0x7f74ff3d9748>]

In [20]: fig.savefig('my_figure.png')

/ sluit window	,

In [21]: from IPython.display import Image

In [22]: Image('my_figure.png')
Out[22]: <IPython.core.display.Image object>
/ TODO we zien niets	,

In [30]: fig.canvas.get_supported_filetypes()
Out[30]: 
{'ps': 'Postscript',
 'eps': 'Encapsulated Postscript',
 'pdf': 'Portable Document Format',
 'pgf': 'PGF code for LaTeX',
 'png': 'Portable Network Graphics',
 'raw': 'Raw RGBA bitmap',
 'rgba': 'Raw RGBA bitmap',
 'svg': 'Scalable Vector Graphics',
 'svgz': 'Scalable Vector Graphics'}

/ 1313	. 

In [60]: plt.figure()
Out[60]: <Figure size 640x480 with 0 Axes>
/ we zien het window met assenstelsel	,

In [61]: plt.subplot(2,1,1)
Out[61]: <matplotlib.axes._subplots.AxesSubplot at 0x7f74ff0d0e10>
In [62]: plt.plot(x,np.sin(x))
Out[62]: [<matplotlib.lines.Line2D at 0x7f74fe7f77f0>]

In [63]: plt.subplot(2,1,2)
Out[63]: <matplotlib.axes._subplots.AxesSubplot at 0x7f74fe7e24a8>
In [64]: plt.plot(x,np.cos(x))
Out[64]: [<matplotlib.lines.Line2D at 0x7f74fe7496d8>]

In [65]: plt.gcf()
Out[65]: <Figure size 640x480 with 2 Axes>

/ get current figure	,
In [67]: fig=plt.gcf()

In [69]: plt.gca()
Out[69]: <matplotlib.axes._subplots.AxesSubplot at 0x7f74fe7e24a8>
/ de onderste	,

/ maar we kunnen de 1ste assenstelstel pakken	, 
In [74]: fig.get_axes()
Out[74]: 
[<matplotlib.axes._subplots.AxesSubplot at 0x7f74ff0d0e10>,
 <matplotlib.axes._subplots.AxesSubplot at 0x7f74fe7e24a8>]

In [75]: fig.get_axes()[0]
Out[75]: <matplotlib.axes._subplots.AxesSubplot at 0x7f74ff0d0e10>
/ we kunnen WH zo in dit assenstelsel tekenen	,


/ 1313	. 

In [70]: fig,ax=plt.subplots(2)
/ we zien een window met 2 assenstelsels, die we hierboven met de hand moesten maken met 2 plt.subplot	,

In [71]: fig
Out[71]: <Figure size 640x480 with 2 Axes>

In [72]: ax
Out[72]: 
array([<matplotlib.axes._subplots.AxesSubplot object at 0x7f74fe71e6a0>,
       <matplotlib.axes._subplots.AxesSubplot object at 0x7f74fe6c4940>],
      dtype=object)

In [81]: ax[0].plot(x,np.sin(x))
Out[81]: [<matplotlib.lines.Line2D at 0x7f74fe4fdc88>]

In [82]: ax[1].plot(x,np.cos(x))
Out[82]: [<matplotlib.lines.Line2D at 0x7f74fe718eb8>]


/ 1313	. 

/ we oef	,

In [83]: plt.figure()
Out[83]: <Figure size 640x480 with 0 Axes>

In [84]: fig=plt.gcf()

In [85]: fig.get_axes()
Out[85]: []
/ klopt	,

In [86]: plt.subplot(2,1,1)
Out[86]: <matplotlib.axes._subplots.AxesSubplot at 0x7f74fe5171d0>

In [87]: plt.subplot(2,1,2)
Out[87]: <matplotlib.axes._subplots.AxesSubplot at 0x7f74fe32ae10>

In [88]: fig.get_axes()
Out[88]: 
[<matplotlib.axes._subplots.AxesSubplot at 0x7f74fe5171d0>,
 <matplotlib.axes._subplots.AxesSubplot at 0x7f74fe32ae10>]

In [89]: ax=fig.get_axes()

In [90]: ax[0].plot(x,np.cos(x))
Out[90]: [<matplotlib.lines.Line2D at 0x7f74fe3309b0>]
/ klopt, tekent in het bovenste assenstelsel	,

In [91]: ax[1].plot(x,np.sin(x))
Out[91]: [<matplotlib.lines.Line2D at 0x7f74fe5250b8>]

In [92]: fig.savefig('my_figure4.png')

In [94]: Image('my_figure4.png')
Out[94]: <IPython.core.display.Image object>
/ TODO we zien niets	,

/ 1313	. 

In [97]: plt.style.available
Out[97]: 
['seaborn-muted',
...
 'seaborn-whitegrid',
...

In [98]:  plt.style.use('seaborn-whitegrid')

In [99]: fig=plt.figure()
/ we zien window	,
In [100]: ax=plt.axes()
/ we zien axis	, hor en ver van 0 tot 1	,

In [103]: x=np.linspace(0,10,101)
In [105]: ax.plot(x,np.sin(x))
Out[105]: [<matplotlib.lines.Line2D at 0x7f74fe30b9e8>]
/ De hor as gaat ineens van 0 naar 10	,

In [107]: plt.plot(x,np.cos(x))
Out[107]: [<matplotlib.lines.Line2D at 0x7f74fe0c1470>]
/ verschijnt in dezelfde axes	, WH omdat fig.gca() dat is	,

/ 1313

In [112]: ax.clear()
/ rm de grafieken, en zet hor as weer op van 0 tot 1	,

In [113]: plt.plot(x,np.cos(x))
Out[113]: [<matplotlib.lines.Line2D at 0x7f74fe270400>]
/ tekent grafiek in assenstelsel	, hor van 0 tot 1	,

/ 1313	. 

In [116]: plt.plot(x,np.sin(x-0),color='blue')
Out[116]: [<matplotlib.lines.Line2D at 0x7f74fe0e2048>]

In [117]: plt.plot(x,np.sin(x-1),color='g')
Out[117]: [<matplotlib.lines.Line2D at 0x7f74fe0ae860>]

In [118]: plt.plot(x,np.sin(x-2),color='0.75')
Out[118]: [<matplotlib.lines.Line2D at 0x7f74fe050080>]

In [119]: plt.plot(x,np.sin(x-3),color='#ffdd44')
Out[119]: [<matplotlib.lines.Line2D at 0x7f74fe050b00>]

In [120]: plt.plot(x,np.sin(x-4),color=(1.,.2,.3))
Out[120]: [<matplotlib.lines.Line2D at 0x7f74fe0aeba8>]

In [121]: plt.plot(x,np.sin(x-5),color='chartreuse')
Out[121]: [<matplotlib.lines.Line2D at 0x7f74fe05fbe0>]

/ 1313	. 

In [123]: ax.clear()

/ gewoon 1 dash -> solid	,
In [135]: plt.plot(x,x+5,linestyle='-')
Out[135]: [<matplotlib.lines.Line2D at 0x7f74fe268b70>]

/ gewoon 2 dashes naast elkaar	, -> dashed	,
In [135]: plt.plot(x,x+5,linestyle='--')
Out[135]: [<matplotlib.lines.Line2D at 0x7f74fe268b70>]

In [136]: plt.plot(x,x+5,linestyle='-.')
Out[136]: [<matplotlib.lines.Line2D at 0x7f74fe9dc048>]

In [138]: plt.plot(x,x+6,linestyle=':')
Out[138]: [<matplotlib.lines.Line2D at 0x7f74fed20438>]

/ 1313	. 

/ combine	,

In [140]: ax.clear()

In [141]:  plt.plot(x,x,'-g')
Out[141]: [<matplotlib.lines.Line2D at 0x7f74fe702e80>]

In [142]:  plt.plot(x,2*x,'--c')
Out[142]: [<matplotlib.lines.Line2D at 0x7f74fe289668>]

In [143]:  plt.plot(x,3*x,'-.k')
Out[143]: [<matplotlib.lines.Line2D at 0x7f74fe05f0b8>]

In [144]:  plt.plot(x,3*x,':r')
Out[144]: [<matplotlib.lines.Line2D at 0x7f74fe06e668>]

/ 1313	. 

/ control axes limits	,

In [151]: ax.clear()

In [152]: plt.plot(x,np.sin(x))
Out[152]: [<matplotlib.lines.Line2D at 0x7f74fe2aff28>]

In [156]: plt.xlim(0,10)
Out[156]: (0, 10)
/ hij begint precies op 0 en eindigt precies op 10	,

In [153]: plt.xlim(-1,11)
Out[153]: (-1, 11)
/ hij begint precies op -1 en eindigt precies op 11	,

In [150]: plt.ylim(-1.5,1.5)
Out[150]: (-1.5, 1.5)

/ 1313	. 

/ revert	,

In [154]: ax.clear()

In [155]: plt.plot(x,np.sin(x))
Out[155]: [<matplotlib.lines.Line2D at 0x7f74fdee8390>]

In [156]: plt.xlim(0,10)
Out[156]: (0, 10)

In [157]: plt.xlim(10,0)
Out[157]: (10, 0)
/ de hor as gaat van 10 naar 0	, precies	,

/ 1313	. 

/ herinner	,
In [100]: ax=plt.axes()

In [100]: ax.clear()

In [159]: plt.plot(x,np.sin(x))
Out[159]: [<matplotlib.lines.Line2D at 0x7f74ff230898>]

In [160]: plt.axis([-1,11,-1.5,1.5])
Out[160]: [-1, 11, -1.5, 1.5]

/ 1313	 .

In [161]: ax.clear()

In [162]: plt.plot(x,np.sin(x))
Out[162]: [<matplotlib.lines.Line2D at 0x7f74fded8f60>]

In [163]: plt.axis('tight')
Out[163]: (-0.5, 10.5, -1.099898100594381, 1.0995484460717855)

/ TODO we zien niet wat er in het boek staat	,

/ 1313	. 

In [164]: ax.clear()

In [165]: plt.plot(x,np.sin(x))
Out[165]: [<matplotlib.lines.Line2D at 0x7f74fe0db048>]

In [166]: plt.axis('equal')
Out[166]: (-0.5, 10.5, -1.099898100594381, 1.0995484460717855)

/ OK	, we zien dezelfde schaal op de hor en vert as	,

/ 1313	. 

/ met plt.axis('normal') rm we plt.axis('equal')	, 
/ met ax.clear() rm we de grafieken	, 
/ maar we kunnen ook plt.figure() , dan weer een nieuw assenstelsel, met 'normal' axis	,

/ 1313	. 

In [169]: ax.clear()

In [170]: plt.plot(x,np.sin(x))
Out[170]: [<matplotlib.lines.Line2D at 0x7f74fde5fac8>]

/ we zien nog steeds dat plt.axis('equal')

In [172]: plt.axis()
Out[172]: (-0.5, 10.5, -4.098561924035491, 4.098212269512895)

In [180]: plt.axis('normal')
Out[180]: (-0.5, 10.5, -1.099898100594381, 1.0995484460717855)
/ is deprecated, maar werkt OK	,
/ TODO

In [181]: ax.clear()

In [182]: plt.plot(x,np.sin(x))
Out[182]: [<matplotlib.lines.Line2D at 0x7f74fde96ef0>]

/ 1313	. 

In [181]: ax.clear()

In [182]: plt.plot(x,np.sin(x))
Out[182]: [<matplotlib.lines.Line2D at 0x7f74fde96ef0>]

In [183]: plt.title('A sine curve')
Out[183]: Text(0.5,1,'A sine curve')

In [184]: plt.xlabel('x')
Out[184]: Text(0.5,28.3833,'x')

In [185]: plt.ylabel('sin(x)')
Out[185]: Text(34.3333,0.5,'sin(x)')

/ Okay	,

/ 1313	. 

In [186]: ax.clear()

In [187]: plt.plot(x,np.sin(x),'-g',label='sin')
Out[187]: [<matplotlib.lines.Line2D at 0x7f74ff0d0470>]

In [190]: plt.plot(x,np.cos(x),':b',label='cos')
Out[190]: [<matplotlib.lines.Line2D at 0x7f74fde43c88>]

In [191]: plt.legend()
Out[191]: <matplotlib.legend.Legend at 0x7f74fe0dba20>
/ nu pas zien we de legend	,

/ 1313	. 

/ met fig en ax is object-oriented interface	, 

/ 1313. 

In [212]: fig=plt.figure()
/ we zien window, zonder assen	,

In [209]: ax=plt.axes()
/ we zien window met assen	, 
/ ook als je NIET eerst plt.figure() doet, krijg je dit	; tenzij je fig nodig hebt, hoef je dit niet te doen	,

/ nu kun je ook voortaan	,
In [210]: ax.clear()

In [228]: x=np.linspace(0,10,31)
In [228]: y=np.sin(x)

In [229]: plt.plot(x,y,'ok')
Out[229]: [<matplotlib.lines.Line2D at 0x7f74fe752710>]
/ zwarte stippen, scatter plot	,
/ als je alleen 'o', zie je blauwe stippen	, 
' ok--' kan ook	, of	,

/ 1313	. 

In [230]: ax.clear()

In [231]: plt.plot(x,y,'ok-.')
Out[231]: [<matplotlib.lines.Line2D at 0x7f74fe2902e8>]

/ 1313	. 

In [239]: rng.rand(5)
Out[239]: array([0.44712538, 0.84640867, 0.69947928, 0.29743695, 0.81379782])

In [232]: ax.clear()

In [233]: rng=np.random.RandomState(0)

In [234]: for marker in ['o','.',',','x','+','v','^','<','>','s','d']:
     ...:     plt.plot(rng.rand(5),rng.rand(5),marker,label="marker='{0}'".format(marker))
     ...:     
/ we zien 5 punten met elk van de markers	,

In [235]: plt.legend(numpoints=1)
Out[235]: <matplotlib.legend.Legend at 0x7f74fcf0ec18>
/ TODO numpoints	,

In [237]: plt.xlim(0,1.8)
Out[237]: (0, 1.8)

/ 1313	. 

In [232]: ax.clear()

In [248]: plt.plot(x,y,'-p',color='gray',markersize=15,linewidth=4,markerfacecolor='white',markeredgecolor='gray',markeredgewidth=2)
Out[248]: [<matplotlib.lines.Line2D at 0x7f74fcc79c50>]

/ 1313	. 

/ scatter	,

/ met scatter kun je per point de marker verschillen	, de kleur	, ...

/ soms reageert ax.clear() niet en moet je eerst	,
In [250]: ax=plt.gca()
In [251]: ax.clear()

In [253]: plt.scatter(x,y,marker='o')
Out[253]: <matplotlib.collections.PathCollection at 0x7f74fce59400>

/ 1313	. 

In [254]: x=rng.randn(100)

In [255]: y=rng.randn(100)

In [256]: colors=rng.rand(100)
In [260]: sizes=1000*rng.rand(100)

In [266]: ax.clear()

In [267]: plt.scatter(x,y,c=colors,s=sizes,alpha=.3,cmap='viridis')
Out[267]: <matplotlib.collections.PathCollection at 0x7f74fca3ef60>

In [268]: plt.colorbar()
Out[268]: <matplotlib.colorbar.Colorbar at 0x7f74fca22240>

/ 1313	. 

In [269]: from sklearn.datasets import load_iris

In [270]: iris=load_iris()

In [271]: iris
Out[271]: 
{'data': array([[5.1, 3.5, 1.4, 0.2],
        [4.9, 3. , 1.4, 0.2],
        [4.7, 3.2, 1.3, 0.2],
        [4.6, 3.1, 1.5, 0.2],
        [5. , 3.6, 1.4, 0.2],
        [5.4, 3.9, 1.7, 0.4],
        [4.6, 3.4, 1.4, 0.3],
        [5. , 3.4, 1.5, 0.2],
        [4.4, 2.9, 1.4, 0.2],
        [4.9, 3.1, 1.5, 0.1],
        [5.4, 3.7, 1.5, 0.2],
        [4.8, 3.4, 1.6, 0.2],
        [4.8, 3. , 1.4, 0.1],
        [4.3, 3. , 1.1, 0.1],
        [5.8, 4. , 1.2, 0.2],
        [5.7, 4.4, 1.5, 0.4],
        [5.4, 3.9, 1.3, 0.4],
        [5.1, 3.5, 1.4, 0.3],
        [5.7, 3.8, 1.7, 0.3],
        [5.1, 3.8, 1.5, 0.3],
        [5.4, 3.4, 1.7, 0.2],
        [5.1, 3.7, 1.5, 0.4],
        [4.6, 3.6, 1. , 0.2],
        [5.1, 3.3, 1.7, 0.5],
        [4.8, 3.4, 1.9, 0.2],
        [5. , 3. , 1.6, 0.2],
        [5. , 3.4, 1.6, 0.4],
        [5.2, 3.5, 1.5, 0.2],
        [5.2, 3.4, 1.4, 0.2],
        [4.7, 3.2, 1.6, 0.2],
        [4.8, 3.1, 1.6, 0.2],
        [5.4, 3.4, 1.5, 0.4],
        [5.2, 4.1, 1.5, 0.1],
        [5.5, 4.2, 1.4, 0.2],
        [4.9, 3.1, 1.5, 0.1],
        [5. , 3.2, 1.2, 0.2],
        [5.5, 3.5, 1.3, 0.2],
        [4.9, 3.1, 1.5, 0.1],
        [4.4, 3. , 1.3, 0.2],
        [5.1, 3.4, 1.5, 0.2],
        [5. , 3.5, 1.3, 0.3],
        [4.5, 2.3, 1.3, 0.3],
        [4.4, 3.2, 1.3, 0.2],
        [5. , 3.5, 1.6, 0.6],
        [5.1, 3.8, 1.9, 0.4],
        [4.8, 3. , 1.4, 0.3],
        [5.1, 3.8, 1.6, 0.2],
        [4.6, 3.2, 1.4, 0.2],
        [5.3, 3.7, 1.5, 0.2],
        [5. , 3.3, 1.4, 0.2],
        [7. , 3.2, 4.7, 1.4],
        [6.4, 3.2, 4.5, 1.5],
        [6.9, 3.1, 4.9, 1.5],
        [5.5, 2.3, 4. , 1.3],
        [6.5, 2.8, 4.6, 1.5],
        [5.7, 2.8, 4.5, 1.3],
        [6.3, 3.3, 4.7, 1.6],
        [4.9, 2.4, 3.3, 1. ],
        [6.6, 2.9, 4.6, 1.3],
        [5.2, 2.7, 3.9, 1.4],
        [5. , 2. , 3.5, 1. ],
        [5.9, 3. , 4.2, 1.5],
        [6. , 2.2, 4. , 1. ],
        [6.1, 2.9, 4.7, 1.4],
        [5.6, 2.9, 3.6, 1.3],
        [6.7, 3.1, 4.4, 1.4],
        [5.6, 3. , 4.5, 1.5],
        [5.8, 2.7, 4.1, 1. ],
        [6.2, 2.2, 4.5, 1.5],
        [5.6, 2.5, 3.9, 1.1],
        [5.9, 3.2, 4.8, 1.8],
        [6.1, 2.8, 4. , 1.3],
        [6.3, 2.5, 4.9, 1.5],
        [6.1, 2.8, 4.7, 1.2],
        [6.4, 2.9, 4.3, 1.3],
        [6.6, 3. , 4.4, 1.4],
        [6.8, 2.8, 4.8, 1.4],
        [6.7, 3. , 5. , 1.7],
        [6. , 2.9, 4.5, 1.5],
        [5.7, 2.6, 3.5, 1. ],
        [5.5, 2.4, 3.8, 1.1],
        [5.5, 2.4, 3.7, 1. ],
        [5.8, 2.7, 3.9, 1.2],
        [6. , 2.7, 5.1, 1.6],
        [5.4, 3. , 4.5, 1.5],
        [6. , 3.4, 4.5, 1.6],
        [6.7, 3.1, 4.7, 1.5],
        [6.3, 2.3, 4.4, 1.3],
        [5.6, 3. , 4.1, 1.3],
        [5.5, 2.5, 4. , 1.3],
        [5.5, 2.6, 4.4, 1.2],
        [6.1, 3. , 4.6, 1.4],
        [5.8, 2.6, 4. , 1.2],
        [5. , 2.3, 3.3, 1. ],
        [5.6, 2.7, 4.2, 1.3],
        [5.7, 3. , 4.2, 1.2],
        [5.7, 2.9, 4.2, 1.3],
        [6.2, 2.9, 4.3, 1.3],
        [5.1, 2.5, 3. , 1.1],
        [5.7, 2.8, 4.1, 1.3],
        [6.3, 3.3, 6. , 2.5],
        [5.8, 2.7, 5.1, 1.9],
        [7.1, 3. , 5.9, 2.1],
        [6.3, 2.9, 5.6, 1.8],
        [6.5, 3. , 5.8, 2.2],
        [7.6, 3. , 6.6, 2.1],
        [4.9, 2.5, 4.5, 1.7],
        [7.3, 2.9, 6.3, 1.8],
        [6.7, 2.5, 5.8, 1.8],
        [7.2, 3.6, 6.1, 2.5],
        [6.5, 3.2, 5.1, 2. ],
        [6.4, 2.7, 5.3, 1.9],
        [6.8, 3. , 5.5, 2.1],
        [5.7, 2.5, 5. , 2. ],
        [5.8, 2.8, 5.1, 2.4],
        [6.4, 3.2, 5.3, 2.3],
        [6.5, 3. , 5.5, 1.8],
        [7.7, 3.8, 6.7, 2.2],
        [7.7, 2.6, 6.9, 2.3],
        [6. , 2.2, 5. , 1.5],
        [6.9, 3.2, 5.7, 2.3],
        [5.6, 2.8, 4.9, 2. ],
        [7.7, 2.8, 6.7, 2. ],
        [6.3, 2.7, 4.9, 1.8],
        [6.7, 3.3, 5.7, 2.1],
        [7.2, 3.2, 6. , 1.8],
        [6.2, 2.8, 4.8, 1.8],
        [6.1, 3. , 4.9, 1.8],
        [6.4, 2.8, 5.6, 2.1],
        [7.2, 3. , 5.8, 1.6],
        [7.4, 2.8, 6.1, 1.9],
        [7.9, 3.8, 6.4, 2. ],
        [6.4, 2.8, 5.6, 2.2],
        [6.3, 2.8, 5.1, 1.5],
        [6.1, 2.6, 5.6, 1.4],
        [7.7, 3. , 6.1, 2.3],
        [6.3, 3.4, 5.6, 2.4],
        [6.4, 3.1, 5.5, 1.8],
        [6. , 3. , 4.8, 1.8],
        [6.9, 3.1, 5.4, 2.1],
        [6.7, 3.1, 5.6, 2.4],
        [6.9, 3.1, 5.1, 2.3],
        [5.8, 2.7, 5.1, 1.9],
        [6.8, 3.2, 5.9, 2.3],
        [6.7, 3.3, 5.7, 2.5],
        [6.7, 3. , 5.2, 2.3],
        [6.3, 2.5, 5. , 1.9],
        [6.5, 3. , 5.2, 2. ],
        [6.2, 3.4, 5.4, 2.3],
        [5.9, 3. , 5.1, 1.8]]),
 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),
 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),
 'DESCR': 'Iris Plants Database\n====================\n\nNotes\n-----\nData Set Characteristics:\n    :Number of Instances: 150 (50 in each of three classes)\n    :Number of Attributes: 4 numeric, predictive attributes and the class\n    :Attribute Information:\n        - sepal length in cm\n        - sepal width in cm\n        - petal length in cm\n        - petal width in cm\n        - class:\n                - Iris-Setosa\n                - Iris-Versicolour\n                - Iris-Virginica\n    :Summary Statistics:\n\n    ============== ==== ==== ======= ===== ====================\n                    Min  Max   Mean    SD   Class Correlation\n    ============== ==== ==== ======= ===== ====================\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\n    ============== ==== ==== ======= ===== ====================\n\n    :Missing Attribute Values: None\n    :Class Distribution: 33.3% for each of 3 classes.\n    :Creator: R.A. Fisher\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n    :Date: July, 1988\n\nThis is a copy of UCI ML iris datasets.\nhttp://archive.ics.uci.edu/ml/datasets/Iris\n\nThe famous Iris database, first used by Sir R.A Fisher\n\nThis is perhaps the best known database to be found in the\npattern recognition literature.  Fisher\'s paper is a classic in the field and\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\ndata set contains 3 classes of 50 instances each, where each class refers to a\ntype of iris plant.  One class is linearly separable from the other 2; the\nlatter are NOT linearly separable from each other.\n\nReferences\n----------\n   - Fisher,R.A. "The use of multiple measurements in taxonomic problems"\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in "Contributions to\n     Mathematical Statistics" (John Wiley, NY, 1950).\n   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n   - Dasarathy, B.V. (1980) "Nosing Around the Neighborhood: A New System\n     Structure and Classification Rule for Recognition in Partially Exposed\n     Environments".  IEEE Transactions on Pattern Analysis and Machine\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n   - Gates, G.W. (1972) "The Reduced Nearest Neighbor Rule".  IEEE Transactions\n     on Information Theory, May 1972, 431-433.\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al"s AUTOCLASS II\n     conceptual clustering system finds 3 classes in the data.\n   - Many, many more ...\n',
 'feature_names': ['sepal length (cm)',
  'sepal width (cm)',
  'petal length (cm)',
  'petal width (cm)']}

In [277]: features=iris.data.T
In [276]: features.shape
Out[276]: (4, 150)
In [277]: features[0]
Out[277]: 
array([5.1, 4.9, 4.7, 4.6, 5. , 5.4, 4.6, 5. , 4.4, 4.9, 5.4, 4.8, 4.8,
       4.3, 5.8, 5.7, 5.4, 5.1, 5.7, 5.1, 5.4, 5.1, 4.6, 5.1, 4.8, 5. ,
       5. , 5.2, 5.2, 4.7, 4.8, 5.4, 5.2, 5.5, 4.9, 5. , 5.5, 4.9, 4.4,
       5.1, 5. , 4.5, 4.4, 5. , 5.1, 4.8, 5.1, 4.6, 5.3, 5. , 7. , 6.4,
       6.9, 5.5, 6.5, 5.7, 6.3, 4.9, 6.6, 5.2, 5. , 5.9, 6. , 6.1, 5.6,
       6.7, 5.6, 5.8, 6.2, 5.6, 5.9, 6.1, 6.3, 6.1, 6.4, 6.6, 6.8, 6.7,
       6. , 5.7, 5.5, 5.5, 5.8, 6. , 5.4, 6. , 6.7, 6.3, 5.6, 5.5, 5.5,
       6.1, 5.8, 5. , 5.6, 5.7, 5.7, 6.2, 5.1, 5.7, 6.3, 5.8, 7.1, 6.3,
       6.5, 7.6, 4.9, 7.3, 6.7, 7.2, 6.5, 6.4, 6.8, 5.7, 5.8, 6.4, 6.5,
       7.7, 7.7, 6. , 6.9, 5.6, 7.7, 6.3, 6.7, 7.2, 6.2, 6.1, 6.4, 7.2,
       7.4, 7.9, 6.4, 6.3, 6.1, 7.7, 6.3, 6.4, 6. , 6.9, 6.7, 6.9, 5.8,
       6.8, 6.7, 6.7, 6.3, 6.5, 6.2, 5.9])

In [278]: features[1]
Out[278]: 
array([3.5, 3. , 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.4, 3. ,
       3. , 4. , 4.4, 3.9, 3.5, 3.8, 3.8, 3.4, 3.7, 3.6, 3.3, 3.4, 3. ,
       3.4, 3.5, 3.4, 3.2, 3.1, 3.4, 4.1, 4.2, 3.1, 3.2, 3.5, 3.1, 3. ,
       3.4, 3.5, 2.3, 3.2, 3.5, 3.8, 3. , 3.8, 3.2, 3.7, 3.3, 3.2, 3.2,
       3.1, 2.3, 2.8, 2.8, 3.3, 2.4, 2.9, 2.7, 2. , 3. , 2.2, 2.9, 2.9,
       3.1, 3. , 2.7, 2.2, 2.5, 3.2, 2.8, 2.5, 2.8, 2.9, 3. , 2.8, 3. ,
       2.9, 2.6, 2.4, 2.4, 2.7, 2.7, 3. , 3.4, 3.1, 2.3, 3. , 2.5, 2.6,
       3. , 2.6, 2.3, 2.7, 3. , 2.9, 2.9, 2.5, 2.8, 3.3, 2.7, 3. , 2.9,
       3. , 3. , 2.5, 2.9, 2.5, 3.6, 3.2, 2.7, 3. , 2.5, 2.8, 3.2, 3. ,
       3.8, 2.6, 2.2, 3.2, 2.8, 2.8, 2.7, 3.3, 3.2, 2.8, 3. , 2.8, 3. ,
       2.8, 3.8, 2.8, 2.8, 2.6, 3. , 3.4, 3.1, 3. , 3.1, 3.1, 3.1, 2.7,
       3.2, 3.3, 3. , 2.5, 3. , 3.4, 3. ])
...

In [282]: plt.scatter(features[0],features[1],alpha=.2,s=100*features[3],c=iris.target,cmap='viridis')
Out[282]: <matplotlib.collections.PathCollection at 0x7f74ee487048>

/ x,y=sepal length, width, color=species of the flower, size point/circle = petal width	, 
/ dus zo 4 dimensions in 2-dim axis	,

/ large datasets: use plt.plot ipv plt.scatter	,

/ na ax.clear() : we zien de colorbar nog	, 
/ TODO

/ 1313	. 

/ visualizing errors	,

In [296]: x=np.linspace(0,10,51)
In [315]: y=np.sin(x)+dy*np.random.randn(51)

In [366]: plt.errorbar(x,y,yerr=dy)
/=
In [366]: plt.errorbar(x,y,yerr=dy,fmt='-')
Out[366]: <ErrorbarContainer object of 3 artists>
/ we zien de punten verbonden door lijnstukjes	, en we zien de errs	,

In [316]: plt.errorbar(x,y,yerr=dy,fmt='.')
Out[316]: <ErrorbarContainer object of 3 artists>
/ we zien alleen .'en	, ze zijn niet verbonden	,
/ de standaard kleur is blauw	, als je zwart wilt kun je 
fmt='.k'
/ of	,
fmt='.',color='black'	,

/ we kunnen ook fmt='o'	, als je een groter rondje wilt	,
/ of fmt='^'	, 

In [357]: ax=plt.gca()
In [358]: ax.clear()

In [386]: plt.errorbar(x,y,yerr=dy,fmt='o',ecolor='lightgray',capsize=5)
Out[386]: <ErrorbarContainer object of 3 artists>
/ capsize is hor streepje aan het einde	, default zien we hem niet, zoals in fig 4-27	, we moeten hem echt geven	,
/ TODO

/ 1313	. 

Init signature: GaussianProcess(*args, **kwargs)
Docstring:     
The legacy Gaussian Process model class.

.. deprecated:: 0.18
    This class will be removed in 0.20.
    Use the :class:`GaussianProcessRegressor` instead.

Read more in the :ref:`User Guide <gaussian_process>`.

/ google,
/ lees	,
http://dfm.io/george/dev/tutorials/first/
->
http://www.gaussianprocess.org/gpml/
/ TODO
/ lees	,
https://scikit-learn.org/stable/modules/gaussian_process.html

In [387]: from sklearn.gaussian_process import GaussianProcess

In [388]: model=lambda x:x*np.sin(x)

In [389]: xdata=np.array([1,3,5,6,8])
In [404]: xdata
Out[404]: array([1, 3, 5, 6, 8])

In [390]: ydata=model(xdata)
In [405]: ydata
Out[405]: array([ 0.84147098,  0.42336002, -4.79462137, -1.67649299,  7.91486597])

In [394]: gp=GaussianProcess(corr='cubic',theta0=1e-2,thetaL=1e-4,thetaU=1e-1,random_start=100)

In [395]: ax.clear()

In [396]: gp.fit(xdata[:,np.newaxis],ydata)
Out[396]: 
GaussianProcess(beta0=None, corr=<function cubic at 0x7f74eda31730>,
        normalize=True, nugget=array(2.22045e-15), optimizer='fmin_cobyla',
        random_start=100,
        random_state=<mtrand.RandomState object at 0x7f75260a35e8>,
        regr=<function constant at 0x7f74eda2ef28>, storage_mode='full',
        theta0=array([[0.01]]), thetaL=array([[0.0001]]),
        thetaU=array([[0.1]]), verbose=False)

In [397]: xfit=np.linspace(0,10,1000)

In [398]: yfit,MSE=gp.predict(xfit[:,np.newaxis],eval_MSE=True)

In [399]: dyfit=2*np.sqrt(MSE)

In [400]: plt.plot(xdata,ydata,'or')
Out[400]: [<matplotlib.lines.Line2D at 0x7f74ed745630>]
/ we zien de 5 punten	, 

In [401]: plt.plot(xfit,yfit,'-',color='gray')
Out[401]: [<matplotlib.lines.Line2D at 0x7f74ed75b240>]
/ we zien een grafiek door de 5 punten	,

In [403]: plt.fill_between(xfit,yfit-dyfit,yfit+dyfit,color='gray',alpha=.2)
Out[403]: <matplotlib.collections.PolyCollection at 0x7f74ed76c588>
/ we zien err gebied rond de grafiek	,

In [412]: fig.savefig('fig4-29.png')


/ 1313	 .

/ contour	,

In [287]: def f(x,y):
     ...:     return np.sin(x)**10+np.cos(10+y*x)*np.cos(x)
     ...: 
     ...: 
/ of	,
In [417]: def f(x,y):
     ...:     return 1-np.exp(np.sqrt(x**2+y**2))
     ...: 
     ...: 


In [288]: x=np.linspace(0,5,51)

In [289]: y=np.linspace(0,5,41)

In [290]: x
Out[290]: 
array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2,
       1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2. , 2.1, 2.2, 2.3, 2.4, 2.5,
       2.6, 2.7, 2.8, 2.9, 3. , 3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8,
       3.9, 4. , 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9, 5. ])

In [291]: y
Out[291]: 
array([0.   , 0.125, 0.25 , 0.375, 0.5  , 0.625, 0.75 , 0.875, 1.   ,
       1.125, 1.25 , 1.375, 1.5  , 1.625, 1.75 , 1.875, 2.   , 2.125,
       2.25 , 2.375, 2.5  , 2.625, 2.75 , 2.875, 3.   , 3.125, 3.25 ,
       3.375, 3.5  , 3.625, 3.75 , 3.875, 4.   , 4.125, 4.25 , 4.375,
       4.5  , 4.625, 4.75 , 4.875, 5.   ])

In [292]: X,Y=np.meshgrid(x,y)
/ X,Y zijn de 51x51 grid punten	,

In [293]: Z=f(X,Y)

In [547]: x.shape
Out[547]: (51,)
In [548]: y.shape
Out[548]: (41,)
In [549]: X.shape
Out[549]: (41, 51)
In [550]: Y.shape
Out[550]: (41, 51)
In [551]: Z.shape
Out[551]: (41, 51)

/ omdat matrices verticaal beginnen (rows), zien we 41x51 ipv 51x41	.
/ de 1ste rij zijn de grid punten op de hor as, 
In [553]: X[0]
Out[553]: 
array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2,
       1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2. , 2.1, 2.2, 2.3, 2.4, 2.5,
       2.6, 2.7, 2.8, 2.9, 3. , 3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8,
       3.9, 4. , 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9, 5. ])
In [552]: Y[0]
Out[552]: 
array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])

/ en de bovenste rij van de grid	,
In [555]: X[40]
Out[555]: 
array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2,
       1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2. , 2.1, 2.2, 2.3, 2.4, 2.5,
       2.6, 2.7, 2.8, 2.9, 3. , 3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8,
       3.9, 4. , 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9, 5. ])

In [556]: Y[40]
Out[556]: 
array([5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,
       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,
       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.])


In [294]: plt.contour(X,Y,Z)
Out[294]: <matplotlib.contour.QuadContourSet at 0x7f74ee505470>
/ OK	,
/ we zien verschillende kleuren, de lichte is WH <0 values	,

/ in het geval van 1-e(Vx2+y2) zien we cirkels	,
/ OK	, 
/ maar bij welke waarden tekent hij ze	, en bij welke waarden niet?
/ TODO

/ als we 1 kleur	,
In [476]: ax.clear()
In [294]: plt.contour(X,Y,Z,colors='black')
/ dan zijn de <0 contouren gestippeld,	 

/ meer lijnen	,  20 contour levels	, dus WH 20 contour waarden	,
/ meerdere kleuren: gray is positief, dieper rood is negatiever	,
In [476]: ax.clear()
In [470]: plt.contour(X,Y,Z,20,cmap='RdGy')
Out[470]: <matplotlib.contour.QuadContourSet at 0x7f74ece371d0>

In [474]: plt.cm.TAB geeft alle colormaps	,
/ bijv, RdBu: blauw is positief	,

In [476]: ax.clear()
In [477]: plt.contourf(X,Y,Z,20,cmap='RdBu')
Out[477]: <matplotlib.contour.QuadContourSet at 0x7f74ede994e0>

/ 1313	.

/ plt.imshow

In [496]: plt.figure()
Out[496]: <Figure size 640x480 with 0 Axes>

/ we zien de origin linksboven	, 
/ we zien hor naar rechts 0 tm 50, vert naar beneden 0 tm 40	,
In [558]: plt.imshow(Z,cmap='PuBu')
Out[558]: <matplotlib.image.AxesImage at 0x7f74eca03e10>
In [563]: plt.axis(aspect='image')
Out[563]: (-0.5, 50.5, 40.5, -0.5)
In [559]: cb=plt.colorbar()
In [560]: cb.remove()

/ we zien de origin linksonder, 
/ we zien hor naar rechts 0 tm 50, vert naar boven 0 tm 40	,
/ we zien de grafiek ook verticaal omgedraaid	,	
In [558]: plt.imshow(Z,cmap='PuBu')
In [565]: plt.axis(aspect='image')
Out[565]: (-0.5, 50.5, -0.5, 40.5)

In [566]: plt.imshow?
extent : scalars (left, right, bottom, top), optional, default: None
    The location, in data-coordinates, of the lower-left and
    upper-right corners. If `None`, the image is positioned such that
    the pixel centers fall on zero-based (row, column) indices.

In [567]: plt.imshow(Z,cmap='PuBu',origin='lower',extent=[0,5,0,5])
Out[567]: <matplotlib.image.AxesImage at 0x7f74ec6b3278>
In [568]: plt.axis(aspect='image')
Out[568]: (0.0, 5.0, 0.0, 5.0)
/ OK	,
/ de indexes 0 tm 50, 0 tm 40 zijn vervangen door de data vars 0 tm 5, 0 tm 5	,

/ met imshow	,
/ als je een foutive cmap geeft, krijg je ze allemaal te zien in de ERR msg	,

/ 131313	. 

/ mix plt.contour en plt.imshow	,

/ bij plt.contour moeten we wel steeds ax.clear()	 (ax=plt.axes())

In [588]: contours=plt.contour(X,Y,Z,2,cmap='RdGy')
In [589]: plt.clabel(contours,inline=True,fontsize=8)
/ we zien 2 contour values, .8 en -.8

In [588]: contours=plt.contour(X,Y,Z,3,cmap='RdGy')
In [589]: plt.clabel(contours,inline=True,fontsize=8)
/ we zien 2 contour values, .6 en -.6
/ TODO

In [587]: ax.clear()
In [588]: contours=plt.contour(X,Y,Z,4,cmap='RdGy')
In [589]: plt.clabel(contours,inline=True,fontsize=8)
Out[589]: <a list of 19 text.Text objects>
/ OK	, we zien 4 contour values	, -.5, 0, .5, 1

/ we gaan nu	,

In [605]: contours=plt.contour(X,Y,Z,4,colors='black')
In [606]: plt.clabel(contours,inline=True,fontsize=8)
Out[606]: <a list of 19 text.Text objects>
/ we zien gestippelde contouren	,
In [610]: plt.imshow(Z,origin='lower',extent=[0,5,0,5],cmap='RdGy')
Out[610]: <matplotlib.image.AxesImage at 0x7f74ec3f1940>
/ alpha
/ TODO





/ 1313	. 

/ histogram

In [630]: plt.figure()
Out[630]: <Figure size 640x480 with 0 Axes>

In [631]: data=np.random.randn(1000)
In [632]: plt.hist(data)
Out[632]: 
(array([  3.,  13.,  53., 153., 246., 268., 181.,  73.,   6.,   4.]),
 array([-3.51810949, -2.83168275, -2.14525602, -1.45882928, -0.77240254,
        -0.0859758 ,  0.60045093,  1.28687767,  1.97330441,  2.65973114,
         3.34615788]),
 <a list of 10 Patch objects>)
/ array([-3.51810949, -2.83168275, ... is het array van intervallen op de hor as	,
/ array([  3.,  13.,  53., ... is het array van values op die intervallen	, zijn dus de aantallen keren dat een randn in het interval ligt	,

/ we zien default 10 intervallen	, 
/ we kunnen ook bijv 20 intervallen willen	,
In [723]: plt.hist(data,20)
Out[723]: 
(array([  1.,   2.,   4.,   9.,  15.,  38.,  62.,  91., 107., 139., 133.,
        135., 102.,  79.,  43.,  30.,   5.,   1.,   2.,   2.]),
 array([-3.51810949, -3.17489612, -2.83168275, -2.48846939, -2.14525602,
        -1.80204265, -1.45882928, -1.11561591, -0.77240254, -0.42918917,
        -0.0859758 ,  0.25723756,  0.60045093,  0.9436643 ,  1.28687767,
         1.63009104,  1.97330441,  2.31651778,  2.65973114,  3.00294451,
         3.34615788]),
 <a list of 20 Patch objects>)
/ we zien een lager histogram met de helft kleinere intervallen: lager is logisch, want in elk kleiner interval vallen minder values	,

In [763]: plt.hist(data,bins=30,density=True)

/ 131313	. 

/ we sluiten alle figs	,

In [790]: kwargs=dict(histtype='stepfilled',alpha=0.3,density=True,bins=40)

In [791]: plt.hist(x1,**kwargs)
/home/eric/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.
/ we zien een nieuw figure, met het histogram, en alpha werkt ook	,

In [792]: plt.hist(x2,**kwargs)
/ we zien het 2de hist ook	,

In [793]: plt.hist(x3,**kwargs)
/ we zien het 3de hist ook	,

/ histtype='bar' is default	,
/ we zien wel verschil met 'step', maar de rest ...
/ TODO

/ normed: histogram is als een kansverdeling	, we zien vert .6 ipv 60	,
/ TODO

/ 131313. 

/ zonder grafiek	,

/ np.histogram ipv np.hist	,

In [915]: z=np.histogram(data,bins=5)
In [916]: z
Out[916]: 
(array([ 16, 206, 514, 254,  10]),
 array([-3.51810949, -2.14525602, -0.77240254,  0.60045093,  1.97330441,
         3.34615788]))

In [917]: counts,bin_edges=z
In [920]: counts
Out[920]: array([ 16, 206, 514, 254,  10])
In [921]: bin_edges
Out[921]: 
array([-3.51810949, -2.14525602, -0.77240254,  0.60045093,  1.97330441,
        3.34615788])


/ 1313	. 

/ multivariate hist	,

/ oef	,

In [883]: np.random.multivariate_normal(mean,cov,5)
Out[883]: 
array([[ 0.0770229 , -2.15709638],
       [ 0.39437254,  1.04820399],
       [-0.93395244, -1.28211078],
       [ 0.60616828,  2.03099499],
       [ 1.06392376,  1.77371811]])

In [884]: np.random.multivariate_normal(mean,cov,5).T
Out[884]: 
array([[ 0.28016612, -0.62055157, -1.42177551, -1.20259369,  0.32675477],
       [ 0.04591664, -0.10448542, -0.08826808, -0.32286675,  0.35133451]])

z=np.random.multivariate_normal(mean,cov,10000).T
In [896]: z
Out[896]: 
array([[-1.07900483, -1.77268228,  1.15333052, -0.6965351 ,  1.98369293],
       [-0.32746432, -2.13581705, -0.41550665, -0.61371236,  2.01387805]])
In [897]: x,y=z
In [898]: x
Out[898]: array([-1.07900483, -1.77268228,  1.15333052, -0.6965351 ,  1.98369293])
In [899]: y
Out[899]: array([-0.32746432, -2.13581705, -0.41550665, -0.61371236,  2.01387805])
/ check	,
In [948]: np.vstack([x,y])     
...

/ 131313	. 

In [907]: mean
Out[907]: [0, 0]

In [908]: cov
Out[908]: [[1, 1], [1, 2]]

In [909]: z=np.random.multivariate_normal(mean,cov,10000).T
/ let op: 10000 ipv 5	,

In [910]: x,y=z

In [912]: x.shape
Out[912]: (10000,)

In [911]: plt.hist2d(x,y,cmap='Blues',bins=30)
/ OK	,

/ 131313	. 

/ geen grafiek	, np.histogram2d ipv np.hist2d	,

In [928]: z=np.histogram2d(x,y,bins=30)
In [928]: counts,xedges,yedges=z       
...

/ 1313	. 

/ kde= kernel density estimation	,

In [958]:  data=np.vstack([x,y])
In [959]: data
Out[959]: 
array([[ 0.10919162, -0.42353887, -1.84777802, ..., -0.21980509,
        -0.22235631,  0.01252764],
       [-0.57638241, -0.36032299, -4.35922146, ...,  0.73213421,
         0.48955722,  0.77585608]])
/ we herstellen	,
In [961]:  np.random.multivariate_normal(mean,cov,10000).T

In [995]: x.shape
Out[995]: (10000,)
In [996]: data.shape
Out[996]: (2, 10000)
In [997]: data
Out[997]: 
array([[ 0.10919162, -0.42353887, -1.84777802, ..., -0.21980509,
        -0.22235631,  0.01252764],
       [-0.57638241, -0.36032299, -4.35922146, ...,  0.73213421,
         0.48955722,  0.77585608]])

In [998]: kde=gaussian_kde(data)
In [966]: kde
Out[966]: <scipy.stats.kde.gaussian_kde at 0x7f74e472c4a8>

xgrid=np.linspace(-3.5,3.5,11)
ygrid=np.linspace(-6,6,11)
Tgrid=np.meshgrid(xgrid,ygrid)
Xgrid,Ygrid=Tgrid

In [998]: xgrid
Out[998]: array([-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5])

In [999]: ygrid
Out[999]: array([-6. , -4.8, -3.6, -2.4, -1.2,  0. ,  1.2,  2.4,  3.6,  4.8,  6. ])

In [1000]: Tgrid
Out[1000]: 
[array([[-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
        [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
        [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
        [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
        [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
        [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
        [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
        [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
        [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
        [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
        [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5]]),
 array([[-6. , -6. , -6. , -6. , -6. , -6. , -6. , -6. , -6. , -6. , -6. ],
        [-4.8, -4.8, -4.8, -4.8, -4.8, -4.8, -4.8, -4.8, -4.8, -4.8, -4.8],
        [-3.6, -3.6, -3.6, -3.6, -3.6, -3.6, -3.6, -3.6, -3.6, -3.6, -3.6],
        [-2.4, -2.4, -2.4, -2.4, -2.4, -2.4, -2.4, -2.4, -2.4, -2.4, -2.4],
        [-1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2],
        [ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ],
        [ 1.2,  1.2,  1.2,  1.2,  1.2,  1.2,  1.2,  1.2,  1.2,  1.2,  1.2],
        [ 2.4,  2.4,  2.4,  2.4,  2.4,  2.4,  2.4,  2.4,  2.4,  2.4,  2.4],
        [ 3.6,  3.6,  3.6,  3.6,  3.6,  3.6,  3.6,  3.6,  3.6,  3.6,  3.6],
        [ 4.8,  4.8,  4.8,  4.8,  4.8,  4.8,  4.8,  4.8,  4.8,  4.8,  4.8],
        [ 6. ,  6. ,  6. ,  6. ,  6. ,  6. ,  6. ,  6. ,  6. ,  6. ,  6. ]])]
/ Tgrid is een list van 2 np.array	,

In [1005]: Xgrid
Out[1005]: 
array([[-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
       [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
       [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
       [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
       [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
       [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
       [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
       [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
       [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
       [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
       [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5]])
In [1006]: Ygrid
Out[1006]: 
array([[-6. , -6. , -6. , -6. , -6. , -6. , -6. , -6. , -6. , -6. , -6. ],
       [-4.8, -4.8, -4.8, -4.8, -4.8, -4.8, -4.8, -4.8, -4.8, -4.8, -4.8],
       [-3.6, -3.6, -3.6, -3.6, -3.6, -3.6, -3.6, -3.6, -3.6, -3.6, -3.6],
       [-2.4, -2.4, -2.4, -2.4, -2.4, -2.4, -2.4, -2.4, -2.4, -2.4, -2.4],
       [-1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2],
       [ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ],
       [ 1.2,  1.2,  1.2,  1.2,  1.2,  1.2,  1.2,  1.2,  1.2,  1.2,  1.2],
       [ 2.4,  2.4,  2.4,  2.4,  2.4,  2.4,  2.4,  2.4,  2.4,  2.4,  2.4],
       [ 3.6,  3.6,  3.6,  3.6,  3.6,  3.6,  3.6,  3.6,  3.6,  3.6,  3.6],
       [ 4.8,  4.8,  4.8,  4.8,  4.8,  4.8,  4.8,  4.8,  4.8,  4.8,  4.8],
       [ 6. ,  6. ,  6. ,  6. ,  6. ,  6. ,  6. ,  6. ,  6. ,  6. ,  6. ]])

In [1007]: Xgrid.ravel()
Out[1007]: 
array([-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5,
       -3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5,
       -3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5,
       -3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5,
       -3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5,
       -3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5,
       -3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5,
       -3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5,
       -3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5,
       -3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5,
       -3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5])

In [1009]: Xgrid.shape
Out[1009]: (11, 11)

In [1010]: Xgrid.ravel().shape
Out[1010]: (121,)

In [1011]: Sgrid=np.vstack([Xgrid.ravel(),Ygrid.ravel()])
In [1012]: Sgrid.shape
Out[1012]: (2, 121)
In [1013]: Sgrid
Out[1013]: 
array([[-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5,
        -3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5,
        -3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5,
        -3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5,
        -3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5,
        -3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5,
        -3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5,
        -3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5,
        -3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5,
        -3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5,
        -3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
       [-6. , -6. , -6. , -6. , -6. , -6. , -6. , -6. , -6. , -6. , -6. ,
        -4.8, -4.8, -4.8, -4.8, -4.8, -4.8, -4.8, -4.8, -4.8, -4.8, -4.8,
        -3.6, -3.6, -3.6, -3.6, -3.6, -3.6, -3.6, -3.6, -3.6, -3.6, -3.6,
        -2.4, -2.4, -2.4, -2.4, -2.4, -2.4, -2.4, -2.4, -2.4, -2.4, -2.4,
        -1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2,
         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,
         1.2,  1.2,  1.2,  1.2,  1.2,  1.2,  1.2,  1.2,  1.2,  1.2,  1.2,
         2.4,  2.4,  2.4,  2.4,  2.4,  2.4,  2.4,  2.4,  2.4,  2.4,  2.4,
         3.6,  3.6,  3.6,  3.6,  3.6,  3.6,  3.6,  3.6,  3.6,  3.6,  3.6,
         4.8,  4.8,  4.8,  4.8,  4.8,  4.8,  4.8,  4.8,  4.8,  4.8,  4.8,
         6. ,  6. ,  6. ,  6. ,  6. ,  6. ,  6. ,  6. ,  6. ,  6. ,  6. ]])

In [1014]: Z=kde.evaluate(Sgrid)
In [1019]: Z.shape
Out[1019]: (121,)

In [1016]: Z.reshape(Xgrid.shape).shape
Out[1016]: (11, 11)

In [1021]: plt.imshow(Z.reshape(Xgrid.shape),origin='lower',aspect='auto',extent=[-3.5,3.5,-6,6],cmap='Blues')
Out[1021]: <matplotlib.image.AxesImage at 0x7f74e46a4f28>
/ OK	,

/ 1313	. 

/ legends,

/ 131313	. 

In [1022]: x=np.linspace(0,10,1001)

In [1023]: x
Out[1023]: array([ 0.  ,  0.01,  0.02, ...,  9.98,  9.99, 10.  ])

In [1024]: fig,ax=plt.subplots()
/ we zien figure met axes	,

In [1025]: ax.plot(x,np.sin(x),'-b',label='sine')
Out[1025]: [<matplotlib.lines.Line2D at 0x7f74e4685da0>]
/ we zien grafiek	,

In [1027]: ax.plot(x,np.cos(x),'--r',label='cosine')
Out[1027]: [<matplotlib.lines.Line2D at 0x7f74e44c5dd8>]
/ we zien grafiek	,

////////////////////////////////
/ we label de grafiek, we zien de woorden sine en cosine niet naast de grafiek of zoiets	, 
/ wel verschijnen deze woorden in de legend	, en dus alleen van die grafieken die gelabeld zijn	,

In [1028]: ax.axis('equal')
Out[1028]: (-0.5, 10.5, -1.0999986683139165, 1.099999936586377)
/ vert van -1 tm 1 wordt van -4 tot 4	, hor en vert hebben dezelfde schaal	,

In [1029]: leg=ax.legend()
/ we zien de legend	, rechtsboven	,
/ zonder frame	,

In [1030]: ax.legend(loc='upper left')
Out[1030]: <matplotlib.legend.Legend at 0x7f74e44eddd8>
/ de legend verhuist naar links	,
/ we hadden al geen frame	,

In [1032]: ax.legend(loc='lower center',ncol=2)
Out[1032]: <matplotlib.legend.Legend at 0x7f74e4672d68>

In [1033]: ax.legend()
Out[1033]: <matplotlib.legend.Legend at 0x7f74e4781da0>
/ default, rechtsboven, onder elkaar	,

In [1092]: ax.legend(frameon=True)
Out[1092]: <matplotlib.legend.Legend at 0x7f74e3af4dd8>
/ we zien een frame rondom de legends	,

In [1099]: ax.legend(frameon=True,shadow=True,borderpad=1,framealpha=1)
Out[1099]: <matplotlib.legend.Legend at 0x7f74e39257f0>
/ we zien schaduw, 
/ en padding in het frame	, maar WH is 1 de default	,
/ en framealpha=1 is WH default, als =.5 is hij donkerder	,
/ fancybox TODO


/ 131313	.

/ een legend van niet alle grafieken	,

In [1050]: x
Out[1050]: array([ 0.  ,  0.01,  0.02, ...,  9.98,  9.99, 10.  ])

In [1051]: x[:,np.newaxis]
Out[1051]: 
array([[ 0.  ],
       [ 0.01],
       [ 0.02],
       ...,
       [ 9.98],
       [ 9.99],
       [10.  ]])

In [1052]: x.shape
Out[1052]: (1001,)

In [1053]: x[:,np.newaxis].shape
Out[1053]: (1001, 1)

/ 13131313	.

/ leuk, maar niet de bedoeling	,

In [1054]: np.sin(x[:,np.newaxis])
Out[1054]: 
array([[ 0.        ],
       [ 0.00999983],
       [ 0.01999867],
       ...,
       [-0.527132  ],
       [-0.53560333],
       [-0.54402111]])

In [1062]: np.sin(x[:,np.newaxis]).shape
Out[1062]: (1001, 1)

In [1055]: np.arange(0,2,.5)
Out[1055]: array([0. , 0.5, 1. , 1.5])

In [1056]: np.pi*np.arange(0,2,.5)
Out[1056]: array([0.        , 1.57079633, 3.14159265, 4.71238898])


In [1058]: y=np.sin(x[:,np.newaxis])+np.pi*np.arange(0,2,.5)
In [1058]: y
Out[1058]: 
array([[ 0.        ,  1.57079633,  3.14159265,  4.71238898],
       [ 0.00999983,  1.58079616,  3.15159249,  4.72238881],
       [ 0.01999867,  1.59079499,  3.16159132,  4.73238765],
       ...,
       [-0.527132  ,  1.04366433,  2.61446066,  4.18525698],
       [-0.53560333,  1.03519299,  2.60598932,  4.17678565],
       [-0.54402111,  1.02677522,  2.59757154,  4.16836787]])
In [1061]: y.shape
Out[1061]: (1001, 4)

In [1063]: lines=plt.plot(x,y)
/ we zien sin grafieken boven elkaar	,

/ 13131313	. 

/ dit is de bedoeling	,

/ je hebt 4 sets van 1000 punten die met een vaste fase uit fase lopen	,
/ je ziet ze in de 4 kolommen	,

In [1067]: x
Out[1067]: array([ 0.  ,  0.01,  0.02, ...,  9.98,  9.99, 10.  ])

In [1066]: v=x[:,np.newaxis]+np.pi*np.arange(0,2,.5)
In [1066]: v
Out[1066]: 
array([[0.00000000e+00, 1.57079633e+00, 3.14159265e+00, 4.71238898e+00],
       [1.00000000e-02, 1.58079633e+00, 3.15159265e+00, 4.72238898e+00],
       [2.00000000e-02, 1.59079633e+00, 3.16159265e+00, 4.73238898e+00],
       ...,
       [9.98000000e+00, 1.15507963e+01, 1.31215927e+01, 1.46923890e+01],
       [9.99000000e+00, 1.15607963e+01, 1.31315927e+01, 1.47023890e+01],
       [1.00000000e+01, 1.15707963e+01, 1.31415927e+01, 1.47123890e+01]])

In [1071]: plt.plot(x,v)
/ je ziet 4 lijnen parallel, boven elkaar , die stijgen	,

In [1069]: y=np.sin(v)

In [1073]: lines=plt.plot(x,y)
/ OK	,

In [1074]: plt.legend(lines[:2],['first','second'])
Out[1074]: <matplotlib.legend.Legend at 0x7f74e3e97278>
/ we zien de 1ste 2 sin	,

In [1075]: lines
Out[1075]: 
[<matplotlib.lines.Line2D at 0x7f74ecce75f8>,
 <matplotlib.lines.Line2D at 0x7f74ecac1240>,
 <matplotlib.lines.Line2D at 0x7f74ecac1470>,
 <matplotlib.lines.Line2D at 0x7f74ecac1908>]

In [1076]: lines[:2]
Out[1076]: 
[<matplotlib.lines.Line2D at 0x7f74ecce75f8>,
 <matplotlib.lines.Line2D at 0x7f74ecac1240>]

/ de legend gaat de goede kleur aan	,
/ de 1ste gaat door 0,0	en de 2de door 0,1	, de grafiek van de 2de ligt links van die van de 1ste	,

/ 13131313	.

/ het kan ook zo	,

/ y[:,0] is de 1ste kolom	,
/ y[:,1] is de 2de  kolom	,

In [1080]: plt.plot(x,y[:,0],label='first')
Out[1080]: [<matplotlib.lines.Line2D at 0x7f74e3cf9320>]
In [1081]: plt.plot(x,y[:,1],label='second')
Out[1081]: [<matplotlib.lines.Line2D at 0x7f74e3cb8b00>]
In [1083]: plt.plot(x,y[:,2:])
Out[1083]: 
[<matplotlib.lines.Line2D at 0x7f74e3cc4908>,
 <matplotlib.lines.Line2D at 0x7f74e3cc4f60>]

In [1084]: plt.legend(framealpha=1,frameon=True)
Out[1084]: <matplotlib.legend.Legend at 0x7f74e3cd8e80>
/ Nu zien we wel een frame	,

/ 131313	.

[eric@almond vanderplas]$ find -name "*california*" | xargs -I % cp % .
/ Zit in PythonDataScienceHandbook	,

In [1108]: cities=pd.read_csv('california_cities.csv')

In [1110]:  cities.index
Out[1110]: RangeIndex(start=0, stop=482, step=1)

In [1111]:  cities.columns
Out[1111]: 
Index(['Unnamed: 0', 'city', 'latd', 'longd', 'elevation_m', 'elevation_ft',
       'population_total', 'area_total_sq_mi', 'area_land_sq_mi',
       'area_water_sq_mi', 'area_total_km2', 'area_land_km2', 'area_water_km2',
       'area_water_percent'],
      dtype='object')

In [1112]: type(cities)
Out[1112]: pandas.core.frame.DataFrame

In [1113]: cities.shape
Out[1113]: (482, 14)

In [1114]: cities.head()
Out[1114]: 
   Unnamed: 0         city         ...          area_water_km2  area_water_percent
0           0     Adelanto         ...                   0.046                0.03
1           1  AgouraHills         ...                   0.076                0.37
2           2      Alameda         ...                  31.983               53.79
3           3       Albany         ...                   9.524               67.28
4           4     Alhambra         ...                   0.003                0.01

[5 rows x 14 columns]

/ bij plt.scatter is s de marker size (grootte rondje) en c de color	,

In [1121]: lat,long, popul,area=cities['latd'],cities['longd'],cities['population_total'],cities['area_total_km2']
/ dit zijn alle 4 series	,

In [1128]: ax.clear()
/ anders hebben we de schalen op de assen van de sinussen uit de vorige opdracht met de legends nog	, en zit -126...-114 hor en 32...42 vert op een kluitje,

In [1129]: plt.scatter(long,lat,label=None,c=np.log10(popul),cmap='viridis',s=area,linewidths=0,alpha=.5)
Out[1129]: <matplotlib.collections.PathCollection at 0x7f74e3ae2ac8>
/ NB. linewidths met s	,

In [1130]: plt.axis('equal')
Out[1130]: 
(-124.74956214749963,
 -114.10105930859528,
 32.10406652121161,
 42.43650110977464)
/ deze doet wel iets	,

In [1131]: plt.xlabel('longitude')
Out[1131]: Text(0.5,28.3833,'longitude')

In [1132]: plt.ylabel('latitude')
Out[1132]: Text(53.9583,0.5,'latitude')

In [1138]: plt.colorbar(label='log$_{10}$(population)')
Out[1138]: <matplotlib.colorbar.Colorbar at 0x7f74dcca1e10>

In [1139]: plt.clim(3,7)
/ beperk	,
/ waarden colorbar tussen 3 en 7	, en ook in de grafiek minder gevallen , alleen de desbetreffende	,
/ omdat	,

/ 131313	. 


In [1158]: np.log10(popul)<3.0
Out[1158]: 
0      False
1      False
2      False
...

In [1149]: popul[np.log10(popul)<3.0]
Out[1149]: 
7      185
114    939
132    737
144    839
190    219
195    804
242    769
326    449
327      1
366    334
428    418
435    367
448    112
Name: population_total, dtype: int64

In [1150]: np.log10(popul[np.log10(popul)<3.0])
Out[1150]: 
7      2.267172
114    2.972666
132    2.867467
144    2.923762
190    2.340444
195    2.905256
242    2.885926
326    2.652246
327    0.000000
366    2.523746
428    2.621176
435    2.564666
448    2.049218
Name: population_total, dtype: float64

/ Als we condition willen combine , moeten we de condition tussen () en & use	,

In [1165]: (np.log10(popul)>0.0) & (np.log10(popul)<3.0)
Out[1165]: 
0      False
1      False
2      False
...
In [1166]: popul[(np.log10(popul)>0.0) & (np.log10(popul)<3.0)]
Out[1166]: 
7      185
114    939
132    737
144    839
190    219
195    804
242    769
326    449
366    334
428    418
435    367
448    112
Name: population_total, dtype: int64

/ 13131313	.

/ we hebben aangepast, e-notatie vervangen	,
In [1167]: popul.describe()
Out[1167]: 
count    482
mean       64894.93
std       203204.1
min            1
25%        10902
50%        29057.5
75%        66466.5
max      3884307
Name: population_total, dtype: float64

In [1173]: np.log10(popul).describe()
Out[1173]: 
count    482.000000
mean       4.395021
std        0.651117
min        0.000000
25%        4.037506
50%        4.463257
75%        4.822591
max        6.589314
Name: population_total, dtype: float64

/ 131313	. 

/ 13131313	. 

/ niet nodig allemaal	,

In [1176]: area.describe()
Out[1176]: 
count     477.000000
mean       46.753283
std        90.972269
min         0.813000
25%         9.551000
50%        23.551000
75%        51.772000
max      1302.000000
Name: area_total_km2, dtype: float64

In [1177]: area <100.0
Out[1177]: 
0      False
1       True
2       True
3       True
...
In [1181]: area[area==100.0].count()
Out[1181]: 0

/ 13131313	. 

In [1182]: for area in [100,300,500]:
      ...:     plt.scatter([],[],c='k',alpha=.3,s=area,label=str(area)+' km$^2$')
      ...:     
/ we zien nog niets	,
/ we moeten een label geven	, anders verschijnt item niet in de legend , omdat we in de plt.legend hieronder niet zeggen welk van welke items er een legend item moet komen; dat kan ook, zie hierboven en in boek(252) bovenste regel	.

In [1184]: plt.legend(scatterpoints=1,labelspacing=1,title='City Area')
Out[1184]: <matplotlib.legend.Legend at 0x7f74dd07f470>
/ nu zien we de legend	,
/ frameon=False is de default	, 
/ scatterpoints is het aantal keer dat we een rondje zien in de legend, 1 is de bedoeling	, 
/ labelspacing is de verticale spacing tussen de legend items	,

/ 131313	. 

/ multiple legends, 
/ TODO

/ 131313	 

In [1202]: x=np.linspace(0,2*np.pi,5)

In [1203]: x
Out[1203]: array([0.        , 1.57079633, 3.14159265, 4.71238898, 6.28318531])

In [1204]: np.cos(x[:,np.newaxis])
Out[1204]: 
array([[ 1.0000000e+00],
       [ 6.1232340e-17],
       [-1.0000000e+00],
       [-1.8369702e-16],
       [ 1.0000000e+00]])

In [1206]: np.sin(x)
Out[1206]: 
array([ 0.0000000e+00,  1.0000000e+00,  1.2246468e-16, -1.0000000e+00,
       -2.4492936e-16])

In [1207]: np.cos(x[:,np.newaxis])*np.sin(x)
/=
In [1208]: np.sin(x)*np.cos(x[:,np.newaxis])
Out[1207]: 
array([[ 0.00000000e+00,  1.00000000e+00,  1.22464680e-16,
        -1.00000000e+00, -2.44929360e-16],
       [ 0.00000000e+00,  6.12323400e-17,  7.49879891e-33,
        -6.12323400e-17, -1.49975978e-32],
       [-0.00000000e+00, -1.00000000e+00, -1.22464680e-16,
         1.00000000e+00,  2.44929360e-16],
       [-0.00000000e+00, -1.83697020e-16, -2.24963967e-32,
         1.83697020e-16,  4.49927935e-32],
       [ 0.00000000e+00,  1.00000000e+00,  1.22464680e-16,
        -1.00000000e+00, -2.44929360e-16]])

In [1212]: im=plt.imshow(I)
/=
In [1294]: im=plt.imshow(I,cmap='jet')
In [1212]: im
Out[1239]: <matplotlib.image.AxesImage at 0x7f74dcb25748>

/ blijkbaar is 'jet' de default colormap	,

In [1213]: cb=plt.colorbar()
In [1213]: cb
Out[1242]: <matplotlib.colorbar.Colorbar at 0x7f74dc211780>

/ we zien op de assen de indices 0,1,2,3,4 van x	, 
/ we hebben x hor in np.sin(x) en vert in np.cos(x[:,np.newaxis])	,

In [1218]: ax=plt.gca()
/ get axes	, 
/ doet dit altijd ipv ax=plt.axes(), hierna kun je: ax.clear()

In [1221]: fig=plt.gcf()
/ current figure	,

/ google	,
matplotlib pyplot get colorbar
/ lees	,
https://stackoverflow.com/questions/19816820/how-to-retrieve-colorbar-instance-from-figure-in-matplotlib

In [1241]: ax.images
Out[1241]: [<matplotlib.image.AxesImage at 0x7f74dcb25748>]
/ klopt	,
In [1243]: im.colorbar
/=
In [1244]: ax.images[-1].colorbar
Out[1243]: <matplotlib.colorbar.Colorbar at 0x7f74dc211780>
/ klopt	,

In [1245]: cb.remove()
In [1246]: im.remove()
/ ok	,
In [1247]: ax.images
Out[1247]: []

/ 13131313	. 

/ stel je doet per ongeluk 2 keer plt.imshow(I)	, dan zijn er 2 images	,

In [1248]: im=plt.imshow(I)

In [1249]: ax.images
Out[1249]: [<matplotlib.image.AxesImage at 0x7f74e39cc4e0>]

In [1250]: im=plt.imshow(I)

In [1251]: ax.images
Out[1251]: 
[<matplotlib.image.AxesImage at 0x7f74e39cc4e0>,
 <matplotlib.image.AxesImage at 0x7f74e420ea20>]

/ als we deze willen rm, moeten we dit een paar keer doen, want er blijven over	, 

In [1275]: for im in ax.images:
      ...:     im.remove()
      ...:     

In [1276]: ax.images
Out[1276]: [<matplotlib.image.AxesImage at 0x7f74e420eb70>]

In [1277]: for im in ax.images:
      ...:     im.remove()
      ...:     

In [1278]: 

In [1278]: ax.images
Out[1278]: []

/ TODO


/ 131313	. 

/ customizing colorbars	,

In [1286]: ax.images
Out[1286]: []
In [1287]: im=plt.imshow(I)
In [1288]: ax.images
Out[1288]: [<matplotlib.image.AxesImage at 0x7f74dcd59a20>]
In [1289]: im.remove()
In [1290]: ax.images
Out[1290]: []

In [1294]: im=plt.imshow(I,cmap='jet')
/ default, want die zie je ook met plt.imshow(I)	,

/ 13131313	. 

/ oef voor (257)

In [1297]: cmap=plt.cm.get_cmap('jet')
In [1298]: cmap
Out[1298]: <matplotlib.colors.LinearSegmentedColormap at 0x7f7524ee5b00>
In [1299]: cmap.N
Out[1299]: 256

In [1300]: colors=cmap(np.arange(cmap.N))
/ WH is (de linker) cmap de cmap van 'jet', hierboven bepaald	, 
/ deze cmap wordt nog een keer used: cmap.N	, 
In [1305]: colors.shape
Out[1305]: (256, 4)
In [1301]: colors
Out[1301]: 
array([[0.        , 0.        , 0.5       , 1.        ],
       [0.        , 0.        , 0.51782531, 1.        ],
       [0.        , 0.        , 0.53565062, 1.        ],
       ...,
       [0.53565062, 0.        , 0.        , 1.        ],
       [0.51782531, 0.        , 0.        , 1.        ],
       [0.5       , 0.        , 0.        , 1.        ]])
/ 256 rijen , kleuren, 
/ elke kleur bestaat uit 4 componenten: RGBA (A is alpha, 1 is opaque)	,

In [1309]:  colors[:,:3]
Out[1309]: 
array([[0.00000000e+00, 0.00000000e+00, 5.00000000e-01],
       [0.00000000e+00, 0.00000000e+00, 5.17825312e-01],
/ R is eerst 0, gaat van 0 naar 1 , blijft 1
/ G is eerst 0, gaat eerder naar 1, blijft even 1 , gaat weer naar 0, blijft 0
/ G gaat van .5 naar 1, blijft even 1, gaat naar 0, blijft 0	,

In [1307]: RGB_weight=[.299,.587,.114]
In [1308]: luminance=np.sqrt(np.dot(colors[:,:3]**2,RGB_weight))

In [1498]: type(colors[:,:3])
Out[1498]: numpy.ndarray
In [1496]: colors[:,:3].shape
Out[1496]: (256, 3)

In [1499]: type(RGB_weight)
Out[1499]: list

/ een list of een (m,) np.array wordt rechts als column gezien in np.dot	, een (m,n) np.array ligt vast	, 

/ hier gebeurt: .299R+.587G+.114B 

In [1511]: type(imed)
Out[1511]: numpy.ndarray

In [1512]: imed.shape
Out[1512]: (256,)

In [1513]: imed
Out[1513]: 
array([0.0285    , 0.03056831, 0.03270906, 0.03492226, 0.0372079 ,
       0.03956599, 0.04199653, 0.0444995 , 0.04707493, 0.0497228 ,
...
       0.10377396, 0.09758915, 0.09159435, 0.08578956, 0.08017477,
       0.07475   ])

In [1516]: luminance=np.sqrt(imed)

In [1516]: luminance[:,np.newaxis]
Out[1516]: 
array([[0.16881943],
       [0.17483795],
       [0.18085647],
...

In [1518]:  type(luminance[:,np.newaxis])
Out[1518]: numpy.ndarray

In [1519]: luminance[:,np.newaxis].shape
Out[1519]: (256, 1)

In [1522]: colors[:,:3]=luminance[:,np.newaxis]

In [1523]: colors[:,:3]
Out[1523]: 
array([[0.16881943, 0.16881943, 0.16881943],
       [0.17483795, 0.17483795, 0.17483795],
       [0.18085647, 0.18085647, 0.18085647],
...
/ 3 columns RGB hetzelfde	: dat is grijs!

In [1527]: lscm=LinearSegmentedColormap.from_list(cmap.name+'_gray',colors,cmap.N)
In [1528]: lscm
Out[1528]: <matplotlib.colors.LinearSegmentedColormap at 0x7f74dc72a4a8>
In [1529]: lscm.name
Out[1529]: 'jet_gray'

/ 13131313	. 

In [1530]: def grayscale_cmap(cmap):
      ...:     cmap=plt.cm.get_cmap(cmap)
      ...:     colors=cmap(np.arange(cmap.N))
      ...:     RGB_weight=[0.299,.587,.114]
      ...:     imd=np.dot(colors[:,:3]**2,RGB_weight)
      ...:     luminance=np.sqrt(imd)
      ...:     colors[:,:3]=luminance[:,np.newaxis]
      ...:     lscm=LinearSegmentedColormap.from_list(cmap.name+"_gray",colors,cmap.N)
      ...:     return lscm
      ...: 
      ...: 

In [1531]: def view_colormap(cmap):
      ...:     cmap=plt.cm.get_cmap(cmap)
      ...:     colors=cmap(np.arange(cmap.N))
      ...:     cmap=grayscale_cmap(cmap)
      ...:     grayscale=cmap(np.arange(cmap.N))
      ...:     fig,ax=plt.subplots(2,figsize=(6,2),subplot_kw=dict(xticks=[],yticks=[]))
      ...:     ax[0].imshow([colors],extend=[0,10,0,1])
      ...:     ax[1].imshow([grayscale],extend=[0,10,0,1])
      ...:     

In [1535]: view_colormap('jet')
/ OK

/ wat gebeurt er ?

In [1537]: cmap
Out[1537]: <matplotlib.colors.LinearSegmentedColormap at 0x7f7524ee5b00>

In [1538]: np.arange(cmap.N)
Out[1538]: 
array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,
        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,
        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,
        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,
        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,
        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,
        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,
        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,
       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,
       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,
       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,
       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,
       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,
       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,
       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,
       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,
       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,
       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,
       247, 248, 249, 250, 251, 252, 253, 254, 255])

In [1540]: colors
Out[1540]: 
array([[0.        , 0.        , 0.5       , 1.        ],
       [0.        , 0.        , 0.51782531, 1.        ],
       [0.        , 0.        , 0.53565062, 1.        ],
       ...,
       [0.53565062, 0.        , 0.        , 1.        ],
       [0.51782531, 0.        , 0.        , 1.        ],
       [0.5       , 0.        , 0.        , 1.        ]])

In [1541]: type(colors)
Out[1541]: numpy.ndarray
In [1542]: colors.shape
Out[1542]: (256, 4)

In [1543]: cmap=grayscale_cmap(cmap)

In [1544]: cmap
Out[1544]: <matplotlib.colors.LinearSegmentedColormap at 0x7f74dc115a90>

In [1545]: grayscale=cmap(np.arange(cmap.N))

In [1546]: grayscale
Out[1546]: 
array([[0.16881943, 0.16881943, 0.16881943, 1.        ],
       [0.17483795, 0.17483795, 0.17483795, 1.        ],
       [0.18085647, 0.18085647, 0.18085647, 1.        ],
       ...,
       [0.29289854, 0.29289854, 0.29289854, 1.        ],
       [0.2831515 , 0.2831515 , 0.2831515 , 1.        ],
       [0.27340446, 0.27340446, 0.27340446, 1.        ]])

/ we zien dat RGB gelijk zijn	, en alpha=1	,

In [1550]: fig,ax=plt.subplots(2,figsize=(6,2),subplot_kw=dict(xticks=[],yticks=[]))
/ figsize, xticks, yticks NIET in docs	,
/ met deze figsize worden de 2 axes kleiner	,
/ met deze subplot_kw zien we niets langs de assen, geen getallen	,

In [1551]: fig
Out[1551]: <Figure size 480x160 with 2 Axes>

In [1552]: ax
Out[1552]: 
array([<matplotlib.axes._subplots.AxesSubplot object at 0x7f74dbf416d8>,
       <matplotlib.axes._subplots.AxesSubplot object at 0x7f74dbd34cf8>],
      dtype=object)

In [1553]: im0=ax[0].imshow([colors])
In [1553]: im0
Out[1553]: <matplotlib.image.AxesImage at 0x7f74dbd87a58>
In [1555]: plt.axis()
Out[1555]: (0.0, 1.0, 0.0, 1.0)

In [1559]: im1=ax[1].imshow([grayscale])

In [1560]: im1
Out[1560]: <matplotlib.image.AxesImage at 0x7f74dbc72438>

In [1561]: plt.axis()
Out[1561]: (-0.5, 255.5, 0.5, -0.5)

/ we zien 2 lijnen	,

In [1567]: im0=ax[0].imshow([colors],extent=[0,1,0,1])
/ smal, niet breed	,
In [1568]: im0=ax[0].imshow([colors],extent=[0,10,0,.5])
/ smal, niet hoog	,

/ 13131313	. 

/ andere cm	,

In [1569]: view_colormap('viridis')
/ OK	,
/ van blauw naar geel	, vlnr	,
/ grijs, wit	, vlnr	,

In [1570]: view_colormap('jet')
/ we zien nieuwe figure,	 
/ blauw, groen, rood, vlnr	,
/ grijs, wit, grijs	,

In [1572]: view_colormap('cubehelix')
/ grijs, wit	, vlnr

In [1573]: view_colormap('RdBu')
/ rood, wit, blauw, vlnr	,
/ grijs, wit, grijs	,`

/ 131313	. 

/ (259)

/ op (255),	

In [1619]: x=np.linspace(0,np.pi,7)

In [1620]: x
Out[1620]: 
array([0.        , 0.52359878, 1.04719755, 1.57079633, 2.0943951 ,
       2.61799388, 3.14159265])

In [1621]: I=np.sin(x)*np.cos(x[:,np.newaxis])

In [1622]: I
Out[1622]: 
array([[ 0.00000000e+00,  5.00000000e-01,  8.66025404e-01,
         1.00000000e+00,  8.66025404e-01,  5.00000000e-01,
         1.22464680e-16],
       [ 0.00000000e+00,  4.33012702e-01,  7.50000000e-01,
         8.66025404e-01,  7.50000000e-01,  4.33012702e-01,
         1.06057524e-16],
       [ 0.00000000e+00,  2.50000000e-01,  4.33012702e-01,
         5.00000000e-01,  4.33012702e-01,  2.50000000e-01,
         6.12323400e-17],
       [ 0.00000000e+00,  3.06161700e-17,  5.30287619e-17,
         6.12323400e-17,  5.30287619e-17,  3.06161700e-17,
         7.49879891e-33],
       [-0.00000000e+00, -2.50000000e-01, -4.33012702e-01,
        -5.00000000e-01, -4.33012702e-01, -2.50000000e-01,
        -6.12323400e-17],
       [-0.00000000e+00, -4.33012702e-01, -7.50000000e-01,
        -8.66025404e-01, -7.50000000e-01, -4.33012702e-01,
        -1.06057524e-16],
       [-0.00000000e+00, -5.00000000e-01, -8.66025404e-01,
        -1.00000000e+00, -8.66025404e-01, -5.00000000e-01,
        -1.22464680e-16]])

In [1672]: I.shape
Out[1672]: (7, 7)


/ nu weer op (259)	,

/ oef	,

In [1627]: np.random.random(I.shape)
Out[1627]: 
array([[0.48254586, 0.19725312, 0.61906005, 0.60422742, 0.19316045,
        0.88708768, 0.84775981],
       [0.74462625, 0.12782377, 0.06495719, 0.1073963 , 0.44469082,
        0.7440744 , 0.4544892 ],
       [0.56479512, 0.5576468 , 0.13922761, 0.9962185 , 0.44655432,
        0.37574351, 0.15407647],
       [0.37230588, 0.0381319 , 0.88795213, 0.33504388, 0.73123214,
        0.37078986, 0.62888329],
       [0.87528967, 0.12298506, 0.43508121, 0.45935351, 0.0067386 ,
        0.9689368 , 0.81131759],
       [0.8190476 , 0.29272071, 0.79253783, 0.25302198, 0.31010047,
        0.12293748, 0.28901007],
       [0.17117943, 0.64097508, 0.68618331, 0.70168567, 0.38745839,
        0.51692799, 0.45187372]])

In [1635]: np.random.random(I.shape)<.5
Out[1635]: 
array([[False, False,  True,  True,  True,  True,  True],
       [ True, False, False,  True,  True, False,  True],
       [ True, False, False, False,  True, False, False],
       [False,  True,  True, False,  True,  True,  True],
       [ True,  True, False,  True, False, False,  True],
       [False, False,  True, False,  True, False, False],
       [ True,  True,  True, False,  True, False, False]])

/ doe een paar keer	,
In [1638]: np.count_nonzero(np.random.random(I.shape)<.5)
Out[1638]: 27

In [1639]: np.count_nonzero(np.random.random(I.shape)<.5)
Out[1639]: 19

In [1640]: np.count_nonzero(np.random.random(I.shape)<.5)
Out[1640]: 24

/ Einde oef	,

In [1646]: s=np.random.random(I.shape)<.2

In [1668]: s.shape
Out[1668]: (7, 7)

In [1686]: s
Out[1686]: 
array([[False, False, False, False, False,  True, False],
       [ True, False, False, False, False, False,  True],
       [False,  True, False, False,  True,  True, False],
       [False, False, False, False, False, False, False],
       [False, False, False, False, False,  True, False],
       [False, False, False, False, False, False, False],
       [False, False,  True, False,  True, False, False]])


In [1648]: I[s]=np.random.normal(0,3,np.count_nonzero(s))
/ Die Is die <.01 zijn veranderen we	,
/ TODO

In [1690]: np.count_nonzero(s)
Out[1690]: 9

/ we hebben I aangepast	,
/ op 9 plaatsen, waar s==True, wordt I vervangen door een random normal

In [1691]: I[s]
Out[1691]: 
array([ 8.34568351,  4.83935119, -3.52636745, -5.35291536, -0.0937313 ,
        0.05910876,  1.13977433, -0.6260776 , -5.00493529])
/ Dit zijn de random normals die op 9 plaatsen worden set in I	,

In [1693]: I
Out[1693]: 
array([[ 0.00000000e+00,  5.00000000e-01,  8.66025404e-01,
         1.00000000e+00,  8.66025404e-01,  8.34568351e+00	// 1ste ,
         1.22464680e-16],
       [ 4.83935119e+00 // 2de,  4.33012702e-01,  7.50000000e-01,
         8.66025404e-01,  7.50000000e-01,  4.33012702e-01,
        -3.52636745e+00 // 3de],
       [ 0.00000000e+00, -5.35291536e+00,  4.33012702e-01,
         5.00000000e-01, -9.37312983e-02,  5.91087556e-02,
         6.12323400e-17],
       [ 0.00000000e+00,  3.06161700e-17,  5.30287619e-17,
         6.12323400e-17,  5.30287619e-17,  3.06161700e-17,
         7.49879891e-33],
       [-0.00000000e+00, -2.50000000e-01, -4.33012702e-01,
        -5.00000000e-01, -4.33012702e-01,  1.13977433e+00,
        -6.12323400e-17],
       [-0.00000000e+00, -4.33012702e-01, -7.50000000e-01,
        -8.66025404e-01, -7.50000000e-01, -4.33012702e-01,
        -1.06057524e-16],
       [-0.00000000e+00, -5.00000000e-01, -6.26077597e-01,
        -1.00000000e+00, -5.00493529e+00, -5.00000000e-01,
        -1.22464680e-16]])

/ dan	,

In [1694]: plt.figure(figsize=(10,3.5))
Out[1694]: <Figure size 800x280 with 0 Axes>

/ 1 rij met subplots en 2 kolommen met subplots	, met nummers
1 2
/ dus 2 naast elkaar	,
In [1695]: plt.subplot(1,2,1)
Out[1695]: <matplotlib.axes._subplots.AxesSubplot at 0x7f74db2e6c50>

In [1696]: plt.imshow(I,cmap='RdBu')
Out[1696]: <matplotlib.image.AxesImage at 0x7f74db2a3da0>

In [1697]: cb=plt.colorbar()
/ we zien colorbar met 7.5 boven, en -4.5 onder	,

/ precies dezelfde komt er naast	,

In [1703]: plt.subplot(1,2,2)
Out[1703]: <matplotlib.axes._subplots.AxesSubplot at 0x7f74db090f98>

In [1704]: plt.imshow(I,cmap='RdBu')
Out[1704]: <matplotlib.image.AxesImage at 0x7f74dafce080>

In [1705]: plt.colorbar(extend='both')
Out[1705]: <matplotlib.colorbar.Colorbar at 0x7f74db00cef0>

/ nu veranderen we colorbar	,
In [1706]: plt.clim(-1,1)

/ 131313	.

/ we doen het nog een keer, maar nu zoals in het boek	,

In [1753]: x=np.linspace(0,10,1000)
In [1754]: I=np.sin(x)*np.cos(x[:,np.newaxis])
In [1756]: I.shape
Out[1756]: (1000, 1000)

In [1757]:  s=np.random.random(I.shape)<.01
In [1758]: s
Out[1758]: 
array([[False, False, False, ..., False, False, False],
       [False, False, False, ..., False, False, False],
       [False, False, False, ..., False, False, False],
       ...,
       [False, False, False, ..., False, False, False],
       [False, False, False, ..., False, False, False],
       [False, False, False, ..., False, False, False]])
/ op willekeurige plaatsen is s==True	,

In [1759]: s.shape
Out[1759]: (1000, 1000)

In [1762]: I[s]=np.random.normal(0,3,np.count_nonzero(s))
/ Waar s==True, dus op een aantal willekeurige plaatsen, wordt I reset	,  
/ TODO hoe werkt deze assignment?

In [1763]: np.count_nonzero(s)
Out[1763]: 9926

In [1781]: plt.figure(figsize=(10,3.5))
Out[1781]: <Figure size 800x280 with 0 Axes>

In [1782]: plt.imshow(I,cmap='RdBu')
Out[1782]: <matplotlib.image.AxesImage at 0x7f74da65d668>

In [1783]: plt.figure(figsize=(10,3.5))
Out[1783]: <Figure size 800x280 with 0 Axes>

In [1784]: plt.subplot(1,2,1)
Out[1784]: <matplotlib.axes._subplots.AxesSubplot at 0x7f74da7b86a0>

In [1785]: plt.imshow(I,cmap='RdBu')
Out[1785]: <matplotlib.image.AxesImage at 0x7f74da4c9128>

In [1786]: cb=plt.colorbar()

In [1787]: plt.subplot(1,2,2)
Out[1787]: <matplotlib.axes._subplots.AxesSubplot at 0x7f74dc00d198>

In [1788]: plt.imshow(I,cmap='RdBu')
Out[1788]: <matplotlib.image.AxesImage at 0x7f74da466eb8>

In [1789]: cb=plt.colorbar(extend='both')

In [1790]: plt.clim(-1,1)

/ de min en max van de colorbar zijn +10	, deze zijn zo groot vanwege die hoge values van de I[s], waar s==True, dus de values van I die we hebben reset op een aantal willekeurige plaatsen	,
/ daardoor vervagen de gewone values	,
/ als we de colorbar beperken tot de gewone values, zien we de gewone values, en we zien ook duidelijk die resetted values	,

/ 1313	.

/ (260)

/ met plt.cm.get_cmap discretized cm	, 

In [1910]: plt.imshow(I,cmap=plt.cm.get_cmap('Blues',6))
Out[1910]: <matplotlib.image.AxesImage at 0x7f74d999ceb8>

In [1911]: cb=plt.colorbar()

In [1912]: plt.clim(-1,1)

/ Einde VERVOLG (218) 

/ INTERMEZZOS (218-260)


/ Intermezzo

In [443]: s=np.linspace(0,1,3)

In [444]: t=np.linspace(0,1,2)

In [445]: S,T=np.meshgrid(s,t)
/ (S,T) zijn de punten van de grid	,

In [545]: s.shape
Out[545]: (3,)
In [546]: t.shape
Out[546]: (2,)
In [543]: S.shape
Out[543]: (2, 3)
In [544]: T.shape
Out[544]: (2, 3)

In [446]: S
Out[446]: 
array([[0. , 0.5, 1. ],
       [0. , 0.5, 1. ]])

In [447]: T
Out[447]: 
array([[0., 0., 0.],
       [1., 1., 1.]])

/ je kunt het assenstelsel zo denken	,

------X----------------->
|
|
|
V

/ Bij X	,
In [448]: S[0,1]
Out[448]: 0.5
In [449]: T[0,1]
Out[449]: 0.0

In [450]: def g(X,Y):
     ...:     return X+Y
     ...: 
     ...: 

In [451]: Z=g(S,T)

In [452]: Z
Out[452]: 
array([[0. , 0.5, 1. ],
       [1. , 1.5, 2. ]])




/ Einde Intermezzo

/ Intermezzo

/ ax.clear() verwijdert de plt.colorbar() niet	,

/ lees	,
cb=plt.colorbar()
retrieve an existing colorbar, that you can do following (and upvoting :)) what I wrote here: How to retrieve colorbar instance from figure in matplotlib then:
cb.remove()
plt.draw() #update plot

/ we maken opnieuw een figure	, gooien de oude weg	,

In [482]: plt.figure()
Out[482]: <Figure size 640x480 with 0 Axes>

In [483]: plt.contourf(X,Y,Z,20,cmap='RdBu')
Out[483]: <matplotlib.contour.QuadContourSet at 0x7f74ecb3f978>

In [486]: ax=plt.gca()
In [487]: ax.clear()

In [488]: cb.remove()
/ OK	,



/ Einde Intermezzo

/ Intermezzo

/ hoe histogram remove?

/ lees,	
https://stackoverflow.com/questions/40409977/how-to-remove-an-histogram-in-matplotlib

In [753]: plt.figure()
Out[753]: <Figure size 640x480 with 0 Axes>

In [754]: n,bins,patches=plt.hist(data)

In [755]: n
Out[755]: array([  3.,  13.,  53., 153., 246., 268., 181.,  73.,   6.,   4.])

In [757]: bins
Out[757]: 
array([-3.51810949, -2.83168275, -2.14525602, -1.45882928, -0.77240254,
       -0.0859758 ,  0.60045093,  1.28687767,  1.97330441,  2.65973114,
        3.34615788])

In [758]: patches
Out[758]: <a list of 10 Patch objects>

In [759]: [patches[j].remove()for j in range(0,10)]
Out[759]: [None, None, None, None, None, None, None, None, None, None]



/ Einde Intermezzo

/ Intermezzo

/ np.random.randn(m,n,...): multivariate std normal 
/ np.random.normal(mean,std deviation,[m,n,...]) multivariate normal	,

In [774]:  np.random.normal(0,10,[3,2])
Out[774]: 
array([[ -0.17411929, -11.76259713],
       [ 11.43011533,  -4.74688145],
       [ -1.59337532,   3.2440845 ]])

In [776]: np.random.randn(3,2)
Out[776]: 
array([[-0.11063869, -0.74031519],
       [-0.14256102, -0.05293286],
       [-1.43573261,  1.25585549]])


/ Einde Intermezzo

/ Intermezzo

/ er zijn	,
In [836]: np.random.multinomial 
/ en	,
In [836]: np.random.multivariate_normal

/ 13	.

In [836]: np.random.multinomial?       
Docstring:
multinomial(n, pvals, size=None)

Draw samples from a multinomial distribution.

The multinomial distribution is a multivariate generalisation of the
binomial distribution.  Take an experiment with one of ``p``
possible outcomes.  An example of such an experiment is throwing a dice,
where the outcome can be 1 through 6.  Each sample drawn from the
distribution represents `n` such experiments.  Its values,
``X_i = [X_0, X_1, ..., X_p]``, represent the number of times the
outcome was ``i``.

Examples
--------

/ 1313	. 

Throw a dice 20 times:

>>> np.random.multinomial(20, [1/6.]*6, size=1)
array([[4, 1, 7, 5, 2, 1]])

It landed 4 times on 1, once on 2, etc.

Now, throw the dice 20 times, and 20 times again:

>>> np.random.multinomial(20, [1/6.]*6, size=2)
array([[3, 4, 3, 3, 4, 3],
       [2, 4, 3, 4, 0, 7]])

For the first run, we threw 3 times 1, 4 times 2, etc.  For the second,
we threw 2 times 1, 4 times 2, etc.

A loaded die is more likely to land on number 6:

>>> np.random.multinomial(100, [1/7.]*5 + [2/7.])
array([11, 16, 14, 17, 16, 26])

The probability inputs should be normalized. As an implementation
detail, the value of the last entry is ignored and assumed to take
up any leftover probability mass, but this should not be relied on.
A biased coin which has twice as much weight on one side as on the
other should be sampled like so:

>>> np.random.multinomial(100, [1.0 / 3, 2.0 / 3])  # RIGHT
array([38, 62])

not like:

>>> np.random.multinomial(100, [1.0, 2.0])  # WRONG
array([100,   0])

/ 1313	. 

In [861]: np.random.multinomial(20,[1/6.]*3,size=1)
Out[861]: array([[ 2,  3, 15]])
/ TODO

/ 13	. 

Examples
--------
>>> mean = (1, 2)
>>> cov = [[1, 0], [0, 1]]
>>> x = np.random.multivariate_normal(mean, cov, (3, 3))
>>> x.shape
(3, 3, 2)

In [872]: np.random.multivariate_normal((1,2),[[1,0],[0,1]],5)
Out[872]: 
array([[ 0.91466928,  0.76540984],
       [ 0.65410758,  1.65250609],
       [-1.27869496,  5.38348598],
       [ 0.21773535,  4.3413754 ],
       [ 0.19241578,  2.08104787]])
In [879]: np.random.multivariate_normal((1,2),[[1,0],[0,1]],5).shape
Out[879]: (5, 2)
/ 5 punten in R^2

In [873]: np.random.multivariate_normal((1,2,3),[[1,0,0],[0,1,0],[0,0,1]],5)
Out[873]: 
array([[1.04346417, 1.32483057, 3.34359017],
       [0.38881455, 2.02656605, 3.23606293],
       [1.78587395, 3.34359881, 1.31469663],
       [0.49650656, 2.95053688, 1.24051098],
       [0.56826108, 2.63156603, 2.33329515]])
In [878]: np.random.multivariate_normal((1,2,3),[[1,0,0],[0,1,0],[0,0,1]],5).shape
Out[878]: (5, 3)
/ 5 punten in R^3


In [875]: np.random.multivariate_normal((1,2,3),[[1,0,0],[0,1,0],[0,0,1]],(5,2))
Out[875]: 
array([[[ 0.68298909,  1.86168105,  3.43981972],
        [ 1.29693951,  0.42769673,  3.77776303]],

       [[ 2.70299758, -0.20952955,  4.15285632],
        [ 0.45626418,  2.00947633,  2.78132339]],

       [[ 0.90051612,  2.35840042,  2.02475056],
        [-0.23873974,  1.51447882,  4.56717637]],

       [[ 2.67487576,  3.15252763,  2.96376598],
        [ 2.09062571,  2.22803149,  4.7196364 ]],

       [[ 2.59391333, -1.34121145,  4.14036205],
        [ 0.62928683,  2.1424412 ,  4.06068084]]])
In [877]: np.random.multivariate_normal((1,2,3),[[1,0,0],[0,1,0],[0,0,1]],(5,2)).shape
Out[877]: (5, 2, 3)
/ (5,2) punten in R^3


/ Einde Intermezzo

/ Intermezzo

In [954]:  [[1,0],[0,1]]
Out[954]: [[1, 0], [0, 1]]

In [957]:  np.array([[1,0],[0,1]])
Out[957]: 
array([[1, 0],
       [0, 1]])

/ een np.array staat aut goed	, we hoeven geen reshape(2,2) te doen	,

/ Einde Intermezzo

/ Intermezzo

In [974]: xgrid=np.linspace(-3.5,3.5,11)

In [975]: ygrid=np.linspace(-6,6,11)

In [976]: xgrid
Out[976]: array([-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5])

In [977]: ygrid
Out[977]: array([-6. , -4.8, -3.6, -2.4, -1.2,  0. ,  1.2,  2.4,  3.6,  4.8,  6. ])

In [978]: Tgrid=np.meshgrid(xgrid,ygrid)

In [979]: Tgrid
Out[979]: 
[array([[-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
        [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
        [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
        [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
        [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
        [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
        [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
        [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
        [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
        [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
        [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5]]),
 array([[-6. , -6. , -6. , -6. , -6. , -6. , -6. , -6. , -6. , -6. , -6. ],
        [-4.8, -4.8, -4.8, -4.8, -4.8, -4.8, -4.8, -4.8, -4.8, -4.8, -4.8],
        [-3.6, -3.6, -3.6, -3.6, -3.6, -3.6, -3.6, -3.6, -3.6, -3.6, -3.6],
        [-2.4, -2.4, -2.4, -2.4, -2.4, -2.4, -2.4, -2.4, -2.4, -2.4, -2.4],
        [-1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2],
        [ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ],
        [ 1.2,  1.2,  1.2,  1.2,  1.2,  1.2,  1.2,  1.2,  1.2,  1.2,  1.2],
        [ 2.4,  2.4,  2.4,  2.4,  2.4,  2.4,  2.4,  2.4,  2.4,  2.4,  2.4],
        [ 3.6,  3.6,  3.6,  3.6,  3.6,  3.6,  3.6,  3.6,  3.6,  3.6,  3.6],
        [ 4.8,  4.8,  4.8,  4.8,  4.8,  4.8,  4.8,  4.8,  4.8,  4.8,  4.8],
        [ 6. ,  6. ,  6. ,  6. ,  6. ,  6. ,  6. ,  6. ,  6. ,  6. ,  6. ]])]

In [980]: Xgrid,Ygrid=Tgrid

In [981]: Xgrid
Out[981]: 
array([[-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
       [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
       [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
       [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
       [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
       [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
       [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
       [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
       [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
       [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5],
       [-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5]])

In [982]: Ygrid
Out[982]: 
array([[-6. , -6. , -6. , -6. , -6. , -6. , -6. , -6. , -6. , -6. , -6. ],
       [-4.8, -4.8, -4.8, -4.8, -4.8, -4.8, -4.8, -4.8, -4.8, -4.8, -4.8],
       [-3.6, -3.6, -3.6, -3.6, -3.6, -3.6, -3.6, -3.6, -3.6, -3.6, -3.6],
       [-2.4, -2.4, -2.4, -2.4, -2.4, -2.4, -2.4, -2.4, -2.4, -2.4, -2.4],
       [-1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2],
       [ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ],
       [ 1.2,  1.2,  1.2,  1.2,  1.2,  1.2,  1.2,  1.2,  1.2,  1.2,  1.2],
       [ 2.4,  2.4,  2.4,  2.4,  2.4,  2.4,  2.4,  2.4,  2.4,  2.4,  2.4],
       [ 3.6,  3.6,  3.6,  3.6,  3.6,  3.6,  3.6,  3.6,  3.6,  3.6,  3.6],
       [ 4.8,  4.8,  4.8,  4.8,  4.8,  4.8,  4.8,  4.8,  4.8,  4.8,  4.8],
       [ 6. ,  6. ,  6. ,  6. ,  6. ,  6. ,  6. ,  6. ,  6. ,  6. ,  6. ]])

In [988]: Xgrid.ravel()
Out[988]: 
array([-3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5,
       -3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5,
       -3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5,
       -3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5,
       -3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5,
       -3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5,
       -3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5,
       -3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5,
       -3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5,
       -3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5,
       -3.5, -2.8, -2.1, -1.4, -0.7,  0. ,  0.7,  1.4,  2.1,  2.8,  3.5])

In [989]: Ygrid.ravel()
Out[989]: 
array([-6. , -6. , -6. , -6. , -6. , -6. , -6. , -6. , -6. , -6. , -6. ,
       -4.8, -4.8, -4.8, -4.8, -4.8, -4.8, -4.8, -4.8, -4.8, -4.8, -4.8,
       -3.6, -3.6, -3.6, -3.6, -3.6, -3.6, -3.6, -3.6, -3.6, -3.6, -3.6,
       -2.4, -2.4, -2.4, -2.4, -2.4, -2.4, -2.4, -2.4, -2.4, -2.4, -2.4,
       -1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2,
        0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,
        1.2,  1.2,  1.2,  1.2,  1.2,  1.2,  1.2,  1.2,  1.2,  1.2,  1.2,
        2.4,  2.4,  2.4,  2.4,  2.4,  2.4,  2.4,  2.4,  2.4,  2.4,  2.4,
        3.6,  3.6,  3.6,  3.6,  3.6,  3.6,  3.6,  3.6,  3.6,  3.6,  3.6,
        4.8,  4.8,  4.8,  4.8,  4.8,  4.8,  4.8,  4.8,  4.8,  4.8,  4.8,
        6. ,  6. ,  6. ,  6. ,  6. ,  6. ,  6. ,  6. ,  6. ,  6. ,  6. ])




/ Einde Intermezzo

/ Intermezzo

In [1167]: popul.describe()
Out[1167]: 
count    4.820000e+02
mean     6.489493e+04
std      2.032041e+05
min      1.000000e+00
25%      1.090200e+04
50%      2.905750e+04
75%      6.646650e+04
max      3.884307e+06
Name: population_total, dtype: float64

/ hoe voorkomen we de e-notatie?

/ google,
series describe how not in scientific notation
/ lees	,
https://stackoverflow.com/questions/21137150/format-suppress-scientific-notation-from-python-pandas-aggregation-results


/ Einde Intermezzo

/ Intermezzo

/ bij fancy indexing, hoe combine conditions?

/ de conditions moeten tussen () 	, en & ertussen	,

In [1165]: (np.log10(popul)>0.0) & (np.log10(popul)<3.0)
Out[1165]: 
0      False
1      False
2      False
...

In [1166]: popul[(np.log10(popul)>0.0) & (np.log10(popul)<3.0)]
Out[1166]: 
7      185
114    939
132    737
144    839
190    219
195    804
242    769
326    449
366    334
428    418
435    367
448    112
Name: population_total, dtype: int64

/ we moeten de conditions tussen (), anders gaat hij 0.0 & np.log10(popul) of zoiets	,


/ Einde Intermezzo

/ Intermezzo


/ lees	,
https://docs.scipy.org/doc/numpy-1.15.0/reference/routines.linalg.html

/ 13	 

/ np.dot	,
/ gewone matrix verm	,

/ 1313	. 

In [1331]: a=np.array([[1,2,3],[3,2,1]])
In [1332]: a.shape
Out[1332]: (2, 3)

In [1333]: np.dot(a,[10,20,30])
Out[1333]: array([140, 100])

/ 1313	. 

In [1334]: b=np.array([10,20,30])
In [1336]: b.shape
Out[1336]: (3,)

In [1335]: np.dot(a,b)
Out[1335]: array([140, 100])

/ 1313	. 

In [1337]: b2=b.reshape(1,3)
In [1338]: b2
Out[1338]: array([[10, 20, 30]])
In [1339]: b2.shape
Out[1339]: (1, 3)

In [1340]: np.dot(a,b2)
/ ERR	,

/ 1313	. 

In [1341]: b2=b.reshape(3,1)

In [1342]: b2
Out[1342]: 
array([[10],
       [20],
       [30]])

In [1343]: np.dot(a,b2)
Out[1343]: 
array([[140],
       [100]])

/ 13	. 

In [1359]: a=np.array([1,2,3])
In [1362]: b=np.array([10,20,30])

In [1376]: ac=a.reshape(3,1)
In [1378]: ar=a.reshape(1,3)
In [1379]: bc=b.reshape(3,1)
In [1377]: br=b.reshape(1,3)

In [1380]: np.dot(ac,br)
Out[1380]: 
array([[10, 20, 30],
       [20, 40, 60],
       [30, 60, 90]])

In [1382]: np.dot(ar,bc)
Out[1382]: array([[140]])

In [1381]: np.dot(ac,bc)
ValueError: shapes (3,1) and (3,1) not aligned: 1 (dim 1) != 3 (dim 0)

In [1383]: np.dot(ar,br)
ValueError: shapes (1,3) and (1,3) not aligned: 3 (dim 1) != 1 (dim 0)


/ 13	. 

In [1392]: l=[10,20,30]

In [1405]: a=np.array(l)
/ we kunnen a ipv l doen	,

/ een list of (m,) numpy array rechts wordt als staand gezien	,
/ dus links moet een rij zijn, of dat nou ar of br is	,
/ een (m,n) np array ligt vast	, 

In [1385]:  np.dot(ar,l)
Out[1385]: array([140])

In [1384]:  np.dot(ac,l)
ValueError: shapes (3,1) and (3,) not aligned: 1 (dim 1) != 3 (dim 0)

In [1397]: np.dot(br,l)
Out[1397]: array([1400])

In [1398]: np.dot(bc,l)
ValueError: shapes (3,1) and (3,) not aligned: 1 (dim 1) != 3 (dim 0)



/ 13	. 

/ een list of (m,) numpy array links wordt als liggend gezien	,
/ dus rechts moet een kolom zijn	, of dat nou ac of bc is	,
/ een (m,n) numpy array ligt vast	,

In [1388]: np.dot(l,bc)
Out[1399]: array([1400])

In [1400]: np.dot(l,br)
ValueError: shapes (3,) and (1,3) not aligned: 3 (dim 0) != 1 (dim 0)

In [1403]: np.dot(l,ac)
Out[1403]: array([140])

In [1404]: np.dot(l,ar)
ValueError: shapes (3,) and (1,3) not aligned: 3 (dim 0) != 1 (dim 0)

/ 13	. 

/ np.dot	,

/ een (m,n) np.array ligt vast	, kan niet liggend of staand worden gezien	,

In [1504]: p=np.array([1,2,3,4,5,6]).reshape(3,2)

In [1505]: p
Out[1505]: 
array([[1, 2],
       [3, 4],
       [5, 6]])

In [1506]: np.dot(p,[1,2])
Out[1506]: array([ 5, 11, 17])

In [1507]: np.dot(p,np.array([1,2]))
Out[1507]: array([ 5, 11, 17])

In [1508]: np.dot([1,2],p)
ValueError: shapes (2,) and (3,2) not aligned: 2 (dim 0) != 3 (dim 0)

/ dus rechts wordt p geen (2,3)	,


/ 13	. 

/ herhaling np.dot	,	

In [1416]: l=[10,20,30]
In [1417]: m=[30,20,10]

In [1418]: np.dot(l,m)
Out[1418]: 1000
/ klopt	, een list links of een (m,) np array wordt liggend gezien, en rechts staand	,

In [1419]: np.dot(ac,ar)
Out[1419]: 
array([[1, 2, 3],
       [2, 4, 6],
       [3, 6, 9]])

In [1420]: np.dot(ar,ac)
Out[1420]: array([[14]])

/ 13	. 

/ np.inner	,

In [1444]: l=[1,2,3]

In [1445]: a=np.array(l)

In [1450]: ar=a.reshape(1,3)
In [1452]: ac=a.reshape(3,1)

In [1446]: r=np.array([1,2,3,4]).reshape(2,2)
In [1454]: r
Out[1454]: 
array([[1, 2],
       [3, 4]])

In [1464]: np.inner(l,l)
Out[1464]: 14

In [1465]: np.inner(a,a)
Out[1465]: 14

In [1466]: np.inner(r,r)
Out[1466]: 
array([[ 5, 11],
       [11, 25]])
/ inproduct rijen onderling (of columns TODO)	, 1ste rij * 1ste rij, 1ste rij * 2de rij, 2de rij * 2de rij	,

In [1467]: np.inner(ac,ar)
ValueError: shapes (3,1) and (3,1) not aligned: 1 (dim 1) != 3 (dim 0)

In [1468]: np.inner(ac,ac)
Out[1468]: 
array([[1, 2, 3],
       [2, 4, 6],
       [3, 6, 9]])

In [1469]: np.inner(ar,ar)
Out[1469]: array([[14]])

In [1470]: np.inner(ar,ac)
ValueError: shapes (1,3) and (1,3) not aligned: 3 (dim 1) != 1 (dim 0)

In [1433]: np.inner?
Notes
-----
For vectors (1-D arrays) it computes the ordinary inner-product::

    np.inner(a, b) = sum(a[:]*b[:])

More generally, if `ndim(a) = r > 0` and `ndim(b) = s > 0`::

    np.inner(a, b) = np.tensordot(a, b, axes=(-1,-1))

or explicitly::

    np.inner(a, b)[i0,...,ir-1,j0,...,js-1]
         = sum(a[i0,...,ir-1,:]*b[j0,...,js-1,:])

In addition `a` or `b` may be scalars, in which case::

   np.inner(a,b) = a*b

Examples
--------
Ordinary inner product for vectors:

>>> a = np.array([1,2,3])
>>> b = np.array([0,1,0])
>>> np.inner(a, b)
2

A multidimensional example:

>>> a = np.arange(24).reshape((2,3,4))
>>> b = np.arange(4)
>>> np.inner(a, b)
array([[ 14,  38,  62],
       [ 86, 110, 134]])

An example where `b` is a scalar:

>>> np.inner(np.eye(2), 7)
array([[ 7.,  0.],
       [ 0.,  7.]])

/ 13	. 

/ np.vdot	,

In [1444]: l=[1,2,3]

In [1445]: a=np.array(l)

In [1450]: ar=a.reshape(1,3)
In [1452]: ac=a.reshape(3,1)

In [1446]: r=np.array([1,2,3,4]).reshape(2,2)
In [1454]: r
Out[1454]: 
array([[1, 2],
       [3, 4]])

In [1447]: np.vdot(l,l)
Out[1447]: 14

In [1455]: np.vdot(a,a)
Out[1455]: 14

In [1457]: np.dot(r,r)
Out[1457]: 
array([[ 7, 10],
       [15, 22]])
/ klopt	,

In [1456]: np.vdot(r,r)
Out[1456]: 30
/ dat is verm corresponderende elems	, en optellen	,

In [1458]: np.dot(ar,ac)
Out[1458]: array([[14]])

In [1459]: np.dot(ac,ar)
Out[1459]: 
array([[1, 2, 3],
       [2, 4, 6],
       [3, 6, 9]])

In [1460]: np.vdot(ar,ac)
Out[1460]: 14

In [1461]: np.vdot(ac,ar)
Out[1461]: 14

/ maar deze kunnen nu ook	,
In [1463]: np.vdot(ac,ac)
Out[1463]: 14
/ terwijl	,
In [1462]: np.dot(ac,ac)
ValueError: shapes (3,1) and (3,1) not aligned: 1 (dim 1) != 3 (dim 0)

/ 13	. 

In [1444]: l=[1,2,3]

In [1445]: a=np.array(l)

In [1450]: ar=a.reshape(1,3)
In [1452]: ac=a.reshape(3,1)

In [1446]: r=np.array([1,2,3,4]).reshape(2,2)
In [1454]: r
Out[1454]: 
array([[1, 2],
       [3, 4]])

In [1471]: np.outer(l,l)
Out[1471]: 
array([[1, 2, 3],
       [2, 4, 6],
       [3, 6, 9]])

In [1472]: np.outer(a,a)
Out[1472]: 
array([[1, 2, 3],
       [2, 4, 6],
       [3, 6, 9]])

In [1473]: np.outer(r,r)
Out[1473]: 
array([[ 1,  2,  3,  4],
       [ 2,  4,  6,  8],
       [ 3,  6,  9, 12],
       [ 4,  8, 12, 16]])

In [1474]: np.outer(ac,ac)
/=
In [1475]: np.outer(ar,ar)
/=
In [1475]: np.outer(ac,ar)
/=
In [1475]: np.outer(ar,ac)
Out[1474]: 
array([[1, 2, 3],
       [2, 4, 6],
       [3, 6, 9]])

/ 13	.

/ np.tensordot	,

In [1482]: np.tensordot(l,l)
IndexError: tuple index out of range

In [1483]: np.tensordot(a,a)
IndexError: tuple index out of range

In [1484]: np.tensordot(r,r)
Out[1484]: array(30)

In [1485]: np.tensordot(ac,ac)
Out[1485]: array(14)

In [1488]: np.tensordot(ar,ar)
Out[1488]: array(14)

In [1486]: np.tensordot(ac,ar)
ValueError: shape-mismatch for sum

In [1487]: np.tensordot(ar,ac)
ValueError: shape-mismatch for sum

/ Einde Intermezzo

/ Intermezzo

/ 13	. 

/ * of np.dot	?

In [1588]: x=np.linspace(0,np.pi,3)
In [1589]: x
Out[1589]: array([0.        , 1.57079633, 3.14159265])

In [1592]: np.cos(x[:,np.newaxis])*np.sin(x)
Out[1592]: 
array([[ 0.00000000e+00,  1.00000000e+00,  1.22464680e-16],
       [ 0.00000000e+00,  6.12323400e-17,  7.49879891e-33],
       [-0.00000000e+00, -1.00000000e+00, -1.22464680e-16]])

n [1598]: np.dot(np.cos(x[:,np.newaxis]).reshape(3,1),np.sin(x).reshape(1,3))
Out[1598]: 
array([[ 0.00000000e+00,  1.00000000e+00,  1.22464680e-16],
       [ 0.00000000e+00,  6.12323400e-17,  7.49879891e-33],
       [-0.00000000e+00, -1.00000000e+00, -1.22464680e-16]])

/ of met 	,

In [1603]: y=np.linspace(0,np.pi,7)

In [1604]: y
Out[1604]: 
array([0.        , 0.52359878, 1.04719755, 1.57079633, 2.0943951 ,
       2.61799388, 3.14159265])


In [1608]: np.cos(x[:,np.newaxis])*np.sin(y)
/=
In [1609]: np.sin(y)*np.cos(x[:,np.newaxis])
/=
In [1610]: np.dot(np.cos(x[:,np.newaxis]).reshape(3,1),np.sin(y).reshape(1,7))
Out[1610]: 
array([[ 0.00000000e+00,  5.00000000e-01,  8.66025404e-01,
         1.00000000e+00,  8.66025404e-01,  5.00000000e-01,
         1.22464680e-16],
       [ 0.00000000e+00,  3.06161700e-17,  5.30287619e-17,
         6.12323400e-17,  5.30287619e-17,  3.06161700e-17,
         7.49879891e-33],
       [-0.00000000e+00, -5.00000000e-01, -8.66025404e-01,
        -1.00000000e+00, -8.66025404e-01, -5.00000000e-01,
        -1.22464680e-16]])




/ Einde Intermezzo

/ Intermezzo

/ normal	,

In [1648]: I[s]=np.random.normal(0,3,np.count_nonzero(s))

In [1649]: I
Out[1649]: 
array([[-1.66106083e+00,  5.00000000e-01, -4.33527529e+00,
         7.13153425e+00,  2.15194476e+00, -7.39196756e-01,
         1.22464680e-16],
       [ 0.00000000e+00,  2.87136634e+00,  7.50000000e-01,
         8.66025404e-01,  7.50000000e-01,  1.57256784e+00,
         1.06057524e-16],
       [ 6.28490357e+00,  2.50000000e-01,  4.33012702e-01,
         5.65317237e+00,  4.33012702e-01,  9.50543966e-01,
         6.12323400e-17],
       [-1.69064212e-01,  3.06161700e-17,  5.30287619e-17,
         2.81248306e+00, -7.92056485e-01, -2.93068731e-01,
         7.49879891e-33],
       [-0.00000000e+00, -3.86332205e-01, -4.33012702e-01,
        -1.01820736e+00, -4.33012702e-01,  1.23471301e+00,
        -6.12323400e-17],
       [-2.20713220e+00, -7.95683331e-01, -7.50000000e-01,
        -8.66025404e-01, -7.50000000e-01, -4.33012702e-01,
         7.58807250e-01],
       [ 2.99342746e+00,  4.24979463e+00, -8.66025404e-01,
         4.37471948e+00, -1.51358264e+00, -1.58623093e-02,
        -1.22464680e-16]])

xamples
--------
Draw samples from the distribution:

>>> mu, sigma = 0, 0.1 # mean and standard deviation
>>> s = np.random.normal(mu, sigma, 1000)

Verify the mean and the variance:

>>> abs(mu - np.mean(s)) < 0.01
True

>>> abs(sigma - np.std(s, ddof=1)) < 0.01
True

Display the histogram of the samples, along with
the probability density function:

>>> import matplotlib.pyplot as plt
>>> count, bins, ignored = plt.hist(s, 30, normed=True)
>>> plt.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) *
...                np.exp( - (bins - mu)**2 / (2 * sigma**2) ),
...          linewidth=2, color='r')
>>> plt.show()



/ Einde Intermezzo

/ Intermezzo

In [1729]: plt.subplot(431)
Out[1729]: <matplotlib.axes._subplots.AxesSubplot at 0x7f74db9af668>

In [1730]: plt.subplot(432)
Out[1730]: <matplotlib.axes._subplots.AxesSubplot at 0x7f74db9af780>

In [1731]: plt.subplot(433)
Out[1731]: <matplotlib.axes._subplots.AxesSubplot at 0x7f74dbab5b38>

In [1732]: plt.subplot(434)
Out[1732]: <matplotlib.axes._subplots.AxesSubplot at 0x7f74dba16d68>

In [1734]: plt.subplot(435)
Out[1734]: <matplotlib.axes._subplots.AxesSubplot at 0x7f74dbb50b38>

In [1735]: plt.subplot(437)
Out[1735]: <matplotlib.axes._subplots.AxesSubplot at 0x7f74db926dd8>

In [1736]: plt.subplot(4,3,12)
Out[1736]: <matplotlib.axes._subplots.AxesSubplot at 0x7f74dad39898>

/ er zijn 4 rijen met subplots	, en 3 kolommen	,
/ het laatste getal is het nummer van de subplot	,
/ als we de nummers tekenen:
1 2 3
4 5 6
7 8 9 
101112


/ Einde Intermezzo

/ Intermezzo

/ wat zijn de values op de colorbar?

/ see (236),

/ 13	. 

/ 1313	. 

In [1791]: rnd=np.random.RandomState(0)

In [1792]: rng=rnd

In [1793]: x=rng.randn(100)

In [1794]: y=rng.randn(100)

In [1795]: colors=rng.randn(100)

In [1797]: sizes=1000*rng.randn(100)

In [1808]: colors.max()
Out[1808]: 2.303916697683942

In [1805]: sc=plt.scatter(x,y,c=colors,s=sizes,alpha=0.3,cmap='viridis')
In [1806]: cb=plt.colorbar()
/ we zien in de colorbar inderdaad ongeveer 2 als max	, 

/ 1313	. 

In [1809]: colors=1000*rng.randn(100)
In [1813]: colors.max()
Out[1813]: 2696.22405256358

In [1810]: sc=plt.scatter(x,y,c=colors,s=sizes,alpha=0.3,cmap='viridis')
In [1812]: cb=plt.colorbar()

/ nu zien we inderdaad op de colorbar max iets van 2500	, 

/ 13	. 

/ (243)

/ 1313	,

In [1815]: x=np.linspace(0,5,50)

In [1816]: y=np.linspace(0,5,40)

In [1817]: X,Y=np.meshgrid(x,y)

In [1818]: T=np.meshgrid(x,y)
In [1819]: X,Y=T

In [1826]: def f(x,y):
      ...:     return np.sin(x)**10+np.cos(10+y*x)*np.cos(x)
      ...: 
      ...: 
In [1827]: Z=f(X,Y)
In [1828]: ct=plt.contour(X,Y,Z,colors='black')
In [1829]: cb=plt.colorbar()
In [1837]: l=cb.ax.get_yticklabels()
In [1839]: [x for x in l]
Out[1839]: 
[Text(1,0,'−0.9'),
 Text(1,0.166667,'−0.6'),
 Text(1,0.333333,'−0.3'),
 Text(1,0.5,'0.0'),
 Text(1,0.666667,'0.3'),
 Text(1,0.833333,'0.6'),
 Text(1,1,'0.9')]
In [1841]: [x.get_text() for x in l]
Out[1841]: ['−0.9', '−0.6', '−0.3', '0.0', '0.3', '0.6', '0.9']

/ 1313	,

In [1848]: ct=plt.contour(X,Y,Z,cmap='RdGy')

In [1849]: cb.remove()

In [1850]: cb=plt.colorbar()

In [1851]: l=cb.ax.get_yticklabels()

In [1852]: [x.get_text() for x in l]
Out[1852]: ['−0.9', '−0.6', '−0.3', '0.0', '0.3', '0.6', '0.9']

/ 1313	. 

In [1842]: ctf= plt.contourf(X,Y,Z,20,cmap='RdGy')
In [1843]: cb.remove()
In [1844]: cb=plt.colorbar()
In [1846]: l=cb.ax.get_yticklabels()
In [1847]: [x.get_text() for x in l]
Out[1847]: ['−0.9', '−0.6', '−0.3', '0.0', '0.3', '0.6', '0.9']

/ lees	,
https://stackoverflow.com/questions/45508036/get-tick-values-of-colorbar-in-matplotlib

/ met nieuwe fct grote colorbar values	, 
/ met 'RdGy'	, 
/ probeer ook met 'black'

/ 1313	. 

In [1815]: x=np.linspace(0,5,50)

In [1816]: y=np.linspace(0,5,40)

In [1817]: X,Y=np.meshgrid(x,y)


In [1868]: x
Out[1868]: 
array([0.        , 0.10204082, 0.20408163, 0.30612245, 0.40816327,
       0.51020408, 0.6122449 , 0.71428571, 0.81632653, 0.91836735,
       1.02040816, 1.12244898, 1.2244898 , 1.32653061, 1.42857143,
       1.53061224, 1.63265306, 1.73469388, 1.83673469, 1.93877551,
       2.04081633, 2.14285714, 2.24489796, 2.34693878, 2.44897959,
       2.55102041, 2.65306122, 2.75510204, 2.85714286, 2.95918367,
       3.06122449, 3.16326531, 3.26530612, 3.36734694, 3.46938776,
       3.57142857, 3.67346939, 3.7755102 , 3.87755102, 3.97959184,
       4.08163265, 4.18367347, 4.28571429, 4.3877551 , 4.48979592,
       4.59183673, 4.69387755, 4.79591837, 4.89795918, 5.        ])

In [1869]:  y
Out[1869]: 
array([0.        , 0.12820513, 0.25641026, 0.38461538, 0.51282051,
       0.64102564, 0.76923077, 0.8974359 , 1.02564103, 1.15384615,
       1.28205128, 1.41025641, 1.53846154, 1.66666667, 1.79487179,
       1.92307692, 2.05128205, 2.17948718, 2.30769231, 2.43589744,
       2.56410256, 2.69230769, 2.82051282, 2.94871795, 3.07692308,
       3.20512821, 3.33333333, 3.46153846, 3.58974359, 3.71794872,
       3.84615385, 3.97435897, 4.1025641 , 4.23076923, 4.35897436,
       4.48717949, 4.61538462, 4.74358974, 4.87179487, 5.        ])




/ nu nemen we een fct die grote values heeft	,

In [1853]: def f(x,y):
      ...:     return 1000*x*y
      ...: 
      ...: 

X,Y=np.meshgrid(x,y)

In [1854]: Z=f(X,Y)

In [1855]: Z
Out[1855]: 
array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
       [0.00000000e+00, 1.30821559e+01, 2.61643119e+01, ...,
        6.14861329e+02, 6.27943485e+02, 6.41025641e+02],
       [0.00000000e+00, 2.61643119e+01, 5.23286238e+01, ...,
        1.22972266e+03, 1.25588697e+03, 1.28205128e+03],
       ...,
       [0.00000000e+00, 4.84039770e+02, 9.68079540e+02, ...,
        2.27498692e+04, 2.32339089e+04, 2.37179487e+04],
       [0.00000000e+00, 4.97121926e+02, 9.94243851e+02, ...,
        2.33647305e+04, 2.38618524e+04, 2.43589744e+04],
       [0.00000000e+00, 5.10204082e+02, 1.02040816e+03, ...,
        2.39795918e+04, 2.44897959e+04, 2.50000000e+04]])

In [1863]: Z.max()
Out[1863]: 25000.0

In [1864]: ct=plt.contour(X,Y,Z,cmap='RdGy')

In [1865]: cb=plt.colorbar()

In [1866]: l=cb.ax.get_yticklabels()

In [1867]: [x.get_text() for x in l]
Out[1867]: ['4000', '8000', '12000', '16000', '20000', '24000']

/ Dit ziet er wel mooi uit, met hyperbolen als contouren	, 



/ Einde Intermezzo

/ Intermezzo

/ np.meshgrid en fcts	,

In [1885]: s=np.array([1,2,3])
In [1886]: t=np.array([11,12,13,14])
In [1890]: S,T=np.meshgrid(s,t)
In [1891]: S
Out[1891]: 
array([[1, 2, 3],
       [1, 2, 3],
       [1, 2, 3],
       [1, 2, 3]])

In [1892]: T
Out[1892]: 
array([[11, 11, 11],
       [12, 12, 12],
       [13, 13, 13],
       [14, 14, 14]])

/ S,T zijn de paren van values op de hor en vert. as,	
/ bijv	,

In [1908]: S[1,2]
Out[1908]: 3
In [1909]: T[1,2]
Out[1909]: 12

In [1896]: def fct(x,y):
      ...:     return x*y
      ...: 
      ...: 
In [1902]: fct(S,T)
Out[1902]: 
array([[11, 22, 33],
       [12, 24, 36],
       [13, 26, 39],
       [14, 28, 42]])




/ Einde Intermezzo

/ Einde INTERMEZZOS (218-260)

/ VERVOLG (261)

/ (261)

In [1913]: from sklearn.datasets import load_digits

In [1914]: digits=load_digits(n_class=6)

In [1915]: fig,ax=plt.subplots(8,8,figsize=(6,6))

In [1916]: fig,ax=plt.subplots(8,8,figsize=(6,6))

In [1917]: for i,axi in enumerate(ax.flat):
      ...:     axi.imshow(digits.images[i],cmap='binary')
      ...:     axi.set(xticks=[],yticks=[])
      ...:     

/ een digit bestaat uit 64 pixels (er zijn toevallig ook 64 digits)	, en een digit is dus een punt in een 64-dim ruimte: elke dim is de brightness of 1 pixel	,



